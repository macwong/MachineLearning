{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\n",
    "# Model 2: https://www.kaggle.com/vincento/keras-starter-4l-0-1694-lb-icebergchallenge\n",
    "# Model 3: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193\n",
    "# Model 4: https://www.kaggle.com/wvadim/keras-tf-lb-0-18\n",
    "\n",
    "# ResNet50\n",
    "# InceptionV3\n",
    "# MobileNet\n",
    "# DenseNet\n",
    "# SqueezeNet\n",
    "# InceptionResNetV2\n",
    "# Xception\n",
    "\n",
    "# Simple model: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "# https://www.kaggle.com/henokanh/cnn-batchnormalization-0-1646\n",
    "# https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "# https://www.kaggle.com/cttsai/ensembling-gbms-lb-203/code\n",
    "# https://www.kaggle.com/yuhaichina/single-model-vgg16-mobilenet-lb-0-1568-with-tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "import abc\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers():\n",
    "    def get_angledata(train, test):\n",
    "        train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "        train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "        test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "\n",
    "        X_angle=train['inc_angle']\n",
    "        X_test_angle=test['inc_angle']\n",
    "        \n",
    "        return X_angle, X_test_angle\n",
    "    \n",
    "    def get_imagedata(data):\n",
    "        X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_1\"]])\n",
    "        X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_2\"]])\n",
    "        X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "        X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "        X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "        X_data = np.concatenate([X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "        return X_data\n",
    "    \n",
    "    def get_generator():\n",
    "        # Define the image transformations here\n",
    "        return ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10)\n",
    "    \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_two_inputs(X1, X2, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "        while True:\n",
    "                X1i = genX1.next()\n",
    "                X2i = genX2.next()\n",
    "                #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "                #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "                yield [X1i[0], X2i[1]], X1i[1]\n",
    "                \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_one_input(X1, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        return genX1\n",
    "                \n",
    "\n",
    "    # Finally create generator\n",
    "    def get_callbacks(filepath, patience=2):\n",
    "        es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "        msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "        return [es, msave, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelBase():\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    def __init__(self, ids = None):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 100\n",
    "        self.ids = ids\n",
    "        self.predictions = None\n",
    "        self.K = 5\n",
    "        \n",
    "        self.model = self.get_model()\n",
    "        \n",
    "    def save_model(self):\n",
    "        name = self.get_name() + datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S') + \".h5\"\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "    def create_submission(self, predict):\n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test['id']\n",
    "        submission['is_iceberg']=preds\n",
    "        submission.to_csv(\"submission-\" + self.get_name() + \".csv\", float_format='%g', index = False)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    #Using K-fold Cross Validation with Data Augmentation.\n",
    "    def train_predict(self, X_train, X_angle, X_test, target_train):\n",
    "        folds = list(StratifiedKFold(n_splits=self.K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "        y_test_pred_log = 0\n",
    "        y_train_pred_log=0\n",
    "        y_valid_pred_log = 0.0*target_train\n",
    "        for j, (train_idx, test_idx) in enumerate(folds):\n",
    "            print('\\n===================FOLD=',j)\n",
    "            X_train_cv = X_train[train_idx]\n",
    "            y_train_cv = target_train[train_idx]\n",
    "            X_holdout = X_train[test_idx]\n",
    "            Y_holdout= target_train[test_idx]\n",
    "\n",
    "            #Angle\n",
    "            X_angle_cv=X_angle[train_idx]\n",
    "            X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "            #define file path and get callbacks\n",
    "            file_path = \"%s_\"%j + self.get_name() + \".hdf5\"\n",
    "            callbacks = Helpers.get_callbacks(filepath=file_path, patience=5)\n",
    "            gen_flow = Helpers.gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "            \n",
    "            galaxyModel= self.get_model()\n",
    "            \n",
    "            input_shape = len(galaxyModel.model.input_shape)\n",
    "            train_array = [X_train,X_angle]\n",
    "            train_array_cv = [X_train_cv,X_angle_cv]\n",
    "            holdout_array = [X_holdout,X_angle_hold]\n",
    "            test_array = [X_test, X_test_angle]\n",
    "            \n",
    "            if input_shape != 2:\n",
    "                train_array = X_train\n",
    "                train_array_cv = X_train_cv\n",
    "                holdout_array = X_holdout\n",
    "                test_array = X_test\n",
    "                gen_flow = Helpers.gen_flow_for_one_input(X_train_cv, y_train_cv)\n",
    "                \n",
    "            galaxyModel.fit_generator(\n",
    "                    gen_flow,\n",
    "                    steps_per_epoch=24,\n",
    "                    epochs=self.epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=(holdout_array, Y_holdout),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "            #Getting the Best Model\n",
    "            galaxyModel.load_weights(filepath=file_path)\n",
    "            #Getting Training Score\n",
    "            score = galaxyModel.evaluate(train_array_cv, y_train_cv, verbose=0)\n",
    "            print('Train loss:', score[0])\n",
    "            print('Train accuracy:', score[1])\n",
    "            #Getting Test Score\n",
    "            score = galaxyModel.evaluate(holdout_array, Y_holdout, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "\n",
    "            #Getting validation Score.\n",
    "            pred_valid=galaxyModel.predict(holdout_array)\n",
    "            y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "            #Getting Test Scores\n",
    "            temp_test=galaxyModel.predict(test_array)\n",
    "            y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "            #Getting Train Scores\n",
    "            temp_train=galaxyModel.predict(train_array)\n",
    "            y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "        y_test_pred_log=y_test_pred_log/self.K\n",
    "        y_train_pred_log=y_train_pred_log/self.K\n",
    "\n",
    "        print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "        print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "        \n",
    "#         self.plot_results()\n",
    "        \n",
    "        self.predictions = y_test_pred_log \n",
    "        return y_test_pred_log\n",
    "    \n",
    "#     def plot_results(self):\n",
    "#         plt.plot(self.history['acc'])\n",
    "#         plt.plot(self.history['val_acc'])\n",
    "#         plt.title('model accuracy')\n",
    "#         plt.ylabel('accuracy')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "#         # summarize history for loss\n",
    "#         plt.plot(self.history['loss'])\n",
    "#         plt.plot(self.history['val_loss'])\n",
    "#         plt.title('model loss')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        input_2 = Input(shape=[1], name=\"angle\")\n",
    "        angle_layer = Dense(1, )(input_2)\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                     input_shape=X_train.shape[1:], classes=1)\n",
    "        x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "        merge_one = concatenate([x, angle_layer])\n",
    "        merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "        merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "        predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "        model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "        sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        \n",
    "        \n",
    "#         input_2 = Input(shape=[1], name=\"angle\")\n",
    "#         angle_layer = Dense(1, )(input_2)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         base_model = VGG16(weights='imagenet', include_top=False, \n",
    "#                      input_shape=X_train.shape[1:], classes=1)\n",
    "        \n",
    "        \n",
    "        base_model=Sequential()\n",
    "\n",
    "        # CNN 1\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "        base_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 2\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 3\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        #CNN 4\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        # You must flatten the data for the dense layers\n",
    "        base_model.add(Flatten())\n",
    "\n",
    "        #Dense 1\n",
    "        base_model.add(Dense(512, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "#         #Dense 2\n",
    "        base_model.add(Dense(256, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # Output \n",
    "        base_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        optimizer = Adam(lr=0.001, decay=0.0)\n",
    "        base_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "#         x = base_model.get_layer('block5_pool').output\n",
    "#         x = base_model.output\n",
    "\n",
    "# #         x = GlobalMaxPooling2D()(x)\n",
    "#         merge_one = concatenate([x, angle_layer])\n",
    "# #         merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "# #         merge_one = Dropout(0.2)(merge_one)\n",
    "# #         merge_one = Dense(256, activation='relu', name='fc3')(merge_one)\n",
    "# #         merge_one = Dropout(0.2)(merge_one)\n",
    "\n",
    "#         predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "#         model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "#         sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#         model.compile(loss='binary_crossentropy',\n",
    "#                       optimizer=sgd,\n",
    "#                       metrics=['accuracy'])\n",
    "        \n",
    "        return base_model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"../_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_angle, X_test_angle = Helpers.get_angledata(train, test)\n",
    "X_train = Helpers.get_imagedata(train)\n",
    "X_test = Helpers.get_imagedata(test)\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 8s 314ms/step - loss: 0.6660 - acc: 0.6314 - val_loss: 0.4915 - val_acc: 0.7460\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 6s 238ms/step - loss: 0.4953 - acc: 0.7404 - val_loss: 0.4786 - val_acc: 0.7347\n",
      "Train loss: 0.490264658178\n",
      "Train accuracy: 0.729088639201\n",
      "Test loss: 0.478633190226\n",
      "Test accuracy: 0.734744707422\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 8s 316ms/step - loss: 0.8795 - acc: 0.5184 - val_loss: 0.6784 - val_acc: 0.5605\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.7464 - acc: 0.5283 - val_loss: 0.6360 - val_acc: 0.6567\n",
      "Train loss: 0.635482364989\n",
      "Train accuracy: 0.646326276537\n",
      "Test loss: 0.636023906063\n",
      "Test accuracy: 0.656679151061\n",
      "\n",
      " Train Log Loss Validation=  0.550150008366\n",
      " Test Log Loss Validation=  0.557230431963\n"
     ]
    }
   ],
   "source": [
    "model = VggModel(ids)\n",
    "\n",
    "preds=model.train_predict(X_train, X_angle, X_test, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv2d_81_input (InputLayer)    (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 73, 73, 64)   1792        conv2d_81_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling2D) (None, 36, 36, 64)   0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 36, 36, 64)   0           max_pooling2d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 34, 34, 128)  73856       dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling2D) (None, 17, 17, 128)  0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 17, 17, 128)  0           max_pooling2d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 15, 15, 128)  147584      dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling2D) (None, 7, 7, 128)    0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 7, 7, 128)    0           max_pooling2d_80[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 64)     73792       dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling2D) (None, 2, 2, 64)     0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 2, 2, 64)     0           max_pooling2d_81[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 256)          0           dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 512)          131584      flatten_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 512)          0           dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 256)          131328      dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "angle (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 256)          0           dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 1)            2           angle[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 257)          0           dropout_165[0][0]                \n",
      "                                                                 dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 1)            258         concatenate_34[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 560,196\n",
      "Trainable params: 560,196\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "model = SimpleModel(ids)\n",
    "print(len(model.model.input_shape))\n",
    "\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 15s 617ms/step - loss: 0.9011 - acc: 0.5481 - val_loss: 0.6251 - val_acc: 0.5186\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 1s 60ms/step - loss: 0.6048 - acc: 0.6180 - val_loss: 0.5572 - val_acc: 0.6708\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.5685 - acc: 0.6825 - val_loss: 0.5303 - val_acc: 0.7081\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.5492 - acc: 0.7057 - val_loss: 0.5112 - val_acc: 0.8075\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.5158 - acc: 0.7511 - val_loss: 0.4513 - val_acc: 0.7795\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.4874 - acc: 0.7665 - val_loss: 0.4319 - val_acc: 0.7950\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.4705 - acc: 0.7848 - val_loss: 0.4091 - val_acc: 0.7981\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 0.4628 - acc: 0.7772 - val_loss: 0.3879 - val_acc: 0.8509\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.4560 - acc: 0.7661 - val_loss: 0.4077 - val_acc: 0.8043\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.4364 - acc: 0.7939 - val_loss: 0.3644 - val_acc: 0.8602\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.4071 - acc: 0.8112 - val_loss: 0.3844 - val_acc: 0.8323\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.4437 - acc: 0.7841 - val_loss: 0.3720 - val_acc: 0.8416\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.4150 - acc: 0.7935 - val_loss: 0.3795 - val_acc: 0.8478\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.4079 - acc: 0.8089 - val_loss: 0.3802 - val_acc: 0.8509\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.3961 - acc: 0.8298 - val_loss: 0.3496 - val_acc: 0.8416\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.3788 - acc: 0.8229 - val_loss: 0.3526 - val_acc: 0.8571\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.4268 - acc: 0.7956 - val_loss: 0.3899 - val_acc: 0.8043\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.4220 - acc: 0.7872 - val_loss: 0.3397 - val_acc: 0.8634\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4407 - acc: 0.7798 - val_loss: 0.3438 - val_acc: 0.8354\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 0.3893 - acc: 0.8314 - val_loss: 0.3145 - val_acc: 0.8727\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.5567 - acc: 0.7402 - val_loss: 0.4335 - val_acc: 0.8043\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.3983 - acc: 0.8148 - val_loss: 0.3267 - val_acc: 0.8478\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.3958 - acc: 0.8236 - val_loss: 0.3659 - val_acc: 0.8261\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.4017 - acc: 0.8050 - val_loss: 0.3412 - val_acc: 0.8416\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3511 - acc: 0.8422 - val_loss: 0.3324 - val_acc: 0.8354\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4046 - acc: 0.8229 - val_loss: 0.3368 - val_acc: 0.8385\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.3644 - acc: 0.8412 - val_loss: 0.3254 - val_acc: 0.8509\n",
      "Epoch 28/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3798 - acc: 0.8186\n",
      "Epoch 00028: reducing learning rate to 0.00010000000474974513.\n",
      "24/24 [==============================] - 3s 119ms/step - loss: 0.3787 - acc: 0.8194 - val_loss: 0.3428 - val_acc: 0.8261\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 0.3550 - acc: 0.8304 - val_loss: 0.3188 - val_acc: 0.8758\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.3419 - acc: 0.8526 - val_loss: 0.3084 - val_acc: 0.8758\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3531 - acc: 0.8349 - val_loss: 0.3087 - val_acc: 0.8851\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 0.3255 - acc: 0.8539 - val_loss: 0.3011 - val_acc: 0.8789\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.3127 - acc: 0.8702 - val_loss: 0.2995 - val_acc: 0.8758\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.3275 - acc: 0.8467 - val_loss: 0.2938 - val_acc: 0.8789\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.3151 - acc: 0.8624 - val_loss: 0.2924 - val_acc: 0.8789\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.3251 - acc: 0.8552 - val_loss: 0.2930 - val_acc: 0.8820\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.3307 - acc: 0.8447 - val_loss: 0.2929 - val_acc: 0.8789\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.3163 - acc: 0.8594 - val_loss: 0.2937 - val_acc: 0.8789\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.3117 - acc: 0.8733 - val_loss: 0.2925 - val_acc: 0.8820\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.2845 - acc: 0.8741 - val_loss: 0.2910 - val_acc: 0.8851\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.3320 - acc: 0.8438 - val_loss: 0.2882 - val_acc: 0.8882\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.3086 - acc: 0.8700 - val_loss: 0.2897 - val_acc: 0.8882\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.3411 - acc: 0.8507 - val_loss: 0.2991 - val_acc: 0.8758\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.3352 - acc: 0.8378 - val_loss: 0.2991 - val_acc: 0.8820\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.3557 - acc: 0.8274 - val_loss: 0.2946 - val_acc: 0.8665\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.3433 - acc: 0.8260 - val_loss: 0.2995 - val_acc: 0.8789\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 0.3041 - acc: 0.8741 - val_loss: 0.2839 - val_acc: 0.8882\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.3366 - acc: 0.8339 - val_loss: 0.2908 - val_acc: 0.8758\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.3152 - acc: 0.8676 - val_loss: 0.2799 - val_acc: 0.8882\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.2875 - acc: 0.8637 - val_loss: 0.2779 - val_acc: 0.8851\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.3031 - acc: 0.8571 - val_loss: 0.2777 - val_acc: 0.8882\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.3031 - acc: 0.8652 - val_loss: 0.2781 - val_acc: 0.8882\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.3168 - acc: 0.8487 - val_loss: 0.2773 - val_acc: 0.8913\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.3114 - acc: 0.8670 - val_loss: 0.2818 - val_acc: 0.8882\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 0.3018 - acc: 0.8591 - val_loss: 0.2750 - val_acc: 0.8820\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.2996 - acc: 0.8670 - val_loss: 0.2777 - val_acc: 0.8882\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.3053 - acc: 0.8748 - val_loss: 0.2720 - val_acc: 0.8851\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.2953 - acc: 0.8781 - val_loss: 0.2677 - val_acc: 0.8851\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.3688 - acc: 0.8319 - val_loss: 0.2869 - val_acc: 0.8882\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2983 - acc: 0.8676 - val_loss: 0.2724 - val_acc: 0.8851\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 101ms/step - loss: 0.2757 - acc: 0.8811 - val_loss: 0.2698 - val_acc: 0.8944\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.2816 - acc: 0.8872 - val_loss: 0.2708 - val_acc: 0.8913\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2978 - acc: 0.8676 - val_loss: 0.2683 - val_acc: 0.8882\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.2901 - acc: 0.8735 - val_loss: 0.2671 - val_acc: 0.8882\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2829 - acc: 0.8800 - val_loss: 0.2662 - val_acc: 0.8789\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2948 - acc: 0.8487 - val_loss: 0.2709 - val_acc: 0.8851\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 3s 106ms/step - loss: 0.2776 - acc: 0.8846 - val_loss: 0.2613 - val_acc: 0.8975\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.3023 - acc: 0.8574 - val_loss: 0.2695 - val_acc: 0.8913\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2905 - acc: 0.8748 - val_loss: 0.2621 - val_acc: 0.8944\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.3179 - acc: 0.8604 - val_loss: 0.2880 - val_acc: 0.8820\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3153 - acc: 0.8513 - val_loss: 0.2614 - val_acc: 0.8882\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2793 - acc: 0.8728 - val_loss: 0.2627 - val_acc: 0.8913\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 0.3078 - acc: 0.8774 - val_loss: 0.2620 - val_acc: 0.9006\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.2856 - acc: 0.8670 - val_loss: 0.2616 - val_acc: 0.8975\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.2614 - acc: 0.8846 - val_loss: 0.2588 - val_acc: 0.8975\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 3s 113ms/step - loss: 0.2891 - acc: 0.8761 - val_loss: 0.2585 - val_acc: 0.8944\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2788 - acc: 0.8767 - val_loss: 0.2647 - val_acc: 0.8882\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.3352 - acc: 0.8606 - val_loss: 0.2616 - val_acc: 0.8851\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.2862 - acc: 0.8807 - val_loss: 0.2597 - val_acc: 0.8820\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.2782 - acc: 0.8787 - val_loss: 0.2572 - val_acc: 0.8913\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2684 - acc: 0.8863 - val_loss: 0.2583 - val_acc: 0.8975\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.2943 - acc: 0.8613 - val_loss: 0.2612 - val_acc: 0.8944\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.2756 - acc: 0.8891 - val_loss: 0.2571 - val_acc: 0.8975\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3386 - acc: 0.8406 - val_loss: 0.2725 - val_acc: 0.8789\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.2965 - acc: 0.8670 - val_loss: 0.2613 - val_acc: 0.8820\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2832 - acc: 0.8741 - val_loss: 0.2631 - val_acc: 0.8944\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.2630 - acc: 0.8826 - val_loss: 0.2516 - val_acc: 0.8975\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.3234 - acc: 0.8293 - val_loss: 0.2601 - val_acc: 0.9006\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 2s 87ms/step - loss: 0.2734 - acc: 0.8757 - val_loss: 0.2566 - val_acc: 0.8882\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2604 - acc: 0.8765 - val_loss: 0.2557 - val_acc: 0.8913\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2519 - acc: 0.8944 - val_loss: 0.2545 - val_acc: 0.8944\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 2s 85ms/step - loss: 0.2628 - acc: 0.8794 - val_loss: 0.2539 - val_acc: 0.8944\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 0.2413 - acc: 0.8961 - val_loss: 0.2542 - val_acc: 0.8882\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2688 - acc: 0.8826 - val_loss: 0.2518 - val_acc: 0.8944\n",
      "Epoch 95/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2854 - acc: 0.8770\n",
      "Epoch 00095: reducing learning rate to 1.0000000474974514e-05.\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.2848 - acc: 0.8761 - val_loss: 0.2668 - val_acc: 0.8975\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.2837 - acc: 0.8717 - val_loss: 0.2576 - val_acc: 0.8944\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 2s 100ms/step - loss: 0.2922 - acc: 0.8650 - val_loss: 0.2536 - val_acc: 0.8913\n",
      "Train loss: 0.230209091245\n",
      "Train accuracy: 0.905616224649\n",
      "Test loss: 0.251607284505\n",
      "Test accuracy: 0.89751552795\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 6s 249ms/step - loss: 1.3475 - acc: 0.5011 - val_loss: 0.6607 - val_acc: 0.6355\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 0.6298 - acc: 0.5934 - val_loss: 0.5691 - val_acc: 0.6667\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 2s 82ms/step - loss: 0.6103 - acc: 0.6120 - val_loss: 0.5725 - val_acc: 0.6667\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.5671 - acc: 0.6606 - val_loss: 0.5418 - val_acc: 0.6947\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.5561 - acc: 0.6914 - val_loss: 0.5338 - val_acc: 0.7072\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.5496 - acc: 0.6966 - val_loss: 0.4620 - val_acc: 0.8069\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.5256 - acc: 0.7485 - val_loss: 0.4475 - val_acc: 0.8193\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.5051 - acc: 0.7395 - val_loss: 0.4399 - val_acc: 0.8037\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.4658 - acc: 0.7802 - val_loss: 0.3898 - val_acc: 0.8224\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4711 - acc: 0.7652 - val_loss: 0.3941 - val_acc: 0.8380\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.4562 - acc: 0.7750 - val_loss: 0.3838 - val_acc: 0.8318\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.4181 - acc: 0.8024 - val_loss: 0.3552 - val_acc: 0.8380\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.4601 - acc: 0.7695 - val_loss: 0.3701 - val_acc: 0.8349\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.4167 - acc: 0.8115 - val_loss: 0.3242 - val_acc: 0.8442\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.4099 - acc: 0.8155 - val_loss: 0.3202 - val_acc: 0.8505\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.4435 - acc: 0.7946 - val_loss: 0.3525 - val_acc: 0.8474\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.4570 - acc: 0.7832 - val_loss: 0.4003 - val_acc: 0.8162\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 2s 83ms/step - loss: 0.4414 - acc: 0.7845 - val_loss: 0.3614 - val_acc: 0.8287\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.4297 - acc: 0.7975 - val_loss: 0.3321 - val_acc: 0.8536\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.4159 - acc: 0.8142 - val_loss: 0.3500 - val_acc: 0.8411\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.3971 - acc: 0.8073 - val_loss: 0.3558 - val_acc: 0.8255\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.3954 - acc: 0.8083 - val_loss: 0.3228 - val_acc: 0.8380\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4137 - acc: 0.8179\n",
      "Epoch 00023: reducing learning rate to 0.00010000000474974513.\n",
      "24/24 [==============================] - 3s 139ms/step - loss: 0.4080 - acc: 0.8116 - val_loss: 0.4420 - val_acc: 0.7819\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.4308 - acc: 0.7969 - val_loss: 0.3161 - val_acc: 0.8598\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.3891 - acc: 0.8249 - val_loss: 0.3161 - val_acc: 0.8598\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 2s 94ms/step - loss: 0.3563 - acc: 0.8311 - val_loss: 0.3067 - val_acc: 0.8567\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.4667 - acc: 0.7826 - val_loss: 0.3136 - val_acc: 0.8598\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 2s 84ms/step - loss: 0.3517 - acc: 0.8520 - val_loss: 0.3115 - val_acc: 0.8598\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 2s 94ms/step - loss: 0.3588 - acc: 0.8278 - val_loss: 0.3022 - val_acc: 0.8660\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.3513 - acc: 0.8474 - val_loss: 0.2968 - val_acc: 0.8660\n",
      "Epoch 31/100\n",
      "18/24 [=====================>........] - ETA: 0s - loss: 0.3369 - acc: 0.8594"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-77e299bde3a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_angle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-99-fe3efb4ca6b8>\u001b[0m in \u001b[0;36mtrain_predict\u001b[1;34m(self, X_train, X_angle, X_test, target_train)\u001b[0m\n\u001b[0;32m     74\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdout_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_holdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                     callbacks=callbacks)\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m#Getting the Best Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2147\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SimpleModel(ids)\n",
    "\n",
    "preds=model.train_predict(X_train, X_angle, X_test, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_submission(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
