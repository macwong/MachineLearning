{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\n",
    "# Model 2: https://www.kaggle.com/vincento/keras-starter-4l-0-1694-lb-icebergchallenge\n",
    "# Model 3: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193\n",
    "\n",
    "# ResNet50\n",
    "# InceptionV3\n",
    "# MobileNet\n",
    "# DenseNet\n",
    "# SqueezeNet\n",
    "# InceptionResNetV2\n",
    "# Xception\n",
    "# LeNet\n",
    "\n",
    "# Simple model: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "# https://www.kaggle.com/henokanh/cnn-batchnormalization-0-1646\n",
    "# https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "# https://www.kaggle.com/cttsai/ensembling-gbms-lb-203/code\n",
    "# https://www.kaggle.com/yuhaichina/single-model-vgg16-mobilenet-lb-0-1568-with-tf\n",
    "# https://www.kaggle.com/wvadim/keras-tf-lb-0-18\n",
    "# https://www.kaggle.com/yekenot/inceptionv3-k-fold-cv-lb-0-1944\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "import abc\n",
    "import cv2\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"../_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers():\n",
    "    def get_angledata(train, test):\n",
    "        train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "        train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "        test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "\n",
    "        X_angle=train['inc_angle']\n",
    "        X_test_angle=test['inc_angle']\n",
    "        \n",
    "        angle_min = np.minimum(X_angle.min(), X_test_angle.min())\n",
    "        angle_max = np.maximum(X_angle.max(), X_test_angle.max())\n",
    "        \n",
    "        X_angle = (X_angle - angle_min) / (angle_max - angle_min)\n",
    "        X_test_angle = (X_test_angle - angle_min) / (angle_max - angle_min)\n",
    "        \n",
    "        return X_angle, X_test_angle\n",
    "    \n",
    "    def get_banddata(data):\n",
    "        X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_1\"]])\n",
    "        X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_2\"]])\n",
    "        X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "#         X_band_3 = (X_band_1 + X_band_2) / 2\n",
    "        X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "        X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "        \n",
    "        return X_band_1, X_band_2, X_band_3, X_band_4, X_band_5\n",
    "\n",
    "    def get_imagedata(train, test):\n",
    "        X_band_train_1, X_band_train_2, X_band_train_3, X_band_train_4, X_band_train_5 = Helpers.get_banddata(train)\n",
    "        X_band_test_1, X_band_test_2, X_band_test_3, X_band_test_4, X_band_test_5 = Helpers.get_banddata(test)\n",
    "        \n",
    "#         print(X_band_3.shape)\n",
    "#         print(X_band_4.shape)\n",
    "#         print(X_band_5.shape)\n",
    "#         print(X_band_test_3.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        band_3_min = np.minimum(X_band_train_3.min(), X_band_test_3.min())\n",
    "        band_4_min = np.minimum(X_band_train_4.min(), X_band_test_4.min())\n",
    "        band_5_min = np.minimum(X_band_train_5.min(), X_band_test_5.min())\n",
    "\n",
    "        band_3_max = np.maximum(X_band_train_3.max(), X_band_test_3.max())\n",
    "        band_4_max = np.maximum(X_band_train_4.max(), X_band_test_4.max())\n",
    "        band_5_max = np.maximum(X_band_train_5.max(), X_band_test_5.max())\n",
    "        \n",
    "#         print(band_3_min)\n",
    "#         print(band_4_min)\n",
    "#         print(band_5_min)\n",
    "#         print(band_3_max)\n",
    "#         print(band_4_max)\n",
    "#         print(band_5_max)\n",
    "\n",
    "        X_band_train_3 = (X_band_train_3 - band_3_min) / (band_3_max - band_3_min)\n",
    "        X_band_train_4 = (X_band_train_4 - band_4_min) / (band_4_max - band_4_min)\n",
    "        X_band_train_5 = (X_band_train_5 - band_5_min) / (band_5_max - band_5_min)\n",
    "        \n",
    "        X_band_test_3 = (X_band_test_3 - band_3_min) / (band_3_max - band_3_min)\n",
    "        X_band_test_4 = (X_band_test_4 - band_4_min) / (band_4_max - band_4_min)\n",
    "        X_band_test_5 = (X_band_test_5 - band_5_min) / (band_5_max - band_5_min)\n",
    "        \n",
    "        X_train = np.concatenate([X_band_train_3[:, :, :, np.newaxis],X_band_train_4[:, :, :, np.newaxis],X_band_train_5[:, :, :, np.newaxis]], axis=-1)\n",
    "        X_test = np.concatenate([X_band_test_3[:, :, :, np.newaxis],X_band_test_4[:, :, :, np.newaxis],X_band_test_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def get_generator():\n",
    "        # Define the image transformations here\n",
    "        return ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10)\n",
    "    \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_two_inputs(X1, X2, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "        while True:\n",
    "                X1i = genX1.next()\n",
    "                X2i = genX2.next()\n",
    "                #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "                #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "                yield [X1i[0], X2i[1]], X1i[1]\n",
    "                \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_one_input(X1, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        return genX1\n",
    "                \n",
    "\n",
    "    # Finally create generator\n",
    "    def get_callbacks(filepath, patience=2):\n",
    "        es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "        msave = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', mode='min')\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "        return [es, msave, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_angle, X_test_angle = Helpers.get_angledata(train, test)\n",
    "X_train, X_test = Helpers.get_imagedata(train, test)\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelBase():\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    def __init__(self, ids = None):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 100\n",
    "        self.ids = ids\n",
    "        self.predictions = None\n",
    "        self.K = 5\n",
    "        \n",
    "        self.model = self.get_model()\n",
    "        \n",
    "    def save_model(self):\n",
    "        name = self.get_name() + datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S') + \".h5\"\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "    def create_submission(self, predict):\n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test['id']\n",
    "        submission['is_iceberg']=preds\n",
    "        submission.to_csv(\"submission-\" + self.get_name() + \".csv\", float_format='%g', index = False)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        pass\n",
    "    \n",
    "    def get_size(self):\n",
    "        return -1\n",
    "    \n",
    "        \n",
    "    #Using K-fold Cross Validation with Data Augmentation.\n",
    "    def train_predict(self, X_train, X_angle, X_test, target_train):\n",
    "        img_size = self.get_size()\n",
    "        \n",
    "        X_train_resized = X_train\n",
    "        X_test_resized = X_test\n",
    "            \n",
    "        if img_size > 0:\n",
    "            X_train_resized = np.empty(shape = (X_train.shape[0], img_size, img_size, 3))\n",
    "            X_test_resized = np.empty(shape = (X_test.shape[0], img_size, img_size, 3))\n",
    "            count = 0\n",
    "            for img in X_train:\n",
    "                new_img = cv2.resize(img, (img_size, img_size))\n",
    "                X_train_resized[count] = new_img\n",
    "                count += 1\n",
    "\n",
    "            count = 0\n",
    "            for img in X_test:\n",
    "                new_img = cv2.resize(img, (img_size, img_size))\n",
    "                X_test_resized[count] = new_img\n",
    "                count += 1\n",
    "                \n",
    "        print(\"Orig:\", X_train.shape)\n",
    "        print(\"Resized:\", X_train_resized.shape)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.K, shuffle=True, random_state=16).split(X_train_resized, target_train))\n",
    "        y_test_pred_log = 0\n",
    "        y_train_pred_log=0\n",
    "        y_valid_pred_log = 0.0*target_train\n",
    "        for j, (train_idx, test_idx) in enumerate(folds):\n",
    "            print('\\n===================FOLD=',j)\n",
    "            X_train_cv = X_train_resized[train_idx]\n",
    "            y_train_cv = target_train[train_idx]\n",
    "            X_holdout = X_train_resized[test_idx]\n",
    "            Y_holdout= target_train[test_idx]\n",
    "\n",
    "            #Angle\n",
    "            X_angle_cv=X_angle[train_idx]\n",
    "            X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "            #define file path and get callbacks\n",
    "            file_path = \"%s_\"%j + self.get_name() + \".hdf5\"\n",
    "            callbacks = Helpers.get_callbacks(filepath=file_path, patience=5)\n",
    "            gen_flow = Helpers.gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "            \n",
    "            galaxyModel = self.get_model()\n",
    "            \n",
    "#             if galaxyModel.model is not None:\n",
    "#                 input_shape = len(galaxyModel.model.input_shape)\n",
    "#             else:\n",
    "            input_shape = len(galaxyModel.input_shape)\n",
    "                \n",
    "            train_array = [X_train_resized,X_angle]\n",
    "            train_array_cv = [X_train_cv,X_angle_cv]\n",
    "            holdout_array = [X_holdout,X_angle_hold]\n",
    "            test_array = [X_test_resized, X_test_angle]\n",
    "            \n",
    "            if input_shape != 2:\n",
    "                train_array = X_train_resized\n",
    "                train_array_cv = X_train_cv\n",
    "                holdout_array = X_holdout\n",
    "                test_array = X_test_resized\n",
    "                gen_flow = Helpers.gen_flow_for_one_input(X_train_cv, y_train_cv)\n",
    "                \n",
    "            galaxyModel.fit_generator(\n",
    "                    gen_flow,\n",
    "                    steps_per_epoch=24,\n",
    "                    epochs=self.epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=(holdout_array, Y_holdout),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "            #Getting the Best Model\n",
    "            galaxyModel.load_weights(filepath=file_path)\n",
    "            #Getting Training Score\n",
    "            score = galaxyModel.evaluate(train_array_cv, y_train_cv, verbose=0)\n",
    "            print('Train loss:', score[0])\n",
    "            print('Train accuracy:', score[1])\n",
    "            #Getting Test Score\n",
    "            score = galaxyModel.evaluate(holdout_array, Y_holdout, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "\n",
    "            #Getting validation Score.\n",
    "            pred_valid=galaxyModel.predict(holdout_array)\n",
    "            y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "            #Getting Test Scores\n",
    "            temp_test=galaxyModel.predict(test_array)\n",
    "            y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "            #Getting Train Scores\n",
    "            temp_train=galaxyModel.predict(train_array)\n",
    "            y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "        y_test_pred_log=y_test_pred_log/self.K\n",
    "        y_train_pred_log=y_train_pred_log/self.K\n",
    "\n",
    "        print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "        print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "        \n",
    "#         self.plot_results\n",
    "        self.create_submission(preds)\n",
    "        \n",
    "        self.predictions = y_test_pred_log \n",
    "        return y_test_pred_log\n",
    "    \n",
    "#     def plot_results(self):\n",
    "#         plt.plot(self.history['acc'])\n",
    "#         plt.plot(self.history['val_acc'])\n",
    "#         plt.title('model accuracy')\n",
    "#         plt.ylabel('accuracy')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "#         # summarize history for loss\n",
    "#         plt.plot(self.history['loss'])\n",
    "#         plt.plot(self.history['val_loss'])\n",
    "#         plt.title('model loss')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VggModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        input_2 = Input(shape=[1], name=\"angle\")\n",
    "        angle_layer = Dense(1, )(input_2)\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                     input_shape=X_train.shape[1:], classes=1)\n",
    "        x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "        merge_one = concatenate([x, angle_layer])\n",
    "        merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "        merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "        predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "        model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "        sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        base_model=Sequential()\n",
    "\n",
    "        # CNN 1\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "        base_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 2\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 3\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        #CNN 4\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        # You must flatten the data for the dense layers\n",
    "        base_model.add(Flatten())\n",
    "\n",
    "        #Dense 1\n",
    "        base_model.add(Dense(512, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        #Dense 2\n",
    "        base_model.add(Dense(256, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # Output \n",
    "        base_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        optimizer = Adam(lr=0.001, decay=0.0)\n",
    "        base_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        return base_model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchNormModel(ModelBase):\n",
    "    def ConvBlock(model, layers, filters):\n",
    "        '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "            model.add(BatchNormalization(axis=3))\n",
    "\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    def get_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input image: 75x75x3\n",
    "        model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "        BatchNormModel.ConvBlock(model, 1, 32)\n",
    "        # 37x37x32\n",
    "        BatchNormModel.ConvBlock(model, 1, 64)\n",
    "        # 18x18x64\n",
    "        BatchNormModel.ConvBlock(model, 1, 128)\n",
    "        # 9x9x128\n",
    "        BatchNormModel.ConvBlock(model, 1, 128)\n",
    "        # 4x4x128\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        # 4x4x2\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        \n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"batchnorm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "class MobileNetModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        image_size = self.get_size()\n",
    "        img_input = keras.layers.Input(shape=(image_size, image_size, 3))\n",
    "        mobile_model = MobileNet(input_tensor = img_input, weights=None, alpha=1.0, include_top=True, classes=1)\n",
    "\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        mobile_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        \n",
    "        return mobile_model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"mobilenet\"\n",
    "    \n",
    "    def get_size(self):\n",
    "        return 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "class InceptionV3Model(ModelBase):\n",
    "    def get_model(self):\n",
    "#         input_tensor = Input(shape=(self.get_size(), self.get_size(), 3))\n",
    "#         base_model = InceptionV3(include_top=False,\n",
    "#                        weights=None,\n",
    "#                        input_shape=(self.get_size(), self.get_size(), 3))\n",
    "        \n",
    "#         bn = BatchNormalization()(input_tensor)\n",
    "#         x = base_model(bn)\n",
    "#         x = GlobalAveragePooling2D()(x)\n",
    "#         x = Dropout(0.5)(x)\n",
    "#         output = Dense(1, activation='sigmoid')(x)\n",
    "#         model = Model(input_tensor, output)\n",
    "\n",
    "        v3_model = InceptionV3(include_top=False, weights=None, input_shape=(self.get_size(), self.get_size(), 3))\n",
    "\n",
    "        x = v3_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        predictions = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        model = Model(inputs=v3_model.input, outputs=predictions)\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        return model\n",
    "        \n",
    "    def get_name(self):\n",
    "        return \"inceptionv3\"\n",
    "    \n",
    "    def get_size(self):\n",
    "        return 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig: (1604, 75, 75, 3)\n",
      "Resized: (1604, 75, 75, 3)\n",
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 11s 440ms/step - loss: 0.6972 - acc: 0.5224 - val_loss: 0.6998 - val_acc: 0.4752\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 5s 216ms/step - loss: 0.6931 - acc: 0.5378 - val_loss: 0.6409 - val_acc: 0.6304\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 5s 217ms/step - loss: 0.6216 - acc: 0.6348 - val_loss: 0.5486 - val_acc: 0.6522\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.5989 - acc: 0.6241 - val_loss: 0.4996 - val_acc: 0.7391\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 5s 196ms/step - loss: 0.6416 - acc: 0.6068 - val_loss: 0.5511 - val_acc: 0.6273\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 5s 218ms/step - loss: 0.5356 - acc: 0.6756 - val_loss: 0.4657 - val_acc: 0.7640\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 5s 227ms/step - loss: 0.5212 - acc: 0.7363 - val_loss: 0.6213 - val_acc: 0.6584\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.5066 - acc: 0.7374 - val_loss: 0.4369 - val_acc: 0.7733\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 5s 198ms/step - loss: 0.5016 - acc: 0.7367 - val_loss: 0.4446 - val_acc: 0.7919\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 5s 198ms/step - loss: 0.5797 - acc: 0.6617 - val_loss: 0.7026 - val_acc: 0.4689\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 5s 198ms/step - loss: 0.7039 - acc: 0.4980 - val_loss: 0.6898 - val_acc: 0.5311\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 5s 198ms/step - loss: 0.6983 - acc: 0.5083 - val_loss: 0.6883 - val_acc: 0.5311\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 5s 198ms/step - loss: 0.6968 - acc: 0.5041 - val_loss: 0.6871 - val_acc: 0.5311\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 5s 229ms/step - loss: 0.6554 - acc: 0.5703 - val_loss: 0.5255 - val_acc: 0.7050\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 5s 199ms/step - loss: 0.5299 - acc: 0.6891 - val_loss: 0.4754 - val_acc: 0.7516\n",
      "Epoch 16/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4826 - acc: 0.7575\n",
      "Epoch 00016: reducing learning rate to 0.00010000000474974513.\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.4815 - acc: 0.7587 - val_loss: 0.4587 - val_acc: 0.7702\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 6s 232ms/step - loss: 0.5364 - acc: 0.7667 - val_loss: 0.4289 - val_acc: 0.7888\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.4396 - acc: 0.8044 - val_loss: 0.4032 - val_acc: 0.8168\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.4649 - acc: 0.7726 - val_loss: 0.3892 - val_acc: 0.8230\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.4190 - acc: 0.8070 - val_loss: 0.3886 - val_acc: 0.8230\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 6s 255ms/step - loss: 0.4080 - acc: 0.8088 - val_loss: 0.3818 - val_acc: 0.8447\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 5s 200ms/step - loss: 0.4008 - acc: 0.8187 - val_loss: 0.4217 - val_acc: 0.7950\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.4171 - acc: 0.8148 - val_loss: 0.3842 - val_acc: 0.8199\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.4030 - acc: 0.8089 - val_loss: 0.3594 - val_acc: 0.8478\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.4197 - acc: 0.8000 - val_loss: 0.3620 - val_acc: 0.8447\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 5s 226ms/step - loss: 0.4015 - acc: 0.8215 - val_loss: 0.3477 - val_acc: 0.8602\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.4115 - acc: 0.8006 - val_loss: 0.3684 - val_acc: 0.8323\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 6s 232ms/step - loss: 0.4319 - acc: 0.7829 - val_loss: 0.3619 - val_acc: 0.8385\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.4114 - acc: 0.8063 - val_loss: 0.3994 - val_acc: 0.8106\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 5s 229ms/step - loss: 0.3893 - acc: 0.8259 - val_loss: 0.3382 - val_acc: 0.8571\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.3993 - acc: 0.8065 - val_loss: 0.3335 - val_acc: 0.8540\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 5s 229ms/step - loss: 0.3678 - acc: 0.8448 - val_loss: 0.3226 - val_acc: 0.8602\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 5s 227ms/step - loss: 0.3968 - acc: 0.8156 - val_loss: 0.3180 - val_acc: 0.8571\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 5s 228ms/step - loss: 0.3676 - acc: 0.8285 - val_loss: 0.3129 - val_acc: 0.8602\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.3262 - acc: 0.8510 - val_loss: 0.3233 - val_acc: 0.8509\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.3621 - acc: 0.8202 - val_loss: 0.3039 - val_acc: 0.8727\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.3804 - acc: 0.8215 - val_loss: 0.3106 - val_acc: 0.8634\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.3256 - acc: 0.8507 - val_loss: 0.2991 - val_acc: 0.8696\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 5s 227ms/step - loss: 0.3311 - acc: 0.8591 - val_loss: 0.2945 - val_acc: 0.8851\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.3169 - acc: 0.8650 - val_loss: 0.2977 - val_acc: 0.8602\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.3728 - acc: 0.8156 - val_loss: 0.2977 - val_acc: 0.8602\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.3352 - acc: 0.8460 - val_loss: 0.3338 - val_acc: 0.8416\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.3429 - acc: 0.8326 - val_loss: 0.3046 - val_acc: 0.8602\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.3826 - acc: 0.8241 - val_loss: 0.3469 - val_acc: 0.8478\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.3268 - acc: 0.8437 - val_loss: 0.2950 - val_acc: 0.8509\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.3283 - acc: 0.8572 - val_loss: 0.2813 - val_acc: 0.8913\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.3190 - acc: 0.8676 - val_loss: 0.2820 - val_acc: 0.8851\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3206 - acc: 0.8391 - val_loss: 0.2808 - val_acc: 0.8758\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.2729 - acc: 0.8857 - val_loss: 0.2848 - val_acc: 0.8851\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2942 - acc: 0.8735 - val_loss: 0.3098 - val_acc: 0.8602\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2945 - acc: 0.8774 - val_loss: 0.2936 - val_acc: 0.8602\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2802 - acc: 0.8820 - val_loss: 0.2983 - val_acc: 0.8602\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2768 - acc: 0.8859 - val_loss: 0.2887 - val_acc: 0.8727\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 5s 228ms/step - loss: 0.2956 - acc: 0.8767 - val_loss: 0.2704 - val_acc: 0.8913\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3137 - acc: 0.8600 - val_loss: 0.2664 - val_acc: 0.8851\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.2579 - acc: 0.8876 - val_loss: 0.2745 - val_acc: 0.8789\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2662 - acc: 0.8872 - val_loss: 0.2775 - val_acc: 0.8727\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2677 - acc: 0.8917 - val_loss: 0.2709 - val_acc: 0.8851\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.2565 - acc: 0.8904 - val_loss: 0.2626 - val_acc: 0.8820\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2516 - acc: 0.8963 - val_loss: 0.2843 - val_acc: 0.8696\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 6s 236ms/step - loss: 0.2769 - acc: 0.8767 - val_loss: 0.2620 - val_acc: 0.8882\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2491 - acc: 0.8911 - val_loss: 0.2983 - val_acc: 0.8634\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.2425 - acc: 0.8968 - val_loss: 0.2787 - val_acc: 0.8727\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2637 - acc: 0.8872 - val_loss: 0.2647 - val_acc: 0.8913\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.3318 - acc: 0.8536 - val_loss: 0.2956 - val_acc: 0.8665\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2723 - acc: 0.8839 - val_loss: 0.2685 - val_acc: 0.8820\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2628 - acc: 0.8898 - val_loss: 0.2758 - val_acc: 0.8820\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2825 - acc: 0.8800 - val_loss: 0.2634 - val_acc: 0.8882\n",
      "Epoch 69/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2395 - acc: 0.8988\n",
      "Epoch 00069: reducing learning rate to 1.0000000474974514e-05.\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2428 - acc: 0.8970 - val_loss: 0.2668 - val_acc: 0.8820\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.2599 - acc: 0.8883 - val_loss: 0.2643 - val_acc: 0.8851\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.2518 - acc: 0.8944 - val_loss: 0.2540 - val_acc: 0.8882\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2476 - acc: 0.8989 - val_loss: 0.2552 - val_acc: 0.8944\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2562 - acc: 0.8976 - val_loss: 0.2567 - val_acc: 0.8882\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 5s 227ms/step - loss: 0.2247 - acc: 0.9022 - val_loss: 0.2534 - val_acc: 0.8820\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2624 - acc: 0.8776 - val_loss: 0.2543 - val_acc: 0.8913\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2514 - acc: 0.8795 - val_loss: 0.2564 - val_acc: 0.8820\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.2278 - acc: 0.9072 - val_loss: 0.2568 - val_acc: 0.8851\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2264 - acc: 0.9041 - val_loss: 0.2560 - val_acc: 0.8851\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2428 - acc: 0.8989 - val_loss: 0.2581 - val_acc: 0.8882\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2329 - acc: 0.9015 - val_loss: 0.2570 - val_acc: 0.8913\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2577 - acc: 0.9002 - val_loss: 0.2548 - val_acc: 0.8882\n",
      "Epoch 82/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2344 - acc: 0.9035\n",
      "Epoch 00082: reducing learning rate to 1.0000000656873453e-06.\n",
      "24/24 [==============================] - 5s 204ms/step - loss: 0.2335 - acc: 0.9035 - val_loss: 0.2576 - val_acc: 0.8882\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.2409 - acc: 0.8976 - val_loss: 0.2553 - val_acc: 0.8851\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.2374 - acc: 0.9013 - val_loss: 0.2551 - val_acc: 0.8882\n",
      "Train loss: 0.216708813554\n",
      "Train accuracy: 0.914196567863\n",
      "Test loss: 0.253388928731\n",
      "Test accuracy: 0.88198757764\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 12s 487ms/step - loss: 0.7008 - acc: 0.5266 - val_loss: 0.6307 - val_acc: 0.6854\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.6753 - acc: 0.5937 - val_loss: 0.6614 - val_acc: 0.5296\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 5s 228ms/step - loss: 0.6156 - acc: 0.6351 - val_loss: 0.5187 - val_acc: 0.7290\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.5579 - acc: 0.6951 - val_loss: 0.5005 - val_acc: 0.7352\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.5218 - acc: 0.7196 - val_loss: 0.4328 - val_acc: 0.7819\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 5s 228ms/step - loss: 0.4678 - acc: 0.7711 - val_loss: 0.3894 - val_acc: 0.7975\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 6s 241ms/step - loss: 0.4441 - acc: 0.7835 - val_loss: 0.3795 - val_acc: 0.8255\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.4357 - acc: 0.7982 - val_loss: 0.4315 - val_acc: 0.8069\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.4580 - acc: 0.7861 - val_loss: 0.3669 - val_acc: 0.8255\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 5s 226ms/step - loss: 0.4197 - acc: 0.8050 - val_loss: 0.3217 - val_acc: 0.8474\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 5s 229ms/step - loss: 0.3723 - acc: 0.8389 - val_loss: 0.2875 - val_acc: 0.8723\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.3652 - acc: 0.8370 - val_loss: 0.2515 - val_acc: 0.9190\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.3780 - acc: 0.8145 - val_loss: 0.2572 - val_acc: 0.8847\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 5s 218ms/step - loss: 0.3841 - acc: 0.8126 - val_loss: 0.3852 - val_acc: 0.8224\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 5s 203ms/step - loss: 0.3314 - acc: 0.8484 - val_loss: 0.2649 - val_acc: 0.8816\n",
      "Epoch 16/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3648 - acc: 0.8299"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-e68978fe55ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# model = InceptionV3Model(ids)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_angle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-74-b04e0b6c72c3>\u001b[0m in \u001b[0;36mtrain_predict\u001b[1;34m(self, X_train, X_angle, X_test, target_train)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdout_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_holdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                     callbacks=callbacks)\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m#Getting the Best Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2176\u001b[0m                                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                 verbose=0)\n\u001b[0m\u001b[0;32m   2178\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1732\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1733\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1734\u001b[1;33m                                steps=steps)\n\u001b[0m\u001b[0;32m   1735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = VggModel(ids)\n",
    "# model = SimpleModel(ids)\n",
    "# model = BatchNormModel(ids)\n",
    "# model = MobileNetModel(ids)\n",
    "# model = InceptionV3Model(ids)\n",
    "\n",
    "preds=model.train_predict(X_train, X_angle, X_test, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
