{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\n",
    "# Model 2: https://www.kaggle.com/vincento/keras-starter-4l-0-1694-lb-icebergchallenge\n",
    "# Model 3: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193\n",
    "# Model 4: https://www.kaggle.com/wvadim/keras-tf-lb-0-18\n",
    "\n",
    "# ResNet50\n",
    "# InceptionV3\n",
    "# MobileNet\n",
    "# DenseNet\n",
    "# SqueezeNet\n",
    "# InceptionResNetV2\n",
    "# Xception\n",
    "\n",
    "# Simple model: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "# https://www.kaggle.com/henokanh/cnn-batchnormalization-0-1646\n",
    "# https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "# https://www.kaggle.com/cttsai/ensembling-gbms-lb-203/code\n",
    "# https://www.kaggle.com/yuhaichina/single-model-vgg16-mobilenet-lb-0-1568-with-tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "import abc\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers():\n",
    "    def get_angledata(train, test):\n",
    "        train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "        train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "        test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "\n",
    "        X_angle=train['inc_angle']\n",
    "        X_test_angle=test['inc_angle']\n",
    "        \n",
    "        return X_angle, X_test_angle\n",
    "    \n",
    "    def get_imagedata(data):\n",
    "        X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_1\"]])\n",
    "        X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_2\"]])\n",
    "        X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "        X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "        X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "        X_data = np.concatenate([X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "        return X_data\n",
    "    \n",
    "    def get_generator():\n",
    "        # Define the image transformations here\n",
    "        return ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10)\n",
    "    \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_two_inputs(X1, X2, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "        while True:\n",
    "                X1i = genX1.next()\n",
    "                X2i = genX2.next()\n",
    "                #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "                #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "                yield [X1i[0], X2i[1]], X1i[1]\n",
    "                \n",
    "\n",
    "    # Finally create generator\n",
    "    def get_callbacks(filepath, patience=2):\n",
    "        es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "        msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "        return [es, msave, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelBase():\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    def __init__(self, ids = None):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 100\n",
    "        self.ids = ids\n",
    "        self.predictions = None\n",
    "        self.K = 2\n",
    "        \n",
    "        self.model = self.get_model()\n",
    "        \n",
    "    def save_model(self):\n",
    "        name = self.get_name() + datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S') + \".h5\"\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "    def create_submission(self, predict):\n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test['id']\n",
    "        submission['is_iceberg']=preds\n",
    "        submission.to_csv(\"submission-\" + self.get_name() + \".csv\", float_format='%g', index = False)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    #Using K-fold Cross Validation with Data Augmentation.\n",
    "    def myAngleCV(self, X_train, X_angle, X_test, target_train):\n",
    "        folds = list(StratifiedKFold(n_splits=self.K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "        y_test_pred_log = 0\n",
    "        y_train_pred_log=0\n",
    "        y_valid_pred_log = 0.0*target_train\n",
    "        for j, (train_idx, test_idx) in enumerate(folds):\n",
    "            print('\\n===================FOLD=',j)\n",
    "            X_train_cv = X_train[train_idx]\n",
    "            y_train_cv = target_train[train_idx]\n",
    "            X_holdout = X_train[test_idx]\n",
    "            Y_holdout= target_train[test_idx]\n",
    "\n",
    "            #Angle\n",
    "            X_angle_cv=X_angle[train_idx]\n",
    "            X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "            #define file path and get callbacks\n",
    "            file_path = \"%s_aug_model_weights.hdf5\"%j\n",
    "            callbacks = Helpers.get_callbacks(filepath=file_path, patience=5)\n",
    "            gen_flow = Helpers.gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "            \n",
    "            galaxyModel= self.get_model()\n",
    "            galaxyModel.fit_generator(\n",
    "                    gen_flow,\n",
    "                    steps_per_epoch=24,\n",
    "                    epochs=100,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "            #Getting the Best Model\n",
    "            galaxyModel.load_weights(filepath=file_path)\n",
    "            #Getting Training Score\n",
    "            score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "            print('Train loss:', score[0])\n",
    "            print('Train accuracy:', score[1])\n",
    "            #Getting Test Score\n",
    "            score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "\n",
    "            #Getting validation Score.\n",
    "            pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "            y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "            #Getting Test Scores\n",
    "            temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "            y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "            #Getting Train Scores\n",
    "            temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "            y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "        y_test_pred_log=y_test_pred_log/self.K\n",
    "        y_train_pred_log=y_train_pred_log/self.K\n",
    "\n",
    "        print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "        print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "        \n",
    "#         self.plot_results()\n",
    "        \n",
    "        self.predictions = y_test_pred_log \n",
    "        return y_test_pred_log\n",
    "    \n",
    "#     def plot_results(self):\n",
    "#         plt.plot(self.history['acc'])\n",
    "#         plt.plot(self.history['val_acc'])\n",
    "#         plt.title('model accuracy')\n",
    "#         plt.ylabel('accuracy')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "#         # summarize history for loss\n",
    "#         plt.plot(self.history['loss'])\n",
    "#         plt.plot(self.history['val_loss'])\n",
    "#         plt.title('model loss')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        input_2 = Input(shape=[1], name=\"angle\")\n",
    "        angle_layer = Dense(1, )(input_2)\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                     input_shape=X_train.shape[1:], classes=1)\n",
    "        x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "        merge_one = concatenate([x, angle_layer])\n",
    "        merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "        merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "        predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "        model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "        sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"../_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_angle, X_test_angle = Helpers.get_angledata(train, test)\n",
    "X_train = Helpers.get_imagedata(train)\n",
    "X_test = Helpers.get_imagedata(test)\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 9s 378ms/step - loss: 1.1044 - acc: 0.5007 - val_loss: 0.6679 - val_acc: 0.5305\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.7169 - acc: 0.5823 - val_loss: 0.6308 - val_acc: 0.6040\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 6s 231ms/step - loss: 0.6226 - acc: 0.6319 - val_loss: 0.5481 - val_acc: 0.7024\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.5755 - acc: 0.6598 - val_loss: 0.4845 - val_acc: 0.7372\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.5634 - acc: 0.6824 - val_loss: 0.4752 - val_acc: 0.7509\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.5063 - acc: 0.7159 - val_loss: 0.3618 - val_acc: 0.8244\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 6s 243ms/step - loss: 0.4690 - acc: 0.7617 - val_loss: 0.3297 - val_acc: 0.8630\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 6s 239ms/step - loss: 0.3960 - acc: 0.8087 - val_loss: 0.2833 - val_acc: 0.8767\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 6s 240ms/step - loss: 0.3534 - acc: 0.8456 - val_loss: 0.2626 - val_acc: 0.8966\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 5s 215ms/step - loss: 0.3396 - acc: 0.8494 - val_loss: 0.3048 - val_acc: 0.8468\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 6s 236ms/step - loss: 0.3438 - acc: 0.8327 - val_loss: 0.2432 - val_acc: 0.9128\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 5s 216ms/step - loss: 0.3097 - acc: 0.8559 - val_loss: 0.3274 - val_acc: 0.8692\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 5s 226ms/step - loss: 0.2945 - acc: 0.8732 - val_loss: 0.2738 - val_acc: 0.8904\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.2976 - acc: 0.8707 - val_loss: 0.2406 - val_acc: 0.9029\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 5s 216ms/step - loss: 0.2539 - acc: 0.8960 - val_loss: 0.2902 - val_acc: 0.8755\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 5s 217ms/step - loss: 0.2861 - acc: 0.8636 - val_loss: 0.2820 - val_acc: 0.8667\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 6s 239ms/step - loss: 0.2422 - acc: 0.8978 - val_loss: 0.2214 - val_acc: 0.9191\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 6s 242ms/step - loss: 0.2361 - acc: 0.9007 - val_loss: 0.2144 - val_acc: 0.9228\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 5s 217ms/step - loss: 0.2450 - acc: 0.8918 - val_loss: 0.2680 - val_acc: 0.8892\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 6s 241ms/step - loss: 0.2477 - acc: 0.9012 - val_loss: 0.2078 - val_acc: 0.9203\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.2311 - acc: 0.8915 - val_loss: 0.2015 - val_acc: 0.9178\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 5s 218ms/step - loss: 0.2376 - acc: 0.8942 - val_loss: 0.2183 - val_acc: 0.9191\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.2159 - acc: 0.9169 - val_loss: 0.2297 - val_acc: 0.9141\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 6s 246ms/step - loss: 0.2128 - acc: 0.9137 - val_loss: 0.1971 - val_acc: 0.9328\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.1803 - acc: 0.9197 - val_loss: 0.2741 - val_acc: 0.9004\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.2245 - acc: 0.9064 - val_loss: 0.2234 - val_acc: 0.9153\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.1848 - acc: 0.9279 - val_loss: 0.2116 - val_acc: 0.9153\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.1870 - acc: 0.9252 - val_loss: 0.2840 - val_acc: 0.8917\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.2043 - acc: 0.9098 - val_loss: 0.2468 - val_acc: 0.9054\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.1809 - acc: 0.9216 - val_loss: 0.2396 - val_acc: 0.9066\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 5s 218ms/step - loss: 0.2002 - acc: 0.9161 - val_loss: 0.2122 - val_acc: 0.9103\n",
      "Epoch 32/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1898 - acc: 0.9234\n",
      "Epoch 00032: reducing learning rate to 0.00010000000474974513.\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.1869 - acc: 0.9253 - val_loss: 0.2318 - val_acc: 0.9153\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.1727 - acc: 0.9343 - val_loss: 0.2046 - val_acc: 0.9290\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.1624 - acc: 0.9377 - val_loss: 0.1990 - val_acc: 0.9278\n",
      "Train loss: 0.13195397836\n",
      "Train accuracy: 0.956304619226\n",
      "Test loss: 0.197130645399\n",
      "Test accuracy: 0.932752179328\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 8s 350ms/step - loss: 0.7188 - acc: 0.5949 - val_loss: 0.5213 - val_acc: 0.7141\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 6s 243ms/step - loss: 0.5021 - acc: 0.7355 - val_loss: 0.4008 - val_acc: 0.7878\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.3765 - acc: 0.8203 - val_loss: 0.3216 - val_acc: 0.8402\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 6s 243ms/step - loss: 0.2800 - acc: 0.8636 - val_loss: 0.2868 - val_acc: 0.8677\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 6s 242ms/step - loss: 0.2599 - acc: 0.8798 - val_loss: 0.2798 - val_acc: 0.8739\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.2303 - acc: 0.8940 - val_loss: 0.3204 - val_acc: 0.8427\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 6s 248ms/step - loss: 0.2403 - acc: 0.8862 - val_loss: 0.2607 - val_acc: 0.8814\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 6s 250ms/step - loss: 0.2241 - acc: 0.9032 - val_loss: 0.2455 - val_acc: 0.8889\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.2138 - acc: 0.8950 - val_loss: 0.2289 - val_acc: 0.9076\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.2061 - acc: 0.9083 - val_loss: 0.2885 - val_acc: 0.8639\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.1919 - acc: 0.9112 - val_loss: 0.2620 - val_acc: 0.8976\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.2055 - acc: 0.9049 - val_loss: 0.2601 - val_acc: 0.8826\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.1725 - acc: 0.9226 - val_loss: 0.2684 - val_acc: 0.8851\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.1779 - acc: 0.9204 - val_loss: 0.2521 - val_acc: 0.8851\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.1663 - acc: 0.9263 - val_loss: 0.3190 - val_acc: 0.8714\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.1704 - acc: 0.9288 - val_loss: 0.2831 - val_acc: 0.8876\n",
      "Epoch 17/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.1826 - acc: 0.9233\n",
      "Epoch 00017: reducing learning rate to 0.00010000000474974513.\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.1855 - acc: 0.9206 - val_loss: 0.3899 - val_acc: 0.8527\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3050 - acc: 0.8751 - val_loss: 0.2512 - val_acc: 0.8864\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.1546 - acc: 0.9407 - val_loss: 0.2310 - val_acc: 0.8951\n",
      "Train loss: 0.158968830316\n",
      "Train accuracy: 0.935242839352\n",
      "Test loss: 0.228905588798\n",
      "Test accuracy: 0.907615480649\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'float' and 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-63cc33c5d701>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVggModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyAngleCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_angle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-6854551f3ca4>\u001b[0m in \u001b[0;36mmyAngleCV\u001b[1;34m(self, X_train, X_angle, X_test, target_train)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0my_train_pred_log\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mtemp_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0my_test_pred_log\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_test_pred_log\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0my_train_pred_log\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_pred_log\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'float' and 'module'"
     ]
    }
   ],
   "source": [
    "model = VggModel(ids)\n",
    "\n",
    "preds=model.myAngleCV(X_train, X_angle, X_test, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
