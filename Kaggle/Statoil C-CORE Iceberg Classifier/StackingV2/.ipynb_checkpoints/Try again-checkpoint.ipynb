{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\n",
    "# Model 2: https://www.kaggle.com/vincento/keras-starter-4l-0-1694-lb-icebergchallenge\n",
    "# Model 3: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193\n",
    "# Model 4: https://www.kaggle.com/wvadim/keras-tf-lb-0-18\n",
    "\n",
    "# ResNet50\n",
    "# InceptionV3\n",
    "# MobileNet\n",
    "# DenseNet\n",
    "# SqueezeNet\n",
    "# InceptionResNetV2\n",
    "# Xception\n",
    "\n",
    "# Simple model: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "# https://www.kaggle.com/henokanh/cnn-batchnormalization-0-1646\n",
    "# https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "# https://www.kaggle.com/cttsai/ensembling-gbms-lb-203/code\n",
    "# https://www.kaggle.com/yuhaichina/single-model-vgg16-mobilenet-lb-0-1568-with-tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "import abc\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers():\n",
    "    def get_angledata(train, test):\n",
    "        train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "        train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "        test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "\n",
    "        X_angle=train['inc_angle']\n",
    "        X_test_angle=test['inc_angle']\n",
    "        \n",
    "        return X_angle, X_test_angle\n",
    "    \n",
    "    def get_imagedata(data):\n",
    "        X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_1\"]])\n",
    "        X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_2\"]])\n",
    "        X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "        X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "        X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "        X_data = np.concatenate([X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "        return X_data\n",
    "    \n",
    "    def get_generator():\n",
    "        # Define the image transformations here\n",
    "        return ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10)\n",
    "    \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_two_inputs(X1, X2, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "        while True:\n",
    "                X1i = genX1.next()\n",
    "                X2i = genX2.next()\n",
    "                #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "                #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "                yield [X1i[0], X2i[1]], X1i[1]\n",
    "                \n",
    "\n",
    "    # Finally create generator\n",
    "    def get_callbacks(filepath, patience=2):\n",
    "        es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "        msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "        return [es, msave, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelBase():\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    def __init__(self, ids = None):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 2\n",
    "        self.ids = ids\n",
    "        self.predictions = None\n",
    "        self.K = 2\n",
    "        \n",
    "        self.model = self.get_model()\n",
    "        \n",
    "    def save_model(self):\n",
    "        name = self.get_name() + datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S') + \".h5\"\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "    def create_submission(self, predict):\n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test['id']\n",
    "        submission['is_iceberg']=preds\n",
    "        submission.to_csv(\"submission-\" + self.get_name() + \".csv\", float_format='%g', index = False)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    #Using K-fold Cross Validation with Data Augmentation.\n",
    "    def train_predict(self, X_train, X_angle, X_test, target_train):\n",
    "        folds = list(StratifiedKFold(n_splits=self.K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "        y_test_pred_log = 0\n",
    "        y_train_pred_log=0\n",
    "        y_valid_pred_log = 0.0*target_train\n",
    "        for j, (train_idx, test_idx) in enumerate(folds):\n",
    "            print('\\n===================FOLD=',j)\n",
    "            X_train_cv = X_train[train_idx]\n",
    "            y_train_cv = target_train[train_idx]\n",
    "            X_holdout = X_train[test_idx]\n",
    "            Y_holdout= target_train[test_idx]\n",
    "\n",
    "            #Angle\n",
    "            X_angle_cv=X_angle[train_idx]\n",
    "            X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "            #define file path and get callbacks\n",
    "            file_path = \"%s_\"%j + self.get_name() + \".hdf5\"\n",
    "            callbacks = Helpers.get_callbacks(filepath=file_path, patience=5)\n",
    "            gen_flow = Helpers.gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "            \n",
    "            galaxyModel= self.get_model()\n",
    "            galaxyModel.fit_generator(\n",
    "                    gen_flow,\n",
    "                    steps_per_epoch=24,\n",
    "                    epochs=self.epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "            #Getting the Best Model\n",
    "            galaxyModel.load_weights(filepath=file_path)\n",
    "            #Getting Training Score\n",
    "            score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "            print('Train loss:', score[0])\n",
    "            print('Train accuracy:', score[1])\n",
    "            #Getting Test Score\n",
    "            score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "\n",
    "            #Getting validation Score.\n",
    "            pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "            y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "            #Getting Test Scores\n",
    "            temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "            y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "            #Getting Train Scores\n",
    "            temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "            y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "        y_test_pred_log=y_test_pred_log/self.K\n",
    "        y_train_pred_log=y_train_pred_log/self.K\n",
    "\n",
    "        print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "        print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "        \n",
    "#         self.plot_results()\n",
    "        \n",
    "        self.predictions = y_test_pred_log \n",
    "        return y_test_pred_log\n",
    "    \n",
    "#     def plot_results(self):\n",
    "#         plt.plot(self.history['acc'])\n",
    "#         plt.plot(self.history['val_acc'])\n",
    "#         plt.title('model accuracy')\n",
    "#         plt.ylabel('accuracy')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "#         # summarize history for loss\n",
    "#         plt.plot(self.history['loss'])\n",
    "#         plt.plot(self.history['val_loss'])\n",
    "#         plt.title('model loss')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        input_2 = Input(shape=[1], name=\"angle\")\n",
    "        angle_layer = Dense(1, )(input_2)\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                     input_shape=X_train.shape[1:], classes=1)\n",
    "        x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "        merge_one = concatenate([x, angle_layer])\n",
    "        merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "        merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "        predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "        model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "        sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"../_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_angle, X_test_angle = Helpers.get_angledata(train, test)\n",
    "X_train = Helpers.get_imagedata(train)\n",
    "X_test = Helpers.get_imagedata(test)\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 8s 314ms/step - loss: 0.6660 - acc: 0.6314 - val_loss: 0.4915 - val_acc: 0.7460\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 6s 238ms/step - loss: 0.4953 - acc: 0.7404 - val_loss: 0.4786 - val_acc: 0.7347\n",
      "Train loss: 0.490264658178\n",
      "Train accuracy: 0.729088639201\n",
      "Test loss: 0.478633190226\n",
      "Test accuracy: 0.734744707422\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 8s 316ms/step - loss: 0.8795 - acc: 0.5184 - val_loss: 0.6784 - val_acc: 0.5605\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.7464 - acc: 0.5283 - val_loss: 0.6360 - val_acc: 0.6567\n",
      "Train loss: 0.635482364989\n",
      "Train accuracy: 0.646326276537\n",
      "Test loss: 0.636023906063\n",
      "Test accuracy: 0.656679151061\n",
      "\n",
      " Train Log Loss Validation=  0.550150008366\n",
      " Test Log Loss Validation=  0.557230431963\n"
     ]
    }
   ],
   "source": [
    "model = VggModel(ids)\n",
    "\n",
    "preds=model.train_predict(X_train, X_angle, X_test, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_submission(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
