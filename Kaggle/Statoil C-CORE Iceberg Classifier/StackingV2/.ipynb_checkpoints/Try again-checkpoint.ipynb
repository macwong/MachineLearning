{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\n",
    "# Model 2: https://www.kaggle.com/vincento/keras-starter-4l-0-1694-lb-icebergchallenge\n",
    "# Model 3: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193\n",
    "\n",
    "# ResNet50\n",
    "# InceptionV3\n",
    "# MobileNet\n",
    "# DenseNet\n",
    "# SqueezeNet\n",
    "# InceptionResNetV2\n",
    "# Xception\n",
    "# LeNet\n",
    "\n",
    "# Simple model: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "# https://www.kaggle.com/henokanh/cnn-batchnormalization-0-1646\n",
    "# https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "# https://www.kaggle.com/cttsai/ensembling-gbms-lb-203/code\n",
    "# https://www.kaggle.com/yuhaichina/single-model-vgg16-mobilenet-lb-0-1568-with-tf\n",
    "# https://www.kaggle.com/wvadim/keras-tf-lb-0-18\n",
    "# https://www.kaggle.com/yekenot/inceptionv3-k-fold-cv-lb-0-1944\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "import abc\n",
    "import cv2\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers():\n",
    "    def get_angledata(train, test):\n",
    "        train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "        train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "        test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "\n",
    "        X_angle=train['inc_angle']\n",
    "        X_test_angle=test['inc_angle']\n",
    "        \n",
    "        angle_min = np.minimum(X_angle.min(), X_test_angle.min())\n",
    "        angle_max = np.maximum(X_angle.max(), X_test_angle.max())\n",
    "        \n",
    "        X_angle = (X_angle - angle_min) / (angle_max - angle_min)\n",
    "        X_test_angle = (X_test_angle - angle_min) / (angle_max - angle_min)\n",
    "        \n",
    "        return X_angle, X_test_angle\n",
    "    \n",
    "    def get_banddata(data):\n",
    "        X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_1\"]])\n",
    "        X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_2\"]])\n",
    "        X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "        X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "        X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "        \n",
    "        return X_band_1, X_band_2, X_band_3, X_band_4, X_band_5\n",
    "\n",
    "    def get_imagedata(train, test):\n",
    "        X_band_1, X_band_2, X_band_3, X_band_4, X_band_5 = Helpers.get_banddata(train)\n",
    "        X_band_test_1, X_band_test_2, X_band_test_3, X_band_test_4, X_band_test_5 = Helpers.get_banddata(test)\n",
    "        \n",
    "        band_3_min = np.minimum(X_band_3.min(), X_band_test_3.min())\n",
    "        band_4_min = np.minimum(X_band_4.min(), X_band_test_4.min())\n",
    "        band_5_min = np.minimum(X_band_5.min(), X_band_test_5.min())\n",
    "\n",
    "        band_3_max = np.maximum(X_band_3.max(), X_band_test_3.max())\n",
    "        band_4_max = np.maximum(X_band_4.max(), X_band_test_4.max())\n",
    "        band_5_max = np.maximum(X_band_5.max(), X_band_test_5.max())\n",
    "\n",
    "#         X_band_3 = (X_band_3 - band_3_min) / (band_3_max - band_3_min)\n",
    "#         X_band_4 = (X_band_4 - band_4_min) / (band_4_max - band_4_min)\n",
    "#         X_band_5 = (X_band_5 - band_5_min) / (band_5_max - band_5_min)\n",
    "        \n",
    "#         X_band_test_3 = (X_band_test_3 - band_3_min) / (band_3_max - band_3_min)\n",
    "#         X_band_test_4 = (X_band_test_4 - band_4_min) / (band_4_max - band_4_min)\n",
    "#         X_band_test_5 = (X_band_test_5 - band_5_min) / (band_5_max - band_5_min)\n",
    "        \n",
    "        X_train = np.concatenate([X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "        X_test = np.concatenate([X_band_test_3[:, :, :, np.newaxis],X_band_test_4[:, :, :, np.newaxis],X_band_test_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "        return X_train, X_test\n",
    "    \n",
    "    def get_generator():\n",
    "        # Define the image transformations here\n",
    "        return ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10)\n",
    "    \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_two_inputs(X1, X2, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "        while True:\n",
    "                X1i = genX1.next()\n",
    "                X2i = genX2.next()\n",
    "                #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "                #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "                yield [X1i[0], X2i[1]], X1i[1]\n",
    "                \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_one_input(X1, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        return genX1\n",
    "                \n",
    "\n",
    "    # Finally create generator\n",
    "    def get_callbacks(filepath, patience=2):\n",
    "        es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "        msave = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', mode='min')\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "        return [es, msave, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"../_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_angle, X_test_angle = Helpers.get_angledata(train, test)\n",
    "X_train, X_test = Helpers.get_imagedata(train, test)\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelBase():\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    def __init__(self, ids = None):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 100\n",
    "        self.ids = ids\n",
    "        self.predictions = None\n",
    "        self.K = 5\n",
    "        \n",
    "        self.model = self.get_model()\n",
    "        \n",
    "    def save_model(self):\n",
    "        name = self.get_name() + datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S') + \".h5\"\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "    def create_submission(self, predict):\n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test['id']\n",
    "        submission['is_iceberg']=preds\n",
    "        submission.to_csv(\"submission-\" + self.get_name() + \".csv\", float_format='%g', index = False)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        pass\n",
    "    \n",
    "    def get_size(self):\n",
    "        return -1\n",
    "    \n",
    "        \n",
    "    #Using K-fold Cross Validation with Data Augmentation.\n",
    "    def train_predict(self, X_train, X_angle, X_test, target_train):\n",
    "        img_size = self.get_size()\n",
    "        \n",
    "        X_train_resized = X_train\n",
    "        X_test_resized = X_test\n",
    "            \n",
    "        if img_size > 0:\n",
    "            X_train_resized = np.empty(shape = (X_train.shape[0], img_size, img_size, 3))\n",
    "            X_test_resized = np.empty(shape = (X_test.shape[0], img_size, img_size, 3))\n",
    "            count = 0\n",
    "            for img in X_train:\n",
    "                new_img = cv2.resize(img, (img_size, img_size))\n",
    "                X_train_resized[count] = new_img\n",
    "                count += 1\n",
    "\n",
    "            count = 0\n",
    "            for img in X_test:\n",
    "                new_img = cv2.resize(img, (img_size, img_size))\n",
    "                X_test_resized[count] = new_img\n",
    "                count += 1\n",
    "                \n",
    "        print(\"Orig:\", X_train.shape)\n",
    "        print(\"Resized:\", X_train_resized.shape)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.K, shuffle=True, random_state=16).split(X_train_resized, target_train))\n",
    "        y_test_pred_log = 0\n",
    "        y_train_pred_log=0\n",
    "        y_valid_pred_log = 0.0*target_train\n",
    "        for j, (train_idx, test_idx) in enumerate(folds):\n",
    "            print('\\n===================FOLD=',j)\n",
    "            X_train_cv = X_train_resized[train_idx]\n",
    "            y_train_cv = target_train[train_idx]\n",
    "            X_holdout = X_train_resized[test_idx]\n",
    "            Y_holdout= target_train[test_idx]\n",
    "\n",
    "            #Angle\n",
    "            X_angle_cv=X_angle[train_idx]\n",
    "            X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "            #define file path and get callbacks\n",
    "            file_path = \"%s_\"%j + self.get_name() + \".hdf5\"\n",
    "            callbacks = Helpers.get_callbacks(filepath=file_path, patience=5)\n",
    "            gen_flow = Helpers.gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "            \n",
    "            galaxyModel = self.get_model()\n",
    "            \n",
    "#             if galaxyModel.model is not None:\n",
    "#                 input_shape = len(galaxyModel.model.input_shape)\n",
    "#             else:\n",
    "            input_shape = len(galaxyModel.input_shape)\n",
    "                \n",
    "            train_array = [X_train_resized,X_angle]\n",
    "            train_array_cv = [X_train_cv,X_angle_cv]\n",
    "            holdout_array = [X_holdout,X_angle_hold]\n",
    "            test_array = [X_test_resized, X_test_angle]\n",
    "            \n",
    "            if input_shape != 2:\n",
    "                train_array = X_train_resized\n",
    "                train_array_cv = X_train_cv\n",
    "                holdout_array = X_holdout\n",
    "                test_array = X_test_resized\n",
    "                gen_flow = Helpers.gen_flow_for_one_input(X_train_cv, y_train_cv)\n",
    "                \n",
    "            galaxyModel.fit_generator(\n",
    "                    gen_flow,\n",
    "                    steps_per_epoch=24,\n",
    "                    epochs=self.epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=(holdout_array, Y_holdout),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "            #Getting the Best Model\n",
    "            galaxyModel.load_weights(filepath=file_path)\n",
    "            #Getting Training Score\n",
    "            score = galaxyModel.evaluate(train_array_cv, y_train_cv, verbose=0)\n",
    "            print('Train loss:', score[0])\n",
    "            print('Train accuracy:', score[1])\n",
    "            #Getting Test Score\n",
    "            score = galaxyModel.evaluate(holdout_array, Y_holdout, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "\n",
    "            #Getting validation Score.\n",
    "            pred_valid=galaxyModel.predict(holdout_array)\n",
    "            y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "            #Getting Test Scores\n",
    "            temp_test=galaxyModel.predict(test_array)\n",
    "            y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "            #Getting Train Scores\n",
    "            temp_train=galaxyModel.predict(train_array)\n",
    "            y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "        y_test_pred_log=y_test_pred_log/self.K\n",
    "        y_train_pred_log=y_train_pred_log/self.K\n",
    "\n",
    "        print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "        print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "        \n",
    "#         self.plot_results\n",
    "        self.create_submission(preds)\n",
    "        \n",
    "        self.predictions = y_test_pred_log \n",
    "        return y_test_pred_log\n",
    "    \n",
    "#     def plot_results(self):\n",
    "#         plt.plot(self.history['acc'])\n",
    "#         plt.plot(self.history['val_acc'])\n",
    "#         plt.title('model accuracy')\n",
    "#         plt.ylabel('accuracy')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "#         # summarize history for loss\n",
    "#         plt.plot(self.history['loss'])\n",
    "#         plt.plot(self.history['val_loss'])\n",
    "#         plt.title('model loss')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VggModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        input_2 = Input(shape=[1], name=\"angle\")\n",
    "        angle_layer = Dense(1, )(input_2)\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                     input_shape=X_train.shape[1:], classes=1)\n",
    "        x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "        merge_one = concatenate([x, angle_layer])\n",
    "        merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "        merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "        predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "        model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "        sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        base_model=Sequential()\n",
    "\n",
    "        # CNN 1\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "        base_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 2\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 3\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        #CNN 4\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        # You must flatten the data for the dense layers\n",
    "        base_model.add(Flatten())\n",
    "\n",
    "        #Dense 1\n",
    "        base_model.add(Dense(512, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        #Dense 2\n",
    "        base_model.add(Dense(256, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # Output \n",
    "        base_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        optimizer = Adam(lr=0.001, decay=0.0)\n",
    "        base_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        return base_model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchNormModel(ModelBase):\n",
    "    def ConvBlock(model, layers, filters):\n",
    "        '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "            model.add(BatchNormalization(axis=3))\n",
    "\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    def get_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input image: 75x75x3\n",
    "        model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "        BatchNormModel.ConvBlock(model, 1, 32)\n",
    "        # 37x37x32\n",
    "        BatchNormModel.ConvBlock(model, 1, 64)\n",
    "        # 18x18x64\n",
    "        BatchNormModel.ConvBlock(model, 1, 128)\n",
    "        # 9x9x128\n",
    "        BatchNormModel.ConvBlock(model, 1, 128)\n",
    "        # 4x4x128\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        # 4x4x2\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        \n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"batchnorm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "class MobileNetModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        image_size = self.get_size()\n",
    "        img_input = keras.layers.Input(shape=(image_size, image_size, 3))\n",
    "        mobile_model = MobileNet(input_tensor = img_input, weights=None, alpha=1.0, include_top=True, classes=1)\n",
    "\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        mobile_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        \n",
    "        return mobile_model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"mobilenet\"\n",
    "    \n",
    "    def get_size(self):\n",
    "        return 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "class InceptionV3Model(ModelBase):\n",
    "    def get_model(self):\n",
    "#         input_tensor = Input(shape=(self.get_size(), self.get_size(), 3))\n",
    "#         base_model = InceptionV3(include_top=False,\n",
    "#                        weights=None,\n",
    "#                        input_shape=(self.get_size(), self.get_size(), 3))\n",
    "        \n",
    "#         bn = BatchNormalization()(input_tensor)\n",
    "#         x = base_model(bn)\n",
    "#         x = GlobalAveragePooling2D()(x)\n",
    "#         x = Dropout(0.5)(x)\n",
    "#         output = Dense(1, activation='sigmoid')(x)\n",
    "#         model = Model(input_tensor, output)\n",
    "\n",
    "        v3_model = InceptionV3(include_top=False, weights=None, input_shape=(self.get_size(), self.get_size(), 3))\n",
    "\n",
    "        x = v3_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(512, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        predictions = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        model = Model(inputs=v3_model.input, outputs=predictions)\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        return model\n",
    "        \n",
    "    def get_name(self):\n",
    "        return \"inceptionv3\"\n",
    "    \n",
    "    def get_size(self):\n",
    "        return 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig: (1604, 75, 75, 3)\n",
      "Resized: (1604, 75, 75, 3)\n",
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 11s 462ms/step - loss: 0.7632 - acc: 0.5080 - val_loss: 0.6948 - val_acc: 0.5248\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 5s 215ms/step - loss: 0.7205 - acc: 0.4891 - val_loss: 0.6892 - val_acc: 0.5311\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 5s 211ms/step - loss: 0.7057 - acc: 0.5072 - val_loss: 0.6802 - val_acc: 0.6118\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 5s 214ms/step - loss: 0.7074 - acc: 0.5041 - val_loss: 0.6744 - val_acc: 0.6273\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 5s 197ms/step - loss: 0.7068 - acc: 0.5178 - val_loss: 0.6792 - val_acc: 0.5807\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 5s 213ms/step - loss: 0.6798 - acc: 0.5465 - val_loss: 0.6290 - val_acc: 0.6242\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 5s 228ms/step - loss: 0.7123 - acc: 0.5405 - val_loss: 0.6788 - val_acc: 0.5311\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 5s 216ms/step - loss: 0.6468 - acc: 0.6178 - val_loss: 0.6228 - val_acc: 0.5870\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 5s 216ms/step - loss: 0.6086 - acc: 0.6570 - val_loss: 0.5048 - val_acc: 0.7360\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 5s 212ms/step - loss: 0.5635 - acc: 0.6844 - val_loss: 0.4531 - val_acc: 0.7826\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 5s 198ms/step - loss: 0.6255 - acc: 0.6265 - val_loss: 0.6886 - val_acc: 0.5280\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 5s 199ms/step - loss: 0.6935 - acc: 0.5372 - val_loss: 0.6795 - val_acc: 0.5870\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 5s 199ms/step - loss: 0.7052 - acc: 0.4863 - val_loss: 0.6941 - val_acc: 0.4720\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 6s 229ms/step - loss: 0.6840 - acc: 0.5490 - val_loss: 0.6600 - val_acc: 0.7267\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 5s 200ms/step - loss: 0.6435 - acc: 0.6459 - val_loss: 0.7267 - val_acc: 0.5311\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.6028 - acc: 0.6709 - val_loss: 0.4893 - val_acc: 0.7453\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 5s 200ms/step - loss: 0.5910 - acc: 0.6643 - val_loss: 0.5169 - val_acc: 0.7857\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 5s 217ms/step - loss: 0.4930 - acc: 0.7633 - val_loss: 0.3981 - val_acc: 0.8199\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 5s 214ms/step - loss: 0.3974 - acc: 0.8174 - val_loss: 0.3180 - val_acc: 0.8540\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.4664 - acc: 0.7874 - val_loss: 0.4657 - val_acc: 0.7764\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 6s 233ms/step - loss: 0.3543 - acc: 0.8347 - val_loss: 0.3772 - val_acc: 0.8106\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3969 - acc: 0.7978 - val_loss: 0.3106 - val_acc: 0.8602\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 5s 200ms/step - loss: 0.3280 - acc: 0.8572 - val_loss: 0.3159 - val_acc: 0.8509\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 5s 214ms/step - loss: 0.3284 - acc: 0.8372 - val_loss: 0.2580 - val_acc: 0.8882\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.3255 - acc: 0.8578 - val_loss: 0.2989 - val_acc: 0.8602\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.3160 - acc: 0.8339 - val_loss: 0.2742 - val_acc: 0.8634\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.3424 - acc: 0.8280 - val_loss: 0.2582 - val_acc: 0.8665\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 6s 231ms/step - loss: 0.2864 - acc: 0.8746 - val_loss: 0.2849 - val_acc: 0.8634\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 5s 219ms/step - loss: 0.2882 - acc: 0.8794 - val_loss: 0.2517 - val_acc: 0.8913\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.2466 - acc: 0.8957 - val_loss: 0.2415 - val_acc: 0.8913\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.4255 - acc: 0.7869 - val_loss: 0.4874 - val_acc: 0.7578\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.3940 - acc: 0.8220 - val_loss: 0.2617 - val_acc: 0.9037\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.3347 - acc: 0.8565 - val_loss: 0.2692 - val_acc: 0.8571\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 5s 218ms/step - loss: 0.2660 - acc: 0.8728 - val_loss: 0.2184 - val_acc: 0.8913\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 6s 231ms/step - loss: 0.2304 - acc: 0.9000 - val_loss: 0.2710 - val_acc: 0.8758\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.3204 - acc: 0.8469 - val_loss: 0.3071 - val_acc: 0.8882\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3178 - acc: 0.8546 - val_loss: 0.2085 - val_acc: 0.9224\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 5s 217ms/step - loss: 0.2550 - acc: 0.8944 - val_loss: 0.2035 - val_acc: 0.9317\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.3881 - acc: 0.8072 - val_loss: 0.2602 - val_acc: 0.8634\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.2731 - acc: 0.8781 - val_loss: 0.2434 - val_acc: 0.8882\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.2823 - acc: 0.8800 - val_loss: 0.2216 - val_acc: 0.9006\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 6s 231ms/step - loss: 0.2456 - acc: 0.8846 - val_loss: 0.2141 - val_acc: 0.9037\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.2542 - acc: 0.8944 - val_loss: 0.2184 - val_acc: 0.9006\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.2937 - acc: 0.8658 - val_loss: 0.3616 - val_acc: 0.8012\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.2808 - acc: 0.8852 - val_loss: 0.2216 - val_acc: 0.9130\n",
      "Epoch 46/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2458 - acc: 0.8995\n",
      "Epoch 00046: reducing learning rate to 0.00010000000474974513.\n",
      "24/24 [==============================] - 6s 246ms/step - loss: 0.2417 - acc: 0.9015 - val_loss: 0.2349 - val_acc: 0.8913\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 5s 201ms/step - loss: 0.2811 - acc: 0.8767 - val_loss: 0.2249 - val_acc: 0.9006\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 5s 202ms/step - loss: 0.2253 - acc: 0.9100 - val_loss: 0.2165 - val_acc: 0.9006\n",
      "Train loss: 0.204329945368\n",
      "Train accuracy: 0.914976599064\n",
      "Test loss: 0.203463749403\n",
      "Test accuracy: 0.931677018634\n",
      "\n",
      "===================FOLD= 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-e68978fe55ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# model = InceptionV3Model(ids)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_angle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-b04e0b6c72c3>\u001b[0m in \u001b[0;36mtrain_predict\u001b[1;34m(self, X_train, X_angle, X_test, target_train)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mgen_flow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_flow_for_two_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_angle_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0mgalaxyModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;31m#             if galaxyModel.model is not None:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-4531ab76bb18>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mangle_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         base_model = VGG16(weights='imagenet', include_top=False, \n\u001b[1;32m----> 6\u001b[1;33m                      input_shape=X_train.shape[1:], classes=1)\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'block5_pool'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[0;32m    173\u001b[0m                                     \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                                     file_hash='6d6bbae143d832006294945121d1f1fc')\n\u001b[1;32m--> 175\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'theano'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mlayer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_all_kernels_in_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name)\u001b[0m\n\u001b[0;32m   2620\u001b[0m             \u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2621\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2622\u001b[1;33m             \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   3141\u001b[0m                              ' elements.')\n\u001b[0;32m   3142\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3143\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2250\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2251\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2252\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 182\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    183\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1115\u001b[0m                 run_metadata):\n\u001b[0;32m   1116\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[1;32m-> 1166\u001b[1;33m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[0;32m   1167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = VggModel(ids)\n",
    "# model = SimpleModel(ids)\n",
    "# model = BatchNormModel(ids)\n",
    "# model = MobileNetModel(ids)\n",
    "# model = InceptionV3Model(ids)\n",
    "\n",
    "preds=model.train_predict(X_train, X_angle, X_test, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
