{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\n",
    "# Model 2: https://www.kaggle.com/vincento/keras-starter-4l-0-1694-lb-icebergchallenge\n",
    "# Model 3: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193\n",
    "\n",
    "# ResNet50\n",
    "# InceptionV3\n",
    "# MobileNet\n",
    "# DenseNet\n",
    "# SqueezeNet\n",
    "# InceptionResNetV2\n",
    "# Xception\n",
    "# LeNet\n",
    "\n",
    "# Simple model: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "# https://www.kaggle.com/henokanh/cnn-batchnormalization-0-1646\n",
    "# https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "# https://www.kaggle.com/cttsai/ensembling-gbms-lb-203/code\n",
    "# https://www.kaggle.com/yuhaichina/single-model-vgg16-mobilenet-lb-0-1568-with-tf\n",
    "# https://www.kaggle.com/wvadim/keras-tf-lb-0-18\n",
    "# https://www.kaggle.com/yekenot/inceptionv3-k-fold-cv-lb-0-1944\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "import abc\n",
    "import cv2\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers():\n",
    "    def get_angledata(train, test):\n",
    "        train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "        train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "        test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "\n",
    "        X_angle=train['inc_angle']\n",
    "        X_test_angle=test['inc_angle']\n",
    "        \n",
    "        return X_angle, X_test_angle\n",
    "    \n",
    "    def get_imagedata(data):\n",
    "        X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_1\"]])\n",
    "        X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_2\"]])\n",
    "        X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "        X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "        X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "        X_data = np.concatenate([X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "        return X_data\n",
    "    \n",
    "    def get_generator():\n",
    "        # Define the image transformations here\n",
    "        return ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10)\n",
    "    \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_two_inputs(X1, X2, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "        while True:\n",
    "                X1i = genX1.next()\n",
    "                X2i = genX2.next()\n",
    "                #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "                #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "                yield [X1i[0], X2i[1]], X1i[1]\n",
    "                \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_one_input(X1, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        return genX1\n",
    "                \n",
    "\n",
    "    # Finally create generator\n",
    "    def get_callbacks(filepath, patience=2):\n",
    "        es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "        msave = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', mode='min')\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "        return [es, msave, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"../_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_angle, X_test_angle = Helpers.get_angledata(train, test)\n",
    "X_train = Helpers.get_imagedata(train)\n",
    "X_test = Helpers.get_imagedata(test)\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBase():\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    def __init__(self, ids = None):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 100\n",
    "        self.ids = ids\n",
    "        self.predictions = None\n",
    "        self.K = 5\n",
    "        \n",
    "        self.model = self.get_model()\n",
    "        \n",
    "    def save_model(self):\n",
    "        name = self.get_name() + datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S') + \".h5\"\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "    def create_submission(self, predict):\n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test['id']\n",
    "        submission['is_iceberg']=preds\n",
    "        submission.to_csv(\"submission-\" + self.get_name() + \".csv\", float_format='%g', index = False)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        pass\n",
    "    \n",
    "    def get_size(self):\n",
    "        return -1\n",
    "    \n",
    "        \n",
    "    #Using K-fold Cross Validation with Data Augmentation.\n",
    "    def train_predict(self, X_train, X_angle, X_test, target_train):\n",
    "        img_size = self.get_size()\n",
    "        \n",
    "        X_train_resized = X_train\n",
    "        X_test_resized = X_test\n",
    "            \n",
    "        if img_size > 0:\n",
    "            X_train_resized = np.empty(shape = (X_train.shape[0], img_size, img_size, 3))\n",
    "            X_test_resized = np.empty(shape = (X_test.shape[0], img_size, img_size, 3))\n",
    "            count = 0\n",
    "            for img in X_train:\n",
    "                new_img = cv2.resize(img, (img_size, img_size))\n",
    "                X_train_resized[count] = new_img\n",
    "                count += 1\n",
    "\n",
    "            count = 0\n",
    "            for img in X_test:\n",
    "                new_img = cv2.resize(img, (img_size, img_size))\n",
    "                X_test_resized[count] = new_img\n",
    "                count += 1\n",
    "\n",
    "        print(\"Orig:\", X_train.shape)\n",
    "        print(\"Resized:\", X_train_resized.shape)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.K, shuffle=True, random_state=16).split(X_train_resized, target_train))\n",
    "        y_test_pred_log = 0\n",
    "        y_train_pred_log=0\n",
    "        y_valid_pred_log = 0.0*target_train\n",
    "        for j, (train_idx, test_idx) in enumerate(folds):\n",
    "            print('\\n===================FOLD=',j)\n",
    "            X_train_cv = X_train_resized[train_idx]\n",
    "            y_train_cv = target_train[train_idx]\n",
    "            X_holdout = X_train_resized[test_idx]\n",
    "            Y_holdout= target_train[test_idx]\n",
    "\n",
    "            #Angle\n",
    "            X_angle_cv=X_angle[train_idx]\n",
    "            X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "            #define file path and get callbacks\n",
    "            file_path = \"%s_\"%j + self.get_name() + \".hdf5\"\n",
    "            callbacks = Helpers.get_callbacks(filepath=file_path, patience=5)\n",
    "            gen_flow = Helpers.gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "            \n",
    "            galaxyModel = self.get_model()\n",
    "            \n",
    "#             if galaxyModel.model is not None:\n",
    "#                 input_shape = len(galaxyModel.model.input_shape)\n",
    "#             else:\n",
    "            input_shape = len(galaxyModel.input_shape)\n",
    "                \n",
    "            train_array = [X_train_resized,X_angle]\n",
    "            train_array_cv = [X_train_cv,X_angle_cv]\n",
    "            holdout_array = [X_holdout,X_angle_hold]\n",
    "            test_array = [X_test_resized, X_test_angle]\n",
    "            \n",
    "            if input_shape != 2:\n",
    "                train_array = X_train_resized\n",
    "                train_array_cv = X_train_cv\n",
    "                holdout_array = X_holdout\n",
    "                test_array = X_test_resized\n",
    "                gen_flow = Helpers.gen_flow_for_one_input(X_train_cv, y_train_cv)\n",
    "                \n",
    "            galaxyModel.fit_generator(\n",
    "                    gen_flow,\n",
    "                    steps_per_epoch=24,\n",
    "                    epochs=self.epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=(holdout_array, Y_holdout),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "            #Getting the Best Model\n",
    "            galaxyModel.load_weights(filepath=file_path)\n",
    "            #Getting Training Score\n",
    "            score = galaxyModel.evaluate(train_array_cv, y_train_cv, verbose=0)\n",
    "            print('Train loss:', score[0])\n",
    "            print('Train accuracy:', score[1])\n",
    "            #Getting Test Score\n",
    "            score = galaxyModel.evaluate(holdout_array, Y_holdout, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "\n",
    "            #Getting validation Score.\n",
    "            pred_valid=galaxyModel.predict(holdout_array)\n",
    "            y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "            #Getting Test Scores\n",
    "            temp_test=galaxyModel.predict(test_array)\n",
    "            y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "            #Getting Train Scores\n",
    "            temp_train=galaxyModel.predict(train_array)\n",
    "            y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "        y_test_pred_log=y_test_pred_log/self.K\n",
    "        y_train_pred_log=y_train_pred_log/self.K\n",
    "\n",
    "        print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "        print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "        \n",
    "#         self.plot_results\n",
    "        self.create_submission(preds)\n",
    "        \n",
    "        self.predictions = y_test_pred_log \n",
    "        return y_test_pred_log\n",
    "    \n",
    "#     def plot_results(self):\n",
    "#         plt.plot(self.history['acc'])\n",
    "#         plt.plot(self.history['val_acc'])\n",
    "#         plt.title('model accuracy')\n",
    "#         plt.ylabel('accuracy')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "#         # summarize history for loss\n",
    "#         plt.plot(self.history['loss'])\n",
    "#         plt.plot(self.history['val_loss'])\n",
    "#         plt.title('model loss')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        input_2 = Input(shape=[1], name=\"angle\")\n",
    "        angle_layer = Dense(1, )(input_2)\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                     input_shape=X_train.shape[1:], classes=1)\n",
    "        x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "        merge_one = concatenate([x, angle_layer])\n",
    "        merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "        merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "        predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "        model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "        sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        base_model=Sequential()\n",
    "\n",
    "        # CNN 1\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "        base_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 2\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 3\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        #CNN 4\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        # You must flatten the data for the dense layers\n",
    "        base_model.add(Flatten())\n",
    "\n",
    "        #Dense 1\n",
    "        base_model.add(Dense(512, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        #Dense 2\n",
    "        base_model.add(Dense(256, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # Output \n",
    "        base_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        optimizer = Adam(lr=0.001, decay=0.0)\n",
    "        base_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        return base_model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchNormModel(ModelBase):\n",
    "    def ConvBlock(model, layers, filters):\n",
    "        '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "            model.add(BatchNormalization(axis=3))\n",
    "\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    def get_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input image: 75x75x3\n",
    "        model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "        BatchNormModel.ConvBlock(model, 1, 32)\n",
    "        # 37x37x32\n",
    "        BatchNormModel.ConvBlock(model, 1, 64)\n",
    "        # 18x18x64\n",
    "        BatchNormModel.ConvBlock(model, 1, 128)\n",
    "        # 9x9x128\n",
    "        BatchNormModel.ConvBlock(model, 1, 128)\n",
    "        # 4x4x128\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        # 4x4x2\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        \n",
    "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"batchnorm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import MobileNet\n",
    "\n",
    "class MobileNetModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        image_size = self.get_size()\n",
    "        img_input = keras.layers.Input(shape=(image_size, image_size, 3))\n",
    "        mobile_model = MobileNet(input_tensor = img_input, weights=None, alpha=1.0, include_top=True, classes=1)\n",
    "\n",
    "        optimizer = Adam(lr=0.001)\n",
    "        mobile_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "        \n",
    "        return mobile_model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"mobilenet\"\n",
    "    \n",
    "    def get_size(self):\n",
    "        return 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-204-8deba83dd033>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model = BatchNormModel(ids)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMobileNetModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_angle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-197-c89099126575>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ids)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-203-eb487097f2c8>\u001b[0m in \u001b[0;36mget_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMobileNetModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModelBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mimage_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mimg_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mmobile_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_size' is not defined"
     ]
    }
   ],
   "source": [
    "# model = VggModel(ids)\n",
    "# model = SimpleModel(ids)\n",
    "# model = BatchNormModel(ids)\n",
    "\n",
    "model = MobileNetModel(ids)\n",
    "preds=model.train_predict(X_train, X_angle, X_test, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig: (1604, 75, 75, 3)\n",
      "Resized: (1604, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "img_size = 128\n",
    "X_train_resized = np.empty(shape = (X_train.shape[0], 128, 128, 3))\n",
    "X_test_resized = np.empty(shape = (X_test.shape[0], 128, 128, 3))\n",
    "if img_size > 0:\n",
    "    count = 0\n",
    "    for img in X_train:\n",
    "        new_img = cv2.resize(img, (img_size, img_size))\n",
    "        X_train_resized[count] = new_img\n",
    "        count += 1\n",
    "\n",
    "    count = 0\n",
    "    for img in X_test:\n",
    "        new_img = cv2.resize(img, (img_size, img_size))\n",
    "        X_test_resized[count] = new_img\n",
    "        count += 1\n",
    "\n",
    "print(\"Orig:\", X_train.shape)\n",
    "print(\"Resized:\", X_train_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
