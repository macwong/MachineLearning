{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1: https://www.kaggle.com/devm2024/transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\n",
    "# Model 2: https://www.kaggle.com/vincento/keras-starter-4l-0-1694-lb-icebergchallenge\n",
    "# Model 3: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193\n",
    "# Model 4: https://www.kaggle.com/wvadim/keras-tf-lb-0-18\n",
    "\n",
    "# ResNet50\n",
    "# InceptionV3\n",
    "# MobileNet\n",
    "# DenseNet\n",
    "# SqueezeNet\n",
    "# InceptionResNetV2\n",
    "# Xception\n",
    "\n",
    "# Simple model: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d\n",
    "# https://www.kaggle.com/henokanh/cnn-batchnormalization-0-1646\n",
    "# https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl\n",
    "# https://www.kaggle.com/cttsai/ensembling-gbms-lb-203/code\n",
    "# https://www.kaggle.com/yuhaichina/single-model-vgg16-mobilenet-lb-0-1568-with-tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "import abc\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helpers():\n",
    "    def get_angledata(train, test):\n",
    "        train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "        train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "        test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "\n",
    "        X_angle=train['inc_angle']\n",
    "        X_test_angle=test['inc_angle']\n",
    "        \n",
    "        return X_angle, X_test_angle\n",
    "    \n",
    "    def get_imagedata(data):\n",
    "        X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_1\"]])\n",
    "        X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\"band_2\"]])\n",
    "        X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "        X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "        X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "        X_data = np.concatenate([X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "        return X_data\n",
    "    \n",
    "    def get_generator():\n",
    "        # Define the image transformations here\n",
    "        return ImageDataGenerator(horizontal_flip = True,\n",
    "                                 vertical_flip = True,\n",
    "                                 width_shift_range = 0.,\n",
    "                                 height_shift_range = 0.,\n",
    "                                 channel_shift_range=0,\n",
    "                                 zoom_range = 0.2,\n",
    "                                 rotation_range = 10)\n",
    "    \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_two_inputs(X1, X2, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "        while True:\n",
    "                X1i = genX1.next()\n",
    "                X2i = genX2.next()\n",
    "                #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "                #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "                yield [X1i[0], X2i[1]], X1i[1]\n",
    "                \n",
    "    # Here is the function that merges our two generators\n",
    "    # We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "    def gen_flow_for_one_input(X1, y, batch_size = 64):\n",
    "        gen = Helpers.get_generator()\n",
    "        genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "        return genX1\n",
    "                \n",
    "\n",
    "    # Finally create generator\n",
    "    def get_callbacks(filepath, patience=2):\n",
    "        es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "        msave = ModelCheckpoint(filepath, save_best_only=True, monitor='val_loss', mode='min')\n",
    "        reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')\n",
    "        return [es, msave, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelBase():\n",
    "    __metaclass__ = abc.ABCMeta\n",
    "    \n",
    "    def __init__(self, ids = None):\n",
    "        self.batch_size = 64\n",
    "        self.epochs = 100\n",
    "        self.ids = ids\n",
    "        self.predictions = None\n",
    "        self.K = 5\n",
    "        \n",
    "        self.model = self.get_model()\n",
    "        \n",
    "    def save_model(self):\n",
    "        name = self.get_name() + datetime.datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S') + \".h5\"\n",
    "        self.model.save_weights(name)\n",
    "        \n",
    "    def create_submission(self, predict):\n",
    "        submission = pd.DataFrame()\n",
    "        submission['id']=test['id']\n",
    "        submission['is_iceberg']=preds\n",
    "        submission.to_csv(\"submission-\" + self.get_name() + \".csv\", float_format='%g', index = False)\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def get_model(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_name(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "    #Using K-fold Cross Validation with Data Augmentation.\n",
    "    def train_predict(self, X_train, X_angle, X_test, target_train):\n",
    "        folds = list(StratifiedKFold(n_splits=self.K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "        y_test_pred_log = 0\n",
    "        y_train_pred_log=0\n",
    "        y_valid_pred_log = 0.0*target_train\n",
    "        for j, (train_idx, test_idx) in enumerate(folds):\n",
    "            print('\\n===================FOLD=',j)\n",
    "            X_train_cv = X_train[train_idx]\n",
    "            y_train_cv = target_train[train_idx]\n",
    "            X_holdout = X_train[test_idx]\n",
    "            Y_holdout= target_train[test_idx]\n",
    "\n",
    "            #Angle\n",
    "            X_angle_cv=X_angle[train_idx]\n",
    "            X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "            #define file path and get callbacks\n",
    "            file_path = \"%s_\"%j + self.get_name() + \".hdf5\"\n",
    "            callbacks = Helpers.get_callbacks(filepath=file_path, patience=5)\n",
    "            gen_flow = Helpers.gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "            \n",
    "            galaxyModel= self.get_model()\n",
    "            \n",
    "            input_shape = len(galaxyModel.model.input_shape)\n",
    "            train_array = [X_train,X_angle]\n",
    "            train_array_cv = [X_train_cv,X_angle_cv]\n",
    "            holdout_array = [X_holdout,X_angle_hold]\n",
    "            test_array = [X_test, X_test_angle]\n",
    "            \n",
    "            if input_shape != 2:\n",
    "                train_array = X_train\n",
    "                train_array_cv = X_train_cv\n",
    "                holdout_array = X_holdout\n",
    "                test_array = X_test\n",
    "                gen_flow = Helpers.gen_flow_for_one_input(X_train_cv, y_train_cv)\n",
    "                \n",
    "            galaxyModel.fit_generator(\n",
    "                    gen_flow,\n",
    "                    steps_per_epoch=24,\n",
    "                    epochs=self.epochs,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data=(holdout_array, Y_holdout),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "            #Getting the Best Model\n",
    "            galaxyModel.load_weights(filepath=file_path)\n",
    "            #Getting Training Score\n",
    "            score = galaxyModel.evaluate(train_array_cv, y_train_cv, verbose=0)\n",
    "            print('Train loss:', score[0])\n",
    "            print('Train accuracy:', score[1])\n",
    "            #Getting Test Score\n",
    "            score = galaxyModel.evaluate(holdout_array, Y_holdout, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "\n",
    "            #Getting validation Score.\n",
    "            pred_valid=galaxyModel.predict(holdout_array)\n",
    "            y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "            #Getting Test Scores\n",
    "            temp_test=galaxyModel.predict(test_array)\n",
    "            y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "            #Getting Train Scores\n",
    "            temp_train=galaxyModel.predict(train_array)\n",
    "            y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "        y_test_pred_log=y_test_pred_log/self.K\n",
    "        y_train_pred_log=y_train_pred_log/self.K\n",
    "\n",
    "        print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "        print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "        \n",
    "#         self.plot_results\n",
    "        self.create_submission(preds)\n",
    "        \n",
    "        self.predictions = y_test_pred_log \n",
    "        return y_test_pred_log\n",
    "    \n",
    "#     def plot_results(self):\n",
    "#         plt.plot(self.history['acc'])\n",
    "#         plt.plot(self.history['val_acc'])\n",
    "#         plt.title('model accuracy')\n",
    "#         plt.ylabel('accuracy')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "#         # summarize history for loss\n",
    "#         plt.plot(self.history['loss'])\n",
    "#         plt.plot(self.history['val_loss'])\n",
    "#         plt.title('model loss')\n",
    "#         plt.ylabel('loss')\n",
    "#         plt.xlabel('epoch')\n",
    "#         plt.legend(['train', 'test'], loc='upper left')\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        input_2 = Input(shape=[1], name=\"angle\")\n",
    "        angle_layer = Dense(1, )(input_2)\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                     input_shape=X_train.shape[1:], classes=1)\n",
    "        x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "        merge_one = concatenate([x, angle_layer])\n",
    "        merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "        merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "        merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "        predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "        model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "        sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"vgg16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleModel(ModelBase):\n",
    "    def get_model(self):\n",
    "        \n",
    "        \n",
    "#         input_2 = Input(shape=[1], name=\"angle\")\n",
    "#         angle_layer = Dense(1, )(input_2)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         base_model = VGG16(weights='imagenet', include_top=False, \n",
    "#                      input_shape=X_train.shape[1:], classes=1)\n",
    "        \n",
    "        \n",
    "        base_model=Sequential()\n",
    "\n",
    "        # CNN 1\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 3)))\n",
    "        base_model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 2\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # CNN 3\n",
    "        base_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        #CNN 4\n",
    "        base_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "        base_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        base_model.add(Dropout(0.3))\n",
    "\n",
    "        # You must flatten the data for the dense layers\n",
    "        base_model.add(Flatten())\n",
    "\n",
    "        #Dense 1\n",
    "        base_model.add(Dense(512, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "#         #Dense 2\n",
    "        base_model.add(Dense(256, activation='relu'))\n",
    "        base_model.add(Dropout(0.2))\n",
    "\n",
    "        # Output \n",
    "        base_model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        optimizer = Adam(lr=0.001, decay=0.0)\n",
    "        base_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "#         x = base_model.get_layer('block5_pool').output\n",
    "#         x = base_model.output\n",
    "\n",
    "# #         x = GlobalMaxPooling2D()(x)\n",
    "#         merge_one = concatenate([x, angle_layer])\n",
    "# #         merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "# #         merge_one = Dropout(0.2)(merge_one)\n",
    "# #         merge_one = Dense(256, activation='relu', name='fc3')(merge_one)\n",
    "# #         merge_one = Dropout(0.2)(merge_one)\n",
    "\n",
    "#         predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "\n",
    "#         model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "\n",
    "#         sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#         model.compile(loss='binary_crossentropy',\n",
    "#                       optimizer=sgd,\n",
    "#                       metrics=['accuracy'])\n",
    "        \n",
    "        return base_model\n",
    "\n",
    "    def get_name(self):\n",
    "        return \"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"../_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"../_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "X_angle, X_test_angle = Helpers.get_angledata(train, test)\n",
    "X_train = Helpers.get_imagedata(train)\n",
    "X_test = Helpers.get_imagedata(test)\n",
    "ids = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 8s 314ms/step - loss: 0.6660 - acc: 0.6314 - val_loss: 0.4915 - val_acc: 0.7460\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 6s 238ms/step - loss: 0.4953 - acc: 0.7404 - val_loss: 0.4786 - val_acc: 0.7347\n",
      "Train loss: 0.490264658178\n",
      "Train accuracy: 0.729088639201\n",
      "Test loss: 0.478633190226\n",
      "Test accuracy: 0.734744707422\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/2\n",
      "24/24 [==============================] - 8s 316ms/step - loss: 0.8795 - acc: 0.5184 - val_loss: 0.6784 - val_acc: 0.5605\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.7464 - acc: 0.5283 - val_loss: 0.6360 - val_acc: 0.6567\n",
      "Train loss: 0.635482364989\n",
      "Train accuracy: 0.646326276537\n",
      "Test loss: 0.636023906063\n",
      "Test accuracy: 0.656679151061\n",
      "\n",
      " Train Log Loss Validation=  0.550150008366\n",
      " Test Log Loss Validation=  0.557230431963\n"
     ]
    }
   ],
   "source": [
    "model = VggModel(ids)\n",
    "\n",
    "preds=model.train_predict(X_train, X_angle, X_test, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 15s 629ms/step - loss: 1.2657 - acc: 0.5072 - val_loss: 0.6946 - val_acc: 0.4689\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.6877 - acc: 0.5080 - val_loss: 0.6202 - val_acc: 0.5311\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.6006 - acc: 0.5908 - val_loss: 0.5537 - val_acc: 0.6739\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.6030 - acc: 0.6389 - val_loss: 0.5462 - val_acc: 0.6894\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.5622 - acc: 0.6694 - val_loss: 0.5383 - val_acc: 0.7050\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.5968 - acc: 0.6864 - val_loss: 0.5675 - val_acc: 0.6925\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.5616 - acc: 0.6668 - val_loss: 0.5316 - val_acc: 0.6988\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.5611 - acc: 0.6889 - val_loss: 0.5255 - val_acc: 0.7174\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.5197 - acc: 0.7300 - val_loss: 0.4826 - val_acc: 0.7640\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s 73ms/step - loss: 0.4945 - acc: 0.7563 - val_loss: 0.4475 - val_acc: 0.7919\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.4817 - acc: 0.7704 - val_loss: 0.4647 - val_acc: 0.7484\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.4923 - acc: 0.7728 - val_loss: 0.4264 - val_acc: 0.8043\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.4693 - acc: 0.7716 - val_loss: 0.4589 - val_acc: 0.7702\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.4669 - acc: 0.7687 - val_loss: 0.3911 - val_acc: 0.8354\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.4409 - acc: 0.8096 - val_loss: 0.3736 - val_acc: 0.8416\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3992 - acc: 0.8259 - val_loss: 0.3857 - val_acc: 0.8292\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.4436 - acc: 0.7801 - val_loss: 0.3779 - val_acc: 0.8416\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.4116 - acc: 0.8177 - val_loss: 0.3597 - val_acc: 0.8385\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.4288 - acc: 0.8076 - val_loss: 0.3665 - val_acc: 0.8602\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3912 - acc: 0.8081 - val_loss: 0.4277 - val_acc: 0.7981\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.4323 - acc: 0.8102 - val_loss: 0.3474 - val_acc: 0.8696\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.4151 - acc: 0.8135 - val_loss: 0.3648 - val_acc: 0.8478\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.3740 - acc: 0.8331 - val_loss: 0.3362 - val_acc: 0.8571\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.3658 - acc: 0.8367 - val_loss: 0.3297 - val_acc: 0.8634\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.3519 - acc: 0.8372 - val_loss: 0.2988 - val_acc: 0.8696\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.3987 - acc: 0.8109 - val_loss: 0.3594 - val_acc: 0.8230\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3668 - acc: 0.8075 - val_loss: 0.3369 - val_acc: 0.8509\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.3618 - acc: 0.8350 - val_loss: 0.3095 - val_acc: 0.8540\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.4726 - acc: 0.7556 - val_loss: 0.3832 - val_acc: 0.8230\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3829 - acc: 0.8187 - val_loss: 0.3190 - val_acc: 0.8634\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3781 - acc: 0.8350 - val_loss: 0.3155 - val_acc: 0.8540\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3673 - acc: 0.8308 - val_loss: 0.3438 - val_acc: 0.8292\n",
      "Epoch 33/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.3795 - acc: 0.8145\n",
      "Epoch 00033: reducing learning rate to 0.00010000000474974513.\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.3778 - acc: 0.8163 - val_loss: 0.3083 - val_acc: 0.8571\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.3693 - acc: 0.8319 - val_loss: 0.2967 - val_acc: 0.8602\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.3266 - acc: 0.8578 - val_loss: 0.2930 - val_acc: 0.8634\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 0.3196 - acc: 0.8552 - val_loss: 0.2905 - val_acc: 0.8634\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.3371 - acc: 0.8411 - val_loss: 0.2841 - val_acc: 0.8727\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.2985 - acc: 0.8726 - val_loss: 0.2821 - val_acc: 0.8789\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.3027 - acc: 0.8767 - val_loss: 0.2729 - val_acc: 0.8727\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.2930 - acc: 0.8741 - val_loss: 0.2745 - val_acc: 0.8665\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.2981 - acc: 0.8702 - val_loss: 0.2716 - val_acc: 0.8820\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.2885 - acc: 0.8689 - val_loss: 0.2652 - val_acc: 0.8851\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3099 - acc: 0.8663 - val_loss: 0.2652 - val_acc: 0.8820\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2798 - acc: 0.8696 - val_loss: 0.2657 - val_acc: 0.8820\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3512 - acc: 0.8136 - val_loss: 0.2799 - val_acc: 0.8820\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.2973 - acc: 0.8783 - val_loss: 0.2699 - val_acc: 0.8727\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.3227 - acc: 0.8506 - val_loss: 0.2683 - val_acc: 0.8944\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.2908 - acc: 0.8702 - val_loss: 0.2638 - val_acc: 0.8789\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2940 - acc: 0.8761 - val_loss: 0.2644 - val_acc: 0.8758\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.2765 - acc: 0.8831 - val_loss: 0.2580 - val_acc: 0.8789\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 0.2845 - acc: 0.8781 - val_loss: 0.2580 - val_acc: 0.8851\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.2713 - acc: 0.8774 - val_loss: 0.2551 - val_acc: 0.8944\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.2797 - acc: 0.8737 - val_loss: 0.2546 - val_acc: 0.8944\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 1s 60ms/step - loss: 0.3194 - acc: 0.8752 - val_loss: 0.2544 - val_acc: 0.8975\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.2766 - acc: 0.8702 - val_loss: 0.2530 - val_acc: 0.8913\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.2782 - acc: 0.8904 - val_loss: 0.2619 - val_acc: 0.8851\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2600 - acc: 0.8811 - val_loss: 0.2573 - val_acc: 0.8882\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.2775 - acc: 0.8737 - val_loss: 0.2565 - val_acc: 0.8944\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2809 - acc: 0.8741 - val_loss: 0.2544 - val_acc: 0.8882\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2773 - acc: 0.8813 - val_loss: 0.2570 - val_acc: 0.8851\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2850 - acc: 0.8765 - val_loss: 0.2530 - val_acc: 0.8944\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.2696 - acc: 0.8741 - val_loss: 0.2544 - val_acc: 0.8851\n",
      "Epoch 63/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2547 - acc: 0.8857\n",
      "Epoch 00063: reducing learning rate to 1.0000000474974514e-05.\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2544 - acc: 0.8852 - val_loss: 0.2534 - val_acc: 0.8882\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.2645 - acc: 0.8930 - val_loss: 0.2531 - val_acc: 0.8913\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.3093 - acc: 0.8650 - val_loss: 0.2519 - val_acc: 0.8882\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.2627 - acc: 0.8904 - val_loss: 0.2524 - val_acc: 0.8882\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3016 - acc: 0.8658 - val_loss: 0.2530 - val_acc: 0.8913\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.2767 - acc: 0.8839 - val_loss: 0.2529 - val_acc: 0.8913\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2575 - acc: 0.8794 - val_loss: 0.2526 - val_acc: 0.8882\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.2780 - acc: 0.8774 - val_loss: 0.2522 - val_acc: 0.8851\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.2737 - acc: 0.8606 - val_loss: 0.2521 - val_acc: 0.8851\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.3862 - acc: 0.8580 - val_loss: 0.2513 - val_acc: 0.8975\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.2446 - acc: 0.8911 - val_loss: 0.2517 - val_acc: 0.8882\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.3330 - acc: 0.8619 - val_loss: 0.2521 - val_acc: 0.8882\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2573 - acc: 0.8846 - val_loss: 0.2523 - val_acc: 0.8913\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.2846 - acc: 0.8796 - val_loss: 0.2523 - val_acc: 0.8913\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3030 - acc: 0.8617 - val_loss: 0.2515 - val_acc: 0.8882\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.2790 - acc: 0.8748 - val_loss: 0.2516 - val_acc: 0.8944\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2644 - acc: 0.8754 - val_loss: 0.2518 - val_acc: 0.8913\n",
      "Epoch 80/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2700 - acc: 0.8892\n",
      "Epoch 00080: reducing learning rate to 1.0000000656873453e-06.\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2680 - acc: 0.8898 - val_loss: 0.2513 - val_acc: 0.8913\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.2432 - acc: 0.8955 - val_loss: 0.2513 - val_acc: 0.8913\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.3155 - acc: 0.8458 - val_loss: 0.2513 - val_acc: 0.8913\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 2s 64ms/step - loss: 0.2663 - acc: 0.8813 - val_loss: 0.2513 - val_acc: 0.8913\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2882 - acc: 0.8813 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.2721 - acc: 0.8826 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2497 - acc: 0.8929 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Epoch 87/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.2584 - acc: 0.8821\n",
      "Epoch 00087: reducing learning rate to 1.0000001111620805e-07.\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.2603 - acc: 0.8796 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3040 - acc: 0.8715 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.2683 - acc: 0.8717 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.2654 - acc: 0.8865 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2673 - acc: 0.8787 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.2440 - acc: 0.8852 - val_loss: 0.2514 - val_acc: 0.8913\n",
      "Train loss: 0.235973291669\n",
      "Train accuracy: 0.897815912637\n",
      "Test loss: 0.251307897409\n",
      "Test accuracy: 0.891304347826\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 15s 642ms/step - loss: 1.0955 - acc: 0.5363 - val_loss: 0.6908 - val_acc: 0.5109\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 1s 59ms/step - loss: 0.6704 - acc: 0.5673 - val_loss: 0.6044 - val_acc: 0.6075\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.6121 - acc: 0.6032 - val_loss: 0.5649 - val_acc: 0.6791\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.5706 - acc: 0.6398 - val_loss: 0.5424 - val_acc: 0.6916\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.5718 - acc: 0.6593 - val_loss: 0.5405 - val_acc: 0.7134\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 1s 59ms/step - loss: 0.5651 - acc: 0.6316 - val_loss: 0.5084 - val_acc: 0.7944\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.5515 - acc: 0.7049 - val_loss: 0.4823 - val_acc: 0.8131\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.5240 - acc: 0.7255 - val_loss: 0.4682 - val_acc: 0.7726\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.5102 - acc: 0.7368 - val_loss: 0.4403 - val_acc: 0.7913\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.5019 - acc: 0.7552 - val_loss: 0.4027 - val_acc: 0.8193\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.4168 - acc: 0.8112 - val_loss: 0.3678 - val_acc: 0.8162\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.4784 - acc: 0.7711 - val_loss: 0.3941 - val_acc: 0.8255\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.4280 - acc: 0.8128 - val_loss: 0.3752 - val_acc: 0.8287\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.4211 - acc: 0.8207 - val_loss: 0.3758 - val_acc: 0.8660\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.4568 - acc: 0.7747 - val_loss: 0.3818 - val_acc: 0.8598\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.4248 - acc: 0.8008 - val_loss: 0.3706 - val_acc: 0.8069\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.4195 - acc: 0.8014 - val_loss: 0.3535 - val_acc: 0.8380\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.3937 - acc: 0.8357 - val_loss: 0.3305 - val_acc: 0.8349\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.4612 - acc: 0.7734 - val_loss: 0.3435 - val_acc: 0.8660\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.4462 - acc: 0.7803 - val_loss: 0.3584 - val_acc: 0.8100\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.4186 - acc: 0.8119 - val_loss: 0.3258 - val_acc: 0.8536\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.3946 - acc: 0.8187 - val_loss: 0.3438 - val_acc: 0.8318\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.3668 - acc: 0.8413 - val_loss: 0.3237 - val_acc: 0.8505\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.4010 - acc: 0.8203 - val_loss: 0.3559 - val_acc: 0.8567\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 0.3826 - acc: 0.8177 - val_loss: 0.3096 - val_acc: 0.8723\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 45ms/step - loss: 0.5560 - acc: 0.7003 - val_loss: 0.5008 - val_acc: 0.7134\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.4905 - acc: 0.7350 - val_loss: 0.3818 - val_acc: 0.8349\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.3958 - acc: 0.8129 - val_loss: 0.3042 - val_acc: 0.8723\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.4058 - acc: 0.8164 - val_loss: 0.3373 - val_acc: 0.8598\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3847 - acc: 0.8217 - val_loss: 0.3284 - val_acc: 0.8442\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 0.3722 - acc: 0.8341 - val_loss: 0.3588 - val_acc: 0.8287\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.3777 - acc: 0.8229 - val_loss: 0.3142 - val_acc: 0.8567\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3799 - acc: 0.8194 - val_loss: 0.3124 - val_acc: 0.8536\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.3437 - acc: 0.8474 - val_loss: 0.2869 - val_acc: 0.8629\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.3374 - acc: 0.8416 - val_loss: 0.2770 - val_acc: 0.8816\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3916 - acc: 0.8187 - val_loss: 0.3328 - val_acc: 0.8287\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.3585 - acc: 0.8318 - val_loss: 0.3104 - val_acc: 0.8660\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.3407 - acc: 0.8457 - val_loss: 0.3056 - val_acc: 0.8598\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.3596 - acc: 0.8389 - val_loss: 0.2633 - val_acc: 0.8847\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.3620 - acc: 0.8266 - val_loss: 0.2842 - val_acc: 0.8598\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.3345 - acc: 0.8477 - val_loss: 0.2894 - val_acc: 0.8785\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.3939 - acc: 0.8191 - val_loss: 0.3779 - val_acc: 0.8287\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.3524 - acc: 0.8275 - val_loss: 0.2954 - val_acc: 0.8692\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3224 - acc: 0.8644 - val_loss: 0.2936 - val_acc: 0.8474\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.3410 - acc: 0.8393 - val_loss: 0.2834 - val_acc: 0.8629\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3202 - acc: 0.8702 - val_loss: 0.2671 - val_acc: 0.8910\n",
      "Epoch 47/100\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 0.3016 - acc: 0.8620\n",
      "Epoch 00047: reducing learning rate to 0.00010000000474974513.\n",
      "24/24 [==============================] - 2s 86ms/step - loss: 0.2937 - acc: 0.8658 - val_loss: 0.2722 - val_acc: 0.8754\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.2847 - acc: 0.8722 - val_loss: 0.2599 - val_acc: 0.8723\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.2798 - acc: 0.8794 - val_loss: 0.2562 - val_acc: 0.8785\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 0.2769 - acc: 0.8781 - val_loss: 0.2535 - val_acc: 0.8785\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.2720 - acc: 0.8826 - val_loss: 0.2512 - val_acc: 0.8816\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2812 - acc: 0.8846 - val_loss: 0.2520 - val_acc: 0.8754\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.2714 - acc: 0.8813 - val_loss: 0.2474 - val_acc: 0.8785\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.3464 - acc: 0.8510 - val_loss: 0.2599 - val_acc: 0.8879\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 1s 59ms/step - loss: 0.2896 - acc: 0.8596 - val_loss: 0.2501 - val_acc: 0.8754\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.2777 - acc: 0.8891 - val_loss: 0.2414 - val_acc: 0.8972\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2699 - acc: 0.8872 - val_loss: 0.2465 - val_acc: 0.8754\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.2590 - acc: 0.8852 - val_loss: 0.2376 - val_acc: 0.8785\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.2430 - acc: 0.8929 - val_loss: 0.2388 - val_acc: 0.8754\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.2702 - acc: 0.8867 - val_loss: 0.2360 - val_acc: 0.8847\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.2278 - acc: 0.8994 - val_loss: 0.2326 - val_acc: 0.8847\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.2660 - acc: 0.8763 - val_loss: 0.2298 - val_acc: 0.8847\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2974 - acc: 0.8753 - val_loss: 0.2397 - val_acc: 0.8847\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.2584 - acc: 0.8957 - val_loss: 0.2295 - val_acc: 0.8972\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2542 - acc: 0.9020 - val_loss: 0.2303 - val_acc: 0.8910\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.2303 - acc: 0.9035 - val_loss: 0.2267 - val_acc: 0.8972\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.2778 - acc: 0.8717 - val_loss: 0.2300 - val_acc: 0.8879\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 1s 53ms/step - loss: 0.2616 - acc: 0.8828 - val_loss: 0.2250 - val_acc: 0.9034\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.2657 - acc: 0.8715 - val_loss: 0.2254 - val_acc: 0.8972\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2511 - acc: 0.8917 - val_loss: 0.2259 - val_acc: 0.8847\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.2559 - acc: 0.8872 - val_loss: 0.2292 - val_acc: 0.8816\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.2383 - acc: 0.8878 - val_loss: 0.2213 - val_acc: 0.8941\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.2490 - acc: 0.8931 - val_loss: 0.2170 - val_acc: 0.9065\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.3521 - acc: 0.8710 - val_loss: 0.2375 - val_acc: 0.9097\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2738 - acc: 0.8797 - val_loss: 0.2294 - val_acc: 0.8910\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2748 - acc: 0.8771 - val_loss: 0.2295 - val_acc: 0.9128\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2485 - acc: 0.8989 - val_loss: 0.2235 - val_acc: 0.9003\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.2647 - acc: 0.8784 - val_loss: 0.2214 - val_acc: 0.8972\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.2461 - acc: 0.9009 - val_loss: 0.2166 - val_acc: 0.9003\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.2525 - acc: 0.9027 - val_loss: 0.2237 - val_acc: 0.8972\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 1s 61ms/step - loss: 0.2314 - acc: 0.9002 - val_loss: 0.2201 - val_acc: 0.8972\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.2616 - acc: 0.8878 - val_loss: 0.2193 - val_acc: 0.9065\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2308 - acc: 0.8901 - val_loss: 0.2182 - val_acc: 0.8910\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2659 - acc: 0.8862 - val_loss: 0.2167 - val_acc: 0.8941\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.2330 - acc: 0.8886 - val_loss: 0.2183 - val_acc: 0.8941\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 56ms/step - loss: 0.2299 - acc: 0.8971 - val_loss: 0.2164 - val_acc: 0.9034\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.2513 - acc: 0.8924 - val_loss: 0.2138 - val_acc: 0.9128\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.2690 - acc: 0.8873 - val_loss: 0.2179 - val_acc: 0.9097\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 1s 58ms/step - loss: 0.2270 - acc: 0.9035 - val_loss: 0.2137 - val_acc: 0.9034\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 1s 56ms/step - loss: 0.2403 - acc: 0.9062 - val_loss: 0.2118 - val_acc: 0.9034\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2486 - acc: 0.8890 - val_loss: 0.2415 - val_acc: 0.8692\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.2636 - acc: 0.8852 - val_loss: 0.2132 - val_acc: 0.9159\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.2351 - acc: 0.9094 - val_loss: 0.2142 - val_acc: 0.9065\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 1s 46ms/step - loss: 0.2234 - acc: 0.9092 - val_loss: 0.2135 - val_acc: 0.9065\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.2343 - acc: 0.9023 - val_loss: 0.2123 - val_acc: 0.9003\n",
      "Epoch 96/100\n",
      "24/24 [==============================] - 2s 64ms/step - loss: 0.2309 - acc: 0.9027 - val_loss: 0.2090 - val_acc: 0.9159\n",
      "Epoch 97/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.2176 - acc: 0.9054 - val_loss: 0.2081 - val_acc: 0.9034\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.2562 - acc: 0.8882 - val_loss: 0.2045 - val_acc: 0.9128\n",
      "Epoch 99/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.2396 - acc: 0.9035 - val_loss: 0.2032 - val_acc: 0.9159\n",
      "Epoch 100/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.2345 - acc: 0.9028 - val_loss: 0.2061 - val_acc: 0.9128\n",
      "Train loss: 0.205967337938\n",
      "Train accuracy: 0.918160561185\n",
      "Test loss: 0.203210427326\n",
      "Test accuracy: 0.915887850467\n",
      "\n",
      "===================FOLD= 2\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 6s 240ms/step - loss: 1.3809 - acc: 0.4940 - val_loss: 0.6804 - val_acc: 0.6075\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.6471 - acc: 0.5677 - val_loss: 0.5823 - val_acc: 0.6729\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.5711 - acc: 0.6094 - val_loss: 0.5863 - val_acc: 0.6760\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.5604 - acc: 0.6658 - val_loss: 0.5964 - val_acc: 0.6916\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 1s 59ms/step - loss: 0.5682 - acc: 0.6400 - val_loss: 0.5788 - val_acc: 0.7040\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.5170 - acc: 0.6979 - val_loss: 0.5916 - val_acc: 0.7570\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.5269 - acc: 0.7036 - val_loss: 0.5495 - val_acc: 0.8131\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 1s 57ms/step - loss: 0.4856 - acc: 0.7731 - val_loss: 0.4794 - val_acc: 0.8100\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.4471 - acc: 0.7874 - val_loss: 0.4526 - val_acc: 0.8287\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.4436 - acc: 0.8096 - val_loss: 0.4652 - val_acc: 0.7539\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.4562 - acc: 0.7767 - val_loss: 0.4353 - val_acc: 0.8349\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.4057 - acc: 0.8132 - val_loss: 0.4158 - val_acc: 0.8411\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 1s 59ms/step - loss: 0.4359 - acc: 0.7877 - val_loss: 0.4097 - val_acc: 0.8536\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.4183 - acc: 0.8115 - val_loss: 0.4314 - val_acc: 0.8193\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.4270 - acc: 0.8021 - val_loss: 0.5019 - val_acc: 0.7383\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.5301 - acc: 0.6766 - val_loss: 0.5339 - val_acc: 0.6947\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 1s 50ms/step - loss: 0.4763 - acc: 0.7384 - val_loss: 0.5100 - val_acc: 0.7321\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.4607 - acc: 0.7744 - val_loss: 0.4463 - val_acc: 0.8349\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 1s 55ms/step - loss: 0.4184 - acc: 0.7962 - val_loss: 0.3871 - val_acc: 0.8536\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.3832 - acc: 0.8259 - val_loss: 0.4556 - val_acc: 0.7944\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 1s 60ms/step - loss: 0.5247 - acc: 0.7469 - val_loss: 0.4067 - val_acc: 0.8629\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.4116 - acc: 0.7949 - val_loss: 0.3879 - val_acc: 0.8660\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.4055 - acc: 0.8233 - val_loss: 0.3912 - val_acc: 0.8442\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 1s 54ms/step - loss: 0.3936 - acc: 0.8239 - val_loss: 0.3471 - val_acc: 0.8442\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 1s 44ms/step - loss: 0.4190 - acc: 0.7949 - val_loss: 0.3821 - val_acc: 0.8598\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 1s 51ms/step - loss: 0.3528 - acc: 0.8376 - val_loss: 0.3557 - val_acc: 0.8660\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3369 - acc: 0.8461 - val_loss: 0.3536 - val_acc: 0.8754\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.4373 - acc: 0.7848 - val_loss: 0.4273 - val_acc: 0.8692\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 1s 45ms/step - loss: 0.4395 - acc: 0.7988 - val_loss: 0.4012 - val_acc: 0.8598\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 1s 47ms/step - loss: 0.3914 - acc: 0.8200 - val_loss: 0.3571 - val_acc: 0.8692\n",
      "Epoch 31/100\n",
      "15/24 [=================>............] - ETA: 0s - loss: 0.3393 - acc: 0.8510"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-77e299bde3a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_angle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-104-fe3efb4ca6b8>\u001b[0m in \u001b[0;36mtrain_predict\u001b[1;34m(self, X_train, X_angle, X_test, target_train)\u001b[0m\n\u001b[0;32m     74\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mholdout_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_holdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                     callbacks=callbacks)\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m#Getting the Best Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2113\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2114\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2115\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SimpleModel(ids)\n",
    "\n",
    "preds=model.train_predict(X_train, X_angle, X_test, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.create_submission(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
