{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "import helpers\n",
    "from models import DaveModel, DaveVGG, DaveVGG19, SimpleModel, LeNetModel\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"_RawData/test.json/data/processed/test.json\")\n",
    "\n",
    "X = helpers.get_images(train)\n",
    "X_test = helpers.get_images(test)\n",
    "\n",
    "y = to_categorical(train.is_iceberg.values,num_classes=2)\n",
    "\n",
    "Xtr, Xv, ytr, yv = train_test_split(X, y, shuffle=False, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling2D\n",
    "import models\n",
    "from models import DaveBaseModel\n",
    "import helpers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16, VGG19\n",
    "import abc\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class DaveModel2(DaveBaseModel):\n",
    "    def ConvBlock(model, layers, filters):\n",
    "        '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "            model.add(BatchNormalization(axis=3))\n",
    "            model.add(Dropout(0.5))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    def get_model(self):\n",
    "        '''Create the FCN and return a keras model.'''\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input image: 75x75x3\n",
    "        model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "        DaveModel.ConvBlock(model, 1, 64)\n",
    "        # 37x37x32\n",
    "        DaveModel.ConvBlock(model, 1, 128)\n",
    "        # 18x18x64\n",
    "        DaveModel.ConvBlock(model, 1, 256)\n",
    "        # 9x9x128\n",
    "        DaveModel.ConvBlock(model, 1, 256)\n",
    "        # 4x4x128\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        # 4x4x2\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def get_generator(self, Xtr, Xv):\n",
    "        data_gen = ImageDataGenerator(\n",
    "#                     shear_range=0.05,\n",
    "#                     zoom_range=0.01,\n",
    "                    rotation_range=180,\n",
    "                    width_shift_range=0.01,\n",
    "                    height_shift_range=0.01,\n",
    "                    vertical_flip=True,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "        data_gen.fit(Xtr)\n",
    "\n",
    "        val_gen = ImageDataGenerator()\n",
    "        val_gen.fit(Xv)\n",
    "        \n",
    "        return data_gen, val_gen\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"davemodel2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DaveModel2(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.model.load_weights(\"01 - 2137.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: davemodel2\n",
      "Batch Size: 32\n",
      "Epochs: 80\n",
      "Epoch 1/80\n",
      "41/40 [==============================] - 3s - loss: 0.5503 - acc: 0.7160 - val_loss: 0.6797 - val_acc: 0.6449\n",
      "Epoch 2/80\n",
      "41/40 [==============================] - 2s - loss: 0.4689 - acc: 0.7659 - val_loss: 0.6484 - val_acc: 0.6573\n",
      "Epoch 3/80\n",
      "41/40 [==============================] - 2s - loss: 0.4095 - acc: 0.7895 - val_loss: 0.7865 - val_acc: 0.6573\n",
      "Epoch 4/80\n",
      "41/40 [==============================] - 2s - loss: 0.4031 - acc: 0.7965 - val_loss: 1.0421 - val_acc: 0.6573\n",
      "Epoch 5/80\n",
      "41/40 [==============================] - 2s - loss: 0.3885 - acc: 0.8132 - val_loss: 1.2742 - val_acc: 0.6573\n",
      "Epoch 6/80\n",
      "41/40 [==============================] - 2s - loss: 0.3753 - acc: 0.8178 - val_loss: 1.6077 - val_acc: 0.6573\n",
      "Epoch 7/80\n",
      "41/40 [==============================] - 2s - loss: 0.3593 - acc: 0.8304 - val_loss: 1.9076 - val_acc: 0.6573\n",
      "Epoch 8/80\n",
      "41/40 [==============================] - 2s - loss: 0.3374 - acc: 0.8383 - val_loss: 2.6436 - val_acc: 0.6573\n",
      "Epoch 9/80\n",
      "41/40 [==============================] - 2s - loss: 0.3301 - acc: 0.8391 - val_loss: 2.8464 - val_acc: 0.6573\n",
      "Epoch 10/80\n",
      "41/40 [==============================] - 2s - loss: 0.3272 - acc: 0.8410 - val_loss: 2.7509 - val_acc: 0.6573\n",
      "Epoch 11/80\n",
      "41/40 [==============================] - 2s - loss: 0.3185 - acc: 0.8437 - val_loss: 2.6861 - val_acc: 0.6573\n",
      "Epoch 12/80\n",
      "41/40 [==============================] - 2s - loss: 0.3517 - acc: 0.8300 - val_loss: 2.2646 - val_acc: 0.6573\n",
      "Epoch 13/80\n",
      "41/40 [==============================] - 2s - loss: 0.3084 - acc: 0.8349 - val_loss: 1.8319 - val_acc: 0.6573\n",
      "Epoch 14/80\n",
      "41/40 [==============================] - 2s - loss: 0.3425 - acc: 0.8224 - val_loss: 0.9110 - val_acc: 0.6916\n",
      "Epoch 15/80\n",
      "41/40 [==============================] - 2s - loss: 0.3330 - acc: 0.8360 - val_loss: 0.4221 - val_acc: 0.7850\n",
      "Epoch 16/80\n",
      "41/40 [==============================] - 2s - loss: 0.3174 - acc: 0.8388 - val_loss: 0.4064 - val_acc: 0.7850\n",
      "Epoch 17/80\n",
      "41/40 [==============================] - 2s - loss: 0.3177 - acc: 0.8498 - val_loss: 0.3730 - val_acc: 0.8100\n",
      "Epoch 18/80\n",
      "41/40 [==============================] - 2s - loss: 0.3157 - acc: 0.8400 - val_loss: 0.3249 - val_acc: 0.8411\n",
      "Epoch 19/80\n",
      "41/40 [==============================] - 2s - loss: 0.3162 - acc: 0.8494 - val_loss: 0.3209 - val_acc: 0.8318\n",
      "Epoch 20/80\n",
      "41/40 [==============================] - 2s - loss: 0.3131 - acc: 0.8528 - val_loss: 0.3114 - val_acc: 0.8224\n",
      "Epoch 21/80\n",
      "41/40 [==============================] - 2s - loss: 0.3089 - acc: 0.8604 - val_loss: 0.3352 - val_acc: 0.8567\n",
      "Epoch 22/80\n",
      "41/40 [==============================] - 2s - loss: 0.3027 - acc: 0.8510 - val_loss: 0.3140 - val_acc: 0.8349\n",
      "Epoch 23/80\n",
      "41/40 [==============================] - 2s - loss: 0.3120 - acc: 0.8464 - val_loss: 0.3193 - val_acc: 0.8536\n",
      "Epoch 24/80\n",
      "41/40 [==============================] - 2s - loss: 0.2861 - acc: 0.8711 - val_loss: 0.3195 - val_acc: 0.8442\n",
      "Epoch 25/80\n",
      "41/40 [==============================] - 2s - loss: 0.2952 - acc: 0.8594 - val_loss: 0.2982 - val_acc: 0.8660\n",
      "Epoch 26/80\n",
      "41/40 [==============================] - 2s - loss: 0.2918 - acc: 0.8609 - val_loss: 0.2918 - val_acc: 0.8692\n",
      "Epoch 27/80\n",
      "41/40 [==============================] - 2s - loss: 0.2942 - acc: 0.8627 - val_loss: 0.3053 - val_acc: 0.8536\n",
      "Epoch 28/80\n",
      "41/40 [==============================] - 2s - loss: 0.2942 - acc: 0.8590 - val_loss: 0.3033 - val_acc: 0.8474\n",
      "Epoch 29/80\n",
      "41/40 [==============================] - 2s - loss: 0.3115 - acc: 0.8460 - val_loss: 0.3562 - val_acc: 0.8411\n",
      "Epoch 30/80\n",
      "41/40 [==============================] - 2s - loss: 0.3085 - acc: 0.8529 - val_loss: 0.3531 - val_acc: 0.8536\n",
      "Epoch 31/80\n",
      "41/40 [==============================] - 2s - loss: 0.3060 - acc: 0.8487 - val_loss: 0.3396 - val_acc: 0.8536\n",
      "Epoch 32/80\n",
      "41/40 [==============================] - 2s - loss: 0.2980 - acc: 0.8650 - val_loss: 0.4008 - val_acc: 0.7913\n",
      "Epoch 33/80\n",
      "41/40 [==============================] - 2s - loss: 0.2751 - acc: 0.8742 - val_loss: 0.3066 - val_acc: 0.8598\n",
      "Epoch 34/80\n",
      "41/40 [==============================] - 2s - loss: 0.2791 - acc: 0.8644 - val_loss: 0.3170 - val_acc: 0.8318\n",
      "Epoch 35/80\n",
      "41/40 [==============================] - 2s - loss: 0.2876 - acc: 0.8711 - val_loss: 0.3140 - val_acc: 0.8598\n",
      "Epoch 36/80\n",
      "41/40 [==============================] - 2s - loss: 0.2693 - acc: 0.8784 - val_loss: 0.3084 - val_acc: 0.8536\n",
      "Epoch 37/80\n",
      "41/40 [==============================] - 2s - loss: 0.2795 - acc: 0.8719 - val_loss: 0.3283 - val_acc: 0.8536\n",
      "Epoch 38/80\n",
      "41/40 [==============================] - 2s - loss: 0.2657 - acc: 0.8803 - val_loss: 0.3749 - val_acc: 0.8349\n",
      "Epoch 39/80\n",
      "41/40 [==============================] - 2s - loss: 0.2706 - acc: 0.8761 - val_loss: 0.3260 - val_acc: 0.8598\n",
      "Epoch 40/80\n",
      "41/40 [==============================] - 2s - loss: 0.2831 - acc: 0.8841 - val_loss: 0.3236 - val_acc: 0.8442\n",
      "Epoch 41/80\n",
      "41/40 [==============================] - 2s - loss: 0.2768 - acc: 0.8879 - val_loss: 0.2905 - val_acc: 0.8629\n",
      "Epoch 42/80\n",
      "41/40 [==============================] - 2s - loss: 0.2714 - acc: 0.8769 - val_loss: 0.3116 - val_acc: 0.8785\n",
      "Epoch 43/80\n",
      "41/40 [==============================] - 2s - loss: 0.2709 - acc: 0.8822 - val_loss: 0.3053 - val_acc: 0.8598\n",
      "Epoch 44/80\n",
      "41/40 [==============================] - 2s - loss: 0.2644 - acc: 0.8761 - val_loss: 0.2948 - val_acc: 0.8629\n",
      "Epoch 45/80\n",
      "41/40 [==============================] - 2s - loss: 0.2761 - acc: 0.8792 - val_loss: 0.3130 - val_acc: 0.8567\n",
      "Epoch 46/80\n",
      "41/40 [==============================] - 2s - loss: 0.2712 - acc: 0.8738 - val_loss: 0.3573 - val_acc: 0.8380\n",
      "Epoch 47/80\n",
      "41/40 [==============================] - 2s - loss: 0.2757 - acc: 0.8765 - val_loss: 0.3221 - val_acc: 0.8567\n",
      "Epoch 48/80\n",
      "41/40 [==============================] - 2s - loss: 0.2494 - acc: 0.8909 - val_loss: 0.3482 - val_acc: 0.8255\n",
      "Epoch 49/80\n",
      "41/40 [==============================] - 2s - loss: 0.2612 - acc: 0.8879 - val_loss: 0.3002 - val_acc: 0.8598\n",
      "Epoch 50/80\n",
      "41/40 [==============================] - 2s - loss: 0.2450 - acc: 0.8970 - val_loss: 0.3041 - val_acc: 0.8536\n",
      "Epoch 51/80\n",
      "41/40 [==============================] - 2s - loss: 0.2699 - acc: 0.8815 - val_loss: 0.3325 - val_acc: 0.8380\n",
      "Epoch 52/80\n",
      "41/40 [==============================] - 2s - loss: 0.2777 - acc: 0.8815 - val_loss: 0.3068 - val_acc: 0.8723\n",
      "Epoch 53/80\n",
      "41/40 [==============================] - 2s - loss: 0.2706 - acc: 0.8860 - val_loss: 0.4351 - val_acc: 0.8131\n",
      "Epoch 54/80\n",
      "41/40 [==============================] - 2s - loss: 0.2620 - acc: 0.8697 - val_loss: 0.3150 - val_acc: 0.8536\n",
      "Epoch 55/80\n",
      "41/40 [==============================] - 2s - loss: 0.2594 - acc: 0.8841 - val_loss: 0.3129 - val_acc: 0.8598\n",
      "Epoch 56/80\n",
      "41/40 [==============================] - 2s - loss: 0.2509 - acc: 0.8868 - val_loss: 0.3059 - val_acc: 0.8567\n",
      "Epoch 57/80\n",
      "41/40 [==============================] - 2s - loss: 0.2519 - acc: 0.8914 - val_loss: 0.3083 - val_acc: 0.8723\n",
      "Epoch 58/80\n",
      "41/40 [==============================] - 2s - loss: 0.2623 - acc: 0.8845 - val_loss: 0.3221 - val_acc: 0.8567\n",
      "Epoch 59/80\n",
      "41/40 [==============================] - 2s - loss: 0.2973 - acc: 0.8697 - val_loss: 0.3049 - val_acc: 0.8598\n",
      "Epoch 60/80\n",
      "41/40 [==============================] - 2s - loss: 0.2638 - acc: 0.8833 - val_loss: 0.3221 - val_acc: 0.8536\n",
      "Epoch 61/80\n",
      "41/40 [==============================] - 2s - loss: 0.2499 - acc: 0.8970 - val_loss: 0.2950 - val_acc: 0.8754\n",
      "Epoch 62/80\n",
      "41/40 [==============================] - 2s - loss: 0.2584 - acc: 0.8891 - val_loss: 0.2914 - val_acc: 0.8723\n",
      "Epoch 63/80\n",
      "41/40 [==============================] - 2s - loss: 0.2734 - acc: 0.8853 - val_loss: 0.3276 - val_acc: 0.8754\n",
      "Epoch 64/80\n",
      "41/40 [==============================] - 2s - loss: 0.2496 - acc: 0.8899 - val_loss: 0.3169 - val_acc: 0.8505\n",
      "Epoch 65/80\n",
      "41/40 [==============================] - 2s - loss: 0.2509 - acc: 0.8944 - val_loss: 0.3001 - val_acc: 0.8723\n",
      "Epoch 66/80\n",
      "41/40 [==============================] - 2s - loss: 0.2497 - acc: 0.8856 - val_loss: 0.3198 - val_acc: 0.8442\n",
      "Epoch 67/80\n",
      "41/40 [==============================] - 2s - loss: 0.2764 - acc: 0.8952 - val_loss: 0.2869 - val_acc: 0.8692\n",
      "Epoch 68/80\n",
      "41/40 [==============================] - 2s - loss: 0.2503 - acc: 0.8970 - val_loss: 0.2955 - val_acc: 0.8723\n",
      "Epoch 69/80\n",
      "41/40 [==============================] - 2s - loss: 0.2178 - acc: 0.9092 - val_loss: 0.3059 - val_acc: 0.8692\n",
      "Epoch 70/80\n",
      "41/40 [==============================] - 2s - loss: 0.2354 - acc: 0.9047 - val_loss: 0.2713 - val_acc: 0.8785\n",
      "Epoch 71/80\n",
      "41/40 [==============================] - 2s - loss: 0.2272 - acc: 0.9024 - val_loss: 0.2997 - val_acc: 0.8692\n",
      "Epoch 72/80\n",
      "41/40 [==============================] - 2s - loss: 0.2362 - acc: 0.8952 - val_loss: 0.3205 - val_acc: 0.8692\n",
      "Epoch 73/80\n",
      "41/40 [==============================] - 2s - loss: 0.2399 - acc: 0.8960 - val_loss: 0.2952 - val_acc: 0.8536\n",
      "Epoch 74/80\n",
      "41/40 [==============================] - 2s - loss: 0.2492 - acc: 0.8914 - val_loss: 0.3279 - val_acc: 0.8536\n",
      "Epoch 75/80\n",
      "41/40 [==============================] - 2s - loss: 0.2450 - acc: 0.9001 - val_loss: 0.2937 - val_acc: 0.8598\n",
      "Epoch 76/80\n",
      "41/40 [==============================] - 2s - loss: 0.2400 - acc: 0.8921 - val_loss: 0.2697 - val_acc: 0.8785\n",
      "Epoch 77/80\n",
      "41/40 [==============================] - 2s - loss: 0.2371 - acc: 0.9039 - val_loss: 0.2855 - val_acc: 0.8598\n",
      "Epoch 78/80\n",
      "41/40 [==============================] - 2s - loss: 0.2263 - acc: 0.8967 - val_loss: 0.3316 - val_acc: 0.8442\n",
      "Epoch 79/80\n",
      "41/40 [==============================] - 2s - loss: 0.2153 - acc: 0.9070 - val_loss: 0.2860 - val_acc: 0.8816\n",
      "Epoch 80/80\n",
      "41/40 [==============================] - 2s - loss: 0.2180 - acc: 0.9138 - val_loss: 0.3170 - val_acc: 0.8474\n"
     ]
    }
   ],
   "source": [
    "model.train(batch_size = 32, epochs = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXdYVFfegN9D7yJFULCDvbeoMYlGjabHmGpMN72Y3Ww2\nyW7a7mY32U3ZfKmmmR5T7G5MbNHE3lGxgqgICNJBOsz5/jhzYRgGGGCG5nmfhwfm3nvunAvD+Z1f\nF1JKNBqNRqOpD5eWnoBGo9Fo2gZaYGg0Go3GLrTA0Gg0Go1daIGh0Wg0GrvQAkOj0Wg0dqEFhkaj\n0WjsQgsMjQYQQnwuhHjZzmtPCiGmOHtOGk1rQwsMjUaj0diFFhgaTTtCCOHW0nPQtF+0wNC0Gcym\noKeEEPuFEAVCiE+FEGFCiJ+FEPlCiLVCiI4W118jhDgohMgRQmwQQvS3ODdcCLHHPO57wMvqva4S\nQsSYx24RQgyxc45XCiH2CiHyhBCnhRAvWZ2fYL5fjvn8Xebj3kKIN4QQp4QQuUKITeZjE4UQSTZ+\nD1PMP78khFgohPhaCJEH3CWEGCOE2Gp+jzNCiHeFEB4W4wcKIdYIIbKEEGlCiL8IIcKFEIVCiGCL\n60YIIdKFEO72PLum/aMFhqatMROYCvQBrgZ+Bv4ChKI+z48DCCH6AAuAJ8znVgIrhBAe5sVzKfAV\nEAT8aL4v5rHDgfnAA0Aw8CGwXAjhacf8CoA7gEDgSuAhIcR15vt2N8/3HfOchgEx5nGvAyOB8eY5\n/Rkw2fk7uRZYaH7Pb4AK4A9ACDAOmAw8bJ6DP7AW+AXoAkQB66SUqcAG4CaL+94OfCelLLNzHpp2\njhYYmrbGO1LKNCllMrAR2C6l3CulLAaWAMPN190M/CSlXGNe8F4HvFEL8ljAHXhLSlkmpVwI7LR4\nj/uBD6WU26WUFVLKL4AS87g6kVJukFIekFKapJT7UULrEvPpWcBaKeUC8/tmSiljhBAuwD3AXCll\nsvk9t0gpS+z8nWyVUi41v2eRlHK3lHKblLJcSnkSJfCMOVwFpEop35BSFksp86WU283nvgBmAwgh\nXIFbUUJVowG0wNC0PdIsfi6y8drP/HMX4JRxQkppAk4DEeZzybJ65c1TFj93B540m3RyhBA5QFfz\nuDoRQlwghFhvNuXkAg+idvqY73HcxrAQlEnM1jl7OG01hz5CiP8JIVLNZqp/2TEHgGXAACFET5QW\nlyul3NHIOWnaIVpgaNorKaiFHwAhhEAtlsnAGSDCfMygm8XPp4F/SikDLb58pJQL7Hjfb4HlQFcp\nZQdgHmC8z2mgt40xGUBxLecKAB+L53BFmbMssS45/QFwBIiWUgagTHaWc+hla+JmLe0HlJZxO1q7\n0FihBYamvfIDcKUQYrLZafskyqy0BdgKlAOPCyHchRDXA2Msxn4MPGjWFoQQwtfszPa34339gSwp\nZbEQYgzKDGXwDTBFCHGTEMJNCBEshBhm1n7mA28KIboIIVyFEOPMPpNjgJf5/d2B54D6fCn+QB5w\nTgjRD3jI4tz/gM5CiCeEEJ5CCH8hxAUW578E7gKuQQsMjRVaYGjaJVLKo6id8juoHfzVwNVSylIp\nZSlwPWphzEL5OxZbjN0F3Ae8C2QD8eZr7eFh4O9CiHzgBZTgMu6bCFyBEl5ZKIf3UPPpPwEHUL6U\nLODfgIuUMtd8z09Q2lEBUC1qygZ/QgmqfJTw+95iDvkoc9PVQCoQB0yyOL8Z5WzfI6W0NNNpNAjd\nQEmj0VgihPgV+FZK+UlLz0XTutACQ6PRVCKEGA2sQflg8lt6PprWhTZJaTQaAIQQX6ByNJ7QwkJj\nC61haDQajcYutIah0Wg0GrtoV4XKQkJCZI8ePVp6GhqNRtNm2L17d4aU0jq3xybtSmD06NGDXbt2\ntfQ0NBqNps0ghLA7fFqbpDQajUZjF1pgaDQajcYutMDQaDQajV20Kx+GLcrKykhKSqK4uLilp+JU\nvLy8iIyMxN1d97rRaDTOod0LjKSkJPz9/enRowfVi5O2H6SUZGZmkpSURM+ePVt6OhqNpp3S7k1S\nxcXFBAcHt1thASCEIDg4uN1rURqNpmVp9wIDaNfCwuB8eEaNRtOynBcCQ6PRaNor2xMymb/pBM1R\n5kkLDCeTk5PD+++/3+BxV1xxBTk5OU6YkUajaS9knivh8e/28uXWkxSVVTj9/bTAcDK1CYzy8vI6\nx61cuZLAwEBnTUuj0bRxTCbJkz/uI7ugjHdnjcDHw/kxTO0+SqqleeaZZzh+/DjDhg3D3d0dLy8v\nOnbsyJEjRzh27BjXXXcdp0+fpri4mLlz53L//fcDVWVOzp07x+WXX86ECRPYsmULERERLFu2DG9v\n7xZ+Mo2mfSOlbNW+wY83JrDhaDr/uHYggyI6NMt7nlcC428rDnIoJc+h9xzQJYAXrx5Y6/lXX32V\n2NhYYmJi2LBhA1deeSWxsbGV4a/z588nKCiIoqIiRo8ezcyZMwkODq52j7i4OBYsWMDHH3/MTTfd\nxKJFi5g9e7ZDn0Oj0VRRXFbBFW9vZFjXQF69fggebq3LGLP7VDavrTrK5YPCmT22e7O973klMFoD\nY8aMqZYr8fbbb7NkyRIATp8+TVxcXA2B0bNnT4YNGwbAyJEjOXnyZLPNV6M5H/nf/jMkpBeQkF7A\n2bwSPpg9An+v1pEUm11QyuML9hLewYtXZw5pVi3ovBIYdWkCzYWvr2/lzxs2bGDt2rVs3boVHx8f\nJk6caDOXwtPTs/JnV1dXioqKmmWuGs35ylfbThHVyY8HL+nN04v2c8tH2/js7tF08vdqsTlJKVm8\nJ5lXfj5CblEpPz44ng7ezSvEnKpnCSGmCyGOCiHihRDP2DjfUQixRAixXwixQwgxyN6xbQV/f3/y\n8213u8zNzaVjx474+Phw5MgRtm3b1syz02g01uxPymHf6RxuH9udG0ZG8umdoziRUcDMD7awKS6j\nWcJXpZSYTFVfh1LyuOnDrTz54z4iOnqz+KELGda1+YNinKZhCCFcgfeAqUASsFMIsVxKecjisr8A\nMVLKGUKIfubrJ9s5tk0QHBzMhRdeyKBBg/D29iYsLKzy3PTp05k3bx79+/enb9++jB07tgVnqtFo\nAL7cegofD1euHxEBwMS+nVhw31ju/2oXsz/dTr9wf+67qBdXD+1Sw7dRWFrOiYwCTmQUEOjtwYTo\nkAa//7rDaTzxfQz5xdUjKTv6uPPvmYO5cWRXXFxaxhnvtJ7eQohxwEtSymnm188CSClfsbjmJ+BV\nKeVG8+vjwHigV31jbTFq1Chp3UDp8OHD9O/f31GP1ao5n55Vo6mPsgoTKTlFdA/2tXn+q60nOXQm\nj79dM6hy4c8uKGXsK+u4YWQk/5wxuNr1JeUVLItJ4ZONCRxLO0egjzsdfTwqzxeWlpOWV1JtzGOX\nRvHHqX3s9jN8vzORvyyJpX9nf6b2D6887uPhyo2jIgm0eD9HIYTYLaUcZc+1zvRhRACnLV4nARdY\nXbMPuB7YKIQYA3QHIu0cC4AQ4n7gfoBu3bo5ZOIajaZtk19cxgNf7WZbQiar/3AJUZ38qp2XUvLu\n+njS8krIKSzjnVuH4+bqwg+7TlNSbuKOcT1q3NPTzZWbRnXlxpGR/B6XwYp9KZSWmyrPe7i50CPY\nh54hfvQM8eWLLSd559d40vKK+deMwbi5VmkjBSVKe/D1dKuaz6/xvLHmGBf3CeWD20ZUnmtNtPSM\nXgX+TwgRAxwA9gINSleUUn4EfARKw3D4DDUaTZvibF4xd322k2Np+Zgk/BJ7hkcvja52TWxyHml5\nJUyICuHn2FT+vHA//7lhCF9vP8WYnkH0Dfev9f5CCC7pE8olfepug/3qzMGEBXjy9q/xZJ4r5c/T\n+7ExLp1fj5xlx4ksyk2S8AAveob44u7mwu/H0rl+eAT/vmEI7q6tK4zXwJkCIxnoavE60nysEill\nHnA3gFA62wkgAfCub6xGo2n9rD6Yyss/HeafMwZxUXTdC6wjSEg/xx3zd5BVUMond47irbVxrDqY\nVkNgrDmchouAt28dzrfbT/H66mMkZhVyOquIp6f3c8hchBD88bK+hAZ48cKyWNYdOQtAnzA/5lzU\nC38vNxLSCziRcY6EjHM8OimKJy+z33zVEjhTYOwEooUQPVGL/S3ALMsLhBCBQKGUshSYA/wupcwT\nQtQ7VqPRNI70/BJeXB7L45Oj6Rce4LT3+XZ7Is8tPYAEnvguhpVzLyIsoGFhqW+uPsrOk9n0DPWl\nV4gvPUN8Gdc72GYZjL2J2dz7xS4EsOC+sQztGsiR1Hxe/fkISdmFRHb0qbx27aE0RnbvSJCvB49M\niqKgtIIPNhynk78n0waG17h3U7h9bHeiO/kRd/YcE/uE0jXIp/5BrRSnCQwpZbkQ4lFgFeAKzJdS\nHhRCPGg+Pw/oD3whhJDAQeDeusY6a64azfnEm2uOsfJAKsnZRSx++EJcHRxxI6Xk/9bF8dbaOCb2\nDeWPU/tw84fbmPvdXr6ZM9bu98sqKOWD344T6ufJkdQ8sgvLAOgR7MO7s0ZUK4ex/shZHv5mD6H+\nnnx5zxh6hChH97SB4bz68xFWH0zjngkqYTYlp4hDZ/J49nKlSQgh+PO0voT4edI9yMcp5qCxvYIZ\n2yu4/gtbOU71YUgpVwIrrY7Ns/h5K9DH3rEajaZpHE3N5/udiQzoHMC+pFy+25nIbRc4rrSElJLn\nlsbyzfZEbhgZySvXD8bd1YW/XzuQpxbu551f43hiis1/+Rosj0mmrELy2d1j6BvuT3ZBKXsSs/nr\nkliuf38Lz189gNkXdGPh7iSeWXyA/p39+eyuMYT6VyW69gzxpW+YP6sOplYKjHWH0wCY3L8qxF0I\nwb0TdLfK+midnpV2RGPLmwO89dZbFBYWOnhGmvOZV34+jJ+nG9/MuYBxvYL5zy9HyTxXUuv1ZRUm\nnl8ay5wvdmEy1R9TsuFYOt9sT2TOhJ68ZuG8vWFkJNcPj+DtdXFsPZ5p11wX7UlmUERApQO6o68H\nk/uHsXLuRYyPCub5pbFc9/4Wnlq4n/G9g/nu/nHVhIXBtIFh7DyZVfmcaw6fpWeIL71DbYfbampH\nCwwnowWGpiXILSyj2Ko/wsa4dDYcTeexS6Pp6OvB368dSEFJOa/+fMTmPQpLy7nvy118te0Uaw+n\nsWRv3XEnUkreXH2MyI7e/Hl6v2rOWyEE/7huED2CfZn73V6yCkrrvNextHwOJOcyc0RkjXNBvh7M\nv3M0T0/vR2xyLtcN68Knd47Gr5Yw1MsGhmOSsPZwGudKytl2PJMp/Tu1audya0ULDCdjWd78qaee\n4rXXXmP06NEMGTKEF198EYCCggKuvPJKhg4dyqBBg/j+++95++23SUlJYdKkSUyaNKmFn0LTHNiz\ng7eHCpPkync2cvF/1rMsJhkpJRUmyT9/OkzXIG/uGK9MUNFh/sy5qBc/7k5i18msavfIPFfCrR9v\n5/dj6bx83SCGdg3ktVVHKSqtPep99aE0DiTnMndytM3qrr6ebrw7awTZhaW8tLxul+Si3Um4uQiu\nGdrF5nkXF8FDE3uz94Wp/PfmYXVWkx3YJYDIjt78EpvKxmPplFaYmGJhjtLYT0vnYTQvPz8DqQcc\ne8/wwXD5q7Wetixvvnr1ahYuXMiOHTuQUnLNNdfw+++/k56eTpcuXfjpp58AVWOqQ4cOvPnmm6xf\nv56QkIaXF9C0LTbGpfPYgr386bK+TS5XvT0hk6TsIsIDvJj7XQzfbk9kTM8gjqTm8+6s4Xi6uVZe\n+/jkKJbHJPPM4gOVpTCkhIW7k0jJKWLe7JFcNjCcPmH+3PThVj7dlFAjRBWUsHtz9TF6hfgyY3hE\nrXMb0CWAxy6N5s01x7hicGemD6oZkVReYWLJ3mQm9etEsF9NE5MlAXZUkBVCMG1gOF9tPYW7qwsd\nvN0Z2b1jveM0NdEaRjOyevVqVq9ezfDhwxkxYgRHjhwhLi6OwYMHs2bNGp5++mk2btxIhw7N0wxF\n03yk5BRx5/wdPL1wf2WWr8GOE1nc9+UuCkrKeXH5QTbGpTfpvZbFpODr4cq6Jy/hnzMGcTQtn3d+\njWd4t0CuHNy52rU+Hm68PGMQSdmF/OeXo/znl6O8tuoo+cVlfDPnAi4zh5iO6RnEtIFhfLDhOGfz\na1ZU/unAGY6m5TN3SnS1jGZbPDSxN4MiAnhu6QGbpqlN8RmczS9h5ojaBU9DmT4onNIKE6sPpXFp\nv071zlFjm/NLw6hDE2gOpJQ8++yzPPDAAzXO7dmzh5UrV/Lcc88xefJkXnjhhRaYocaanMJSOni7\nN8ne/euRNP74wz5KykwUl1ew61QW7902gn7hAexPyuGez3fSJdCb+XeO5oGvdvPIN3tY8siF9A5V\n5SxMJsnCPUnsOJHF81cNqLOkdUl5BStjzzBtUDi+nm7cdkF3rhjUmS+2nuSqIV1sPsel/cI48NI0\nKixMYu6uLjXCX5+5vD9TD//GW2vj+JdFnaXyChP/XXuMPmF+XD3EtgnJEndXF167YSjXvLuJF5cf\n5J1bh1c7v2hPMoE+7kzq16nee9nLiG4dCfHzIONcqTZHNQEtZp2MZXnzadOmMX/+fM6dOwdAcnIy\nZ8+eJSUlBR8fH2bPns1TTz3Fnj17aozVND+nswoZ8691LNrTuCIDZRUmXll5mHs+30XnDt789PgE\nvrn3AnKLyrn23c28sy6OO+bvINDHnW/mXECPEF8+uXMU7q4uzPliFzmFpcQm5zJz3hb+vHA/C3cn\ncc/nO2toKJZsOJpOfnE51w6r2p139PXgiSl9atRTssTd1QUvd9fKL1u5Ej1DfJk9tjvf7UjkaGp+\nZentpTEpJKQX8Mepfeyuotq/szJNrdiXwi+xZyqP5xWXsfpgKtcM7VLNdNZUXF2UWcrDzYWL+2gT\nb2M5vzSMFsCyvPnll1/OrFmzGDduHAB+fn58/fXXxMfH89RTT+Hi4oK7uzsffPABAPfffz/Tp0+n\nS5curF+/viUf47xkWUwypeUmvt1+ihtG1ozWsSb+7DlWHjjDiYwCEtLPkZBeQH5JObMu6MYLVw3A\ny92VXqF+rJw7gT98H8Mba44RHuDFt3PG0rmD6tHeNciHebePZNbH27jm3c0kZRfS0ceD128cio+H\nK49+u4f7vtzF/LtG4+Vec0FdHpNCsK8HF/Z2TpLY3MnRLNqTxLS3fq92fGCXgAZnSD80sTerD6Xy\n2IK99Ag+Rq9QX0wSSspNNqOjmsrTl/fj9nHdW03nvEYTuxh+/jPM3Q8ezZs17rTy5i2BLm9+/jyr\ns5FSMvW/v5OQfg6ThF+fvIReobZ36OdKynl7XRzzN52g3CSJCPSmp7mMxSV9QpkyoKYJpMIkWbo3\nmdE9gugWXPOfftHuJJ5dcoBZY7rxh6l9Ks1Qi/ck8ccf9nFpv07Mmz2yWnRQfnEZo15eyy2ju/K3\nawfVuKej2Hc6hw1Hq/tZrhgcTnRY7QX7aiMlp4gvtp4011Qq4FRmAf07B7DskQt12GttrPwz7PgQ\nHtgInYc0+Xatpby5RtNmOXwmn/iz53h8cjTv/hrH4j3J/Gla32rXSClZsf8M//zpEGl5Jdw8qitP\nTVclJurDVcDMlNch+AYInlDj/MyRkVw7rEsN5+z1IyIpLK3guaWxzP1uL2/dMqzSdLP6YBol5Sau\nGeY4Z7EthnYNZKiDur11CfTm2curNjnlFSaEEK1PWBTnwS/PwriHIczBrZ6lhP/9AYbcBN3H1399\n9gn1PTPOIQKjIWgfhkZjg2X7knFzEdw1vgcXRYeyZG9yjTyJTzae4PEFewn192Txw+P59w1D7BIW\nACTvht2fwfZ5tV5SWyTP7LHdef6qAfwcm8rdn+0kv7jMPOcUIjt6M6Jb87fudBRuNpztrYJN/4WY\nr2HFXLXAO5K0g/V+FqqRlaC+Z8Q7dh52cF4IjPZkdquN8+EZHU16fgk3f7iV55ZWz80xmSQrYlK4\nuE8oQb4ezBwZSXJOEdsSqkpapOQU8eaaY0zp34llj0xgRLcGxvUfXKK+J/wGFWUNnvu9E3ry+o1D\n2X4ii5s/3MahlDw2x2dw7TDbkVBtluQ9cGqr7XNlxbD/RyhxcmBIzmnY9j506AZJO+HQUsfeP36t\n+n58A1TUHtAAgKkCsk+pnzPjHDsPO2j3AsPLy4vMzMx2vaBKKcnMzMTLq2Glo89nTmUWcMO8LWw/\nkcXX2xJZdTC18tyuU9mk5BZz7TAVInrZgDD8vdxYuCep8pq/rziERPLSNQMbviOWEg4tA88OUJIH\nSbvqH2ODG0ZG8smdoziRUcB1722mwiSrRUe1C368Cz6bDj/cCblVv3+O/gLvXwCL58COj507h1//\nof5md62ATgNhzYtQXnv9rQZzfB0IFyjJVZpnXeQmgcm8wchofoHR7n0YkZGRJCUlkZ7etGSo1o6X\nlxeRkY6PLGmPHEjK5e7Pd1Bhkvz44DheWn6Qvy6JZUyPIDr6erAsJhlvd9fKeH0vd1euGtKZZTEp\n/OPacnaczOKXg6k8Na1vtR4LdpO8G3JPw/R/w6pn1YLRfVyjnmVS304suH8s93y+k4hAb/o0wvFc\nA5MJygrA0wH3AijKBu9GZFbnJkPOKeh+IRxbBXGr4cInIGUPHPsFQvqCb6faF1kpoTgXvO000ZWX\nqIXb1SKKKmUv7P8eJvwBOvaAy/4BX1+vhNT4Rxv+TNaUFkDiNhg2C2K+VZ+Fbja7USsMc1SngZAZ\nr56xGTXKdi8w3N3d6dlTly3WKLYcz2DOF7vo6OPBl/eOoXeoH6/fWJVE9vqNQ/npwBmmDgir1lN5\n5ohIFuw4zdKYZD76PYFeIb7MuaiRn6uDS8DVA4beAgcXK5PEpc81+pmGdQ1k/ZMTqXCUFr3nC1j3\nN3jyGLh5NO1eKTHw8aVw248QNblhYxPNpqhp/wTvIFj1F9jwL/Dwg6n/gAsehKUPVV1nzcEl6vzc\n/eBfR7JeRTns/BjWm+897WUYeL06t+o58AmBCX9Ur6MmQ9QU+P0/apH3CWrYM1lzchNUlMKgGyD9\nqPosTPpL7dcbAiN6Kmx+C/JTIaBz7dc7mHZvktK0bSpMkts/3c4PO083+V5FpRU8+cM+OnfwYvHD\n4yszqY0ksuX7UnhxeSw5hWU1it6N7N6RHsE+/G3FIU5lFvL3awc1LrFMSji4FHpfqna+vSerRbXA\nvpLftdHBx50g3yYu7gZJO5VWUHC26ffa/wPICtj3XcPHntqiFvCwwdCxO9zyDTy4CR7bAxc+roRZ\nxEjIS1YLpzVxa6C8WGkJtXFyM3x4MfzyDESOAr9QWHgPfHE1bH0PTm2Cic+Al0Vnwqn/UH6T319r\n+DNZE78W3Lyh2zj1WUjeA4VZtV+flQBuXtDzYvW6mf0YWmBomoVaey4UZMCKJ1RsuQ1WHjjDxrgM\nfrbIBm4sn25K4ExuMa9cP6RGq1CjvtGCHafp4O3OxX2q958WQnD9iEhKy01cNaQzE6IbmS2ctAvy\nkmDgDPU6ajIgIaEVJWYatvGCJppxTSblqwE4+rNyUjeExK3QdQy4WhhCwgdX1xYiRqjvyXtsjN+i\nvtdWcHTLO/D5FcqPdPPXMHsx3LcernxDjVn9VwjpAyPvqj4ubAAMvx22fwhvj6j6mn85lDawHUH8\nOugxAdy9lOZS32ch+6QyjYWYm1BlNm+klBYYGqfz84EzjHx5Le+tj68KPjBVKDvwOyNUSOGOD5XN\n2gIpJe+tV/8Qh880LRLmbH4xH2w4zrSBYYzpWdOM4O7qwus3DsXdVXDVkM42y2XPuqAbM0dE8sJV\nAxo/EcMc1fdy9brLcGXfj1/X+Hs6GmMROtdEgZFsFo5DbobSfGWft5fCLDh7CLrVk5cQPgSEa00/\nRt4ZtbgCpNUiMGK+hcgx8MgO6H+18gW4uMLoOfDYbmWGmjGvuk/DYMpLMOpu9ffrMhyCo5SAiltt\n/zNmnYCs42ZBgRJ+XoEQ/2sdYxIgqBcERCjNpJlDa9u9D0PT8vx0QGkHr606SlpeMS9e6IPrwjvU\nLq7nJcoW/d2tcHg5jH2octyvR85yJDWfgV0COJiSR1ZBaaPNLm+tjaOk3MTT0/vVek2/8AB+nnsx\n4R1sR5uF+Hnyxk1DG/X+QNWOu/dk8DJXJHZxhV6T1GLazA5MmxRmQZHZJNJUDePgUiUcp7+qFtKD\nS6HflfaNPb1dfa8vkc3DBzoNUI5wSwztIrC7bQ2j5BykH4GL/2y7vIZvCEx5sfb39QlSmoiBqQLe\n6KtCbgdeV/ecDQwBavh2XFyh18TaPwtSKiHTaxK4uEBwb22S0rQvyitM/H4snZkjIrn/4l58ufUU\nm758EZkRT9q0eXzS87/c+nsQie69qYhdXDlOSsm76+OJCPSuzLA+fCavxv2llMSczqkzbPpYWj7f\n7Uhk9tjutZb3MIjq5Fdr57YmY+y4rReUqMlwLg3SYp3zvg3BMlSzKT4Mk0ktnlFT1OLa76qGmaVO\nbVbCJmJk/ddGjFAmKcvPwKmtyv8x9Ba1yFrnapzZB9JUZdJqKi6u0P8aFc1lr1kq/leV2xEcVXUs\nagrkn1HalTX5qVBeBEHmYIvgqGYPrdUCQ+NU9iTmkFdczuT+nfjLFf157sr+hOfsYXN5Hy5YFsDL\nK4+Qca6EH4pG4pq0g+LMRAC2JWSxNzGHBy/pxZAItRs/lFJTYGxLyOK69zazuI6Ksq+sPIyvpxuP\nT67Z+KdZMXbchjnKoPel6rulWcpkapFM3mo71oKMxt8neZdyRg8wC8eBMxpmljq1FbqMULb9+ogY\nAcU5VRFEoBzmkaOh8zBAQprVAmxoJF0cJDBAbQTKCu0zS1WUwYnf1WbBUpOw9VkwMJ4vqJf6HhKt\nwo4dmRNSD1pgaJzK+qNncXURlU7iOSMD6euSRFbwKP52zUA2/nkSa/54CYOn3gXA0m/ep6zCxPsb\n4gnx8+TGUV0J9vMkLMDTpoax9bha1D7emGBTy9gUl8H6o+k8OinKcVFEjUFKOLyiujnKIKCLiqs3\nMn6T98BTNmYmAAAgAElEQVSnU+DdkbDNznIRjiIjDlzcISASzjVBwzi4BFw9q4Rjz4uVr8bIcK+L\n0gI4E2N/boqhhRiO76JstUPvPl45yaGmHyN5t9rd+1UPbmgS3S8E31D7nvH0DiVArUONO0RAaP+q\nz4IllQLD0DCilZaUdaJp824AWmBonMr6I2cZ1b1jVSvNxG0AXHP1TO4c34OuQcp+PO2SC8ny70dU\nxjpu+2Q7G+MymHNRz8oS3v07B3DIhsDYcTILNxfBkdR8thyvHppaYZK8/NMhIgK9uXN8D+c9pD1k\nxEFuIvS5zPb5qEvV72b5YypvITdJhVquehbibCweziIzXu1g/cMb78MwfDVRk6vCUV3dlWP56M9Q\nVlT3+KRdYCqv3+FtENpfOYANrSFxOyDV769DpBLQ1n6M5D0QMbzGrZqEYZaKW62EXl3Er1XOeiM8\n1pKoySpCzPoe2SfAxU0JOoAQsymrGf0YWmBonEZKThFHUvO51LJzWuKWWm3TQaNvZJTLMU6fiCPA\ny61ab+sBnQOIP3uOkvKKymOl5Sb2JuZw8+iuhPh58MnGhGr3W7QniSOp+Tx9eb+q3hGb31YF5Gwh\nJXx+FWx6q3EPvPcb+GqG7eJ0himmdy3Ja70nq5IPe7+BcY/Ao7vgtoVK81h4t0rqaiwV5fDxZNj5\naf3XZsQp27hfJ/sERnEefHalyl0wSnck7VTmKCN02GDAdVB6rsrcUpAByx6FjyZW12YStwJChdTa\ng6sbdB5aFSmVuEVpSZGjlLknfAikWviHCjKUKcce/0hDGTijfrNUWZEK8Og6pqa2CUpgVJTCiY3V\nj2clQGC3qjDjYLOJtRn9GFpgaBpFUWkF5RWmOq8xeiZUa7VZl23avMB8MOI0b9w0rJrzuX/nAMpN\nkri0c5XHDiTnUlJuYkJUCLeP7cH6o+nEn1XOzcLSct5YfZRhXQO5eohFJuzxX2Hf9yqqxZq8FDi5\nEda+CLGL6vsV1CR2kbq/rVIV8WvVP3jH7jXPgdppTn9VJaZN+6famXv6wa0LVKLWtzfVndBVFzmn\nlE9h5Z9UMlttVJSrRSkkSkUJ1ScwTBWw6F61wB/5Cd4dDRvfhAM/KHNUn+k1n9E7SP2ejJDqfQuU\nf+H72VW2+FNbIGyQ/SU9QPkxzuxXvoFTW9Vrd9WUirBBqiKs8Tc3Evkc6b8w6D5elSs5WEuBQilh\n6cOQeVyVObF5jwvBM0CZMC3JSoCOFtUFvALAL0zdq5nQAkPTYHIKS3nzP8/z4Kvz+PC34+QW2a62\nuv7oWSICvYk2WoPWZ5sO7g3hgxmWt4GpVk2H+ndWpg1LP8bOk2oBHdUjiNlju+Hh5sKnm04C8PHv\nJ0jLK+G5K/tXr95amKkiTbKqayNAVZRSQKT6p66vEJwlUlaZRKxt2GXFKqO4rtIYLq4qpDjMKscj\nsCvc8q3KK/jhDmXuscXRX+Dw/2yfM3ag3kHw491w9rDt63JOKS0nOFotegUZtb8fwJoX1E76itdU\nLkPvS1VJkZ2fqGgfy+xoqDJLHVyshFfnYfDQFrj+IxVGu2IulJcqDaWhtbUiRqq/a8pe9dXNYnz4\n4Op/8+TdgIAuwxr2Hvbg4goDjGgpG2ap3/6jnn/KS9B3es3zAG6e0PcKOLJC/T7AHFJ7ssrhbRAc\nrU1SmtbN35Yd4Mmyj3hYLOaVn48w/pV1/H3FIbIKSiuvKSmvYHN8BpP6hVYt2PbYpgfOgKQd1SuT\novpJe7m7VPNj7DyRRa8QX0L9PQn282TmiAgW70niSGoeH/5+nMsHhTOqh1WSXlG2+p66v+Z7G8fu\nWqFMMgtm1UgmrJXsE+reLu7Kfm9plkrcohas2sxR9dF1tCp6d3Kj7XlLCT8/pRZrWxgLyh1L1a77\n25ttlyIxdqoh0cp5Kyuqfl/W7PkStr4LYx6A0fdWle64bZH6+1rk01Rj9BzoegHc+DncsQxC+6ro\noknPKW1jyQPKpGNPIyFLupj9ETs+UkLPcny4ufug8btL3qPe11HFFa0ZcJ36e1ubpWIXq1pYQ2fB\nhbWYRQ0GzlCFE0/8pl4XZqlqtkFW9ctCmje0VgsMjU1yi8qqCQCDVQdT2bn/AF6ijBHiKP97ZBxT\nB4Tx5daTzPxgC4mZKgb98M51FJWWMamvpf/CDtu0EYZplJQw4+oi6BseUKlhmEySXaeyGd29o3IK\nH1rG4+GHmGTaxusffUZZRS1JeoXmhTLVRs5DaqwquxDUC279Xtnbv7tVzcX4iltr20dhROiMuU9V\norXUTuLXKb9Njwtrf+76MPwBtqJnMo9DTqL6bivEMjNeaRfhg5WJKz/VbAKy+vsagiU4uip6yFYu\nxsnN8L8/Ko1i2r+qn4ueAvf8DD0vsv0cnYfAvavV81hqfhf/SRXgO2jOxbHX4W0Q1EtlSR9cgvqM\nWVR8De2nnMWpsepvl7zbOf4LA8MstfPTqs/Nnq9UIcSuY+Hqt+pP0Ow9SZmlDG3VOqTWIDhKJVo2\n1lzZQJwqMIQQ04UQR4UQ8UKIZ2yc7yCEWCGE2CeEOCiEuNvi3EkhxAEhRIwQonENAzQN5lRmAS8s\ni2Xsv9Yx9pV1fLXtVGW4anZBKX9dEsvE4Bx1cUkeg9ySeOuW4Xz/wFiyC0u5/oMtJOxew7BVN/KA\n+y+M6x1scXM7bNPBvZVtefPbyqdgwYDOARw+k4+UkmNn88ktKuM6r93wzUz44Q46r36AeR5v8Ynp\nBR4e4UOPEN/q9y4rVrtXsJ39m3qgKgwzbADcMF8tMj/cUfX1zUzbMfIpe5Wv4aI/KeFgaZaKX6cW\nEQ/fmuPsxa+TmttxG2UjDIe6rLBdWygjXmkNoBzB176rtJ79VgUBM+JU6KtvsNIwwLYfY93fVSjw\nDZ9Vr/PUFIRQ84ocrRz9dVWXrW18xEilwYYNrP4Zc/NUpdBTDyhhXphRpZE4AxdXGHyD0giNz83y\nR5W/4eav1Xzqw81TZcUf+Z8S7EZbVlsmKWg2LcNpAkMI4Qq8B1wODABuFUJYF+F5BDgkpRwKTATe\nEEJYBstPklIOs7dBuabxnMwo4IGvdjHx9Q0s2JHIlUM6M65XMM8vjeXRBXvJLy7jxeUHySks5VHL\nNsLm0tIjuwex8MFxeLq58OvyrwF4zG0pPuVmE1JFmf226WvfU7v7BbdWy5od0Nmf3KIyUnKL2XlC\n7aiGp/6owgwf3AwPbSFp/MsA3DvExj+lUfLCxa2mwCg5p3Zx4RYP12ca/PGQsrM/tAUe2KjCN21F\nwCTvVmN9g9XO++BSZf/PTYb0w403R1kSNUXZ+outwovj16l5gW3/RGZc1cICMPhG5Ty19rVkxldd\n52vWDG3lYmQdh16XNMwpbQ/u3nDXT0pDaQxG1nY3G5+x8MHKR2Vofs7UMACm/h0e2lr12XloCzy8\ntWF5HwOuU2aphA1mDUOoUieWGBuBZvJjOFPDGAPESykTpJSlwHfAtVbXSMBfKCO3H5AF1NOjUONo\n9p3O4foPtrDleCYPT+zN5qcv5fUbh/LZXaN5eno/folNZfIbv7F8XwqPXRpNeNlppS4HRCqtwUxU\nJ38WPTSeiW77OWkKw1sWwm//VifP7LffNh02AGZ+qso3LH2w0vE6oIvZ8Z2Sx46T2Yz1T8creQuM\nvkfZqcMGEjlQ3T/AlFPzvoY5KmIUnEutXlzv7CFAKg3IEv9wtWMNG6jMKT0urJmtXFGu5mosWANn\nqBIgyburNIKG9oKwRe/Jagd90iLcsrxEvR5yo2r+k36k+pjiPFV2JMSi/IQQao4Jv1X3ZWTEVS1A\nfmaBYZ3tXVqgtA7rhctRuHnaDjW1B0MI2PqMhQ9WJTfi1igN0Prv7Ghc3dXn2PjshA1suIbZe5Lq\nynhoqRIYARE1owsDuyu/WVvXMIAIwLKJQZL5mCXvAv2BFOAAMFdKaYRlSGCtEGK3EOL+2t5ECHG/\nEGKXEGJXe++q5ww2HD3LLR9tw9fTleWPTuCpaf3oZC797eIieGhib76/fyyuLoIhkR14eFLvqlj9\n7uOUhmFh0w93zSOqIoH06BupGHa7ipjJPF5VDM5e23Tf6crRe2gZ/PaqOhSuBMahM3nsPJHFw77r\nVfjm8DuqxvmYy47bKmth2Hl7XaK+W2b/GhqHYZKqjagpaidu9FUGtUiXFVYtWH0vrzJLxa8F/86q\nQF5T6XqBqo9k6cdI3Kreu++VylxhLTAq/RJR1Y8PvE6ZsI6YI6uK85QQNa7zClSJZdY+jBxVuoWO\nPZr+PI4m+jK47gMViWWN4fg+uET9jZvaGKo5cPOEfleov1H60ZoOb1AmwaCezVbmvKWd3tOAGKAL\nMAx4VwhhxOJNkFIOQ5m0HhFC2EiJBCnlR1LKUVLKUaGhDkzzPw9YtDuJOV/soleoL4seGk9Pa5u/\nmVE9gvjtqUn88MA43F1dlAAIiVaq/7m06iGq5h316Mk34j75r8quv+YFFRsf1Kthtulxj8Lw2UpL\nObAQP083egT7sPpQKvl52YzNXwODrldmIANfs8AotCUwzLtpI7vW0vGdekDtbDvU0+bWMC1ZahnW\ndYm8OqjrDi1V5oTekx1ThdbNA3pcpExQhpCOX6d2mD0mKOfuWSuBYdSjsjRJgTKfBfWqMksZC46h\nYbi4KD+GtQ/DEJTO0jCagour6oJnqxx5mHkjUFbonPwLZ2FES52JsS0wQP1t24GGkQx0tXgdaT5m\nyd3AYqmIB04A/QCklMnm72eBJSgTl8YBlFWYeOXnwzz54z4u6BXEd/ePpZN/3UXePNxcVLZ0aYEy\ntwRHV6n+li0y49epXX74ECUcLnxC7ZDi1zY88kUIuPK/KpFp6cOQtIv+nQOITc5jhusmPCoKVJhm\ntYn6gruPbQ3D8GEER4N/l+p+jLRYc2+Fehb2kGjo0LW64zt5txISlg7JgdepbOfiHFX2w1FETVb5\nEoaQjl8H3caqJL9O/dVxy0ipzDhlqrJebIRQNvITvyuzlCEwLDUR39CaPTFyzAKjtgTE1opvsPqb\ng/P9F46kl9ksBTUd3gaRo9RGx1EteuvAmQJjJxAthOhpdmTfAiy3uiYRmAwghAgD+gIJQghfIYS/\n+bgvcBnQCmo/O5dDKXlc995mthxvQpXQekjJKeKWj7bx4W8JzLqgG5/dNQZ/Lxs7stqojNWPUpEn\n3h2V9gDK13B8nXL6upg/WuMeUf+oFSUNT8YCtau+6SvlS/huFmOCCgHJ3e5rkJ2H2f7n9wmp2yTl\n3bHKCQoqAzjtoH12bSHUop3wm3Lkgwqp7TK86pmhyiwlXNQ/vaMwfCHx61Qy39mDVQ14QvspM5Pl\nbjMjTmkDtiJzBs4wm6VWqOuES/VFyS+0pkkq+5RysPu2QW3eMDc6qqR5c+DmUdVDpGMtGsZFf4Tb\nFzdLLxWnCQwpZTnwKLAKOAz8IKU8KIR4UAjxoPmyfwDjhRAHgHXA01LKDCAM2CSE2AfsAH6SUv7i\nrLm2BqSU/G3FQWJO53DX/J38b39K/YMayLrDaVzx9kaOnMnj7VuH868Zg212lqsTy1h9Fxdllqps\nhblPmX2MBQxUc5rL/mHuQ3xJ4ybuGwyzfoCyIm449hSTXGLoTRJizH22/0l8Q2oxSWUpZ72bh1o8\n0o+qUNusE8pUUZ//wqD3ZFVpNGmnqguUdrCm4PLqoHbwPS9R/SAcRVAvtXDEr63pUA81551Y+jEM\n86EtwgdDUG8V0ZUZp+oUWQoWWyapnFPqupZu9NQYel2i5m5tnmvtDL9N+eo6N6F5l4Nwasc9KeVK\nYKXVsXkWP6egtAfrcQlAy/92mpE1h9LYfiKLp6b1ZcPRszy2YC8Z+SXcdWEtu4oGsjcxmzlf7qJf\neADv3zbCtr+ivLR+Z6BhEzd2ot3Hw9GVkJ9WZabpbWWCGXyDquLZFEdjp35ww3z8vr2Jee5xFLt1\nwGvQTNvX+oYo34o1hZlKuwDlBJUVKuTVKA8dbmfkTK9LlEM4fp0K0ZUVtu3iM5xUmjxqCsR8o2z1\nfmFVmlFItJqXITBMJmVqslURFczRUtepYosBESr72RLDJGXZ/S37VNszRxmMfVh1d3RpaddtA+kx\nAf6S4riclybQ8jPQUFZh4tWfj9A71JcHLu7FvRN6Mve7vby04hD7k3JxcRGcyCjgREYBbi6C2WO7\nM3ts9wb1d3hj9TGCfDz48cFxtjvK7f0aVv1VxYoHdKn9RplxyoZvtLU0/BKJW9QCGj7Edqy5I6JS\noqciLvsnnquepXzU7VXF5azxCanZMAeUD8PH7CA38i1SY6vKRofayAy3hVcHlWB2fF2Vk92WaczF\n1b77NZSoybDzY+UbGjqrajF381SC3MjFyEtWJSpComq/18AZsPENVXq9/1XVz/mGqvGlBcpHIqXS\nMLqNdc5zORshlEBti7QCYQEtHyWlARbsSCQho4C/XNEfN1flXH7/tpHcMa47S2KS+f1YOu6ugmkD\nw+nfOYA31xxj/Kvr+OuSA5zOqr8d5LaETDbFZ/DQxN61tx89tVU5aH99ue6bGSG1Bp2HKCfzsdWq\nBpSlOcoZjH0I7lyB2+Tna7/GqLRq7QQszKoyD3XsCe6+yvGdekD5Y+zJwDWImgIpMSqJz78zBHSu\nf4yj6HGRioyCmvkdoX2rNAxL82FthA1SZimoGXpbmYth9mMUZUNJXtvVMDRNpnWIrfOYvOIy3lob\nx/jewdX6Rri6CP5+7SCev2qACmW14FhaPp9uPMGPu5JYeeAM3z8wjj5htgupSSl5c/UxOvl7Vusv\nUQNjkYn5VqntnYfUvEZKZeIYNqvqmKu72m3v/16ZZhyRoFYXQtRuYjHwDVFO9tJz1QvMFWZWLYou\nLiqZKi1WmaTqu6c1UZfC+peVH6HvlQ0b21Q8/dQu/+Smmg71Tv2VibCs2CKktg4Nw0ji2/h6TV9H\nZXmQDKW5GDkYrTGkVtMsaA2jhXl//XGyC0v5yxVWZbjNWAsLgD5h/vz7hiGs+sPFuLu6cNsn2zmZ\nYbvD18a4DHaczOLRS6OqmghZI6VyAA+5WZV7WP1X2yF6+alqEbbesXYfr4SFhx9EtoLo59qS94qy\nq0xSoHwWybshP8V+/4VB52GqoB+0TNTNxX+Cyc9Xz0EBc6SU2XeRGaf+Jv7hdd9r9L0w6h4l+C0x\nBIZRHqSthtRqHIbWMJqJ3MIyEjLOVfoiEtILSMgo4FhaPjOGRzAoouHlEHqG+PLNnAu4+aNt3PbJ\ndn54cBwRgVV2fSklb6w5RkSgNzeP7lr7jXKTVNRP1wuU8/aXp5Wppc+06tdVJndZ7ViN2j09L24d\nGbTVdsbmoIHyUmVOsYxYCh8M5cVVPzcEF1dVuiF2UcsIjF4T1Zc1nfqr7+lHqsyH9UU0BXSBq/5b\n87h1AcLWnLSnaRa0wHAiZRUm/rrkAOsOnyXTolS4q4ugW5APPUN8uTg6hIcm9m70e0SH+fPlPWOY\n9fE2bvt4G+/fNpKoTn54uLmw7vBZ9p3O4dXrB+PpVoezzzBHdeqv6izt+AhWP6/CRy2dbbXZxCNH\nKzv4kJsa/RwOxdh1W4bWGn0dqgkMC7NbWAMFBiiNLGmn+p21FoKjlGP37GEVUtvtgvrH1Ia1wMg5\npRz+ji46qGkzaIHhJCpMkie+j+Gn/WeYMTyC/p396RXiR48QX7oF+TQ8/6EOBkV04PN7xjD7k+1c\n8fZGXF0EXTt6c66knO7BPswcWU+5C0NghPZTGsLUv8P3t8GeL5S5wiAjXiVtBViVBPPwgcf3OOx5\nmoyt0txGWRBvC4HRqT8glNPa2rRjD32m1dTCWhojUiplryrlHTy7CffyUALCUsPQ2sV5jRYYTsBk\nkjy9aD8/7T/DX6/oz30X15LS70BGdOvIqicuZufJLGXyyiggKauQxydH2/SDVOPsERXPb+y++12p\nwmXX/0uVwjZabWaaTRytPY7dlg/DKAti6cPw8FVFAWur0dNW6dRPtQhF1h1Saw++nar7MKxzNTTn\nFVpgOBgpJS+tOMjC3Uk8MSW6WYSFQdcgH7oG+TR8YPrh6guBEDDtn/DxJNj8Fkx+QR3PiHNOH2RH\n4+GjQn0LLUp3Gz9bZ13P+q6ql0R7IbQ/HF6hfm5qVrNvqBK8Uqooqegaebaa84hWvlVse8z7LYEv\nt57igYt7MXdyGyhBYERIhfavfjxiBAy+Cba+p5zi5SVqh9lWyioYuRgGlXWkrARGYLeGNbVpC1gK\n/+DG+8eAqnpS59JUgIA2SZ3XaIHhYBbsSGRCVAjPXN7PZphsqyP3tAqV7WQjy3ny80qgrPuHylWQ\nptrrErU2rAsQVpqkHFjXqbViREoFRDStLSxU1ZPK1iG1Gi0wHEpiZiGJWYVMHRDWNoQFKO0CamoY\noHbf4x5WvZ9jF6pjTd2xNhfWhfMKs5SZqrZyIu0JI1KqroQ9e/HtpCLMjJBqrWGc12iB4UA2xasd\n7YVRIS08kwZg1B2qzZk54Q/KUbzxDfW6LZmkqvkwsqo7vNszbp4waKbtznMNxaiVZTSJCuzW9Htq\n2ixaYDiQzfEZhAd40Tu0iWaA5iTdKkLKGq8OMPFZZY7yC6uKmGrt+ARXOWuheqXa84GZH8OY+5p+\nH6OeVNIupW14NCKoQtNu0ALDQVSYJJuPZzAhOqTtmKNAaRj1VWkdeZe6JtxGfanWim+oqidVkq9e\nF2WdH/4LR2PktKTFav+FRofVOopDKXnkFJYxoS2Zo0wm5cMYcXvd17m6wz1trH+VZW9vrwClYWhz\nSsMxBIapXPsvNFrDcBQb45WDdXxUG7KT5yVBWYF9fSC8O7Ytk05ltrfZj1GYVTOkVlM/lq1YtYZx\n3qMFhoPYHJ9Bv3B/Ovl7tfRU7OesRUmQ9obh4C5Ih4pyKM49f5zejsTTX7XXBa2habTAcATFZRXs\nPJndtqKjQGV4g+0cjLaOpUmqOAeQ2ofRGISo0jK0Seq8RwsMB7DzZBal5SYmRLcxgXH2CPiFty1T\nk71U1pNKr8ry1hpG4zAEhjZJnfdogeEANsVn4O4qGNOjje1g0w+3T+0CzPWkfJUPo7JSbTsUjM2B\nbygIF9XLXXNeowWGA9gUl8Hwbh3xra1fdmvEZIL0Y7YzvNsLviHKJHU+lQVxBp36qd7fru4tPRNN\nC6MFRhPJKijlYEoeF7U1/0XuaXOEVDsuV20UIKysVKtNUo3i0hfg3tUtPQtNK0ALjCby2zHVK+DC\nNue/MBze7VjDMAoQ1lapVmMfrm7nRw0uTb20IRtK62JPYjafbEzgl9hUwgO8GNKIntwtypkYZZcO\nG9TSM3EevqGQekBpGK6eTa/cqtGc52iB0UBSc4t59Ns97DqVjb+XG/df3Ju7L+yBW31d7VobybtV\n/oWnX0vPxHn4Blf5MHyCVIioRqNpNFpgNJBvtp9iT2I2L1w1gJtGd8WvLTm6DaSE5D3QZ3pLz8S5\n+IZCRanq5aD9FxpNk7FrWyyEWCyEuFII0ca20Y5nx4ksBnbpwD0TerZNYQGq1WZhhuqq154xcjEy\njumQWo3GAdgrAN4HZgFxQohXhRB2hdYIIaYLIY4KIeKFEM/YON9BCLFCCLFPCHFQCHG3vWNbgpLy\nCvaezmF0W8u3sMbobdDeBYaR7X0uTYfUajQOwC6BIaVcK6W8DRgBnATWCiG2CCHuFkLYDM4WQrgC\n7wGXAwOAW4UQA6wuewQ4JKUcCkwE3hBCeNg5ttk5kJRLabmJMT3b+G41eTe4ekCngS09E+fiaxG5\npk1SGk2TsdvEJIQIBu4C5gB7gf9DCZA1tQwZA8RLKROklKXAd8C1VtdIwF+oBhJ+QBZQbufYZmfH\nSRWe2eY1jOS9qreFm0dLz8S5+FgIDB1Sq9E0GXt9GEuAjYAPcLWU8hop5fdSysdQC70tIoDTFq+T\nzMcseRfoD6QAB4C5UkqTnWONud0vhNglhNiVnp5u6xKHsfNEFr1DfQn283Tq+zgVUwWk7G3/5ijQ\nGoZG42Ds1TDellIOkFK+IqU8Y3lCSjmqCe8/DYgBugDDgHeFEA3qASql/EhKOUpKOSo0NLT+AY2k\nwiTZdSqbMT3b+E4145jK8I4Y2dIzcT7u3uBh3s9oH4ZG02TsFRgDhBCBxgshREchxMP1jEkGLKuV\nRZqPWXI3sFgq4oETQD87xzYrR1PzyS8ubwfmqN3qe5fzQMOAKs1CaxgaTZOxV2DcJ6XMMV5IKbOB\n+jrM7wSihRA9hRAewC3AcqtrEoHJAEKIMKAvkGDn2GZlZ7vxX+wBzwAIjmrpmTQPRmlu7cPQaJqM\nvYkErkIIIaWUUBkBVafHVEpZLoR4FFgFuALzpZQHhRAPms/PA/4BfC6EOAAI4GkpZYb5PWqMbfjj\nOY4dJ7Po3MGLyI5tvKZO8m7oMgxczpOUGsOP4dPGI9s0mlaAvQLjF+B7IcSH5tcPmI/ViZRyJbDS\n6tg8i59TgMvsHdtSSCnZeSKLsb2CEW25vERZMaQdhPGPtvRMmo9KgaFNUhpNU7FXYDyNEhIPmV+v\nAT5xyoxaIYlZhZzNL2F0W3d4p8WCqez88V8ABPYAzw7KDKfRaJqEXQLDHOr6gfnrvGPHCeW/aHMd\n9axJNjK8z4MIKYNxD8PgG3ThQY3GAdglMIQQ0cArqKxrL+O4lLKXk+bVqth5MosO3u5Ed2rjlV2T\nd4NfGAR0aemZNB8evhDUs6VnodG0C+z1fH6G0i7KgUnAl8DXzppUa2PnyWxG9+iIi0sb36Wm7FHa\nhd5tazSaRmCvD8NbSrnOHCl1CnhJCLEbeMGJc2sVnM0v5kRGAbeM7lr/xa2NzW9DVoL5hVRJe4Nv\natEpaTSatou9AqPEXNo8zhzumkztJUHaFXtOZQMwqq35L0oLYM3zKtPZ3Ucd69AV+tgMStNoNJp6\nsVdgzEXVkXoclTsxCbjTWZNqTew9nYO7q2BglzYWZVOSr75P/TuMvrdl56LRaNoF9QoMc5LezVLK\nPyuc7ZsAABJiSURBVAHnUOU8zhtiEnMY0DkAL3fXlp5KwyjOU991OKlGo3EQ9Tq9pZQVwIRmmEur\no7zCxP6kXIZ3a4NZwoaG4enfsvPQaDTtBntNUnuFEMuBH4EC46CUcrFTZtVKOJZ2jqKyCoZ1Daz/\n4tZGiVnD8NIahkajcQz2CgwvIBO41OKYBNq1wIg5reottk2BoTUMjUbjWOzN9D6v/BYGMaez6ejj\nTvdgn5aeSsMxNAwtMDQajYOwN9P7M5RGUQ0p5T0On1ErIuZ0DkO7BrbNgoOVGoY2SWk0Gsdgr0nq\nfxY/ewEzUG1V2y35xWXEnT3HFYM7t/RUGoc2SWk0Ggdjr0lqkeVrIcQCYJNTZtRKOJCUi5S0zQgp\nUCYpN29wdW/pmWg0mnZCY7voRAOdHDmR1sZew+Ed2QYd3qDyMLR2odFoHIi9Pox8qvswUlE9Mtot\nMadz6BXiSwefNrpDL8nXAkOj0TgUe01S59XKI6Vkb2IOF0eHtPRUGk9Jvs7B0Gg0DsUuk5QQYoYQ\nooPF60AhxHXOm1bLkpxTRMa5EoZ1a6PmKNAahkajcTj2+jBelFLmGi+klDnAi86ZUsvTphP2DEry\ndEitRqNxKPYKDFvX2RuS2+aISczBw82FfuFteMHVGoZGo3Ew9gqMXUKIN4UQvc1fbwK7nTmxliTm\ndA6DIzrg4dbYILJWgNYwNBqNg7F3RXwMKAW+B74DioFHnDWplqSswsSB5Ny2bY6SUmsYGo3G4dgb\nJVUAPOPkubQKErMKKSk3MaBzG96dlxaANGmBodFoHIq9UVJrhBCBFq87CiFWOW9aLUdKThEAkR29\nW3gmTUCXBdFoNE7AXpNUiDkyCgApZTbtNNM7OVsJjIj2IDC8OtR9nUaj0TQAewWGSQjRzXghhOiB\njeq17YGUnCJcBIQFeLX0VBqP1jA0Go0TsDc09q/AJiHEb4AALgLud9qsWpCknCLCA7xwd23LEVLm\nlBktMDQajQOxa1WUUv4CjAKOAguAJ4Gi+sYJIaYLIY4KIeKFEDWc5kKIp4QQMeavWCFEhRAiyHzu\npBDigPncrgY9VRNIySmiS2AbNkeB1jA0Go1TsLf44BxgLhAJxABjga1Ub9lqPcYVeA+YCiQBO4UQ\ny6WUh4xrpJSvAa+Zr78a+IOUMsviNpOklBkNeqImkpxTxIi2WtLcQDdP0mg0TsBeu8tcYDRwSko5\nCRgO5NQ9hDFAvJQyQUpZisrfuLaO629FaS8tRoVJkppbrDUMjUajsYG9AqNYSlkMIITwlFIeAfrW\nMyYCOG3xOsl8rAZCCB9gOmDZqEkCa4UQu4UQtfpLhBD3CyF2CSF2paen2/EotZOeX0JZhSSirQuM\nYt3PW6PROB57nd5J5jyMpcAaIUQ2cMqB87ga2GxljpogpUwWQnQyv+cRKeXv1gOllB8BHwGMGjWq\nSZFbyTmFQBsPqQXdbU+j0TgFezO9Z5h/fEkIsR7oAPxSz7BkoKvF60jzMVvcgpU5SkqZbP5+Vgix\nBGXiqiEwHElyTjFA29cwdC8MjUbjBBocOyql/E1Kudzsl6iLnUC0EKKnEMIDJRSWW19k7rNxCbDM\n4pivEMLf+Bm4DIht6FwbipG01y58GNocpdFoHIzTSpRLKcuFEI8CqwBXYL6U8qAQ4kHz+XnmS2cA\nq831qgzCgCVCCGOO35pDe51KSk4RHbzd8fNs45XbS3Q/b41G43icujJKKVcCK62OzbN6/TnwudWx\nBGCoM+dmi+ScorZvjgKzhqFNUhqNxrG04XRmx9MukvZAm6Q0Go1T0ALDguTsorZdpdZAaxgajcYJ\naIFhJq+4jPyScroEtuGigwbF2oeh0WgcjxYYZirLmgf6tPBMmoiUyumtw2o1Go2D0QLDjNE4qc1r\nGKUFgNQahkajcThaYJhJzmkHjZNA15HSaDROQwsMM8k5RXi4uhDi69nSU2kaJUYdKW2S0mg0jkUL\nDDPJ2UV0CfTCxUW09FSahi5trtFonIQWGGbaTw6GrlSr0WicgxYYZtpVljdogaHRaByOFhhAabmJ\ns/kl7UPD0L0wNBqNk9ACA0jNLUbKdhAhBVUahs7D0Gg0DkYLDCDJ3Dgpsj1oGIbA8NAahkajcSxa\nYAAp5sZJ7cIkVZIH7j7g2sZLtGs0mlaHFhhUlQXp3NazvEH3wtBoNE5DCwxUSG2ovyeebq4tPZWm\noyvVajQaJ6EFBu0opBZ0LwyNRuM0tMBAaRhaYGg0Gk3dnPcCQ0qpNIz2EFILWmBoNBqncd6H0kgJ\nix4aT4CXe0tPxTEU54FXh5aehUajaYec9wLDxUUwKKIdLbBaw9BoNE7ivDdJtSuMbntaYGg0Gieg\nBUZ7Qnfb02g0TkQLjPaEbp6k0WiciBYY7Qld2lyj0TgRLTDaE7rbnkajcSJaYLQndLc9jUbjRLTA\naE8YzZN0LwyNRuMEnCowhBDThRBHhRDxQohnbJx/SggRY/6KFUJUCCGC7BmrsYH2YWg0GifiNIEh\nhHAF3gMuBwYAtwohBlheI6V8TUo5TEo5DHgW+E1KmWXPWI0NtMDQaDROxJkaxhggXkqZIKUsBb4D\nrq3j+luBBY0cqwHdbU+j0TgVZwqMCOC0xesk87EaCCF8gOnAokaMvV+I/2/v7mOkqO84jr8/coo8\nKE+iVUBBpLbWKtYTUbFVqAZNq21iU3yqaUyNiabaNmklfTD276YPSW3RWsVWq60WKjFGFGoxGq0c\niniACCqFo+odWEVQQeTbP+Z3sN1KHc7Ozeze55Vsdue3s3uf29u9787vNzM/tUlq6+rq+sihG9q2\nzbDvIM+2Z2aFqMqg9xeBxyPi9b19YETcHBGtEdE6cuTIAqI1EJ8WxMwKVGTB2ACMqVkendo+yAx2\nd0ft7WOtm088aGYFKrJgLAYmSBonaT+yojCvfiVJQ4DPAfft7WOtjguGmRWosM7uiNgh6WpgPtAP\nuDUilku6Mt0/K636ZeChiNj6YY8tKmvTeHezj8Ews8IUOjoaEQ8AD9S1zapbng3MzvNY+xDb3oID\nDik7hZk1qaoMetv/w9sbYcCwslOYWZNywWgW77wBW7tg+Piyk5hZk3LBaBabXsyuD5pQbg4za1ou\nGM1i0+rseoQLhpkVwwWjWWxcDeoHw8aWncTMmpQLRrPYtDorFi37lZ3EzJqUC0az2LjG4xdmVigX\njGawcye8/iKMOKrsJGbWxFwwmsGb62HHu97CMLNCuWA0A+8hZWa9wAWjGXQfg+EuKTMrkAtGM9i4\nGvofCIMPLjuJmTUxF4xmsGl1tnUhlZ3EzJqYC0Yz8C61ZtYLXDAa3fatsLnDA95mVjgXjEa366SD\nHvA2s2K5YDQ671JrZr3EBaPRbVwDCEZ4HgwzK5YLRqPbtAaGjIF9B5SdxMyanAtGo9u02uMXZtYr\nXDAaWUTWJeXxCzPrBS4YjWzLa7D9LR+DYWa9wgWjkW3s3kPKA95mVjwXjEbmXWrNrBe1lB2gknZs\ny+aXqLrOldAyAA4cVXYSM+sDXDDqbf4n/HJSNjbQCD52HOzjDUUzK54LRr2222D7Fph2PbT0LzvN\nhzv8lLITmFkf4YJRa8d2WDIbJpwNp3+77DRmZpVSaF+GpOmSVklaI+m6PaxzhqSlkpZLWlTTvlbS\nc+m+tiJz7rJyHmzthEnf6JUfZ2bWSArbwpDUD7gROAvoABZLmhcRK2rWGQr8CpgeEesk1U8Zd2ZE\nbCwq439ZfAsMGwfjp/XajzQzaxRFbmFMAtZExEsRsR24Gzi/bp2LgDkRsQ4gIjoLzPO/vdoO656A\nky73ILKZ2Qco8j/jKGB9zXJHaqv1cWCYpL9JWiLpazX3BbAgtV+xpx8i6QpJbZLaurq6ep528W+g\nZX+YeHHPn8PMrImVPejdApwITAMGAE9IejIiXgCmRMSG1E31sKTnI+LR+ieIiJuBmwFaW1ujRyne\neQOW/Qk+fQEMHN7T38XMrKkVuYWxARhTszw6tdXqAOZHxNY0VvEocDxARGxI153AXLIurmI8eze8\n9zac5MFuM7M9KbJgLAYmSBonaT9gBjCvbp37gCmSWiQNBE4GVkoaJOkAAEmDgLOB9kJSRmSD3aNP\ngsMmFvIjzMyaQWFdUhGxQ9LVwHygH3BrRCyXdGW6f1ZErJT0ILAM2AncEhHtko4E5krqzviHiHiw\nkKDbt8Lhk2H81EKe3sysWSiiZ93+VdTa2hptbb1zyIaZWTOQtCQiWvOs6/1HzcwsFxcMMzPLxQXD\nzMxyccEwM7NcXDDMzCwXFwwzM8vFBcPMzHJxwTAzs1ya6sA9SV3AP3r48IOA3pt7I7+q5oLqZqtq\nLqhutqrmgupmq2ou2LtsR0TEyDwrNlXB+CgkteU92rE3VTUXVDdbVXNBdbNVNRdUN1tVc0Fx2dwl\nZWZmubhgmJlZLi4Yu91cdoA9qGouqG62quaC6marai6obraq5oKCsnkMw8zMcvEWhpmZ5eKCYWZm\nufT5giFpuqRVktZIuq7kLLdK6pTUXtM2XNLDklan62El5Boj6RFJKyQtl3RNhbLtL+kpSc+mbDdU\nJVvK0U/SM5Lur1iutZKek7RUUltVskkaKuleSc9LWinplIrkOjq9Vt2XzZKurUi2b6X3fruku9Jn\nopBcfbpgSOoH3AicAxwDXCjpmBIjzQam17VdByyMiAnAwrTc23YA34mIY4DJwFXpdapCtm3A1Ig4\nHpgITJc0uSLZAK4BVtYsVyUXwJkRMbFmf/0qZPsF8GBEfAI4nuy1Kz1XRKxKr9VE4ETgbWBu2dkk\njQK+CbRGxLFk02HPKCxXRPTZC3AKML9meSYws+RMY4H2muVVwKHp9qHAqgq8bvcBZ1UtGzAQeBo4\nuQrZgNHpwzoVuL9Kf09gLXBQXVup2YAhwMuknXGqkusDcp4NPF6FbMAoYD0wHGgB7k/5CsnVp7cw\n2P1id+tIbVVySES8km6/ChxSZhhJY4ETgL9TkWyp22cp0Ak8HBFVyfZz4LvAzpq2KuQCCGCBpCWS\nrkhtZWcbB3QBt6VuvFskDapArnozgLvS7VKzRcQG4CfAOuAV4M2IeKioXH29YDSUyL4ulLYftKTB\nwJ+BayNic+19ZWaLiPcj6yoYDUySdGzZ2SR9AeiMiCV7Wqfkv+eU9JqdQ9bF+NnaO0vK1gJ8Bvh1\nRJwAbKWuK6UCn4H9gPOAe+rvK+l9Ngw4n6zYHgYMknRJUbn6esHYAIypWR6d2qrkNUmHAqTrzjJC\nSNqXrFjcGRFzqpStW0S8ATxCNg5UdrbTgPMkrQXuBqZKuqMCuYBd30yJiE6yvvhJFcjWAXSkLUSA\ne8kKSNm5ap0DPB0Rr6XlsrN9Hng5Iroi4j1gDnBqUbn6esFYDEyQNC59c5gBzCs5U715wGXp9mVk\n4we9SpKA3wIrI+KnFcs2UtLQdHsA2djK82Vni4iZETE6IsaSva/+GhGXlJ0LQNIgSQd03ybr824v\nO1tEvAqsl3R0apoGrCg7V50L2d0dBeVnWwdMljQwfU6nke0oUEyuMgePqnABzgVeAF4Evl9ylrvI\n+iHfI/u2dTkwgmzgdDWwABheQq4pZJu0y4Cl6XJuRbIdBzyTsrUDP0rtpWeryXgGuwe9S88FHAk8\nmy7Lu9/3Fck2EWhLf8+/AMOqkCtlGwRsAobUtJWeDbiB7EtSO/B7oH9RuXxqEDMzy6Wvd0mZmVlO\nLhhmZpaLC4aZmeXigmFmZrm4YJiZWS4uGGYVIOmM7jPamlWVC4aZmeXigmG2FyRdkubfWCrppnTi\nwy2SfpbmJFgoaWRad6KkJyUtkzS3e04CSUdJWqBsDo+nJY1PTz+4Zi6IO9ORu2aV4YJhlpOkTwJf\nBU6L7MR97wMXkx0B3BYRnwIWAdenh/wO+F5EHAc8V9N+J3BjZHN4nEp2dD9kZwG+lmxuliPJzkdl\nVhktZQcwayDTyCbPWZy+/A8gO6nbTuCPaZ07gDmShgBDI2JRar8duCedw2lURMwFiIh3AdLzPRUR\nHWl5KdncKI8V/2uZ5eOCYZafgNsjYuZ/NEo/rFuvp+fb2VZz+338+bSKcZeUWX4LgQskHQy75sA+\nguxzdEFa5yLgsYh4E/iXpNNT+6XAooh4C+iQ9KX0HP0lDezV38Ksh/wNxiyniFgh6QfAQ5L2ITur\n8FVkE/1MSvd1ko1zQHZa6VmpILwEfD21XwrcJOnH6Tm+0ou/hlmP+Wy1Zh+RpC0RMbjsHGZFc5eU\nmZnl4i0MMzPLxVsYZmaWiwuGmZnl4oJhZma5uGCYmVkuLhhmZpbLvwHeSteMEJ74+gAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ca67fbbc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niPRTKIiISD+FgoiI9Pv/bT9sAUknnkwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ca67fb6550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0369616\n",
      "0.0369616\n",
      "0.196795\n",
      "0.196795\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0312446\n",
      "0.0312446\n",
      "0.0574131\n",
      "0.0574131\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0410375\n",
      "0.0410375\n",
      "0.025\n",
      "0.025\n",
      "0.294159\n",
      "0.294159\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0808564\n",
      "0.0808564\n",
      "0.0948212\n",
      "0.0948212\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.751833\n",
      "0.751833\n",
      "0.252036\n",
      "0.252036\n",
      "0.0272324\n",
      "0.0272324\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.566309\n",
      "0.566309\n",
      "0.0661362\n",
      "0.0661362\n",
      "0.0257904\n",
      "0.0257904\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.6548\n",
      "0.6548\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.936005\n",
      "0.936005\n",
      "0.923681\n",
      "0.923681\n",
      "0.0290829\n",
      "0.0290829\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.886727\n",
      "0.886727\n",
      "0.029926\n",
      "0.029926\n",
      "0.0496582\n",
      "0.0496582\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.177203\n",
      "0.177203\n",
      "0.661889\n",
      "0.661889\n",
      "0.975\n",
      "0.975\n",
      "0.348275\n",
      "0.348275\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.166034\n",
      "0.166034\n",
      "0.975\n",
      "0.975\n",
      "0.0773542\n",
      "0.0773542\n",
      "0.123763\n",
      "0.123763\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.128248\n",
      "0.128248\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0312221\n",
      "0.0312221\n",
      "0.975\n",
      "0.975\n",
      "0.296991\n",
      "0.296991\n",
      "0.0520963\n",
      "0.0520963\n",
      "0.0545643\n",
      "0.0545643\n",
      "0.326776\n",
      "0.326776\n",
      "0.025\n",
      "0.025\n",
      "0.0376448\n",
      "0.0376448\n",
      "0.025\n",
      "0.025\n",
      "0.511582\n",
      "0.511582\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0506004\n",
      "0.0506004\n",
      "0.060948\n",
      "0.060948\n",
      "0.196591\n",
      "0.196591\n",
      "0.975\n",
      "0.975\n",
      "0.410994\n",
      "0.410994\n",
      "0.33119\n",
      "0.33119\n",
      "0.0649462\n",
      "0.0649462\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.097247\n",
      "0.097247\n",
      "0.025\n",
      "0.025\n",
      "0.287629\n",
      "0.287629\n",
      "0.025\n",
      "0.025\n",
      "0.280797\n",
      "0.280797\n",
      "0.025\n",
      "0.025\n",
      "0.4401\n",
      "0.4401\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.931019\n",
      "0.931019\n",
      "0.025\n",
      "0.025\n",
      "0.076322\n",
      "0.076322\n",
      "0.0468558\n",
      "0.0468558\n",
      "0.116452\n",
      "0.116452\n",
      "0.119902\n",
      "0.119902\n",
      "0.479691\n",
      "0.479691\n",
      "0.336317\n",
      "0.336317\n",
      "0.964458\n",
      "0.964458\n",
      "0.40006\n",
      "0.40006\n",
      "0.0873552\n",
      "0.0873552\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.317454\n",
      "0.317454\n",
      "0.142896\n",
      "0.142896\n",
      "0.975\n",
      "0.975\n",
      "0.0518816\n",
      "0.0518816\n",
      "0.154585\n",
      "0.154585\n",
      "0.025\n",
      "0.025\n",
      "0.232983\n",
      "0.232983\n",
      "0.253899\n",
      "0.253899\n",
      "0.695552\n",
      "0.695552\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0503526\n",
      "0.0503526\n",
      "0.299488\n",
      "0.299488\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.851063\n",
      "0.851063\n",
      "0.296699\n",
      "0.296699\n",
      "0.0889624\n",
      "0.0889624\n",
      "0.553978\n",
      "0.553978\n",
      "0.025\n",
      "0.025\n",
      "0.732811\n",
      "0.732811\n",
      "0.975\n",
      "0.975\n",
      "0.159874\n",
      "0.159874\n",
      "0.025\n",
      "0.025\n",
      "0.123744\n",
      "0.123744\n",
      "0.159498\n",
      "0.159498\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.107546\n",
      "0.107546\n",
      "0.025\n",
      "0.025\n",
      "0.0292534\n",
      "0.0292534\n",
      "0.0427586\n",
      "0.0427586\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0341584\n",
      "0.0341584\n",
      "0.304217\n",
      "0.304217\n",
      "0.961387\n",
      "0.961387\n",
      "0.353591\n",
      "0.353591\n",
      "0.284185\n",
      "0.284185\n",
      "0.025\n",
      "0.025\n",
      "0.627639\n",
      "0.627639\n",
      "0.025\n",
      "0.025\n",
      "0.275988\n",
      "0.275988\n",
      "0.025\n",
      "0.025\n",
      "0.0430564\n",
      "0.0430564\n",
      "0.174717\n",
      "0.174717\n",
      "0.0825035\n",
      "0.0825035\n",
      "0.025\n",
      "0.025\n",
      "0.0810577\n",
      "0.0810577\n",
      "0.025\n",
      "0.025\n",
      "0.931243\n",
      "0.931243\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.974981\n",
      "0.974981\n",
      "0.117923\n",
      "0.117923\n",
      "0.295464\n",
      "0.295464\n",
      "0.054646\n",
      "0.054646\n",
      "0.025\n",
      "0.025\n",
      "0.621482\n",
      "0.621482\n",
      "0.975\n",
      "0.975\n",
      "0.0968197\n",
      "0.0968197\n",
      "0.640787\n",
      "0.640787\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.364001\n",
      "0.364001\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.114937\n",
      "0.114937\n",
      "0.0354706\n",
      "0.0354706\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.969299\n",
      "0.969299\n",
      "0.630603\n",
      "0.630603\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0657768\n",
      "0.0657768\n",
      "0.975\n",
      "0.975\n",
      "0.855383\n",
      "0.855383\n",
      "0.025\n",
      "0.025\n",
      "0.200143\n",
      "0.200143\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0911025\n",
      "0.0911025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.292563\n",
      "0.292563\n",
      "0.025\n",
      "0.025\n",
      "0.123246\n",
      "0.123246\n",
      "0.87064\n",
      "0.87064\n",
      "0.0293348\n",
      "0.0293348\n",
      "0.025\n",
      "0.025\n",
      "0.516594\n",
      "0.516594\n",
      "0.15595\n",
      "0.15595\n",
      "0.15003\n",
      "0.15003\n",
      "0.025\n",
      "0.025\n",
      "0.02782\n",
      "0.02782\n",
      "0.182238\n",
      "0.182238\n",
      "0.783433\n",
      "0.783433\n",
      "0.025\n",
      "0.025\n",
      "0.381075\n",
      "0.381075\n",
      "0.0520871\n",
      "0.0520871\n",
      "0.025\n",
      "0.025\n",
      "0.154503\n",
      "0.154503\n",
      "0.810549\n",
      "0.810549\n",
      "0.824199\n",
      "0.824199\n",
      "0.668247\n",
      "0.668247\n",
      "0.025\n",
      "0.025\n",
      "0.455531\n",
      "0.455531\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.126891\n",
      "0.126891\n",
      "0.975\n",
      "0.975\n",
      "0.249188\n",
      "0.249188\n",
      "0.148453\n",
      "0.148453\n",
      "0.025\n",
      "0.025\n",
      "0.273874\n",
      "0.273874\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.826132\n",
      "0.826132\n",
      "0.025\n",
      "0.025\n",
      "0.0493614\n",
      "0.0493614\n",
      "0.025\n",
      "0.025\n",
      "0.0670055\n",
      "0.0670055\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.18607\n",
      "0.18607\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0345821\n",
      "0.0345821\n",
      "0.0752668\n",
      "0.0752668\n",
      "0.025\n",
      "0.025\n",
      "0.943178\n",
      "0.943178\n",
      "0.329613\n",
      "0.329613\n",
      "0.025\n",
      "0.025\n",
      "0.146025\n",
      "0.146025\n",
      "0.975\n",
      "0.975\n",
      "0.0505505\n",
      "0.0505505\n",
      "0.265704\n",
      "0.265704\n",
      "0.025\n",
      "0.025\n",
      "0.236223\n",
      "0.236223\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0786254\n",
      "0.0786254\n",
      "0.025\n",
      "0.025\n",
      "0.524849\n",
      "0.524849\n",
      "0.079105\n",
      "0.079105\n",
      "0.0614109\n",
      "0.0614109\n",
      "0.261484\n",
      "0.261484\n",
      "0.0388182\n",
      "0.0388182\n",
      "0.337566\n",
      "0.337566\n",
      "0.025\n",
      "0.025\n",
      "0.157734\n",
      "0.157734\n",
      "0.0465069\n",
      "0.0465069\n",
      "0.025\n",
      "0.025\n",
      "0.884612\n",
      "0.884612\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.268313\n",
      "0.268313\n",
      "0.975\n",
      "0.975\n",
      "0.180137\n",
      "0.180137\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.443968\n",
      "0.443968\n",
      "0.0436921\n",
      "0.0436921\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.82665\n",
      "0.82665\n",
      "0.364493\n",
      "0.364493\n",
      "0.0517582\n",
      "0.0517582\n",
      "0.025\n",
      "0.025\n",
      "0.166034\n",
      "0.166034\n",
      "0.214763\n",
      "0.214763\n",
      "0.025\n",
      "0.025\n",
      "0.599469\n",
      "0.599469\n",
      "0.025\n",
      "0.025\n",
      "0.579207\n",
      "0.579207\n",
      "0.959659\n",
      "0.959659\n",
      "0.352706\n",
      "0.352706\n",
      "0.975\n",
      "0.975\n",
      "0.80484\n",
      "0.80484\n",
      "0.975\n",
      "0.975\n",
      "0.167459\n",
      "0.167459\n",
      "0.655158\n",
      "0.655158\n",
      "0.36711\n",
      "0.36711\n",
      "0.025\n",
      "0.025\n",
      "0.179853\n",
      "0.179853\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0340626\n",
      "0.0340626\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0436926\n",
      "0.0436926\n",
      "0.196947\n",
      "0.196947\n",
      "0.607444\n",
      "0.607444\n",
      "0.177114\n",
      "0.177114\n",
      "0.946653\n",
      "0.946653\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.620643\n",
      "0.620643\n",
      "0.67199\n",
      "0.67199\n",
      "0.0784133\n",
      "0.0784133\n",
      "0.524161\n",
      "0.524161\n",
      "0.122704\n",
      "0.122704\n",
      "0.975\n",
      "0.975\n",
      "0.0535003\n",
      "0.0535003\n",
      "0.0859254\n",
      "0.0859254\n",
      "0.254673\n",
      "0.254673\n",
      "0.0362061\n",
      "0.0362061\n",
      "0.13963\n",
      "0.13963\n",
      "0.831371\n",
      "0.831371\n",
      "0.025\n",
      "0.025\n",
      "0.959215\n",
      "0.959215\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.867134\n",
      "0.867134\n",
      "0.914149\n",
      "0.914149\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.117926\n",
      "0.117926\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.748487\n",
      "0.748487\n",
      "0.025\n",
      "0.025\n",
      "0.168023\n",
      "0.168023\n",
      "0.025\n",
      "0.025\n",
      "0.0690718\n",
      "0.0690718\n",
      "0.193466\n",
      "0.193466\n",
      "0.614543\n",
      "0.614543\n",
      "0.920118\n",
      "0.920118\n",
      "0.975\n",
      "0.975\n",
      "0.0277314\n",
      "0.0277314\n",
      "0.025\n",
      "0.025\n",
      "0.082585\n",
      "0.082585\n",
      "0.548564\n",
      "0.548564\n",
      "0.258123\n",
      "0.258123\n",
      "0.108709\n",
      "0.108709\n",
      "0.975\n",
      "0.975\n",
      "0.0327292\n",
      "0.0327292\n",
      "0.025\n",
      "0.025\n",
      "0.891061\n",
      "0.891061\n",
      "0.025\n",
      "0.025\n",
      "0.132321\n",
      "0.132321\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.326728\n",
      "0.326728\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.819268\n",
      "0.819268\n",
      "0.240942\n",
      "0.240942\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0553464\n",
      "0.0553464\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0333931\n",
      "0.0333931\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.908114\n",
      "0.908114\n",
      "0.0263366\n",
      "0.0263366\n",
      "0.0824678\n",
      "0.0824678\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.936829\n",
      "0.936829\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.137253\n",
      "0.137253\n",
      "0.0695639\n",
      "0.0695639\n",
      "0.025\n",
      "0.025\n",
      "0.810749\n",
      "0.810749\n",
      "0.975\n",
      "0.975\n",
      "0.0275144\n",
      "0.0275144\n",
      "0.975\n",
      "0.975\n",
      "0.0557539\n",
      "0.0557539\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.277229\n",
      "0.277229\n",
      "0.735555\n",
      "0.735555\n",
      "0.465266\n",
      "0.465266\n",
      "0.025\n",
      "0.025\n",
      "0.190568\n",
      "0.190568\n",
      "0.31593\n",
      "0.31593\n",
      "0.025\n",
      "0.025\n",
      "0.911432\n",
      "0.911432\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.256056\n",
      "0.256056\n",
      "0.025\n",
      "0.025\n",
      "0.0307619\n",
      "0.0307619\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.571933\n",
      "0.571933\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0866958\n",
      "0.0866958\n",
      "0.025\n",
      "0.025\n",
      "0.133761\n",
      "0.133761\n",
      "0.025\n",
      "0.025\n",
      "0.167607\n",
      "0.167607\n",
      "0.0316893\n",
      "0.0316893\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.974435\n",
      "0.974435\n",
      "0.887838\n",
      "0.887838\n",
      "0.025\n",
      "0.025\n",
      "0.866287\n",
      "0.866287\n",
      "0.025\n",
      "0.025\n",
      "0.0509651\n",
      "0.0509651\n",
      "0.154548\n",
      "0.154548\n",
      "0.975\n",
      "0.975\n",
      "0.0628504\n",
      "0.0628504\n",
      "0.109726\n",
      "0.109726\n",
      "0.025\n",
      "0.025\n",
      "0.704068\n",
      "0.704068\n",
      "0.025\n",
      "0.025\n",
      "0.646006\n",
      "0.646006\n",
      "0.025\n",
      "0.025\n",
      "0.0364459\n",
      "0.0364459\n",
      "0.025\n",
      "0.025\n",
      "0.0813578\n",
      "0.0813578\n",
      "0.648537\n",
      "0.648537\n",
      "0.485814\n",
      "0.485814\n",
      "0.0366396\n",
      "0.0366396\n",
      "0.423968\n",
      "0.423968\n",
      "0.0255427\n",
      "0.0255427\n",
      "0.192713\n",
      "0.192713\n",
      "0.0661861\n",
      "0.0661861\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.96774\n",
      "0.96774\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0304085\n",
      "0.0304085\n",
      "0.907147\n",
      "0.907147\n",
      "0.975\n",
      "0.975\n",
      "0.0529763\n",
      "0.0529763\n",
      "0.60839\n",
      "0.60839\n",
      "0.025\n",
      "0.025\n",
      "0.886777\n",
      "0.886777\n",
      "0.025\n",
      "0.025\n",
      "0.0465298\n",
      "0.0465298\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0649554\n",
      "0.0649554\n",
      "0.025\n",
      "0.025\n",
      "0.351486\n",
      "0.351486\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.177699\n",
      "0.177699\n",
      "0.62872\n",
      "0.62872\n",
      "0.960601\n",
      "0.960601\n",
      "0.025\n",
      "0.025\n",
      "0.0744346\n",
      "0.0744346\n",
      "0.0570724\n",
      "0.0570724\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.401245\n",
      "0.401245\n",
      "0.732211\n",
      "0.732211\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0379352\n",
      "0.0379352\n",
      "0.975\n",
      "0.975\n",
      "0.504773\n",
      "0.504773\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0707751\n",
      "0.0707751\n",
      "0.975\n",
      "0.975\n",
      "0.0570972\n",
      "0.0570972\n",
      "0.173007\n",
      "0.173007\n",
      "0.975\n",
      "0.975\n",
      "0.0746103\n",
      "0.0746103\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.583665\n",
      "0.583665\n",
      "0.300457\n",
      "0.300457\n",
      "0.025\n",
      "0.025\n",
      "0.716339\n",
      "0.716339\n",
      "0.0936643\n",
      "0.0936643\n",
      "0.202931\n",
      "0.202931\n",
      "0.203108\n",
      "0.203108\n",
      "0.275143\n",
      "0.275143\n",
      "0.0777695\n",
      "0.0777695\n",
      "0.118204\n",
      "0.118204\n",
      "0.025\n",
      "0.025\n",
      "0.028533\n",
      "0.028533\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0392463\n",
      "0.0392463\n",
      "0.0331045\n",
      "0.0331045\n",
      "0.537005\n",
      "0.537005\n",
      "0.278391\n",
      "0.278391\n",
      "0.025\n",
      "0.025\n",
      "0.671523\n",
      "0.671523\n",
      "0.025\n",
      "0.025\n",
      "0.522223\n",
      "0.522223\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0677551\n",
      "0.0677551\n",
      "0.025\n",
      "0.025\n",
      "0.821164\n",
      "0.821164\n",
      "0.025\n",
      "0.025\n",
      "0.501144\n",
      "0.501144\n",
      "0.0941134\n",
      "0.0941134\n",
      "0.966863\n",
      "0.966863\n",
      "0.11553\n",
      "0.11553\n",
      "0.536179\n",
      "0.536179\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.124369\n",
      "0.124369\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.173567\n",
      "0.173567\n",
      "0.025\n",
      "0.025\n",
      "0.962477\n",
      "0.962477\n",
      "0.975\n",
      "0.975\n",
      "0.0389132\n",
      "0.0389132\n",
      "0.025\n",
      "0.025\n",
      "0.796702\n",
      "0.796702\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0915112\n",
      "0.0915112\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.908564\n",
      "0.908564\n",
      "0.931184\n",
      "0.931184\n",
      "0.925214\n",
      "0.925214\n",
      "0.0340234\n",
      "0.0340234\n",
      "0.025\n",
      "0.025\n",
      "0.833216\n",
      "0.833216\n",
      "0.484482\n",
      "0.484482\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.484114\n",
      "0.484114\n",
      "0.795571\n",
      "0.795571\n",
      "0.0690093\n",
      "0.0690093\n",
      "0.0649232\n",
      "0.0649232\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0809074\n",
      "0.0809074\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0320237\n",
      "0.0320237\n",
      "0.798099\n",
      "0.798099\n",
      "0.025\n",
      "0.025\n",
      "0.0935142\n",
      "0.0935142\n",
      "0.889439\n",
      "0.889439\n",
      "0.025\n",
      "0.025\n",
      "0.058514\n",
      "0.058514\n",
      "0.0484833\n",
      "0.0484833\n",
      "0.129954\n",
      "0.129954\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.939844\n",
      "0.939844\n",
      "0.769591\n",
      "0.769591\n",
      "0.0540772\n",
      "0.0540772\n",
      "0.025\n",
      "0.025\n",
      "0.0499039\n",
      "0.0499039\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0307284\n",
      "0.0307284\n",
      "0.288\n",
      "0.288\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.51689\n",
      "0.51689\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.421129\n",
      "0.421129\n",
      "0.170137\n",
      "0.170137\n",
      "0.975\n",
      "0.975\n",
      "0.12968\n",
      "0.12968\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.774387\n",
      "0.774387\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0410164\n",
      "0.0410164\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.100848\n",
      "0.100848\n",
      "0.97273\n",
      "0.97273\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0673769\n",
      "0.0673769\n",
      "0.151365\n",
      "0.151365\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.12859\n",
      "0.12859\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.750463\n",
      "0.750463\n",
      "0.443601\n",
      "0.443601\n",
      "0.156294\n",
      "0.156294\n",
      "0.0878315\n",
      "0.0878315\n",
      "0.723992\n",
      "0.723992\n",
      "0.151549\n",
      "0.151549\n",
      "0.0344036\n",
      "0.0344036\n",
      "0.0603491\n",
      "0.0603491\n",
      "0.916778\n",
      "0.916778\n",
      "0.025\n",
      "0.025\n",
      "0.0440225\n",
      "0.0440225\n",
      "0.025\n",
      "0.025\n",
      "0.07713\n",
      "0.07713\n",
      "0.025\n",
      "0.025\n",
      "0.786195\n",
      "0.786195\n",
      "0.975\n",
      "0.975\n",
      "0.130032\n",
      "0.130032\n",
      "0.167072\n",
      "0.167072\n",
      "0.0397986\n",
      "0.0397986\n",
      "0.025\n",
      "0.025\n",
      "0.218135\n",
      "0.218135\n",
      "0.114593\n",
      "0.114593\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.194471\n",
      "0.194471\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.17282\n",
      "0.17282\n",
      "0.4686\n",
      "0.4686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.118946\n",
      "0.118946\n",
      "0.941532\n",
      "0.941532\n",
      "0.13793\n",
      "0.13793\n",
      "0.13074\n",
      "0.13074\n",
      "0.919576\n",
      "0.919576\n",
      "0.509091\n",
      "0.509091\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0492613\n",
      "0.0492613\n",
      "0.025\n",
      "0.025\n",
      "0.313927\n",
      "0.313927\n",
      "0.970596\n",
      "0.970596\n",
      "0.224206\n",
      "0.224206\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.911998\n",
      "0.911998\n",
      "0.0433278\n",
      "0.0433278\n",
      "0.801345\n",
      "0.801345\n",
      "0.067093\n",
      "0.067093\n",
      "0.485473\n",
      "0.485473\n",
      "0.0878854\n",
      "0.0878854\n",
      "0.92975\n",
      "0.92975\n",
      "0.623491\n",
      "0.623491\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.19078\n",
      "0.19078\n",
      "0.025\n",
      "0.025\n",
      "0.040799\n",
      "0.040799\n",
      "0.025\n",
      "0.025\n",
      "0.60829\n",
      "0.60829\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0376866\n",
      "0.0376866\n",
      "0.975\n",
      "0.975\n",
      "0.133031\n",
      "0.133031\n",
      "0.742541\n",
      "0.742541\n",
      "0.025\n",
      "0.025\n",
      "0.0573791\n",
      "0.0573791\n",
      "0.573465\n",
      "0.573465\n",
      "0.352197\n",
      "0.352197\n",
      "0.025\n",
      "0.025\n",
      "0.0530096\n",
      "0.0530096\n",
      "0.025\n",
      "0.025\n",
      "0.96856\n",
      "0.96856\n",
      "0.187725\n",
      "0.187725\n",
      "0.131131\n",
      "0.131131\n",
      "0.591825\n",
      "0.591825\n",
      "0.281134\n",
      "0.281134\n",
      "0.103923\n",
      "0.103923\n",
      "0.0327066\n",
      "0.0327066\n",
      "0.025\n",
      "0.025\n",
      "0.113619\n",
      "0.113619\n",
      "0.961255\n",
      "0.961255\n",
      "0.937439\n",
      "0.937439\n",
      "0.358256\n",
      "0.358256\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.559745\n",
      "0.559745\n",
      "0.324155\n",
      "0.324155\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.516091\n",
      "0.516091\n",
      "0.255373\n",
      "0.255373\n",
      "0.025\n",
      "0.025\n",
      "0.404232\n",
      "0.404232\n",
      "0.285156\n",
      "0.285156\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.692047\n",
      "0.692047\n",
      "0.561544\n",
      "0.561544\n",
      "0.025\n",
      "0.025\n",
      "0.64584\n",
      "0.64584\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.338185\n",
      "0.338185\n",
      "0.025\n",
      "0.025\n",
      "0.478947\n",
      "0.478947\n",
      "0.025\n",
      "0.025\n",
      "0.564063\n",
      "0.564063\n",
      "0.43282\n",
      "0.43282\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.936683\n",
      "0.936683\n",
      "0.0328466\n",
      "0.0328466\n",
      "0.975\n",
      "0.975\n",
      "0.873238\n",
      "0.873238\n",
      "0.066912\n",
      "0.066912\n",
      "0.0858133\n",
      "0.0858133\n",
      "0.279839\n",
      "0.279839\n",
      "0.025\n",
      "0.025\n",
      "0.0371452\n",
      "0.0371452\n",
      "0.970738\n",
      "0.970738\n",
      "0.8751\n",
      "0.8751\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.110528\n",
      "0.110528\n",
      "0.522763\n",
      "0.522763\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0628513\n",
      "0.0628513\n",
      "0.652993\n",
      "0.652993\n",
      "0.025\n",
      "0.025\n",
      "0.0640371\n",
      "0.0640371\n",
      "0.679884\n",
      "0.679884\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.306434\n",
      "0.306434\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0752826\n",
      "0.0752826\n",
      "0.0952333\n",
      "0.0952333\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0947225\n",
      "0.0947225\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.111502\n",
      "0.111502\n",
      "0.025\n",
      "0.025\n",
      "0.312474\n",
      "0.312474\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.316815\n",
      "0.316815\n",
      "0.025\n",
      "0.025\n",
      "0.363134\n",
      "0.363134\n",
      "0.0275475\n",
      "0.0275475\n",
      "0.226627\n",
      "0.226627\n",
      "0.025\n",
      "0.025\n",
      "0.967602\n",
      "0.967602\n",
      "0.100786\n",
      "0.100786\n",
      "0.372055\n",
      "0.372055\n",
      "0.0687073\n",
      "0.0687073\n",
      "0.025\n",
      "0.025\n",
      "0.121857\n",
      "0.121857\n",
      "0.025\n",
      "0.025\n",
      "0.0265747\n",
      "0.0265747\n",
      "0.025\n",
      "0.025\n",
      "0.256997\n",
      "0.256997\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.892199\n",
      "0.892199\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0975805\n",
      "0.0975805\n",
      "0.975\n",
      "0.975\n",
      "0.926385\n",
      "0.926385\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.209265\n",
      "0.209265\n",
      "0.039755\n",
      "0.039755\n",
      "0.434043\n",
      "0.434043\n",
      "0.746724\n",
      "0.746724\n",
      "0.025\n",
      "0.025\n",
      "0.0429584\n",
      "0.0429584\n",
      "0.881792\n",
      "0.881792\n",
      "0.802407\n",
      "0.802407\n",
      "0.0343714\n",
      "0.0343714\n",
      "0.025\n",
      "0.025\n",
      "0.154679\n",
      "0.154679\n",
      "0.283198\n",
      "0.283198\n",
      "0.0371093\n",
      "0.0371093\n",
      "0.042224\n",
      "0.042224\n",
      "0.358213\n",
      "0.358213\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.970324\n",
      "0.970324\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.239561\n",
      "0.239561\n",
      "0.025\n",
      "0.025\n",
      "0.643351\n",
      "0.643351\n",
      "0.0573906\n",
      "0.0573906\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.430532\n",
      "0.430532\n",
      "0.0278918\n",
      "0.0278918\n",
      "0.0820525\n",
      "0.0820525\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.79261\n",
      "0.79261\n",
      "0.0591218\n",
      "0.0591218\n",
      "0.247299\n",
      "0.247299\n",
      "0.975\n",
      "0.975\n",
      "0.0913621\n",
      "0.0913621\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.677836\n",
      "0.677836\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.468939\n",
      "0.468939\n",
      "0.816381\n",
      "0.816381\n",
      "0.025\n",
      "0.025\n",
      "0.0501057\n",
      "0.0501057\n",
      "0.969464\n",
      "0.969464\n",
      "0.975\n",
      "0.975\n",
      "0.861971\n",
      "0.861971\n",
      "0.347668\n",
      "0.347668\n",
      "0.963036\n",
      "0.963036\n",
      "0.0798605\n",
      "0.0798605\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.165792\n",
      "0.165792\n",
      "0.025\n",
      "0.025\n",
      "0.326431\n",
      "0.326431\n",
      "0.169174\n",
      "0.169174\n",
      "0.975\n",
      "0.975\n",
      "0.946813\n",
      "0.946813\n",
      "0.0629756\n",
      "0.0629756\n",
      "0.025\n",
      "0.025\n",
      "0.450007\n",
      "0.450007\n",
      "0.245519\n",
      "0.245519\n",
      "0.0378778\n",
      "0.0378778\n",
      "0.248601\n",
      "0.248601\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.137742\n",
      "0.137742\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.156305\n",
      "0.156305\n",
      "0.876956\n",
      "0.876956\n",
      "0.109002\n",
      "0.109002\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.603928\n",
      "0.603928\n",
      "0.025\n",
      "0.025\n",
      "0.957017\n",
      "0.957017\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.969512\n",
      "0.969512\n",
      "0.205287\n",
      "0.205287\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.35271\n",
      "0.35271\n",
      "0.0880364\n",
      "0.0880364\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.119628\n",
      "0.119628\n",
      "0.025\n",
      "0.025\n",
      "0.626203\n",
      "0.626203\n",
      "0.60323\n",
      "0.60323\n",
      "0.678006\n",
      "0.678006\n",
      "0.168658\n",
      "0.168658\n",
      "0.103194\n",
      "0.103194\n",
      "0.025\n",
      "0.025\n",
      "0.308313\n",
      "0.308313\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.308664\n",
      "0.308664\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0818062\n",
      "0.0818062\n",
      "0.582224\n",
      "0.582224\n",
      "0.33912\n",
      "0.33912\n",
      "0.0655336\n",
      "0.0655336\n",
      "0.113946\n",
      "0.113946\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.125307\n",
      "0.125307\n",
      "0.025\n",
      "0.025\n",
      "0.426242\n",
      "0.426242\n",
      "0.772184\n",
      "0.772184\n",
      "0.685194\n",
      "0.685194\n",
      "0.27886\n",
      "0.27886\n",
      "0.025\n",
      "0.025\n",
      "0.056401\n",
      "0.056401\n",
      "0.469977\n",
      "0.469977\n",
      "0.105833\n",
      "0.105833\n",
      "0.973549\n",
      "0.973549\n",
      "0.068182\n",
      "0.068182\n",
      "0.0967624\n",
      "0.0967624\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0345436\n",
      "0.0345436\n",
      "0.380164\n",
      "0.380164\n",
      "0.029432\n",
      "0.029432\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.313126\n",
      "0.313126\n",
      "0.304906\n",
      "0.304906\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.030215\n",
      "0.030215\n",
      "0.975\n",
      "0.975\n",
      "0.916397\n",
      "0.916397\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.8739\n",
      "0.8739\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0572355\n",
      "0.0572355\n",
      "0.71612\n",
      "0.71612\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.872586\n",
      "0.872586\n",
      "0.025\n",
      "0.025\n",
      "0.465887\n",
      "0.465887\n",
      "0.623277\n",
      "0.623277\n",
      "0.025\n",
      "0.025\n",
      "0.0255094\n",
      "0.0255094\n",
      "0.025\n",
      "0.025\n",
      "0.0331633\n",
      "0.0331633\n",
      "0.025\n",
      "0.025\n",
      "0.139521\n",
      "0.139521\n",
      "0.310105\n",
      "0.310105\n",
      "0.546177\n",
      "0.546177\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0489451\n",
      "0.0489451\n",
      "0.139992\n",
      "0.139992\n",
      "0.0345411\n",
      "0.0345411\n",
      "0.025\n",
      "0.025\n",
      "0.0842865\n",
      "0.0842865\n",
      "0.0355396\n",
      "0.0355396\n",
      "0.974083\n",
      "0.974083\n",
      "0.282198\n",
      "0.282198\n",
      "0.975\n",
      "0.975\n",
      "0.13723\n",
      "0.13723\n",
      "0.0453275\n",
      "0.0453275\n",
      "0.147138\n",
      "0.147138\n",
      "0.105547\n",
      "0.105547\n",
      "0.182725\n",
      "0.182725\n",
      "0.102188\n",
      "0.102188\n",
      "0.578032\n",
      "0.578032\n",
      "0.0975033\n",
      "0.0975033\n",
      "0.941895\n",
      "0.941895\n",
      "0.950402\n",
      "0.950402\n",
      "0.915047\n",
      "0.915047\n",
      "0.025\n",
      "0.025\n",
      "0.0665274\n",
      "0.0665274\n",
      "0.154666\n",
      "0.154666\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.220107\n",
      "0.220107\n",
      "0.025\n",
      "0.025\n",
      "0.674503\n",
      "0.674503\n",
      "0.0565006\n",
      "0.0565006\n",
      "0.025\n",
      "0.025\n",
      "0.0259577\n",
      "0.0259577\n",
      "0.0619564\n",
      "0.0619564\n",
      "0.146492\n",
      "0.146492\n",
      "0.975\n",
      "0.975\n",
      "0.0484082\n",
      "0.0484082\n",
      "0.0462753\n",
      "0.0462753\n",
      "0.967776\n",
      "0.967776\n",
      "0.0591101\n",
      "0.0591101\n",
      "0.0566843\n",
      "0.0566843\n",
      "0.657549\n",
      "0.657549\n",
      "0.807325\n",
      "0.807325\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.224846\n",
      "0.224846\n",
      "0.869444\n",
      "0.869444\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0401175\n",
      "0.0401175\n",
      "0.975\n",
      "0.975\n",
      "0.775008\n",
      "0.775008\n",
      "0.025\n",
      "0.025\n",
      "0.934429\n",
      "0.934429\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0523199\n",
      "0.0523199\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0370857\n",
      "0.0370857\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.933204\n",
      "0.933204\n",
      "0.0555374\n",
      "0.0555374\n",
      "0.0906226\n",
      "0.0906226\n",
      "0.025\n",
      "0.025\n",
      "0.0461644\n",
      "0.0461644\n",
      "0.025\n",
      "0.025\n",
      "0.362824\n",
      "0.362824\n",
      "0.801346\n",
      "0.801346\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.424965\n",
      "0.424965\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.171345\n",
      "0.171345\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.40705\n",
      "0.40705\n",
      "0.0721418\n",
      "0.0721418\n",
      "0.902805\n",
      "0.902805\n",
      "0.12847\n",
      "0.12847\n",
      "0.026196\n",
      "0.026196\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.185465\n",
      "0.185465\n",
      "0.125523\n",
      "0.125523\n",
      "0.025\n",
      "0.025\n",
      "0.0353227\n",
      "0.0353227\n",
      "0.201558\n",
      "0.201558\n",
      "0.025\n",
      "0.025\n",
      "0.18803\n",
      "0.18803\n",
      "0.872867\n",
      "0.872867\n",
      "0.960995\n",
      "0.960995\n",
      "0.422881\n",
      "0.422881\n",
      "0.0759524\n",
      "0.0759524\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0954091\n",
      "0.0954091\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.436151\n",
      "0.436151\n",
      "0.025\n",
      "0.025\n",
      "0.532234\n",
      "0.532234\n",
      "0.025\n",
      "0.025\n",
      "0.0587334\n",
      "0.0587334\n",
      "0.025\n",
      "0.025\n",
      "0.831138\n",
      "0.831138\n",
      "0.025\n",
      "0.025\n",
      "0.913095\n",
      "0.913095\n",
      "0.876893\n",
      "0.876893\n",
      "0.0372732\n",
      "0.0372732\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0283849\n",
      "0.0283849\n",
      "0.0326087\n",
      "0.0326087\n",
      "0.464334\n",
      "0.464334\n",
      "0.890244\n",
      "0.890244\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.163306\n",
      "0.163306\n",
      "0.109189\n",
      "0.109189\n",
      "0.025\n",
      "0.025\n",
      "0.637838\n",
      "0.637838\n",
      "0.171889\n",
      "0.171889\n",
      "0.405085\n",
      "0.405085\n",
      "0.0368251\n",
      "0.0368251\n",
      "0.356965\n",
      "0.356965\n",
      "0.0311639\n",
      "0.0311639\n",
      "0.18988\n",
      "0.18988\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0421217\n",
      "0.0421217\n",
      "0.975\n",
      "0.975\n",
      "0.0830289\n",
      "0.0830289\n",
      "0.453201\n",
      "0.453201\n",
      "0.0545086\n",
      "0.0545086\n",
      "0.527887\n",
      "0.527887\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0488026\n",
      "0.0488026\n",
      "0.306267\n",
      "0.306267\n",
      "0.0301046\n",
      "0.0301046\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0753362\n",
      "0.0753362\n",
      "0.025\n",
      "0.025\n",
      "0.0394744\n",
      "0.0394744\n",
      "0.025\n",
      "0.025\n",
      "0.134034\n",
      "0.134034\n",
      "0.497733\n",
      "0.497733\n",
      "0.025\n",
      "0.025\n",
      "0.960677\n",
      "0.960677\n",
      "0.025\n",
      "0.025\n",
      "0.878326\n",
      "0.878326\n",
      "0.975\n",
      "0.975\n",
      "0.137718\n",
      "0.137718\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.206065\n",
      "0.206065\n",
      "0.025\n",
      "0.025\n",
      "0.872859\n",
      "0.872859\n",
      "0.106756\n",
      "0.106756\n",
      "0.150739\n",
      "0.150739\n",
      "0.0750963\n",
      "0.0750963\n",
      "0.0401085\n",
      "0.0401085\n",
      "0.0495041\n",
      "0.0495041\n",
      "0.071393\n",
      "0.071393\n",
      "0.411962\n",
      "0.411962\n",
      "0.025\n",
      "0.025\n",
      "0.742306\n",
      "0.742306\n",
      "0.207648\n",
      "0.207648\n",
      "0.514185\n",
      "0.514185\n",
      "0.297494\n",
      "0.297494\n",
      "0.0362004\n",
      "0.0362004\n",
      "0.347428\n",
      "0.347428\n",
      "0.0307124\n",
      "0.0307124\n",
      "0.347215\n",
      "0.347215\n",
      "0.365146\n",
      "0.365146\n",
      "0.025\n",
      "0.025\n",
      "0.952594\n",
      "0.952594\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0384901\n",
      "0.0384901\n",
      "0.943375\n",
      "0.943375\n",
      "0.42539\n",
      "0.42539\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.913171\n",
      "0.913171\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.115967\n",
      "0.115967\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.767188\n",
      "0.767188\n",
      "0.100868\n",
      "0.100868\n",
      "0.0330806\n",
      "0.0330806\n",
      "0.737461\n",
      "0.737461\n",
      "0.0834245\n",
      "0.0834245\n",
      "0.025\n",
      "0.025\n",
      "0.373417\n",
      "0.373417\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.928779\n",
      "0.928779\n",
      "0.025\n",
      "0.025\n",
      "0.370611\n",
      "0.370611\n",
      "0.385693\n",
      "0.385693\n",
      "0.409796\n",
      "0.409796\n",
      "0.0881976\n",
      "0.0881976\n",
      "0.0483708\n",
      "0.0483708\n",
      "0.975\n",
      "0.975\n",
      "0.112633\n",
      "0.112633\n",
      "0.025\n",
      "0.025\n",
      "0.412063\n",
      "0.412063\n",
      "0.0719155\n",
      "0.0719155\n",
      "0.340338\n",
      "0.340338\n",
      "0.176163\n",
      "0.176163\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0792373\n",
      "0.0792373\n",
      "0.0358454\n",
      "0.0358454\n",
      "0.447783\n",
      "0.447783\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.234567\n",
      "0.234567\n",
      "0.025\n",
      "0.025\n",
      "0.403825\n",
      "0.403825\n",
      "0.0280232\n",
      "0.0280232\n",
      "0.0776125\n",
      "0.0776125\n",
      "0.0663235\n",
      "0.0663235\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.250371\n",
      "0.250371\n",
      "0.091476\n",
      "0.091476\n",
      "0.025\n",
      "0.025\n",
      "0.0626365\n",
      "0.0626365\n",
      "0.0697557\n",
      "0.0697557\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.442027\n",
      "0.442027\n",
      "0.808104\n",
      "0.808104\n",
      "0.0805829\n",
      "0.0805829\n",
      "0.773955\n",
      "0.773955\n",
      "0.0756418\n",
      "0.0756418\n",
      "0.975\n",
      "0.975\n",
      "0.039206\n",
      "0.039206\n",
      "0.975\n",
      "0.975\n",
      "0.0333042\n",
      "0.0333042\n",
      "0.025\n",
      "0.025\n",
      "0.353908\n",
      "0.353908\n",
      "0.228999\n",
      "0.228999\n",
      "0.025\n",
      "0.025\n",
      "0.0523828\n",
      "0.0523828\n",
      "0.136586\n",
      "0.136586\n",
      "0.025\n",
      "0.025\n",
      "0.103392\n",
      "0.103392\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0616321\n",
      "0.0616321\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.737366\n",
      "0.737366\n",
      "0.975\n",
      "0.975\n",
      "0.617518\n",
      "0.617518\n",
      "0.0754544\n",
      "0.0754544\n",
      "0.103296\n",
      "0.103296\n",
      "0.0336334\n",
      "0.0336334\n",
      "0.383295\n",
      "0.383295\n",
      "0.025\n",
      "0.025\n",
      "0.0493521\n",
      "0.0493521\n",
      "0.514786\n",
      "0.514786\n",
      "0.959485\n",
      "0.959485\n",
      "0.400015\n",
      "0.400015\n",
      "0.388605\n",
      "0.388605\n",
      "0.954014\n",
      "0.954014\n",
      "0.975\n",
      "0.975\n",
      "0.0285653\n",
      "0.0285653\n",
      "0.975\n",
      "0.975\n",
      "0.1224\n",
      "0.1224\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.382048\n",
      "0.382048\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.515904\n",
      "0.515904\n",
      "0.25882\n",
      "0.25882\n",
      "0.025\n",
      "0.025\n",
      "0.808794\n",
      "0.808794\n",
      "0.609254\n",
      "0.609254\n",
      "0.0838904\n",
      "0.0838904\n",
      "0.358502\n",
      "0.358502\n",
      "0.46961\n",
      "0.46961\n",
      "0.0556038\n",
      "0.0556038\n",
      "0.101557\n",
      "0.101557\n",
      "0.0438747\n",
      "0.0438747\n",
      "0.975\n",
      "0.975\n",
      "0.783192\n",
      "0.783192\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0750905\n",
      "0.0750905\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0328563\n",
      "0.0328563\n",
      "0.025\n",
      "0.025\n",
      "0.172833\n",
      "0.172833\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.33227\n",
      "0.33227\n",
      "0.278297\n",
      "0.278297\n",
      "0.101695\n",
      "0.101695\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.936526\n",
      "0.936526\n",
      "0.528794\n",
      "0.528794\n",
      "0.0576089\n",
      "0.0576089\n",
      "0.025\n",
      "0.025\n",
      "0.167439\n",
      "0.167439\n",
      "0.0327141\n",
      "0.0327141\n",
      "0.025\n",
      "0.025\n",
      "0.0451623\n",
      "0.0451623\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0775102\n",
      "0.0775102\n",
      "0.10025\n",
      "0.10025\n",
      "0.025\n",
      "0.025\n",
      "0.890803\n",
      "0.890803\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.227147\n",
      "0.227147\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.03299\n",
      "0.03299\n",
      "0.975\n",
      "0.975\n",
      "0.0994213\n",
      "0.0994213\n",
      "0.0710772\n",
      "0.0710772\n",
      "0.161089\n",
      "0.161089\n",
      "0.0786228\n",
      "0.0786228\n",
      "0.229264\n",
      "0.229264\n",
      "0.975\n",
      "0.975\n",
      "0.0873316\n",
      "0.0873316\n",
      "0.975\n",
      "0.975\n",
      "0.306463\n",
      "0.306463\n",
      "0.0628164\n",
      "0.0628164\n",
      "0.025\n",
      "0.025\n",
      "0.348532\n",
      "0.348532\n",
      "0.975\n",
      "0.975\n",
      "0.0500184\n",
      "0.0500184\n",
      "0.025\n",
      "0.025\n",
      "0.826485\n",
      "0.826485\n",
      "0.0569937\n",
      "0.0569937\n",
      "0.117897\n",
      "0.117897\n",
      "0.451643\n",
      "0.451643\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.925971\n",
      "0.925971\n",
      "0.0454002\n",
      "0.0454002\n",
      "0.025\n",
      "0.025\n",
      "0.475993\n",
      "0.475993\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.475393\n",
      "0.475393\n",
      "0.312139\n",
      "0.312139\n",
      "0.305704\n",
      "0.305704\n",
      "0.025\n",
      "0.025\n",
      "0.369635\n",
      "0.369635\n",
      "0.025\n",
      "0.025\n",
      "0.0641138\n",
      "0.0641138\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.483496\n",
      "0.483496\n",
      "0.288176\n",
      "0.288176\n",
      "0.892067\n",
      "0.892067\n",
      "0.040301\n",
      "0.040301\n",
      "0.973614\n",
      "0.973614\n",
      "0.56584\n",
      "0.56584\n",
      "0.498203\n",
      "0.498203\n",
      "0.88728\n",
      "0.88728\n",
      "0.232432\n",
      "0.232432\n",
      "0.0497007\n",
      "0.0497007\n",
      "0.025\n",
      "0.025\n",
      "0.582492\n",
      "0.582492\n",
      "0.025\n",
      "0.025\n",
      "0.0332827\n",
      "0.0332827\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.806955\n",
      "0.806955\n",
      "0.371849\n",
      "0.371849\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0291111\n",
      "0.0291111\n",
      "0.025\n",
      "0.025\n",
      "0.263846\n",
      "0.263846\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.091576\n",
      "0.091576\n",
      "0.025\n",
      "0.025\n",
      "0.0854486\n",
      "0.0854486\n",
      "0.761983\n",
      "0.761983\n",
      "0.025\n",
      "0.025\n",
      "0.739335\n",
      "0.739335\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.605294\n",
      "0.605294\n",
      "0.0831745\n",
      "0.0831745\n",
      "0.500863\n",
      "0.500863\n",
      "0.025\n",
      "0.025\n",
      "0.193543\n",
      "0.193543\n",
      "0.025\n",
      "0.025\n",
      "0.0573913\n",
      "0.0573913\n",
      "0.092543\n",
      "0.092543\n",
      "0.975\n",
      "0.975\n",
      "0.0739687\n",
      "0.0739687\n",
      "0.025\n",
      "0.025\n",
      "0.0463372\n",
      "0.0463372\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.333715\n",
      "0.333715\n",
      "0.453932\n",
      "0.453932\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.726163\n",
      "0.726163\n",
      "0.125269\n",
      "0.125269\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.965285\n",
      "0.965285\n",
      "0.290261\n",
      "0.290261\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.100419\n",
      "0.100419\n",
      "0.275143\n",
      "0.275143\n",
      "0.352245\n",
      "0.352245\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.240705\n",
      "0.240705\n",
      "0.025\n",
      "0.025\n",
      "0.0679092\n",
      "0.0679092\n",
      "0.025\n",
      "0.025\n",
      "0.0674662\n",
      "0.0674662\n",
      "0.956791\n",
      "0.956791\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0488009\n",
      "0.0488009\n",
      "0.603674\n",
      "0.603674\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0426392\n",
      "0.0426392\n",
      "0.025\n",
      "0.025\n",
      "0.0385845\n",
      "0.0385845\n",
      "0.0496985\n",
      "0.0496985\n",
      "0.025\n",
      "0.025\n",
      "0.0363648\n",
      "0.0363648\n",
      "0.310345\n",
      "0.310345\n",
      "0.211053\n",
      "0.211053\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.93952\n",
      "0.93952\n",
      "0.347824\n",
      "0.347824\n",
      "0.87226\n",
      "0.87226\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.285856\n",
      "0.285856\n",
      "0.521441\n",
      "0.521441\n",
      "0.0729657\n",
      "0.0729657\n",
      "0.025\n",
      "0.025\n",
      "0.835708\n",
      "0.835708\n",
      "0.025\n",
      "0.025\n",
      "0.0313674\n",
      "0.0313674\n",
      "0.025\n",
      "0.025\n",
      "0.0517588\n",
      "0.0517588\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.129671\n",
      "0.129671\n",
      "0.025\n",
      "0.025\n",
      "0.611612\n",
      "0.611612\n",
      "0.154863\n",
      "0.154863\n",
      "0.737648\n",
      "0.737648\n",
      "0.025\n",
      "0.025\n",
      "0.76048\n",
      "0.76048\n",
      "0.0791477\n",
      "0.0791477\n",
      "0.025\n",
      "0.025\n",
      "0.0445562\n",
      "0.0445562\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0377886\n",
      "0.0377886\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.212436\n",
      "0.212436\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.153671\n",
      "0.153671\n",
      "0.0352268\n",
      "0.0352268\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0616908\n",
      "0.0616908\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0615021\n",
      "0.0615021\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.516954\n",
      "0.516954\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0445346\n",
      "0.0445346\n",
      "0.025\n",
      "0.025\n",
      "0.430255\n",
      "0.430255\n",
      "0.975\n",
      "0.975\n",
      "0.0925597\n",
      "0.0925597\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0711845\n",
      "0.0711845\n",
      "0.025\n",
      "0.025\n",
      "0.0600447\n",
      "0.0600447\n",
      "0.417712\n",
      "0.417712\n",
      "0.174348\n",
      "0.174348\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.239468\n",
      "0.239468\n",
      "0.0673221\n",
      "0.0673221\n",
      "0.025\n",
      "0.025\n",
      "0.80675\n",
      "0.80675\n",
      "0.116599\n",
      "0.116599\n",
      "0.025\n",
      "0.025\n",
      "0.777541\n",
      "0.777541\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.876585\n",
      "0.876585\n",
      "0.025\n",
      "0.025\n",
      "0.0453297\n",
      "0.0453297\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0474165\n",
      "0.0474165\n",
      "0.120324\n",
      "0.120324\n",
      "0.0462414\n",
      "0.0462414\n",
      "0.025\n",
      "0.025\n",
      "0.534697\n",
      "0.534697\n",
      "0.0373486\n",
      "0.0373486\n",
      "0.055344\n",
      "0.055344\n",
      "0.0269681\n",
      "0.0269681\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0338896\n",
      "0.0338896\n",
      "0.0421579\n",
      "0.0421579\n",
      "0.826771\n",
      "0.826771\n",
      "0.270241\n",
      "0.270241\n",
      "0.025\n",
      "0.025\n",
      "0.0625973\n",
      "0.0625973\n",
      "0.975\n",
      "0.975\n",
      "0.033007\n",
      "0.033007\n",
      "0.210476\n",
      "0.210476\n",
      "0.025\n",
      "0.025\n",
      "0.205171\n",
      "0.205171\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0797266\n",
      "0.0797266\n",
      "0.025\n",
      "0.025\n",
      "0.304455\n",
      "0.304455\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0429464\n",
      "0.0429464\n",
      "0.824947\n",
      "0.824947\n",
      "0.479639\n",
      "0.479639\n",
      "0.025\n",
      "0.025\n",
      "0.0750834\n",
      "0.0750834\n",
      "0.923757\n",
      "0.923757\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.311684\n",
      "0.311684\n",
      "0.025\n",
      "0.025\n",
      "0.0451748\n",
      "0.0451748\n",
      "0.0735013\n",
      "0.0735013\n",
      "0.975\n",
      "0.975\n",
      "0.246668\n",
      "0.246668\n",
      "0.025\n",
      "0.025\n",
      "0.81221\n",
      "0.81221\n",
      "0.025\n",
      "0.025\n",
      "0.0326182\n",
      "0.0326182\n",
      "0.329443\n",
      "0.329443\n",
      "0.025\n",
      "0.025\n",
      "0.240318\n",
      "0.240318\n",
      "0.025\n",
      "0.025\n",
      "0.0994568\n",
      "0.0994568\n",
      "0.110388\n",
      "0.110388\n",
      "0.0467875\n",
      "0.0467875\n",
      "0.702757\n",
      "0.702757\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.239728\n",
      "0.239728\n",
      "0.025\n",
      "0.025\n",
      "0.0585814\n",
      "0.0585814\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.923945\n",
      "0.923945\n",
      "0.025\n",
      "0.025\n",
      "0.701814\n",
      "0.701814\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.948874\n",
      "0.948874\n",
      "0.025\n",
      "0.025\n",
      "0.295836\n",
      "0.295836\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.165432\n",
      "0.165432\n",
      "0.975\n",
      "0.975\n",
      "0.494725\n",
      "0.494725\n",
      "0.0320517\n",
      "0.0320517\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0410475\n",
      "0.0410475\n",
      "0.025\n",
      "0.025\n",
      "0.10383\n",
      "0.10383\n",
      "0.025\n",
      "0.025\n",
      "0.324647\n",
      "0.324647\n",
      "0.746723\n",
      "0.746723\n",
      "0.271587\n",
      "0.271587\n",
      "0.924158\n",
      "0.924158\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0571879\n",
      "0.0571879\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0394386\n",
      "0.0394386\n",
      "0.975\n",
      "0.975\n",
      "0.770014\n",
      "0.770014\n",
      "0.397834\n",
      "0.397834\n",
      "0.025\n",
      "0.025\n",
      "0.198439\n",
      "0.198439\n",
      "0.313718\n",
      "0.313718\n",
      "0.859589\n",
      "0.859589\n",
      "0.176724\n",
      "0.176724\n",
      "0.400741\n",
      "0.400741\n",
      "0.933632\n",
      "0.933632\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0348973\n",
      "0.0348973\n",
      "0.127642\n",
      "0.127642\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.152935\n",
      "0.152935\n",
      "0.0469494\n",
      "0.0469494\n",
      "0.975\n",
      "0.975\n",
      "0.771605\n",
      "0.771605\n",
      "0.0568128\n",
      "0.0568128\n",
      "0.426232\n",
      "0.426232\n",
      "0.0883729\n",
      "0.0883729\n",
      "0.025\n",
      "0.025\n",
      "0.0360968\n",
      "0.0360968\n",
      "0.025\n",
      "0.025\n",
      "0.0739394\n",
      "0.0739394\n",
      "0.149915\n",
      "0.149915\n",
      "0.362952\n",
      "0.362952\n",
      "0.025\n",
      "0.025\n",
      "0.368923\n",
      "0.368923\n",
      "0.975\n",
      "0.975\n",
      "0.0923855\n",
      "0.0923855\n",
      "0.856319\n",
      "0.856319\n",
      "0.0429791\n",
      "0.0429791\n",
      "0.714354\n",
      "0.714354\n",
      "0.0488365\n",
      "0.0488365\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.232236\n",
      "0.232236\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.738004\n",
      "0.738004\n",
      "0.0404255\n",
      "0.0404255\n",
      "0.334652\n",
      "0.334652\n",
      "0.025\n",
      "0.025\n",
      "0.756728\n",
      "0.756728\n",
      "0.0734034\n",
      "0.0734034\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0436307\n",
      "0.0436307\n",
      "0.450977\n",
      "0.450977\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0380623\n",
      "0.0380623\n",
      "0.025\n",
      "0.025\n",
      "0.0515124\n",
      "0.0515124\n",
      "0.025\n",
      "0.025\n",
      "0.403898\n",
      "0.403898\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0302436\n",
      "0.0302436\n",
      "0.0327455\n",
      "0.0327455\n",
      "0.0262988\n",
      "0.0262988\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0987347\n",
      "0.0987347\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.116478\n",
      "0.116478\n",
      "0.975\n",
      "0.975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.41374\n",
      "0.41374\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.237458\n",
      "0.237458\n",
      "0.025\n",
      "0.025\n",
      "0.0798107\n",
      "0.0798107\n",
      "0.739859\n",
      "0.739859\n",
      "0.0745764\n",
      "0.0745764\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.634939\n",
      "0.634939\n",
      "0.0561586\n",
      "0.0561586\n",
      "0.0355563\n",
      "0.0355563\n",
      "0.0693463\n",
      "0.0693463\n",
      "0.441577\n",
      "0.441577\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.792871\n",
      "0.792871\n",
      "0.025\n",
      "0.025\n",
      "0.719304\n",
      "0.719304\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.890482\n",
      "0.890482\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.107179\n",
      "0.107179\n",
      "0.437344\n",
      "0.437344\n",
      "0.025\n",
      "0.025\n",
      "0.621837\n",
      "0.621837\n",
      "0.122809\n",
      "0.122809\n",
      "0.025\n",
      "0.025\n",
      "0.030401\n",
      "0.030401\n",
      "0.512112\n",
      "0.512112\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.201564\n",
      "0.201564\n",
      "0.025\n",
      "0.025\n",
      "0.074464\n",
      "0.074464\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0962858\n",
      "0.0962858\n",
      "0.70757\n",
      "0.70757\n",
      "0.025\n",
      "0.025\n",
      "0.513321\n",
      "0.513321\n",
      "0.966946\n",
      "0.966946\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.106468\n",
      "0.106468\n",
      "0.972049\n",
      "0.972049\n",
      "0.29002\n",
      "0.29002\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0518122\n",
      "0.0518122\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0346351\n",
      "0.0346351\n",
      "0.0467638\n",
      "0.0467638\n",
      "0.975\n",
      "0.975\n",
      "0.199953\n",
      "0.199953\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0597012\n",
      "0.0597012\n",
      "0.469533\n",
      "0.469533\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.208912\n",
      "0.208912\n",
      "0.0290959\n",
      "0.0290959\n",
      "0.975\n",
      "0.975\n",
      "0.0938252\n",
      "0.0938252\n",
      "0.025\n",
      "0.025\n",
      "0.682814\n",
      "0.682814\n",
      "0.025\n",
      "0.025\n",
      "0.0391792\n",
      "0.0391792\n",
      "0.240351\n",
      "0.240351\n",
      "0.025\n",
      "0.025\n",
      "0.300958\n",
      "0.300958\n",
      "0.0314736\n",
      "0.0314736\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.898881\n",
      "0.898881\n",
      "0.304127\n",
      "0.304127\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.852322\n",
      "0.852322\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.93386\n",
      "0.93386\n",
      "0.301479\n",
      "0.301479\n",
      "0.307558\n",
      "0.307558\n",
      "0.231432\n",
      "0.231432\n",
      "0.025\n",
      "0.025\n",
      "0.56413\n",
      "0.56413\n",
      "0.971958\n",
      "0.971958\n",
      "0.025\n",
      "0.025\n",
      "0.146948\n",
      "0.146948\n",
      "0.183819\n",
      "0.183819\n",
      "0.137257\n",
      "0.137257\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0970095\n",
      "0.0970095\n",
      "0.0883669\n",
      "0.0883669\n",
      "0.0873212\n",
      "0.0873212\n",
      "0.025\n",
      "0.025\n",
      "0.158528\n",
      "0.158528\n",
      "0.025\n",
      "0.025\n",
      "0.0798775\n",
      "0.0798775\n",
      "0.0938175\n",
      "0.0938175\n",
      "0.210672\n",
      "0.210672\n",
      "0.0281169\n",
      "0.0281169\n",
      "0.025\n",
      "0.025\n",
      "0.92626\n",
      "0.92626\n",
      "0.975\n",
      "0.975\n",
      "0.0501714\n",
      "0.0501714\n",
      "0.0780184\n",
      "0.0780184\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.238613\n",
      "0.238613\n",
      "0.975\n",
      "0.975\n",
      "0.0616288\n",
      "0.0616288\n",
      "0.0564132\n",
      "0.0564132\n",
      "0.0891669\n",
      "0.0891669\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0283085\n",
      "0.0283085\n",
      "0.710787\n",
      "0.710787\n",
      "0.315515\n",
      "0.315515\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.10481\n",
      "0.10481\n",
      "0.319459\n",
      "0.319459\n",
      "0.168073\n",
      "0.168073\n",
      "0.847988\n",
      "0.847988\n",
      "0.025\n",
      "0.025\n",
      "0.0252419\n",
      "0.0252419\n",
      "0.0328619\n",
      "0.0328619\n",
      "0.025\n",
      "0.025\n",
      "0.0527467\n",
      "0.0527467\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0272559\n",
      "0.0272559\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.417636\n",
      "0.417636\n",
      "0.840248\n",
      "0.840248\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0753802\n",
      "0.0753802\n",
      "0.975\n",
      "0.975\n",
      "0.530953\n",
      "0.530953\n",
      "0.0374116\n",
      "0.0374116\n",
      "0.041988\n",
      "0.041988\n",
      "0.30212\n",
      "0.30212\n",
      "0.42478\n",
      "0.42478\n",
      "0.673077\n",
      "0.673077\n",
      "0.807781\n",
      "0.807781\n",
      "0.037059\n",
      "0.037059\n",
      "0.291818\n",
      "0.291818\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0364474\n",
      "0.0364474\n",
      "0.025\n",
      "0.025\n",
      "0.381893\n",
      "0.381893\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0488404\n",
      "0.0488404\n",
      "0.636728\n",
      "0.636728\n",
      "0.0595784\n",
      "0.0595784\n",
      "0.025\n",
      "0.025\n",
      "0.520065\n",
      "0.520065\n",
      "0.025\n",
      "0.025\n",
      "0.320211\n",
      "0.320211\n",
      "0.943292\n",
      "0.943292\n",
      "0.303297\n",
      "0.303297\n",
      "0.081613\n",
      "0.081613\n",
      "0.025\n",
      "0.025\n",
      "0.0996532\n",
      "0.0996532\n",
      "0.27875\n",
      "0.27875\n",
      "0.0432952\n",
      "0.0432952\n",
      "0.0706429\n",
      "0.0706429\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.404943\n",
      "0.404943\n",
      "0.13148\n",
      "0.13148\n",
      "0.160301\n",
      "0.160301\n",
      "0.189241\n",
      "0.189241\n",
      "0.131614\n",
      "0.131614\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0263353\n",
      "0.0263353\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.286018\n",
      "0.286018\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.960625\n",
      "0.960625\n",
      "0.0906108\n",
      "0.0906108\n",
      "0.702523\n",
      "0.702523\n",
      "0.025\n",
      "0.025\n",
      "0.0944199\n",
      "0.0944199\n",
      "0.025\n",
      "0.025\n",
      "0.0906422\n",
      "0.0906422\n",
      "0.15941\n",
      "0.15941\n",
      "0.0759453\n",
      "0.0759453\n",
      "0.025\n",
      "0.025\n",
      "0.0760327\n",
      "0.0760327\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.108769\n",
      "0.108769\n",
      "0.956109\n",
      "0.956109\n",
      "0.025\n",
      "0.025\n",
      "0.26206\n",
      "0.26206\n",
      "0.32614\n",
      "0.32614\n",
      "0.0430853\n",
      "0.0430853\n",
      "0.180532\n",
      "0.180532\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.151473\n",
      "0.151473\n",
      "0.975\n",
      "0.975\n",
      "0.333906\n",
      "0.333906\n",
      "0.025\n",
      "0.025\n",
      "0.913528\n",
      "0.913528\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0620592\n",
      "0.0620592\n",
      "0.025\n",
      "0.025\n",
      "0.14514\n",
      "0.14514\n",
      "0.943846\n",
      "0.943846\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0355831\n",
      "0.0355831\n",
      "0.141398\n",
      "0.141398\n",
      "0.025\n",
      "0.025\n",
      "0.320592\n",
      "0.320592\n",
      "0.452554\n",
      "0.452554\n",
      "0.148233\n",
      "0.148233\n",
      "0.025\n",
      "0.025\n",
      "0.681578\n",
      "0.681578\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.531246\n",
      "0.531246\n",
      "0.944742\n",
      "0.944742\n",
      "0.0529352\n",
      "0.0529352\n",
      "0.559519\n",
      "0.559519\n",
      "0.0637079\n",
      "0.0637079\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.714757\n",
      "0.714757\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025903\n",
      "0.025903\n",
      "0.975\n",
      "0.975\n",
      "0.856367\n",
      "0.856367\n",
      "0.025\n",
      "0.025\n",
      "0.191\n",
      "0.191\n",
      "0.823076\n",
      "0.823076\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0600641\n",
      "0.0600641\n",
      "0.24743\n",
      "0.24743\n",
      "0.025\n",
      "0.025\n",
      "0.643392\n",
      "0.643392\n",
      "0.025\n",
      "0.025\n",
      "0.0711047\n",
      "0.0711047\n",
      "0.740583\n",
      "0.740583\n",
      "0.025\n",
      "0.025\n",
      "0.845231\n",
      "0.845231\n",
      "0.0919597\n",
      "0.0919597\n",
      "0.025\n",
      "0.025\n",
      "0.176277\n",
      "0.176277\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0569201\n",
      "0.0569201\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0257987\n",
      "0.0257987\n",
      "0.025\n",
      "0.025\n",
      "0.0493345\n",
      "0.0493345\n",
      "0.148385\n",
      "0.148385\n",
      "0.975\n",
      "0.975\n",
      "0.206092\n",
      "0.206092\n",
      "0.128137\n",
      "0.128137\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0654269\n",
      "0.0654269\n",
      "0.025\n",
      "0.025\n",
      "0.806735\n",
      "0.806735\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.962496\n",
      "0.962496\n",
      "0.122535\n",
      "0.122535\n",
      "0.132424\n",
      "0.132424\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0639895\n",
      "0.0639895\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.140106\n",
      "0.140106\n",
      "0.15194\n",
      "0.15194\n",
      "0.636576\n",
      "0.636576\n",
      "0.764547\n",
      "0.764547\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.110645\n",
      "0.110645\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0835056\n",
      "0.0835056\n",
      "0.933078\n",
      "0.933078\n",
      "0.025\n",
      "0.025\n",
      "0.0639688\n",
      "0.0639688\n",
      "0.533719\n",
      "0.533719\n",
      "0.025\n",
      "0.025\n",
      "0.455249\n",
      "0.455249\n",
      "0.161763\n",
      "0.161763\n",
      "0.0891792\n",
      "0.0891792\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.635172\n",
      "0.635172\n",
      "0.025\n",
      "0.025\n",
      "0.418532\n",
      "0.418532\n",
      "0.55122\n",
      "0.55122\n",
      "0.144311\n",
      "0.144311\n",
      "0.025\n",
      "0.025\n",
      "0.0313374\n",
      "0.0313374\n",
      "0.192968\n",
      "0.192968\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0465992\n",
      "0.0465992\n",
      "0.0460435\n",
      "0.0460435\n",
      "0.758972\n",
      "0.758972\n",
      "0.34532\n",
      "0.34532\n",
      "0.268875\n",
      "0.268875\n",
      "0.0311393\n",
      "0.0311393\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.266367\n",
      "0.266367\n",
      "0.124137\n",
      "0.124137\n",
      "0.951801\n",
      "0.951801\n",
      "0.025\n",
      "0.025\n",
      "0.357303\n",
      "0.357303\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.436917\n",
      "0.436917\n",
      "0.975\n",
      "0.975\n",
      "0.63872\n",
      "0.63872\n",
      "0.025\n",
      "0.025\n",
      "0.701744\n",
      "0.701744\n",
      "0.025\n",
      "0.025\n",
      "0.0402709\n",
      "0.0402709\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.836007\n",
      "0.836007\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.836197\n",
      "0.836197\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0810335\n",
      "0.0810335\n",
      "0.331874\n",
      "0.331874\n",
      "0.025\n",
      "0.025\n",
      "0.105065\n",
      "0.105065\n",
      "0.0558891\n",
      "0.0558891\n",
      "0.241658\n",
      "0.241658\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0313363\n",
      "0.0313363\n",
      "0.025\n",
      "0.025\n",
      "0.0451062\n",
      "0.0451062\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.39593\n",
      "0.39593\n",
      "0.0259365\n",
      "0.0259365\n",
      "0.975\n",
      "0.975\n",
      "0.962243\n",
      "0.962243\n",
      "0.975\n",
      "0.975\n",
      "0.888095\n",
      "0.888095\n",
      "0.025\n",
      "0.025\n",
      "0.255381\n",
      "0.255381\n",
      "0.025\n",
      "0.025\n",
      "0.0409548\n",
      "0.0409548\n",
      "0.0270118\n",
      "0.0270118\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0829166\n",
      "0.0829166\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.655108\n",
      "0.655108\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.243143\n",
      "0.243143\n",
      "0.170913\n",
      "0.170913\n",
      "0.975\n",
      "0.975\n",
      "0.541008\n",
      "0.541008\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0363311\n",
      "0.0363311\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.082208\n",
      "0.082208\n",
      "0.025\n",
      "0.025\n",
      "0.105489\n",
      "0.105489\n",
      "0.025\n",
      "0.025\n",
      "0.0890084\n",
      "0.0890084\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.876294\n",
      "0.876294\n",
      "0.875613\n",
      "0.875613\n",
      "0.347514\n",
      "0.347514\n",
      "0.042083\n",
      "0.042083\n",
      "0.867656\n",
      "0.867656\n",
      "0.975\n",
      "0.975\n",
      "0.221476\n",
      "0.221476\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.80654\n",
      "0.80654\n",
      "0.310011\n",
      "0.310011\n",
      "0.616426\n",
      "0.616426\n",
      "0.18757\n",
      "0.18757\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.867429\n",
      "0.867429\n",
      "0.975\n",
      "0.975\n",
      "0.267531\n",
      "0.267531\n",
      "0.025\n",
      "0.025\n",
      "0.132225\n",
      "0.132225\n",
      "0.975\n",
      "0.975\n",
      "0.0553455\n",
      "0.0553455\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.39016\n",
      "0.39016\n",
      "0.0458317\n",
      "0.0458317\n",
      "0.0540312\n",
      "0.0540312\n",
      "0.025\n",
      "0.025\n",
      "0.809592\n",
      "0.809592\n",
      "0.025\n",
      "0.025\n",
      "0.658624\n",
      "0.658624\n",
      "0.306626\n",
      "0.306626\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.4874\n",
      "0.4874\n",
      "0.1958\n",
      "0.1958\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0639933\n",
      "0.0639933\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0533263\n",
      "0.0533263\n",
      "0.140882\n",
      "0.140882\n",
      "0.439481\n",
      "0.439481\n",
      "0.352012\n",
      "0.352012\n",
      "0.025\n",
      "0.025\n",
      "0.0750718\n",
      "0.0750718\n",
      "0.653736\n",
      "0.653736\n",
      "0.0782548\n",
      "0.0782548\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0252057\n",
      "0.0252057\n",
      "0.0684062\n",
      "0.0684062\n",
      "0.963734\n",
      "0.963734\n",
      "0.195745\n",
      "0.195745\n",
      "0.025\n",
      "0.025\n",
      "0.640542\n",
      "0.640542\n",
      "0.734128\n",
      "0.734128\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.923077\n",
      "0.923077\n",
      "0.0533756\n",
      "0.0533756\n",
      "0.857612\n",
      "0.857612\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.034305\n",
      "0.034305\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.902469\n",
      "0.902469\n",
      "0.025\n",
      "0.025\n",
      "0.728699\n",
      "0.728699\n",
      "0.975\n",
      "0.975\n",
      "0.26151\n",
      "0.26151\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0270452\n",
      "0.0270452\n",
      "0.366685\n",
      "0.366685\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.164521\n",
      "0.164521\n",
      "0.025\n",
      "0.025\n",
      "0.793686\n",
      "0.793686\n",
      "0.0886385\n",
      "0.0886385\n",
      "0.312298\n",
      "0.312298\n",
      "0.070445\n",
      "0.070445\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.228794\n",
      "0.228794\n",
      "0.025\n",
      "0.025\n",
      "0.247222\n",
      "0.247222\n",
      "0.975\n",
      "0.975\n",
      "0.973223\n",
      "0.973223\n",
      "0.975\n",
      "0.975\n",
      "0.49047\n",
      "0.49047\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0415332\n",
      "0.0415332\n",
      "0.030281\n",
      "0.030281\n",
      "0.0432742\n",
      "0.0432742\n",
      "0.309868\n",
      "0.309868\n",
      "0.0331466\n",
      "0.0331466\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0392313\n",
      "0.0392313\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.362789\n",
      "0.362789\n",
      "0.025\n",
      "0.025\n",
      "0.831701\n",
      "0.831701\n",
      "0.134787\n",
      "0.134787\n",
      "0.875396\n",
      "0.875396\n",
      "0.0430372\n",
      "0.0430372\n",
      "0.025\n",
      "0.025\n",
      "0.0308116\n",
      "0.0308116\n",
      "0.850593\n",
      "0.850593\n",
      "0.952192\n",
      "0.952192\n",
      "0.286725\n",
      "0.286725\n",
      "0.0676962\n",
      "0.0676962\n",
      "0.206019\n",
      "0.206019\n",
      "0.025\n",
      "0.025\n",
      "0.570365\n",
      "0.570365\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.150789\n",
      "0.150789\n",
      "0.975\n",
      "0.975\n",
      "0.54162\n",
      "0.54162\n",
      "0.581057\n",
      "0.581057\n",
      "0.949467\n",
      "0.949467\n",
      "0.025\n",
      "0.025\n",
      "0.0658155\n",
      "0.0658155\n",
      "0.0960345\n",
      "0.0960345\n",
      "0.252282\n",
      "0.252282\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.759341\n",
      "0.759341\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0254866\n",
      "0.0254866\n",
      "0.678178\n",
      "0.678178\n",
      "0.25685\n",
      "0.25685\n",
      "0.0265456\n",
      "0.0265456\n",
      "0.025\n",
      "0.025\n",
      "0.0912571\n",
      "0.0912571\n",
      "0.025\n",
      "0.025\n",
      "0.031156\n",
      "0.031156\n",
      "0.182317\n",
      "0.182317\n",
      "0.0468731\n",
      "0.0468731\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.128511\n",
      "0.128511\n",
      "0.290316\n",
      "0.290316\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.963156\n",
      "0.963156\n",
      "0.765128\n",
      "0.765128\n",
      "0.623635\n",
      "0.623635\n",
      "0.0404787\n",
      "0.0404787\n",
      "0.039096\n",
      "0.039096\n",
      "0.025\n",
      "0.025\n",
      "0.125377\n",
      "0.125377\n",
      "0.975\n",
      "0.975\n",
      "0.0820945\n",
      "0.0820945\n",
      "0.621781\n",
      "0.621781\n",
      "0.025\n",
      "0.025\n",
      "0.618033\n",
      "0.618033\n",
      "0.0995574\n",
      "0.0995574\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.774466\n",
      "0.774466\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0812221\n",
      "0.0812221\n",
      "0.114555\n",
      "0.114555\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.129168\n",
      "0.129168\n",
      "0.476016\n",
      "0.476016\n",
      "0.025\n",
      "0.025\n",
      "0.0376909\n",
      "0.0376909\n",
      "0.0981282\n",
      "0.0981282\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0399465\n",
      "0.0399465\n",
      "0.025\n",
      "0.025\n",
      "0.891303\n",
      "0.891303\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0410399\n",
      "0.0410399\n",
      "0.744335\n",
      "0.744335\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0783011\n",
      "0.0783011\n",
      "0.124833\n",
      "0.124833\n",
      "0.0256871\n",
      "0.0256871\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.645594\n",
      "0.645594\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.19707\n",
      "0.19707\n",
      "0.025\n",
      "0.025\n",
      "0.205589\n",
      "0.205589\n",
      "0.252748\n",
      "0.252748\n",
      "0.147902\n",
      "0.147902\n",
      "0.965726\n",
      "0.965726\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.248332\n",
      "0.248332\n",
      "0.115528\n",
      "0.115528\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.952728\n",
      "0.952728\n",
      "0.163296\n",
      "0.163296\n",
      "0.38384\n",
      "0.38384\n",
      "0.975\n",
      "0.975\n",
      "0.116566\n",
      "0.116566\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.945255\n",
      "0.945255\n",
      "0.0353502\n",
      "0.0353502\n",
      "0.0287258\n",
      "0.0287258\n",
      "0.025\n",
      "0.025\n",
      "0.0535283\n",
      "0.0535283\n",
      "0.762173\n",
      "0.762173\n",
      "0.025\n",
      "0.025\n",
      "0.2859\n",
      "0.2859\n",
      "0.975\n",
      "0.975\n",
      "0.187427\n",
      "0.187427\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.24745\n",
      "0.24745\n",
      "0.114539\n",
      "0.114539\n",
      "0.975\n",
      "0.975\n",
      "0.0305547\n",
      "0.0305547\n",
      "0.256879\n",
      "0.256879\n",
      "0.813532\n",
      "0.813532\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.641702\n",
      "0.641702\n",
      "0.0864753\n",
      "0.0864753\n",
      "0.0401688\n",
      "0.0401688\n",
      "0.925726\n",
      "0.925726\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.553201\n",
      "0.553201\n",
      "0.247978\n",
      "0.247978\n",
      "0.890081\n",
      "0.890081\n",
      "0.131247\n",
      "0.131247\n",
      "0.025\n",
      "0.025\n",
      "0.951396\n",
      "0.951396\n",
      "0.189887\n",
      "0.189887\n",
      "0.143509\n",
      "0.143509\n",
      "0.723491\n",
      "0.723491\n",
      "0.597324\n",
      "0.597324\n",
      "0.17931\n",
      "0.17931\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0953556\n",
      "0.0953556\n",
      "0.304932\n",
      "0.304932\n",
      "0.975\n",
      "0.975\n",
      "0.1915\n",
      "0.1915\n",
      "0.025\n",
      "0.025\n",
      "0.675478\n",
      "0.675478\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.145431\n",
      "0.145431\n",
      "0.115988\n",
      "0.115988\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0897957\n",
      "0.0897957\n",
      "0.975\n",
      "0.975\n",
      "0.150869\n",
      "0.150869\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.107546\n",
      "0.107546\n",
      "0.201708\n",
      "0.201708\n",
      "0.975\n",
      "0.975\n",
      "0.0367246\n",
      "0.0367246\n",
      "0.606446\n",
      "0.606446\n",
      "0.300784\n",
      "0.300784\n",
      "0.417174\n",
      "0.417174\n",
      "0.025\n",
      "0.025\n",
      "0.0422994\n",
      "0.0422994\n",
      "0.327399\n",
      "0.327399\n",
      "0.149519\n",
      "0.149519\n",
      "0.809526\n",
      "0.809526\n",
      "0.042476\n",
      "0.042476\n",
      "0.441829\n",
      "0.441829\n",
      "0.6601\n",
      "0.6601\n",
      "0.025\n",
      "0.025\n",
      "0.965323\n",
      "0.965323\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.290208\n",
      "0.290208\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.186657\n",
      "0.186657\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.858429\n",
      "0.858429\n",
      "0.0670476\n",
      "0.0670476\n",
      "0.227315\n",
      "0.227315\n",
      "0.177309\n",
      "0.177309\n",
      "0.025\n",
      "0.025\n",
      "0.709173\n",
      "0.709173\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.856925\n",
      "0.856925\n",
      "0.025\n",
      "0.025\n",
      "0.0421004\n",
      "0.0421004\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0567475\n",
      "0.0567475\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.405481\n",
      "0.405481\n",
      "0.239664\n",
      "0.239664\n",
      "0.0341309\n",
      "0.0341309\n",
      "0.112351\n",
      "0.112351\n",
      "0.25996\n",
      "0.25996\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0400852\n",
      "0.0400852\n",
      "0.374525\n",
      "0.374525\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.454211\n",
      "0.454211\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.837398\n",
      "0.837398\n",
      "0.0852908\n",
      "0.0852908\n",
      "0.296261\n",
      "0.296261\n",
      "0.025\n",
      "0.025\n",
      "0.793268\n",
      "0.793268\n",
      "0.0273135\n",
      "0.0273135\n",
      "0.025\n",
      "0.025\n",
      "0.156728\n",
      "0.156728\n",
      "0.025\n",
      "0.025\n",
      "0.515492\n",
      "0.515492\n",
      "0.025\n",
      "0.025\n",
      "0.933536\n",
      "0.933536\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0733991\n",
      "0.0733991\n",
      "0.923073\n",
      "0.923073\n",
      "0.0436195\n",
      "0.0436195\n",
      "0.37411\n",
      "0.37411\n",
      "0.501401\n",
      "0.501401\n",
      "0.814243\n",
      "0.814243\n",
      "0.113202\n",
      "0.113202\n",
      "0.0418822\n",
      "0.0418822\n",
      "0.586119\n",
      "0.586119\n",
      "0.0325602\n",
      "0.0325602\n",
      "0.143989\n",
      "0.143989\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0260042\n",
      "0.0260042\n",
      "0.480513\n",
      "0.480513\n",
      "0.025\n",
      "0.025\n",
      "0.100818\n",
      "0.100818\n",
      "0.284764\n",
      "0.284764\n",
      "0.253789\n",
      "0.253789\n",
      "0.0438208\n",
      "0.0438208\n",
      "0.025\n",
      "0.025\n",
      "0.0839439\n",
      "0.0839439\n",
      "0.025\n",
      "0.025\n",
      "0.857201\n",
      "0.857201\n",
      "0.204753\n",
      "0.204753\n",
      "0.025\n",
      "0.025\n",
      "0.0272134\n",
      "0.0272134\n",
      "0.025\n",
      "0.025\n",
      "0.722347\n",
      "0.722347\n",
      "0.173608\n",
      "0.173608\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.927497\n",
      "0.927497\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.148953\n",
      "0.148953\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.161926\n",
      "0.161926\n",
      "0.885645\n",
      "0.885645\n",
      "0.870452\n",
      "0.870452\n",
      "0.025\n",
      "0.025\n",
      "0.0827202\n",
      "0.0827202\n",
      "0.025\n",
      "0.025\n",
      "0.104744\n",
      "0.104744\n",
      "0.149372\n",
      "0.149372\n",
      "0.182675\n",
      "0.182675\n",
      "0.025\n",
      "0.025\n",
      "0.365343\n",
      "0.365343\n",
      "0.943673\n",
      "0.943673\n",
      "0.148929\n",
      "0.148929\n",
      "0.914712\n",
      "0.914712\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.180752\n",
      "0.180752\n",
      "0.025\n",
      "0.025\n",
      "0.0816342\n",
      "0.0816342\n",
      "0.246378\n",
      "0.246378\n",
      "0.0383602\n",
      "0.0383602\n",
      "0.183533\n",
      "0.183533\n",
      "0.975\n",
      "0.975\n",
      "0.0874069\n",
      "0.0874069\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.163978\n",
      "0.163978\n",
      "0.025\n",
      "0.025\n",
      "0.136179\n",
      "0.136179\n",
      "0.053098\n",
      "0.053098\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.070096\n",
      "0.070096\n",
      "0.499233\n",
      "0.499233\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0411216\n",
      "0.0411216\n",
      "0.0509376\n",
      "0.0509376\n",
      "0.767193\n",
      "0.767193\n",
      "0.0306089\n",
      "0.0306089\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.950939\n",
      "0.950939\n",
      "0.025\n",
      "0.025\n",
      "0.176757\n",
      "0.176757\n",
      "0.145225\n",
      "0.145225\n",
      "0.0274093\n",
      "0.0274093\n",
      "0.0814687\n",
      "0.0814687\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0985973\n",
      "0.0985973\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.142624\n",
      "0.142624\n",
      "0.20991\n",
      "0.20991\n",
      "0.347392\n",
      "0.347392\n",
      "0.025\n",
      "0.025\n",
      "0.119105\n",
      "0.119105\n",
      "0.025\n",
      "0.025\n",
      "0.0875457\n",
      "0.0875457\n",
      "0.0470143\n",
      "0.0470143\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.318593\n",
      "0.318593\n",
      "0.0310274\n",
      "0.0310274\n",
      "0.0466496\n",
      "0.0466496\n",
      "0.244804\n",
      "0.244804\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.82949\n",
      "0.82949\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.507321\n",
      "0.507321\n",
      "0.025\n",
      "0.025\n",
      "0.405158\n",
      "0.405158\n",
      "0.306665\n",
      "0.306665\n",
      "0.025\n",
      "0.025\n",
      "0.298127\n",
      "0.298127\n",
      "0.883567\n",
      "0.883567\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0835643\n",
      "0.0835643\n",
      "0.651472\n",
      "0.651472\n",
      "0.477767\n",
      "0.477767\n",
      "0.0918732\n",
      "0.0918732\n",
      "0.329817\n",
      "0.329817\n",
      "0.975\n",
      "0.975\n",
      "0.177897\n",
      "0.177897\n",
      "0.502942\n",
      "0.502942\n",
      "0.0965111\n",
      "0.0965111\n",
      "0.025\n",
      "0.025\n",
      "0.630195\n",
      "0.630195\n",
      "0.400618\n",
      "0.400618\n",
      "0.224544\n",
      "0.224544\n",
      "0.025\n",
      "0.025\n",
      "0.401459\n",
      "0.401459\n",
      "0.369504\n",
      "0.369504\n",
      "0.278289\n",
      "0.278289\n",
      "0.975\n",
      "0.975\n",
      "0.526459\n",
      "0.526459\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0382351\n",
      "0.0382351\n",
      "0.909127\n",
      "0.909127\n",
      "0.025\n",
      "0.025\n",
      "0.231961\n",
      "0.231961\n",
      "0.277954\n",
      "0.277954\n",
      "0.309018\n",
      "0.309018\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0398786\n",
      "0.0398786\n",
      "0.025\n",
      "0.025\n",
      "0.277773\n",
      "0.277773\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0314562\n",
      "0.0314562\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.52669\n",
      "0.52669\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0290161\n",
      "0.0290161\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.942496\n",
      "0.942496\n",
      "0.025\n",
      "0.025\n",
      "0.951383\n",
      "0.951383\n",
      "0.0269003\n",
      "0.0269003\n",
      "0.025\n",
      "0.025\n",
      "0.924757\n",
      "0.924757\n",
      "0.025\n",
      "0.025\n",
      "0.347886\n",
      "0.347886\n",
      "0.843684\n",
      "0.843684\n",
      "0.975\n",
      "0.975\n",
      "0.224374\n",
      "0.224374\n",
      "0.353642\n",
      "0.353642\n",
      "0.025\n",
      "0.025\n",
      "0.131568\n",
      "0.131568\n",
      "0.025\n",
      "0.025\n",
      "0.803599\n",
      "0.803599\n",
      "0.0435528\n",
      "0.0435528\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.690885\n",
      "0.690885\n",
      "0.3525\n",
      "0.3525\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.135509\n",
      "0.135509\n",
      "0.581099\n",
      "0.581099\n",
      "0.441663\n",
      "0.441663\n",
      "0.811231\n",
      "0.811231\n",
      "0.025\n",
      "0.025\n",
      "0.554957\n",
      "0.554957\n",
      "0.639187\n",
      "0.639187\n",
      "0.025\n",
      "0.025\n",
      "0.507339\n",
      "0.507339\n",
      "0.504687\n",
      "0.504687\n",
      "0.025\n",
      "0.025\n",
      "0.438509\n",
      "0.438509\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.424166\n",
      "0.424166\n",
      "0.975\n",
      "0.975\n",
      "0.654323\n",
      "0.654323\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.110614\n",
      "0.110614\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.488293\n",
      "0.488293\n",
      "0.0421163\n",
      "0.0421163\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.177232\n",
      "0.177232\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.36852\n",
      "0.36852\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0305578\n",
      "0.0305578\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.942351\n",
      "0.942351\n",
      "0.975\n",
      "0.975\n",
      "0.41956\n",
      "0.41956\n",
      "0.0431295\n",
      "0.0431295\n",
      "0.0551725\n",
      "0.0551725\n",
      "0.025\n",
      "0.025\n",
      "0.0361746\n",
      "0.0361746\n",
      "0.975\n",
      "0.975\n",
      "0.0677846\n",
      "0.0677846\n",
      "0.312479\n",
      "0.312479\n",
      "0.025\n",
      "0.025\n",
      "0.510255\n",
      "0.510255\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.219357\n",
      "0.219357\n",
      "0.025\n",
      "0.025\n",
      "0.445593\n",
      "0.445593\n",
      "0.0253272\n",
      "0.0253272\n",
      "0.025\n",
      "0.025\n",
      "0.807908\n",
      "0.807908\n",
      "0.916692\n",
      "0.916692\n",
      "0.025\n",
      "0.025\n",
      "0.914394\n",
      "0.914394\n",
      "0.0360742\n",
      "0.0360742\n",
      "0.781854\n",
      "0.781854\n",
      "0.025\n",
      "0.025\n",
      "0.0264309\n",
      "0.0264309\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.912658\n",
      "0.912658\n",
      "0.025\n",
      "0.025\n",
      "0.127885\n",
      "0.127885\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.219231\n",
      "0.219231\n",
      "0.975\n",
      "0.975\n",
      "0.712963\n",
      "0.712963\n",
      "0.025\n",
      "0.025\n",
      "0.956146\n",
      "0.956146\n",
      "0.185915\n",
      "0.185915\n",
      "0.34287\n",
      "0.34287\n",
      "0.025\n",
      "0.025\n",
      "0.218105\n",
      "0.218105\n",
      "0.77423\n",
      "0.77423\n",
      "0.025\n",
      "0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0684632\n",
      "0.0684632\n",
      "0.955185\n",
      "0.955185\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0278371\n",
      "0.0278371\n",
      "0.0295323\n",
      "0.0295323\n",
      "0.025\n",
      "0.025\n",
      "0.0363873\n",
      "0.0363873\n",
      "0.542126\n",
      "0.542126\n",
      "0.975\n",
      "0.975\n",
      "0.187507\n",
      "0.187507\n",
      "0.025\n",
      "0.025\n",
      "0.704664\n",
      "0.704664\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.142045\n",
      "0.142045\n",
      "0.975\n",
      "0.975\n",
      "0.0300607\n",
      "0.0300607\n",
      "0.171726\n",
      "0.171726\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.320183\n",
      "0.320183\n",
      "0.863142\n",
      "0.863142\n",
      "0.380441\n",
      "0.380441\n",
      "0.025\n",
      "0.025\n",
      "0.0333543\n",
      "0.0333543\n",
      "0.025\n",
      "0.025\n",
      "0.946894\n",
      "0.946894\n",
      "0.839975\n",
      "0.839975\n",
      "0.025\n",
      "0.025\n",
      "0.357297\n",
      "0.357297\n",
      "0.025\n",
      "0.025\n",
      "0.224844\n",
      "0.224844\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.11139\n",
      "0.11139\n",
      "0.193684\n",
      "0.193684\n",
      "0.0381595\n",
      "0.0381595\n",
      "0.279878\n",
      "0.279878\n",
      "0.062404\n",
      "0.062404\n",
      "0.751801\n",
      "0.751801\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.973738\n",
      "0.973738\n",
      "0.084786\n",
      "0.084786\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.603614\n",
      "0.603614\n",
      "0.950586\n",
      "0.950586\n",
      "0.025\n",
      "0.025\n",
      "0.358568\n",
      "0.358568\n",
      "0.025\n",
      "0.025\n",
      "0.964985\n",
      "0.964985\n",
      "0.702894\n",
      "0.702894\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.190244\n",
      "0.190244\n",
      "0.697024\n",
      "0.697024\n",
      "0.96876\n",
      "0.96876\n",
      "0.025\n",
      "0.025\n",
      "0.072696\n",
      "0.072696\n",
      "0.025\n",
      "0.025\n",
      "0.222339\n",
      "0.222339\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.230516\n",
      "0.230516\n",
      "0.0651285\n",
      "0.0651285\n",
      "0.786941\n",
      "0.786941\n",
      "0.643883\n",
      "0.643883\n",
      "0.95917\n",
      "0.95917\n",
      "0.26866\n",
      "0.26866\n",
      "0.025\n",
      "0.025\n",
      "0.969457\n",
      "0.969457\n",
      "0.0358548\n",
      "0.0358548\n",
      "0.975\n",
      "0.975\n",
      "0.0474483\n",
      "0.0474483\n",
      "0.585079\n",
      "0.585079\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0255892\n",
      "0.0255892\n",
      "0.36448\n",
      "0.36448\n",
      "0.975\n",
      "0.975\n",
      "0.681236\n",
      "0.681236\n",
      "0.143833\n",
      "0.143833\n",
      "0.919982\n",
      "0.919982\n",
      "0.025\n",
      "0.025\n",
      "0.95154\n",
      "0.95154\n",
      "0.214176\n",
      "0.214176\n",
      "0.025\n",
      "0.025\n",
      "0.108889\n",
      "0.108889\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0605918\n",
      "0.0605918\n",
      "0.975\n",
      "0.975\n",
      "0.0764518\n",
      "0.0764518\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.789695\n",
      "0.789695\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.93576\n",
      "0.93576\n",
      "0.952125\n",
      "0.952125\n",
      "0.975\n",
      "0.975\n",
      "0.956019\n",
      "0.956019\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.249466\n",
      "0.249466\n",
      "0.467142\n",
      "0.467142\n",
      "0.272799\n",
      "0.272799\n",
      "0.0389637\n",
      "0.0389637\n",
      "0.893371\n",
      "0.893371\n",
      "0.225288\n",
      "0.225288\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.469647\n",
      "0.469647\n",
      "0.837819\n",
      "0.837819\n",
      "0.025\n",
      "0.025\n",
      "0.0443416\n",
      "0.0443416\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0445799\n",
      "0.0445799\n",
      "0.025\n",
      "0.025\n",
      "0.189099\n",
      "0.189099\n",
      "0.025\n",
      "0.025\n",
      "0.0547667\n",
      "0.0547667\n",
      "0.0273477\n",
      "0.0273477\n",
      "0.442972\n",
      "0.442972\n",
      "0.427708\n",
      "0.427708\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.359397\n",
      "0.359397\n",
      "0.373089\n",
      "0.373089\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0510367\n",
      "0.0510367\n",
      "0.025\n",
      "0.025\n",
      "0.380534\n",
      "0.380534\n",
      "0.0484616\n",
      "0.0484616\n",
      "0.222484\n",
      "0.222484\n",
      "0.025\n",
      "0.025\n",
      "0.232982\n",
      "0.232982\n",
      "0.025\n",
      "0.025\n",
      "0.0405266\n",
      "0.0405266\n",
      "0.025\n",
      "0.025\n",
      "0.70772\n",
      "0.70772\n",
      "0.0501412\n",
      "0.0501412\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.852433\n",
      "0.852433\n",
      "0.117555\n",
      "0.117555\n",
      "0.025\n",
      "0.025\n",
      "0.0262207\n",
      "0.0262207\n",
      "0.306579\n",
      "0.306579\n",
      "0.118343\n",
      "0.118343\n",
      "0.353167\n",
      "0.353167\n",
      "0.0617379\n",
      "0.0617379\n",
      "0.975\n",
      "0.975\n",
      "0.285478\n",
      "0.285478\n",
      "0.0313348\n",
      "0.0313348\n",
      "0.025\n",
      "0.025\n",
      "0.911831\n",
      "0.911831\n",
      "0.975\n",
      "0.975\n",
      "0.182272\n",
      "0.182272\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.272554\n",
      "0.272554\n",
      "0.025\n",
      "0.025\n",
      "0.184418\n",
      "0.184418\n",
      "0.025\n",
      "0.025\n",
      "0.0826558\n",
      "0.0826558\n",
      "0.025\n",
      "0.025\n",
      "0.340077\n",
      "0.340077\n",
      "0.419232\n",
      "0.419232\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.128774\n",
      "0.128774\n",
      "0.962117\n",
      "0.962117\n",
      "0.025\n",
      "0.025\n",
      "0.818384\n",
      "0.818384\n",
      "0.974494\n",
      "0.974494\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.525655\n",
      "0.525655\n",
      "0.765215\n",
      "0.765215\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.386371\n",
      "0.386371\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.177362\n",
      "0.177362\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.555554\n",
      "0.555554\n",
      "0.025\n",
      "0.025\n",
      "0.0688365\n",
      "0.0688365\n",
      "0.722028\n",
      "0.722028\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.414356\n",
      "0.414356\n",
      "0.0717573\n",
      "0.0717573\n",
      "0.477981\n",
      "0.477981\n",
      "0.855886\n",
      "0.855886\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0461653\n",
      "0.0461653\n",
      "0.025\n",
      "0.025\n",
      "0.860317\n",
      "0.860317\n",
      "0.0970466\n",
      "0.0970466\n",
      "0.500768\n",
      "0.500768\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.26877\n",
      "0.26877\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0400627\n",
      "0.0400627\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0754747\n",
      "0.0754747\n",
      "0.025\n",
      "0.025\n",
      "0.934523\n",
      "0.934523\n",
      "0.025\n",
      "0.025\n",
      "0.703194\n",
      "0.703194\n",
      "0.269829\n",
      "0.269829\n",
      "0.401836\n",
      "0.401836\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.118856\n",
      "0.118856\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.327491\n",
      "0.327491\n",
      "0.950746\n",
      "0.950746\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0274534\n",
      "0.0274534\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.145913\n",
      "0.145913\n",
      "0.025\n",
      "0.025\n",
      "0.0420189\n",
      "0.0420189\n",
      "0.025\n",
      "0.025\n",
      "0.106693\n",
      "0.106693\n",
      "0.082925\n",
      "0.082925\n",
      "0.025\n",
      "0.025\n",
      "0.317932\n",
      "0.317932\n",
      "0.025\n",
      "0.025\n",
      "0.0476677\n",
      "0.0476677\n",
      "0.223468\n",
      "0.223468\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0749036\n",
      "0.0749036\n",
      "0.025\n",
      "0.025\n",
      "0.78374\n",
      "0.78374\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.800654\n",
      "0.800654\n",
      "0.597856\n",
      "0.597856\n",
      "0.0323551\n",
      "0.0323551\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.62478\n",
      "0.62478\n",
      "0.551016\n",
      "0.551016\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.532164\n",
      "0.532164\n",
      "0.056336\n",
      "0.056336\n",
      "0.333275\n",
      "0.333275\n",
      "0.025\n",
      "0.025\n",
      "0.366675\n",
      "0.366675\n",
      "0.975\n",
      "0.975\n",
      "0.140127\n",
      "0.140127\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.705892\n",
      "0.705892\n",
      "0.77702\n",
      "0.77702\n",
      "0.301459\n",
      "0.301459\n",
      "0.025\n",
      "0.025\n",
      "0.0609135\n",
      "0.0609135\n",
      "0.278764\n",
      "0.278764\n",
      "0.666009\n",
      "0.666009\n",
      "0.0762559\n",
      "0.0762559\n",
      "0.971074\n",
      "0.971074\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.420674\n",
      "0.420674\n",
      "0.025\n",
      "0.025\n",
      "0.22466\n",
      "0.22466\n",
      "0.025\n",
      "0.025\n",
      "0.329281\n",
      "0.329281\n",
      "0.025\n",
      "0.025\n",
      "0.853656\n",
      "0.853656\n",
      "0.025037\n",
      "0.025037\n",
      "0.189489\n",
      "0.189489\n",
      "0.0559447\n",
      "0.0559447\n",
      "0.426875\n",
      "0.426875\n",
      "0.025\n",
      "0.025\n",
      "0.125905\n",
      "0.125905\n",
      "0.025\n",
      "0.025\n",
      "0.3086\n",
      "0.3086\n",
      "0.025\n",
      "0.025\n",
      "0.142735\n",
      "0.142735\n",
      "0.32452\n",
      "0.32452\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.165524\n",
      "0.165524\n",
      "0.560893\n",
      "0.560893\n",
      "0.0800835\n",
      "0.0800835\n",
      "0.0258746\n",
      "0.0258746\n",
      "0.215552\n",
      "0.215552\n",
      "0.735038\n",
      "0.735038\n",
      "0.737903\n",
      "0.737903\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.901241\n",
      "0.901241\n",
      "0.0677471\n",
      "0.0677471\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.165771\n",
      "0.165771\n",
      "0.975\n",
      "0.975\n",
      "0.895556\n",
      "0.895556\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0312972\n",
      "0.0312972\n",
      "0.025\n",
      "0.025\n",
      "0.0880655\n",
      "0.0880655\n",
      "0.961797\n",
      "0.961797\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.830794\n",
      "0.830794\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.628935\n",
      "0.628935\n",
      "0.0465149\n",
      "0.0465149\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0838935\n",
      "0.0838935\n",
      "0.357\n",
      "0.357\n",
      "0.0705573\n",
      "0.0705573\n",
      "0.025\n",
      "0.025\n",
      "0.256211\n",
      "0.256211\n",
      "0.025\n",
      "0.025\n",
      "0.737833\n",
      "0.737833\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0633359\n",
      "0.0633359\n",
      "0.134487\n",
      "0.134487\n",
      "0.0743221\n",
      "0.0743221\n",
      "0.025\n",
      "0.025\n",
      "0.4784\n",
      "0.4784\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.151456\n",
      "0.151456\n",
      "0.108574\n",
      "0.108574\n",
      "0.583687\n",
      "0.583687\n",
      "0.167327\n",
      "0.167327\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.524961\n",
      "0.524961\n",
      "0.0468663\n",
      "0.0468663\n",
      "0.0929866\n",
      "0.0929866\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0657189\n",
      "0.0657189\n",
      "0.339388\n",
      "0.339388\n",
      "0.130414\n",
      "0.130414\n",
      "0.025\n",
      "0.025\n",
      "0.0978297\n",
      "0.0978297\n",
      "0.0587398\n",
      "0.0587398\n",
      "0.025\n",
      "0.025\n",
      "0.0653516\n",
      "0.0653516\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0323356\n",
      "0.0323356\n",
      "0.0416976\n",
      "0.0416976\n",
      "0.025\n",
      "0.025\n",
      "0.132698\n",
      "0.132698\n",
      "0.025\n",
      "0.025\n",
      "0.0291634\n",
      "0.0291634\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0614354\n",
      "0.0614354\n",
      "0.975\n",
      "0.975\n",
      "0.0996928\n",
      "0.0996928\n",
      "0.324185\n",
      "0.324185\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.266129\n",
      "0.266129\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.3065\n",
      "0.3065\n",
      "0.025\n",
      "0.025\n",
      "0.513139\n",
      "0.513139\n",
      "0.605374\n",
      "0.605374\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0722742\n",
      "0.0722742\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.131189\n",
      "0.131189\n",
      "0.0266229\n",
      "0.0266229\n",
      "0.867626\n",
      "0.867626\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.188132\n",
      "0.188132\n",
      "0.330967\n",
      "0.330967\n",
      "0.025\n",
      "0.025\n",
      "0.0268835\n",
      "0.0268835\n",
      "0.975\n",
      "0.975\n",
      "0.0468247\n",
      "0.0468247\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.576008\n",
      "0.576008\n",
      "0.025\n",
      "0.025\n",
      "0.0695089\n",
      "0.0695089\n",
      "0.684866\n",
      "0.684866\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.712892\n",
      "0.712892\n",
      "0.771509\n",
      "0.771509\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.932317\n",
      "0.932317\n",
      "0.857705\n",
      "0.857705\n",
      "0.0250005\n",
      "0.0250005\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0258585\n",
      "0.0258585\n",
      "0.959015\n",
      "0.959015\n",
      "0.905209\n",
      "0.905209\n",
      "0.44788\n",
      "0.44788\n",
      "0.0661614\n",
      "0.0661614\n",
      "0.0433548\n",
      "0.0433548\n",
      "0.025\n",
      "0.025\n",
      "0.782924\n",
      "0.782924\n",
      "0.184979\n",
      "0.184979\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0686216\n",
      "0.0686216\n",
      "0.975\n",
      "0.975\n",
      "0.308334\n",
      "0.308334\n",
      "0.275126\n",
      "0.275126\n",
      "0.975\n",
      "0.975\n",
      "0.398844\n",
      "0.398844\n",
      "0.025\n",
      "0.025\n",
      "0.502374\n",
      "0.502374\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.535233\n",
      "0.535233\n",
      "0.025\n",
      "0.025\n",
      "0.38507\n",
      "0.38507\n",
      "0.288833\n",
      "0.288833\n",
      "0.727046\n",
      "0.727046\n",
      "0.0593317\n",
      "0.0593317\n",
      "0.025\n",
      "0.025\n",
      "0.0368682\n",
      "0.0368682\n",
      "0.138797\n",
      "0.138797\n",
      "0.025\n",
      "0.025\n",
      "0.028141\n",
      "0.028141\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0437282\n",
      "0.0437282\n",
      "0.395485\n",
      "0.395485\n",
      "0.0522516\n",
      "0.0522516\n",
      "0.025\n",
      "0.025\n",
      "0.307127\n",
      "0.307127\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.855193\n",
      "0.855193\n",
      "0.271333\n",
      "0.271333\n",
      "0.973002\n",
      "0.973002\n",
      "0.080866\n",
      "0.080866\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.207413\n",
      "0.207413\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0565451\n",
      "0.0565451\n",
      "0.705664\n",
      "0.705664\n",
      "0.975\n",
      "0.975\n",
      "0.0515103\n",
      "0.0515103\n",
      "0.975\n",
      "0.975\n",
      "0.0898166\n",
      "0.0898166\n",
      "0.0871646\n",
      "0.0871646\n",
      "0.871556\n",
      "0.871556\n",
      "0.0530683\n",
      "0.0530683\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.659665\n",
      "0.659665\n",
      "0.280387\n",
      "0.280387\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.48926\n",
      "0.48926\n",
      "0.025\n",
      "0.025\n",
      "0.0261614\n",
      "0.0261614\n",
      "0.025\n",
      "0.025\n",
      "0.0302518\n",
      "0.0302518\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.953716\n",
      "0.953716\n",
      "0.154359\n",
      "0.154359\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.37888\n",
      "0.37888\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.3403\n",
      "0.3403\n",
      "0.583481\n",
      "0.583481\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0278654\n",
      "0.0278654\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.124978\n",
      "0.124978\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.567094\n",
      "0.567094\n",
      "0.975\n",
      "0.975\n",
      "0.755085\n",
      "0.755085\n",
      "0.025\n",
      "0.025\n",
      "0.0764481\n",
      "0.0764481\n",
      "0.897545\n",
      "0.897545\n",
      "0.025\n",
      "0.025\n",
      "0.0919403\n",
      "0.0919403\n",
      "0.523993\n",
      "0.523993\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0267759\n",
      "0.0267759\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.938181\n",
      "0.938181\n",
      "0.025\n",
      "0.025\n",
      "0.0965402\n",
      "0.0965402\n",
      "0.975\n",
      "0.975\n",
      "0.829725\n",
      "0.829725\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0864505\n",
      "0.0864505\n",
      "0.0479602\n",
      "0.0479602\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.957458\n",
      "0.957458\n",
      "0.025\n",
      "0.025\n",
      "0.432378\n",
      "0.432378\n",
      "0.127842\n",
      "0.127842\n",
      "0.0588714\n",
      "0.0588714\n",
      "0.107514\n",
      "0.107514\n",
      "0.12055\n",
      "0.12055\n",
      "0.538247\n",
      "0.538247\n",
      "0.975\n",
      "0.975\n",
      "0.0573549\n",
      "0.0573549\n",
      "0.215154\n",
      "0.215154\n",
      "0.025\n",
      "0.025\n",
      "0.143137\n",
      "0.143137\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.656851\n",
      "0.656851\n",
      "0.025\n",
      "0.025\n",
      "0.724142\n",
      "0.724142\n",
      "0.025\n",
      "0.025\n",
      "0.0670848\n",
      "0.0670848\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.789721\n",
      "0.789721\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.139816\n",
      "0.139816\n",
      "0.227152\n",
      "0.227152\n",
      "0.025\n",
      "0.025\n",
      "0.789458\n",
      "0.789458\n",
      "0.960795\n",
      "0.960795\n",
      "0.027148\n",
      "0.027148\n",
      "0.158883\n",
      "0.158883\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0691558\n",
      "0.0691558\n",
      "0.975\n",
      "0.975\n",
      "0.231985\n",
      "0.231985\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.963994\n",
      "0.963994\n",
      "0.15599\n",
      "0.15599\n",
      "0.129372\n",
      "0.129372\n",
      "0.0268084\n",
      "0.0268084\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0987436\n",
      "0.0987436\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0633354\n",
      "0.0633354\n",
      "0.025\n",
      "0.025\n",
      "0.0467232\n",
      "0.0467232\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.429104\n",
      "0.429104\n",
      "0.356726\n",
      "0.356726\n",
      "0.150102\n",
      "0.150102\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.933293\n",
      "0.933293\n",
      "0.86215\n",
      "0.86215\n",
      "0.1964\n",
      "0.1964\n",
      "0.025\n",
      "0.025\n",
      "0.871948\n",
      "0.871948\n",
      "0.025\n",
      "0.025\n",
      "0.951334\n",
      "0.951334\n",
      "0.025\n",
      "0.025\n",
      "0.0580763\n",
      "0.0580763\n",
      "0.957568\n",
      "0.957568\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.535726\n",
      "0.535726\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.526351\n",
      "0.526351\n",
      "0.613604\n",
      "0.613604\n",
      "0.025\n",
      "0.025\n",
      "0.0558523\n",
      "0.0558523\n",
      "0.025\n",
      "0.025\n",
      "0.490753\n",
      "0.490753\n",
      "0.968985\n",
      "0.968985\n",
      "0.11436\n",
      "0.11436\n",
      "0.0275856\n",
      "0.0275856\n",
      "0.0533504\n",
      "0.0533504\n",
      "0.025\n",
      "0.025\n",
      "0.271552\n",
      "0.271552\n",
      "0.938524\n",
      "0.938524\n",
      "0.681947\n",
      "0.681947\n",
      "0.325564\n",
      "0.325564\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0311574\n",
      "0.0311574\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.965513\n",
      "0.965513\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.122965\n",
      "0.122965\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.934736\n",
      "0.934736\n",
      "0.0827202\n",
      "0.0827202\n",
      "0.157526\n",
      "0.157526\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.25491\n",
      "0.25491\n",
      "0.97413\n",
      "0.97413\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.610483\n",
      "0.610483\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.81174\n",
      "0.81174\n",
      "0.461784\n",
      "0.461784\n",
      "0.0377598\n",
      "0.0377598\n",
      "0.472292\n",
      "0.472292\n",
      "0.134198\n",
      "0.134198\n",
      "0.157534\n",
      "0.157534\n",
      "0.120309\n",
      "0.120309\n",
      "0.112974\n",
      "0.112974\n",
      "0.0901276\n",
      "0.0901276\n",
      "0.0433963\n",
      "0.0433963\n",
      "0.025\n",
      "0.025\n",
      "0.688457\n",
      "0.688457\n",
      "0.025\n",
      "0.025\n",
      "0.0776349\n",
      "0.0776349\n",
      "0.103108\n",
      "0.103108\n",
      "0.081968\n",
      "0.081968\n",
      "0.848386\n",
      "0.848386\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.800885\n",
      "0.800885\n",
      "0.025\n",
      "0.025\n",
      "0.3816\n",
      "0.3816\n",
      "0.842479\n",
      "0.842479\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.272951\n",
      "0.272951\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.140105\n",
      "0.140105\n",
      "0.281599\n",
      "0.281599\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.628978\n",
      "0.628978\n",
      "0.0671523\n",
      "0.0671523\n",
      "0.126032\n",
      "0.126032\n",
      "0.025\n",
      "0.025\n",
      "0.0390991\n",
      "0.0390991\n",
      "0.0455839\n",
      "0.0455839\n",
      "0.368903\n",
      "0.368903\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.96749\n",
      "0.96749\n",
      "0.910907\n",
      "0.910907\n",
      "0.165664\n",
      "0.165664\n",
      "0.025\n",
      "0.025\n",
      "0.432613\n",
      "0.432613\n",
      "0.895918\n",
      "0.895918\n",
      "0.798422\n",
      "0.798422\n",
      "0.0463021\n",
      "0.0463021\n",
      "0.025\n",
      "0.025\n",
      "0.336488\n",
      "0.336488\n",
      "0.917697\n",
      "0.917697\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.918215\n",
      "0.918215\n",
      "0.025\n",
      "0.025\n",
      "0.0265147\n",
      "0.0265147\n",
      "0.975\n",
      "0.975\n",
      "0.218386\n",
      "0.218386\n",
      "0.173513\n",
      "0.173513\n",
      "0.0257678\n",
      "0.0257678\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.972991\n",
      "0.972991\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.960248\n",
      "0.960248\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0496636\n",
      "0.0496636\n",
      "0.107655\n",
      "0.107655\n",
      "0.0395381\n",
      "0.0395381\n",
      "0.975\n",
      "0.975\n",
      "0.495289\n",
      "0.495289\n",
      "0.0310487\n",
      "0.0310487\n",
      "0.025\n",
      "0.025\n",
      "0.454072\n",
      "0.454072\n",
      "0.025\n",
      "0.025\n",
      "0.154986\n",
      "0.154986\n",
      "0.975\n",
      "0.975\n",
      "0.212067\n",
      "0.212067\n",
      "0.025\n",
      "0.025\n",
      "0.161097\n",
      "0.161097\n",
      "0.255762\n",
      "0.255762\n",
      "0.581743\n",
      "0.581743\n",
      "0.0633601\n",
      "0.0633601\n",
      "0.325587\n",
      "0.325587\n",
      "0.13083\n",
      "0.13083\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.172398\n",
      "0.172398\n",
      "0.895316\n",
      "0.895316\n",
      "0.945384\n",
      "0.945384\n",
      "0.025\n",
      "0.025\n",
      "0.0255775\n",
      "0.0255775\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.48502\n",
      "0.48502\n",
      "0.0521885\n",
      "0.0521885\n",
      "0.025\n",
      "0.025\n",
      "0.456827\n",
      "0.456827\n",
      "0.025\n",
      "0.025\n",
      "0.786471\n",
      "0.786471\n",
      "0.025\n",
      "0.025\n",
      "0.32065\n",
      "0.32065\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0550592\n",
      "0.0550592\n",
      "0.0399127\n",
      "0.0399127\n",
      "0.975\n",
      "0.975\n",
      "0.343845\n",
      "0.343845\n",
      "0.025\n",
      "0.025\n",
      "0.931919\n",
      "0.931919\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.836716\n",
      "0.836716\n",
      "0.14007\n",
      "0.14007\n",
      "0.025\n",
      "0.025\n",
      "0.224401\n",
      "0.224401\n",
      "0.0674277\n",
      "0.0674277\n",
      "0.025\n",
      "0.025\n",
      "0.251958\n",
      "0.251958\n",
      "0.0664579\n",
      "0.0664579\n",
      "0.481094\n",
      "0.481094\n",
      "0.960713\n",
      "0.960713\n",
      "0.0305288\n",
      "0.0305288\n",
      "0.443365\n",
      "0.443365\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.942358\n",
      "0.942358\n",
      "0.025\n",
      "0.025\n",
      "0.0657044\n",
      "0.0657044\n",
      "0.0940823\n",
      "0.0940823\n",
      "0.025\n",
      "0.025\n",
      "0.335483\n",
      "0.335483\n",
      "0.958135\n",
      "0.958135\n",
      "0.0371299\n",
      "0.0371299\n",
      "0.025\n",
      "0.025\n",
      "0.352224\n",
      "0.352224\n",
      "0.759785\n",
      "0.759785\n",
      "0.0975117\n",
      "0.0975117\n",
      "0.0976509\n",
      "0.0976509\n",
      "0.025\n",
      "0.025\n",
      "0.0466179\n",
      "0.0466179\n",
      "0.825747\n",
      "0.825747\n",
      "0.025\n",
      "0.025\n",
      "0.960886\n",
      "0.960886\n",
      "0.535321\n",
      "0.535321\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0831487\n",
      "0.0831487\n",
      "0.025\n",
      "0.025\n",
      "0.374806\n",
      "0.374806\n",
      "0.025\n",
      "0.025\n",
      "0.0402253\n",
      "0.0402253\n",
      "0.025\n",
      "0.025\n",
      "0.0553791\n",
      "0.0553791\n",
      "0.025\n",
      "0.025\n",
      "0.203587\n",
      "0.203587\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.593752\n",
      "0.593752\n",
      "0.025\n",
      "0.025\n",
      "0.0259421\n",
      "0.0259421\n",
      "0.025\n",
      "0.025\n",
      "0.850308\n",
      "0.850308\n",
      "0.975\n",
      "0.975\n",
      "0.0655747\n",
      "0.0655747\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0801758\n",
      "0.0801758\n",
      "0.0257494\n",
      "0.0257494\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0455244\n",
      "0.0455244\n",
      "0.025\n",
      "0.025\n",
      "0.115827\n",
      "0.115827\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.671658\n",
      "0.671658\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.140968\n",
      "0.140968\n",
      "0.973795\n",
      "0.973795\n",
      "0.0358458\n",
      "0.0358458\n",
      "0.866122\n",
      "0.866122\n",
      "0.0596341\n",
      "0.0596341\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.909849\n",
      "0.909849\n",
      "0.0284496\n",
      "0.0284496\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.80944\n",
      "0.80944\n",
      "0.0313271\n",
      "0.0313271\n",
      "0.025\n",
      "0.025\n",
      "0.202317\n",
      "0.202317\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.958478\n",
      "0.958478\n",
      "0.025\n",
      "0.025\n",
      "0.0905641\n",
      "0.0905641\n",
      "0.115826\n",
      "0.115826\n",
      "0.187598\n",
      "0.187598\n",
      "0.966436\n",
      "0.966436\n",
      "0.025\n",
      "0.025\n",
      "0.528948\n",
      "0.528948\n",
      "0.435338\n",
      "0.435338\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.038716\n",
      "0.038716\n",
      "0.0283049\n",
      "0.0283049\n",
      "0.942304\n",
      "0.942304\n",
      "0.025\n",
      "0.025\n",
      "0.895536\n",
      "0.895536\n",
      "0.793792\n",
      "0.793792\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0262231\n",
      "0.0262231\n",
      "0.025\n",
      "0.025\n",
      "0.180318\n",
      "0.180318\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0944979\n",
      "0.0944979\n",
      "0.975\n",
      "0.975\n",
      "0.95909\n",
      "0.95909\n",
      "0.141475\n",
      "0.141475\n",
      "0.025\n",
      "0.025\n",
      "0.031335\n",
      "0.031335\n",
      "0.025\n",
      "0.025\n",
      "0.261105\n",
      "0.261105\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.269556\n",
      "0.269556\n",
      "0.770163\n",
      "0.770163\n",
      "0.025\n",
      "0.025\n",
      "0.829886\n",
      "0.829886\n",
      "0.975\n",
      "0.975\n",
      "0.205742\n",
      "0.205742\n",
      "0.025\n",
      "0.025\n",
      "0.0374521\n",
      "0.0374521\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0524365\n",
      "0.0524365\n",
      "0.177615\n",
      "0.177615\n",
      "0.303049\n",
      "0.303049\n",
      "0.287757\n",
      "0.287757\n",
      "0.856942\n",
      "0.856942\n",
      "0.763129\n",
      "0.763129\n",
      "0.67287\n",
      "0.67287\n",
      "0.372288\n",
      "0.372288\n",
      "0.197844\n",
      "0.197844\n",
      "0.154401\n",
      "0.154401\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.270662\n",
      "0.270662\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.384926\n",
      "0.384926\n",
      "0.718604\n",
      "0.718604\n",
      "0.0979457\n",
      "0.0979457\n",
      "0.0583476\n",
      "0.0583476\n",
      "0.324023\n",
      "0.324023\n",
      "0.283871\n",
      "0.283871\n",
      "0.025\n",
      "0.025\n",
      "0.11419\n",
      "0.11419\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.341825\n",
      "0.341825\n",
      "0.110077\n",
      "0.110077\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.259003\n",
      "0.259003\n",
      "0.025\n",
      "0.025\n",
      "0.0474012\n",
      "0.0474012\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.618813\n",
      "0.618813\n",
      "0.0589061\n",
      "0.0589061\n",
      "0.488758\n",
      "0.488758\n",
      "0.025\n",
      "0.025\n",
      "0.0469092\n",
      "0.0469092\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.871896\n",
      "0.871896\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.10969\n",
      "0.10969\n",
      "0.025\n",
      "0.025\n",
      "0.0499955\n",
      "0.0499955\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.179519\n",
      "0.179519\n",
      "0.508498\n",
      "0.508498\n",
      "0.214736\n",
      "0.214736\n",
      "0.137213\n",
      "0.137213\n",
      "0.142417\n",
      "0.142417\n",
      "0.975\n",
      "0.975\n",
      "0.139654\n",
      "0.139654\n",
      "0.282122\n",
      "0.282122\n",
      "0.025\n",
      "0.025\n",
      "0.137926\n",
      "0.137926\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.845525\n",
      "0.845525\n",
      "0.558343\n",
      "0.558343\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.47788\n",
      "0.47788\n",
      "0.939976\n",
      "0.939976\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.10234\n",
      "0.10234\n",
      "0.025\n",
      "0.025\n",
      "0.797538\n",
      "0.797538\n",
      "0.549516\n",
      "0.549516\n",
      "0.025\n",
      "0.025\n",
      "0.185313\n",
      "0.185313\n",
      "0.025\n",
      "0.025\n",
      "0.0399893\n",
      "0.0399893\n",
      "0.0270336\n",
      "0.0270336\n",
      "0.189205\n",
      "0.189205\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0611997\n",
      "0.0611997\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.972471\n",
      "0.972471\n",
      "0.975\n",
      "0.975\n",
      "0.0771207\n",
      "0.0771207\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.863792\n",
      "0.863792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0770904\n",
      "0.0770904\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.503511\n",
      "0.503511\n",
      "0.937978\n",
      "0.937978\n",
      "0.337163\n",
      "0.337163\n",
      "0.0597975\n",
      "0.0597975\n",
      "0.685398\n",
      "0.685398\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.218216\n",
      "0.218216\n",
      "0.444544\n",
      "0.444544\n",
      "0.0323253\n",
      "0.0323253\n",
      "0.975\n",
      "0.975\n",
      "0.222656\n",
      "0.222656\n",
      "0.0361735\n",
      "0.0361735\n",
      "0.871895\n",
      "0.871895\n",
      "0.974748\n",
      "0.974748\n",
      "0.150898\n",
      "0.150898\n",
      "0.397852\n",
      "0.397852\n",
      "0.975\n",
      "0.975\n",
      "0.124952\n",
      "0.124952\n",
      "0.198408\n",
      "0.198408\n",
      "0.025\n",
      "0.025\n",
      "0.0814909\n",
      "0.0814909\n",
      "0.955749\n",
      "0.955749\n",
      "0.478331\n",
      "0.478331\n",
      "0.975\n",
      "0.975\n",
      "0.036044\n",
      "0.036044\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.46121\n",
      "0.46121\n",
      "0.12385\n",
      "0.12385\n",
      "0.025\n",
      "0.025\n",
      "0.16372\n",
      "0.16372\n",
      "0.025\n",
      "0.025\n",
      "0.0449038\n",
      "0.0449038\n",
      "0.975\n",
      "0.975\n",
      "0.860858\n",
      "0.860858\n",
      "0.101663\n",
      "0.101663\n",
      "0.0664645\n",
      "0.0664645\n",
      "0.0355116\n",
      "0.0355116\n",
      "0.025\n",
      "0.025\n",
      "0.035743\n",
      "0.035743\n",
      "0.949917\n",
      "0.949917\n",
      "0.0510591\n",
      "0.0510591\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.124609\n",
      "0.124609\n",
      "0.025\n",
      "0.025\n",
      "0.538973\n",
      "0.538973\n",
      "0.0363512\n",
      "0.0363512\n",
      "0.025\n",
      "0.025\n",
      "0.206855\n",
      "0.206855\n",
      "0.278488\n",
      "0.278488\n",
      "0.025\n",
      "0.025\n",
      "0.051896\n",
      "0.051896\n",
      "0.975\n",
      "0.975\n",
      "0.0492997\n",
      "0.0492997\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0266379\n",
      "0.0266379\n",
      "0.310162\n",
      "0.310162\n",
      "0.025\n",
      "0.025\n",
      "0.24828\n",
      "0.24828\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.218591\n",
      "0.218591\n",
      "0.293253\n",
      "0.293253\n",
      "0.975\n",
      "0.975\n",
      "0.316063\n",
      "0.316063\n",
      "0.0341562\n",
      "0.0341562\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.501424\n",
      "0.501424\n",
      "0.025\n",
      "0.025\n",
      "0.963329\n",
      "0.963329\n",
      "0.0614849\n",
      "0.0614849\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.927054\n",
      "0.927054\n",
      "0.0330891\n",
      "0.0330891\n",
      "0.025\n",
      "0.025\n",
      "0.961557\n",
      "0.961557\n",
      "0.82883\n",
      "0.82883\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0993462\n",
      "0.0993462\n",
      "0.025\n",
      "0.025\n",
      "0.666293\n",
      "0.666293\n",
      "0.828461\n",
      "0.828461\n",
      "0.025\n",
      "0.025\n",
      "0.414342\n",
      "0.414342\n",
      "0.401778\n",
      "0.401778\n",
      "0.025\n",
      "0.025\n",
      "0.0454835\n",
      "0.0454835\n",
      "0.823836\n",
      "0.823836\n",
      "0.334546\n",
      "0.334546\n",
      "0.025\n",
      "0.025\n",
      "0.26109\n",
      "0.26109\n",
      "0.0868084\n",
      "0.0868084\n",
      "0.925557\n",
      "0.925557\n",
      "0.025\n",
      "0.025\n",
      "0.157003\n",
      "0.157003\n",
      "0.063991\n",
      "0.063991\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.231507\n",
      "0.231507\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.917524\n",
      "0.917524\n",
      "0.0952478\n",
      "0.0952478\n",
      "0.0338185\n",
      "0.0338185\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0565141\n",
      "0.0565141\n",
      "0.025\n",
      "0.025\n",
      "0.241093\n",
      "0.241093\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.122177\n",
      "0.122177\n",
      "0.109996\n",
      "0.109996\n",
      "0.975\n",
      "0.975\n",
      "0.293681\n",
      "0.293681\n",
      "0.025\n",
      "0.025\n",
      "0.918366\n",
      "0.918366\n",
      "0.464912\n",
      "0.464912\n",
      "0.236134\n",
      "0.236134\n",
      "0.025\n",
      "0.025\n",
      "0.0873471\n",
      "0.0873471\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.105925\n",
      "0.105925\n",
      "0.975\n",
      "0.975\n",
      "0.972623\n",
      "0.972623\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.500781\n",
      "0.500781\n",
      "0.025\n",
      "0.025\n",
      "0.640068\n",
      "0.640068\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0351162\n",
      "0.0351162\n",
      "0.975\n",
      "0.975\n",
      "0.323243\n",
      "0.323243\n",
      "0.287449\n",
      "0.287449\n",
      "0.910494\n",
      "0.910494\n",
      "0.975\n",
      "0.975\n",
      "0.046468\n",
      "0.046468\n",
      "0.025\n",
      "0.025\n",
      "0.228073\n",
      "0.228073\n",
      "0.145321\n",
      "0.145321\n",
      "0.70025\n",
      "0.70025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.219802\n",
      "0.219802\n",
      "0.025\n",
      "0.025\n",
      "0.0704161\n",
      "0.0704161\n",
      "0.13348\n",
      "0.13348\n",
      "0.975\n",
      "0.975\n",
      "0.428605\n",
      "0.428605\n",
      "0.969706\n",
      "0.969706\n",
      "0.296337\n",
      "0.296337\n",
      "0.959355\n",
      "0.959355\n",
      "0.648231\n",
      "0.648231\n",
      "0.025\n",
      "0.025\n",
      "0.0834995\n",
      "0.0834995\n",
      "0.025\n",
      "0.025\n",
      "0.293101\n",
      "0.293101\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.502008\n",
      "0.502008\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.113381\n",
      "0.113381\n",
      "0.0274471\n",
      "0.0274471\n",
      "0.843331\n",
      "0.843331\n",
      "0.754963\n",
      "0.754963\n",
      "0.0263786\n",
      "0.0263786\n",
      "0.025\n",
      "0.025\n",
      "0.254091\n",
      "0.254091\n",
      "0.847039\n",
      "0.847039\n",
      "0.0853182\n",
      "0.0853182\n",
      "0.0612632\n",
      "0.0612632\n",
      "0.025\n",
      "0.025\n",
      "0.0393931\n",
      "0.0393931\n",
      "0.907327\n",
      "0.907327\n",
      "0.0998108\n",
      "0.0998108\n",
      "0.86027\n",
      "0.86027\n",
      "0.025\n",
      "0.025\n",
      "0.0271691\n",
      "0.0271691\n",
      "0.863551\n",
      "0.863551\n",
      "0.843593\n",
      "0.843593\n",
      "0.033898\n",
      "0.033898\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.618313\n",
      "0.618313\n",
      "0.472178\n",
      "0.472178\n",
      "0.0676753\n",
      "0.0676753\n",
      "0.0556616\n",
      "0.0556616\n",
      "0.975\n",
      "0.975\n",
      "0.0319413\n",
      "0.0319413\n",
      "0.975\n",
      "0.975\n",
      "0.851272\n",
      "0.851272\n",
      "0.242811\n",
      "0.242811\n",
      "0.934822\n",
      "0.934822\n",
      "0.181196\n",
      "0.181196\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.874738\n",
      "0.874738\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.207247\n",
      "0.207247\n",
      "0.025\n",
      "0.025\n",
      "0.972983\n",
      "0.972983\n",
      "0.202445\n",
      "0.202445\n",
      "0.772725\n",
      "0.772725\n",
      "0.965642\n",
      "0.965642\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.347498\n",
      "0.347498\n",
      "0.032868\n",
      "0.032868\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.452161\n",
      "0.452161\n",
      "0.0971501\n",
      "0.0971501\n",
      "0.104715\n",
      "0.104715\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0898292\n",
      "0.0898292\n",
      "0.873403\n",
      "0.873403\n",
      "0.174787\n",
      "0.174787\n",
      "0.0969987\n",
      "0.0969987\n",
      "0.025\n",
      "0.025\n",
      "0.424577\n",
      "0.424577\n",
      "0.152834\n",
      "0.152834\n",
      "0.0344852\n",
      "0.0344852\n",
      "0.163163\n",
      "0.163163\n",
      "0.0298843\n",
      "0.0298843\n",
      "0.618712\n",
      "0.618712\n",
      "0.718216\n",
      "0.718216\n",
      "0.025\n",
      "0.025\n",
      "0.124564\n",
      "0.124564\n",
      "0.745993\n",
      "0.745993\n",
      "0.975\n",
      "0.975\n",
      "0.960882\n",
      "0.960882\n",
      "0.685959\n",
      "0.685959\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.150962\n",
      "0.150962\n",
      "0.025\n",
      "0.025\n",
      "0.795279\n",
      "0.795279\n",
      "0.778039\n",
      "0.778039\n",
      "0.647695\n",
      "0.647695\n",
      "0.975\n",
      "0.975\n",
      "0.527155\n",
      "0.527155\n",
      "0.201481\n",
      "0.201481\n",
      "0.122725\n",
      "0.122725\n",
      "0.224514\n",
      "0.224514\n",
      "0.0839743\n",
      "0.0839743\n",
      "0.959622\n",
      "0.959622\n",
      "0.025\n",
      "0.025\n",
      "0.0281508\n",
      "0.0281508\n",
      "0.599519\n",
      "0.599519\n",
      "0.123182\n",
      "0.123182\n",
      "0.0635789\n",
      "0.0635789\n",
      "0.975\n",
      "0.975\n",
      "0.101594\n",
      "0.101594\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0360799\n",
      "0.0360799\n",
      "0.975\n",
      "0.975\n",
      "0.0777357\n",
      "0.0777357\n",
      "0.025\n",
      "0.025\n",
      "0.0415064\n",
      "0.0415064\n",
      "0.513398\n",
      "0.513398\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0530081\n",
      "0.0530081\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.586106\n",
      "0.586106\n",
      "0.089939\n",
      "0.089939\n",
      "0.203415\n",
      "0.203415\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.043306\n",
      "0.043306\n",
      "0.0460692\n",
      "0.0460692\n",
      "0.219456\n",
      "0.219456\n",
      "0.0263467\n",
      "0.0263467\n",
      "0.0724213\n",
      "0.0724213\n",
      "0.0386059\n",
      "0.0386059\n",
      "0.025\n",
      "0.025\n",
      "0.395058\n",
      "0.395058\n",
      "0.975\n",
      "0.975\n",
      "0.944706\n",
      "0.944706\n",
      "0.025\n",
      "0.025\n",
      "0.265966\n",
      "0.265966\n",
      "0.025\n",
      "0.025\n",
      "0.0353683\n",
      "0.0353683\n",
      "0.975\n",
      "0.975\n",
      "0.0495605\n",
      "0.0495605\n",
      "0.534973\n",
      "0.534973\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0362426\n",
      "0.0362426\n",
      "0.025\n",
      "0.025\n",
      "0.900764\n",
      "0.900764\n",
      "0.309174\n",
      "0.309174\n",
      "0.0734751\n",
      "0.0734751\n",
      "0.025\n",
      "0.025\n",
      "0.15087\n",
      "0.15087\n",
      "0.143585\n",
      "0.143585\n",
      "0.025\n",
      "0.025\n",
      "0.0567882\n",
      "0.0567882\n",
      "0.408838\n",
      "0.408838\n",
      "0.0989495\n",
      "0.0989495\n",
      "0.536819\n",
      "0.536819\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.568415\n",
      "0.568415\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.111304\n",
      "0.111304\n",
      "0.975\n",
      "0.975\n",
      "0.917421\n",
      "0.917421\n",
      "0.0493676\n",
      "0.0493676\n",
      "0.560791\n",
      "0.560791\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0317574\n",
      "0.0317574\n",
      "0.898859\n",
      "0.898859\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.193954\n",
      "0.193954\n",
      "0.025\n",
      "0.025\n",
      "0.322369\n",
      "0.322369\n",
      "0.025\n",
      "0.025\n",
      "0.128273\n",
      "0.128273\n",
      "0.0784413\n",
      "0.0784413\n",
      "0.441431\n",
      "0.441431\n",
      "0.975\n",
      "0.975\n",
      "0.0561619\n",
      "0.0561619\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.311771\n",
      "0.311771\n",
      "0.729807\n",
      "0.729807\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0700053\n",
      "0.0700053\n",
      "0.0762864\n",
      "0.0762864\n",
      "0.578847\n",
      "0.578847\n",
      "0.0331779\n",
      "0.0331779\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.205052\n",
      "0.205052\n",
      "0.272909\n",
      "0.272909\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.927979\n",
      "0.927979\n",
      "0.0911887\n",
      "0.0911887\n",
      "0.734376\n",
      "0.734376\n",
      "0.0718736\n",
      "0.0718736\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.946223\n",
      "0.946223\n",
      "0.516436\n",
      "0.516436\n",
      "0.453152\n",
      "0.453152\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.771076\n",
      "0.771076\n",
      "0.975\n",
      "0.975\n",
      "0.09346\n",
      "0.09346\n",
      "0.90794\n",
      "0.90794\n",
      "0.025\n",
      "0.025\n",
      "0.833598\n",
      "0.833598\n",
      "0.0401968\n",
      "0.0401968\n",
      "0.553608\n",
      "0.553608\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.174285\n",
      "0.174285\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.945423\n",
      "0.945423\n",
      "0.205692\n",
      "0.205692\n",
      "0.379539\n",
      "0.379539\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.352196\n",
      "0.352196\n",
      "0.025\n",
      "0.025\n",
      "0.0515923\n",
      "0.0515923\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0918512\n",
      "0.0918512\n",
      "0.969091\n",
      "0.969091\n",
      "0.712254\n",
      "0.712254\n",
      "0.559731\n",
      "0.559731\n",
      "0.047569\n",
      "0.047569\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.087023\n",
      "0.087023\n",
      "0.892282\n",
      "0.892282\n",
      "0.975\n",
      "0.975\n",
      "0.499653\n",
      "0.499653\n",
      "0.025\n",
      "0.025\n",
      "0.025507\n",
      "0.025507\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.388474\n",
      "0.388474\n",
      "0.240783\n",
      "0.240783\n",
      "0.975\n",
      "0.975\n",
      "0.797248\n",
      "0.797248\n",
      "0.025\n",
      "0.025\n",
      "0.462373\n",
      "0.462373\n",
      "0.975\n",
      "0.975\n",
      "0.0703594\n",
      "0.0703594\n",
      "0.025\n",
      "0.025\n",
      "0.519517\n",
      "0.519517\n",
      "0.482175\n",
      "0.482175\n",
      "0.0963517\n",
      "0.0963517\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.559074\n",
      "0.559074\n",
      "0.258353\n",
      "0.258353\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.546587\n",
      "0.546587\n",
      "0.147049\n",
      "0.147049\n",
      "0.025\n",
      "0.025\n",
      "0.0605896\n",
      "0.0605896\n",
      "0.155085\n",
      "0.155085\n",
      "0.434043\n",
      "0.434043\n",
      "0.619189\n",
      "0.619189\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.538519\n",
      "0.538519\n",
      "0.691196\n",
      "0.691196\n",
      "0.972523\n",
      "0.972523\n",
      "0.06362\n",
      "0.06362\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.483045\n",
      "0.483045\n",
      "0.188064\n",
      "0.188064\n",
      "0.11463\n",
      "0.11463\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0560995\n",
      "0.0560995\n",
      "0.0769112\n",
      "0.0769112\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.942589\n",
      "0.942589\n",
      "0.025\n",
      "0.025\n",
      "0.0339101\n",
      "0.0339101\n",
      "0.025\n",
      "0.025\n",
      "0.120343\n",
      "0.120343\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.290353\n",
      "0.290353\n",
      "0.975\n",
      "0.975\n",
      "0.369182\n",
      "0.369182\n",
      "0.025\n",
      "0.025\n",
      "0.771624\n",
      "0.771624\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0403677\n",
      "0.0403677\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0892414\n",
      "0.0892414\n",
      "0.025\n",
      "0.025\n",
      "0.435176\n",
      "0.435176\n",
      "0.025\n",
      "0.025\n",
      "0.059374\n",
      "0.059374\n",
      "0.210916\n",
      "0.210916\n",
      "0.968902\n",
      "0.968902\n",
      "0.733024\n",
      "0.733024\n",
      "0.115988\n",
      "0.115988\n",
      "0.975\n",
      "0.975\n",
      "0.58847\n",
      "0.58847\n",
      "0.0651283\n",
      "0.0651283\n",
      "0.0777706\n",
      "0.0777706\n",
      "0.72014\n",
      "0.72014\n",
      "0.0908521\n",
      "0.0908521\n",
      "0.435545\n",
      "0.435545\n",
      "0.025\n",
      "0.025\n",
      "0.126412\n",
      "0.126412\n",
      "0.975\n",
      "0.975\n",
      "0.870706\n",
      "0.870706\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0272491\n",
      "0.0272491\n",
      "0.947565\n",
      "0.947565\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.105188\n",
      "0.105188\n",
      "0.0315653\n",
      "0.0315653\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.464654\n",
      "0.464654\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0335936\n",
      "0.0335936\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.138009\n",
      "0.138009\n",
      "0.975\n",
      "0.975\n",
      "0.0512991\n",
      "0.0512991\n",
      "0.025\n",
      "0.025\n",
      "0.12191\n",
      "0.12191\n",
      "0.834585\n",
      "0.834585\n",
      "0.025\n",
      "0.025\n",
      "0.0803721\n",
      "0.0803721\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.412004\n",
      "0.412004\n",
      "0.234999\n",
      "0.234999\n",
      "0.025\n",
      "0.025\n",
      "0.0519966\n",
      "0.0519966\n",
      "0.025\n",
      "0.025\n",
      "0.20109\n",
      "0.20109\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.68932\n",
      "0.68932\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.97129\n",
      "0.97129\n",
      "0.683754\n",
      "0.683754\n",
      "0.025\n",
      "0.025\n",
      "0.374278\n",
      "0.374278\n",
      "0.0539118\n",
      "0.0539118\n",
      "0.514238\n",
      "0.514238\n",
      "0.025\n",
      "0.025\n",
      "0.605647\n",
      "0.605647\n",
      "0.612348\n",
      "0.612348\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.956115\n",
      "0.956115\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.407778\n",
      "0.407778\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.256183\n",
      "0.256183\n",
      "0.0355466\n",
      "0.0355466\n",
      "0.268579\n",
      "0.268579\n",
      "0.199831\n",
      "0.199831\n",
      "0.025\n",
      "0.025\n",
      "0.779113\n",
      "0.779113\n",
      "0.0980768\n",
      "0.0980768\n",
      "0.176685\n",
      "0.176685\n",
      "0.910737\n",
      "0.910737\n",
      "0.975\n",
      "0.975\n",
      "0.0720512\n",
      "0.0720512\n",
      "0.025\n",
      "0.025\n",
      "0.058679\n",
      "0.058679\n",
      "0.025\n",
      "0.025\n",
      "0.712917\n",
      "0.712917\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0317587\n",
      "0.0317587\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.367363\n",
      "0.367363\n",
      "0.0879731\n",
      "0.0879731\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.559285\n",
      "0.559285\n",
      "0.025\n",
      "0.025\n",
      "0.123967\n",
      "0.123967\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0264277\n",
      "0.0264277\n",
      "0.543742\n",
      "0.543742\n",
      "0.094197\n",
      "0.094197\n",
      "0.025\n",
      "0.025\n",
      "0.0937164\n",
      "0.0937164\n",
      "0.146659\n",
      "0.146659\n",
      "0.025\n",
      "0.025\n",
      "0.888275\n",
      "0.888275\n",
      "0.761232\n",
      "0.761232\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.853059\n",
      "0.853059\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0529114\n",
      "0.0529114\n",
      "0.78314\n",
      "0.78314\n",
      "0.025\n",
      "0.025\n",
      "0.960287\n",
      "0.960287\n",
      "0.932082\n",
      "0.932082\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.940726\n",
      "0.940726\n",
      "0.975\n",
      "0.975\n",
      "0.277637\n",
      "0.277637\n",
      "0.025\n",
      "0.025\n",
      "0.366264\n",
      "0.366264\n",
      "0.0415493\n",
      "0.0415493\n",
      "0.8175\n",
      "0.8175\n",
      "0.0534152\n",
      "0.0534152\n",
      "0.64388\n",
      "0.64388\n",
      "0.025\n",
      "0.025\n",
      "0.080467\n",
      "0.080467\n",
      "0.025\n",
      "0.025\n",
      "0.0656812\n",
      "0.0656812\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.214294\n",
      "0.214294\n",
      "0.118772\n",
      "0.118772\n",
      "0.577293\n",
      "0.577293\n",
      "0.975\n",
      "0.975\n",
      "0.279675\n",
      "0.279675\n",
      "0.0782158\n",
      "0.0782158\n",
      "0.573537\n",
      "0.573537\n",
      "0.0389578\n",
      "0.0389578\n",
      "0.706943\n",
      "0.706943\n",
      "0.025\n",
      "0.025\n",
      "0.916318\n",
      "0.916318\n",
      "0.101197\n",
      "0.101197\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.197108\n",
      "0.197108\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.201321\n",
      "0.201321\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.790324\n",
      "0.790324\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0820077\n",
      "0.0820077\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.933168\n",
      "0.933168\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.446508\n",
      "0.446508\n",
      "0.0278986\n",
      "0.0278986\n",
      "0.025\n",
      "0.025\n",
      "0.847965\n",
      "0.847965\n",
      "0.772402\n",
      "0.772402\n",
      "0.025\n",
      "0.025\n",
      "0.0501035\n",
      "0.0501035\n",
      "0.0955605\n",
      "0.0955605\n",
      "0.171481\n",
      "0.171481\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.116399\n",
      "0.116399\n",
      "0.025\n",
      "0.025\n",
      "0.0754582\n",
      "0.0754582\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.59198\n",
      "0.59198\n",
      "0.706028\n",
      "0.706028\n",
      "0.025\n",
      "0.025\n",
      "0.0468618\n",
      "0.0468618\n",
      "0.025\n",
      "0.025\n",
      "0.243464\n",
      "0.243464\n",
      "0.0291124\n",
      "0.0291124\n",
      "0.025\n",
      "0.025\n",
      "0.0679223\n",
      "0.0679223\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0316637\n",
      "0.0316637\n",
      "0.284029\n",
      "0.284029\n",
      "0.554524\n",
      "0.554524\n",
      "0.025\n",
      "0.025\n",
      "0.0288607\n",
      "0.0288607\n",
      "0.124645\n",
      "0.124645\n",
      "0.947853\n",
      "0.947853\n",
      "0.560281\n",
      "0.560281\n",
      "0.0742112\n",
      "0.0742112\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0619781\n",
      "0.0619781\n",
      "0.025\n",
      "0.025\n",
      "0.803131\n",
      "0.803131\n",
      "0.025\n",
      "0.025\n",
      "0.170452\n",
      "0.170452\n",
      "0.86074\n",
      "0.86074\n",
      "0.025\n",
      "0.025\n",
      "0.278668\n",
      "0.278668\n",
      "0.0864411\n",
      "0.0864411\n",
      "0.025\n",
      "0.025\n",
      "0.91344\n",
      "0.91344\n",
      "0.88876\n",
      "0.88876\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.852647\n",
      "0.852647\n",
      "0.214409\n",
      "0.214409\n",
      "0.025\n",
      "0.025\n",
      "0.0750404\n",
      "0.0750404\n",
      "0.645188\n",
      "0.645188\n",
      "0.025\n",
      "0.025\n",
      "0.90108\n",
      "0.90108\n",
      "0.975\n",
      "0.975\n",
      "0.181038\n",
      "0.181038\n",
      "0.0360808\n",
      "0.0360808\n",
      "0.963576\n",
      "0.963576\n",
      "0.025\n",
      "0.025\n",
      "0.700102\n",
      "0.700102\n",
      "0.0853435\n",
      "0.0853435\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.1038\n",
      "0.1038\n",
      "0.229465\n",
      "0.229465\n",
      "0.0405318\n",
      "0.0405318\n",
      "0.025\n",
      "0.025\n",
      "0.246817\n",
      "0.246817\n",
      "0.975\n",
      "0.975\n",
      "0.0524039\n",
      "0.0524039\n",
      "0.025\n",
      "0.025\n",
      "0.972156\n",
      "0.972156\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0328405\n",
      "0.0328405\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.262424\n",
      "0.262424\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.9722\n",
      "0.9722\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.553308\n",
      "0.553308\n",
      "0.942321\n",
      "0.942321\n",
      "0.775763\n",
      "0.775763\n",
      "0.167459\n",
      "0.167459\n",
      "0.364252\n",
      "0.364252\n",
      "0.0360666\n",
      "0.0360666\n",
      "0.120797\n",
      "0.120797\n",
      "0.371072\n",
      "0.371072\n",
      "0.106151\n",
      "0.106151\n",
      "0.934979\n",
      "0.934979\n",
      "0.614088\n",
      "0.614088\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0289989\n",
      "0.0289989\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0301031\n",
      "0.0301031\n",
      "0.975\n",
      "0.975\n",
      "0.285731\n",
      "0.285731\n",
      "0.0509939\n",
      "0.0509939\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.757235\n",
      "0.757235\n",
      "0.025\n",
      "0.025\n",
      "0.188791\n",
      "0.188791\n",
      "0.025\n",
      "0.025\n",
      "0.893668\n",
      "0.893668\n",
      "0.025\n",
      "0.025\n",
      "0.0342323\n",
      "0.0342323\n",
      "0.025\n",
      "0.025\n",
      "0.743619\n",
      "0.743619\n",
      "0.599314\n",
      "0.599314\n",
      "0.870753\n",
      "0.870753\n",
      "0.928771\n",
      "0.928771\n",
      "0.0341584\n",
      "0.0341584\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.274163\n",
      "0.274163\n",
      "0.505585\n",
      "0.505585\n",
      "0.145899\n",
      "0.145899\n",
      "0.0705745\n",
      "0.0705745\n",
      "0.975\n",
      "0.975\n",
      "0.125573\n",
      "0.125573\n",
      "0.102765\n",
      "0.102765\n",
      "0.0428208\n",
      "0.0428208\n",
      "0.975\n",
      "0.975\n",
      "0.042816\n",
      "0.042816\n",
      "0.241549\n",
      "0.241549\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0753824\n",
      "0.0753824\n",
      "0.0761062\n",
      "0.0761062\n",
      "0.025\n",
      "0.025\n",
      "0.0921264\n",
      "0.0921264\n",
      "0.605511\n",
      "0.605511\n",
      "0.025\n",
      "0.025\n",
      "0.0685093\n",
      "0.0685093\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.027425\n",
      "0.027425\n",
      "0.524769\n",
      "0.524769\n",
      "0.171519\n",
      "0.171519\n",
      "0.633294\n",
      "0.633294\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0864488\n",
      "0.0864488\n",
      "0.0481532\n",
      "0.0481532\n",
      "0.378978\n",
      "0.378978\n",
      "0.958786\n",
      "0.958786\n",
      "0.974263\n",
      "0.974263\n",
      "0.025\n",
      "0.025\n",
      "0.0461217\n",
      "0.0461217\n",
      "0.758573\n",
      "0.758573\n",
      "0.413334\n",
      "0.413334\n",
      "0.3015\n",
      "0.3015\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.431094\n",
      "0.431094\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.557591\n",
      "0.557591\n",
      "0.117397\n",
      "0.117397\n",
      "0.0586268\n",
      "0.0586268\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0427626\n",
      "0.0427626\n",
      "0.567172\n",
      "0.567172\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.22909\n",
      "0.22909\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.244584\n",
      "0.244584\n",
      "0.130172\n",
      "0.130172\n",
      "0.315398\n",
      "0.315398\n",
      "0.975\n",
      "0.975\n",
      "0.394762\n",
      "0.394762\n",
      "0.660064\n",
      "0.660064\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.170255\n",
      "0.170255\n",
      "0.033397\n",
      "0.033397\n",
      "0.025\n",
      "0.025\n",
      "0.522056\n",
      "0.522056\n",
      "0.0977854\n",
      "0.0977854\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0577406\n",
      "0.0577406\n",
      "0.0300096\n",
      "0.0300096\n",
      "0.888818\n",
      "0.888818\n",
      "0.458745\n",
      "0.458745\n",
      "0.569788\n",
      "0.569788\n",
      "0.025\n",
      "0.025\n",
      "0.128799\n",
      "0.128799\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0484496\n",
      "0.0484496\n",
      "0.0698679\n",
      "0.0698679\n",
      "0.025\n",
      "0.025\n",
      "0.119351\n",
      "0.119351\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.295758\n",
      "0.295758\n",
      "0.222908\n",
      "0.222908\n",
      "0.0509343\n",
      "0.0509343\n",
      "0.025\n",
      "0.025\n",
      "0.952633\n",
      "0.952633\n",
      "0.0303054\n",
      "0.0303054\n",
      "0.970586\n",
      "0.970586\n",
      "0.940097\n",
      "0.940097\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.139424\n",
      "0.139424\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.738804\n",
      "0.738804\n",
      "0.025\n",
      "0.025\n",
      "0.708902\n",
      "0.708902\n",
      "0.025\n",
      "0.025\n",
      "0.272006\n",
      "0.272006\n",
      "0.0463045\n",
      "0.0463045\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0411114\n",
      "0.0411114\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.457\n",
      "0.457\n",
      "0.959144\n",
      "0.959144\n",
      "0.025\n",
      "0.025\n",
      "0.392099\n",
      "0.392099\n",
      "0.337638\n",
      "0.337638\n",
      "0.262914\n",
      "0.262914\n",
      "0.025\n",
      "0.025\n",
      "0.072841\n",
      "0.072841\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.029268\n",
      "0.029268\n",
      "0.170142\n",
      "0.170142\n",
      "0.891354\n",
      "0.891354\n",
      "0.458592\n",
      "0.458592\n",
      "0.521679\n",
      "0.521679\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.952134\n",
      "0.952134\n",
      "0.025\n",
      "0.025\n",
      "0.213591\n",
      "0.213591\n",
      "0.025\n",
      "0.025\n",
      "0.263363\n",
      "0.263363\n",
      "0.240846\n",
      "0.240846\n",
      "0.173932\n",
      "0.173932\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.594379\n",
      "0.594379\n",
      "0.025\n",
      "0.025\n",
      "0.366764\n",
      "0.366764\n",
      "0.0433071\n",
      "0.0433071\n",
      "0.139153\n",
      "0.139153\n",
      "0.025\n",
      "0.025\n",
      "0.0863409\n",
      "0.0863409\n",
      "0.064286\n",
      "0.064286\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.966731\n",
      "0.966731\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0600258\n",
      "0.0600258\n",
      "0.0315699\n",
      "0.0315699\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0365049\n",
      "0.0365049\n",
      "0.975\n",
      "0.975\n",
      "0.757336\n",
      "0.757336\n",
      "0.480532\n",
      "0.480532\n",
      "0.426627\n",
      "0.426627\n",
      "0.90029\n",
      "0.90029\n",
      "0.296615\n",
      "0.296615\n",
      "0.907546\n",
      "0.907546\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.697689\n",
      "0.697689\n",
      "0.025\n",
      "0.025\n",
      "0.136582\n",
      "0.136582\n",
      "0.738181\n",
      "0.738181\n",
      "0.383041\n",
      "0.383041\n",
      "0.30519\n",
      "0.30519\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.325991\n",
      "0.325991\n",
      "0.025\n",
      "0.025\n",
      "0.581946\n",
      "0.581946\n",
      "0.247995\n",
      "0.247995\n",
      "0.025\n",
      "0.025\n",
      "0.812745\n",
      "0.812745\n",
      "0.0383915\n",
      "0.0383915\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0459654\n",
      "0.0459654\n",
      "0.94108\n",
      "0.94108\n",
      "0.946873\n",
      "0.946873\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.110791\n",
      "0.110791\n",
      "0.957686\n",
      "0.957686\n",
      "0.814561\n",
      "0.814561\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.428468\n",
      "0.428468\n",
      "0.825409\n",
      "0.825409\n",
      "0.813483\n",
      "0.813483\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0279513\n",
      "0.0279513\n",
      "0.025\n",
      "0.025\n",
      "0.330604\n",
      "0.330604\n",
      "0.80637\n",
      "0.80637\n",
      "0.975\n",
      "0.975\n",
      "0.607028\n",
      "0.607028\n",
      "0.0716694\n",
      "0.0716694\n",
      "0.0428317\n",
      "0.0428317\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.114116\n",
      "0.114116\n",
      "0.296117\n",
      "0.296117\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.120153\n",
      "0.120153\n",
      "0.166701\n",
      "0.166701\n",
      "0.975\n",
      "0.975\n",
      "0.880717\n",
      "0.880717\n",
      "0.975\n",
      "0.975\n",
      "0.0598956\n",
      "0.0598956\n",
      "0.0444398\n",
      "0.0444398\n",
      "0.968875\n",
      "0.968875\n",
      "0.0641245\n",
      "0.0641245\n",
      "0.025\n",
      "0.025\n",
      "0.774321\n",
      "0.774321\n",
      "0.525185\n",
      "0.525185\n",
      "0.307302\n",
      "0.307302\n",
      "0.0411044\n",
      "0.0411044\n",
      "0.975\n",
      "0.975\n",
      "0.0368681\n",
      "0.0368681\n",
      "0.202527\n",
      "0.202527\n",
      "0.0641484\n",
      "0.0641484\n",
      "0.238013\n",
      "0.238013\n",
      "0.142638\n",
      "0.142638\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.214538\n",
      "0.214538\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.101764\n",
      "0.101764\n",
      "0.975\n",
      "0.975\n",
      "0.0940606\n",
      "0.0940606\n",
      "0.975\n",
      "0.975\n",
      "0.173478\n",
      "0.173478\n",
      "0.025\n",
      "0.025\n",
      "0.0449594\n",
      "0.0449594\n",
      "0.0936397\n",
      "0.0936397\n",
      "0.0739184\n",
      "0.0739184\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.573242\n",
      "0.573242\n",
      "0.025\n",
      "0.025\n",
      "0.95744\n",
      "0.95744\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0544829\n",
      "0.0544829\n",
      "0.164688\n",
      "0.164688\n",
      "0.577097\n",
      "0.577097\n",
      "0.97403\n",
      "0.97403\n",
      "0.904158\n",
      "0.904158\n",
      "0.074286\n",
      "0.074286\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.251413\n",
      "0.251413\n",
      "0.0465\n",
      "0.0465\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0704653\n",
      "0.0704653\n",
      "0.025\n",
      "0.025\n",
      "0.0402858\n",
      "0.0402858\n",
      "0.460714\n",
      "0.460714\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.941521\n",
      "0.941521\n",
      "0.975\n",
      "0.975\n",
      "0.705799\n",
      "0.705799\n",
      "0.0459692\n",
      "0.0459692\n",
      "0.0711934\n",
      "0.0711934\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0638216\n",
      "0.0638216\n",
      "0.709575\n",
      "0.709575\n",
      "0.331887\n",
      "0.331887\n",
      "0.182585\n",
      "0.182585\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.473479\n",
      "0.473479\n",
      "0.108057\n",
      "0.108057\n",
      "0.025\n",
      "0.025\n",
      "0.930739\n",
      "0.930739\n",
      "0.799212\n",
      "0.799212\n",
      "0.025\n",
      "0.025\n",
      "0.0580049\n",
      "0.0580049\n",
      "0.025\n",
      "0.025\n",
      "0.88885\n",
      "0.88885\n",
      "0.160502\n",
      "0.160502\n",
      "0.121026\n",
      "0.121026\n",
      "0.272344\n",
      "0.272344\n",
      "0.135055\n",
      "0.135055\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0253756\n",
      "0.0253756\n",
      "0.735249\n",
      "0.735249\n",
      "0.0338473\n",
      "0.0338473\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.131105\n",
      "0.131105\n",
      "0.72407\n",
      "0.72407\n",
      "0.255606\n",
      "0.255606\n",
      "0.203194\n",
      "0.203194\n",
      "0.232727\n",
      "0.232727\n",
      "0.675016\n",
      "0.675016\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.227308\n",
      "0.227308\n",
      "0.784696\n",
      "0.784696\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.276938\n",
      "0.276938\n",
      "0.025\n",
      "0.025\n",
      "0.962302\n",
      "0.962302\n",
      "0.905546\n",
      "0.905546\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.934409\n",
      "0.934409\n",
      "0.025\n",
      "0.025\n",
      "0.320769\n",
      "0.320769\n",
      "0.846342\n",
      "0.846342\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.813483\n",
      "0.813483\n",
      "0.025\n",
      "0.025\n",
      "0.216679\n",
      "0.216679\n",
      "0.975\n",
      "0.975\n",
      "0.0493933\n",
      "0.0493933\n",
      "0.025\n",
      "0.025\n",
      "0.160761\n",
      "0.160761\n",
      "0.238094\n",
      "0.238094\n",
      "0.025\n",
      "0.025\n",
      "0.136805\n",
      "0.136805\n",
      "0.0296028\n",
      "0.0296028\n",
      "0.294087\n",
      "0.294087\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0260553\n",
      "0.0260553\n",
      "0.025\n",
      "0.025\n",
      "0.401346\n",
      "0.401346\n",
      "0.025\n",
      "0.025\n",
      "0.475638\n",
      "0.475638\n",
      "0.19954\n",
      "0.19954\n",
      "0.025\n",
      "0.025\n",
      "0.0718778\n",
      "0.0718778\n",
      "0.025\n",
      "0.025\n",
      "0.270847\n",
      "0.270847\n",
      "0.025\n",
      "0.025\n",
      "0.273403\n",
      "0.273403\n",
      "0.025\n",
      "0.025\n",
      "0.053655\n",
      "0.053655\n",
      "0.970964\n",
      "0.970964\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0718726\n",
      "0.0718726\n",
      "0.960448\n",
      "0.960448\n",
      "0.044542\n",
      "0.044542\n",
      "0.0326934\n",
      "0.0326934\n",
      "0.025\n",
      "0.025\n",
      "0.946941\n",
      "0.946941\n",
      "0.77784\n",
      "0.77784\n",
      "0.025\n",
      "0.025\n",
      "0.0320934\n",
      "0.0320934\n",
      "0.025\n",
      "0.025\n",
      "0.0776305\n",
      "0.0776305\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.795634\n",
      "0.795634\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.225934\n",
      "0.225934\n",
      "0.110075\n",
      "0.110075\n",
      "0.455408\n",
      "0.455408\n",
      "0.136778\n",
      "0.136778\n",
      "0.0796589\n",
      "0.0796589\n",
      "0.025\n",
      "0.025\n",
      "0.43433\n",
      "0.43433\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.417508\n",
      "0.417508\n",
      "0.975\n",
      "0.975\n",
      "0.362392\n",
      "0.362392\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.763154\n",
      "0.763154\n",
      "0.975\n",
      "0.975\n",
      "0.0408917\n",
      "0.0408917\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.046958\n",
      "0.046958\n",
      "0.025\n",
      "0.025\n",
      "0.0450665\n",
      "0.0450665\n",
      "0.219589\n",
      "0.219589\n",
      "0.765264\n",
      "0.765264\n",
      "0.140001\n",
      "0.140001\n",
      "0.0512771\n",
      "0.0512771\n",
      "0.025\n",
      "0.025\n",
      "0.12114\n",
      "0.12114\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0499786\n",
      "0.0499786\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.453727\n",
      "0.453727\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.425314\n",
      "0.425314\n",
      "0.181152\n",
      "0.181152\n",
      "0.920089\n",
      "0.920089\n",
      "0.0640439\n",
      "0.0640439\n",
      "0.0518295\n",
      "0.0518295\n",
      "0.025\n",
      "0.025\n",
      "0.116525\n",
      "0.116525\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.925253\n",
      "0.925253\n",
      "0.120181\n",
      "0.120181\n",
      "0.102861\n",
      "0.102861\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0513582\n",
      "0.0513582\n",
      "0.53823\n",
      "0.53823\n",
      "0.758333\n",
      "0.758333\n",
      "0.319238\n",
      "0.319238\n",
      "0.025\n",
      "0.025\n",
      "0.931577\n",
      "0.931577\n",
      "0.135728\n",
      "0.135728\n",
      "0.025\n",
      "0.025\n",
      "0.0922452\n",
      "0.0922452\n",
      "0.144626\n",
      "0.144626\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0629491\n",
      "0.0629491\n",
      "0.975\n",
      "0.975\n",
      "0.0742232\n",
      "0.0742232\n",
      "0.025\n",
      "0.025\n",
      "0.92948\n",
      "0.92948\n",
      "0.025\n",
      "0.025\n",
      "0.31596\n",
      "0.31596\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.891817\n",
      "0.891817\n",
      "0.172001\n",
      "0.172001\n",
      "0.025\n",
      "0.025\n",
      "0.452935\n",
      "0.452935\n",
      "0.70116\n",
      "0.70116\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.169911\n",
      "0.169911\n",
      "0.822964\n",
      "0.822964\n",
      "0.0622992\n",
      "0.0622992\n",
      "0.065597\n",
      "0.065597\n",
      "0.460594\n",
      "0.460594\n",
      "0.136571\n",
      "0.136571\n",
      "0.0363266\n",
      "0.0363266\n",
      "0.975\n",
      "0.975\n",
      "0.968794\n",
      "0.968794\n",
      "0.276041\n",
      "0.276041\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.354523\n",
      "0.354523\n",
      "0.629017\n",
      "0.629017\n",
      "0.126884\n",
      "0.126884\n",
      "0.025\n",
      "0.025\n",
      "0.968974\n",
      "0.968974\n",
      "0.31311\n",
      "0.31311\n",
      "0.025\n",
      "0.025\n",
      "0.589317\n",
      "0.589317\n",
      "0.282616\n",
      "0.282616\n",
      "0.0373633\n",
      "0.0373633\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.147157\n",
      "0.147157\n",
      "0.025\n",
      "0.025\n",
      "0.501437\n",
      "0.501437\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0434938\n",
      "0.0434938\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0953564\n",
      "0.0953564\n",
      "0.025\n",
      "0.025\n",
      "0.0280633\n",
      "0.0280633\n",
      "0.025\n",
      "0.025\n",
      "0.952343\n",
      "0.952343\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0807087\n",
      "0.0807087\n",
      "0.025\n",
      "0.025\n",
      "0.473229\n",
      "0.473229\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.170051\n",
      "0.170051\n",
      "0.697124\n",
      "0.697124\n",
      "0.308681\n",
      "0.308681\n",
      "0.415168\n",
      "0.415168\n",
      "0.17672\n",
      "0.17672\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0454353\n",
      "0.0454353\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.237851\n",
      "0.237851\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.941192\n",
      "0.941192\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.648509\n",
      "0.648509\n",
      "0.349709\n",
      "0.349709\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.208774\n",
      "0.208774\n",
      "0.821195\n",
      "0.821195\n",
      "0.436193\n",
      "0.436193\n",
      "0.025\n",
      "0.025\n",
      "0.448579\n",
      "0.448579\n",
      "0.025\n",
      "0.025\n",
      "0.0956011\n",
      "0.0956011\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0913691\n",
      "0.0913691\n",
      "0.142295\n",
      "0.142295\n",
      "0.025\n",
      "0.025\n",
      "0.420419\n",
      "0.420419\n",
      "0.975\n",
      "0.975\n",
      "0.596999\n",
      "0.596999\n",
      "0.025\n",
      "0.025\n",
      "0.858768\n",
      "0.858768\n",
      "0.862738\n",
      "0.862738\n",
      "0.812326\n",
      "0.812326\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.138447\n",
      "0.138447\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.19338\n",
      "0.19338\n",
      "0.194296\n",
      "0.194296\n",
      "0.064986\n",
      "0.064986\n",
      "0.20606\n",
      "0.20606\n",
      "0.025\n",
      "0.025\n",
      "0.189195\n",
      "0.189195\n",
      "0.236428\n",
      "0.236428\n",
      "0.0289307\n",
      "0.0289307\n",
      "0.025\n",
      "0.025\n",
      "0.94823\n",
      "0.94823\n",
      "0.174652\n",
      "0.174652\n",
      "0.170206\n",
      "0.170206\n",
      "0.0680212\n",
      "0.0680212\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.472165\n",
      "0.472165\n",
      "0.067784\n",
      "0.067784\n",
      "0.025\n",
      "0.025\n",
      "0.397585\n",
      "0.397585\n",
      "0.19255\n",
      "0.19255\n",
      "0.0545824\n",
      "0.0545824\n",
      "0.0278425\n",
      "0.0278425\n",
      "0.975\n",
      "0.975\n",
      "0.0355485\n",
      "0.0355485\n",
      "0.0595303\n",
      "0.0595303\n",
      "0.025\n",
      "0.025\n",
      "0.814144\n",
      "0.814144\n",
      "0.0783209\n",
      "0.0783209\n",
      "0.0801411\n",
      "0.0801411\n",
      "0.193321\n",
      "0.193321\n",
      "0.025\n",
      "0.025\n",
      "0.370691\n",
      "0.370691\n",
      "0.297778\n",
      "0.297778\n",
      "0.025\n",
      "0.025\n",
      "0.591696\n",
      "0.591696\n",
      "0.025\n",
      "0.025\n",
      "0.443774\n",
      "0.443774\n",
      "0.025\n",
      "0.025\n",
      "0.689981\n",
      "0.689981\n",
      "0.747201\n",
      "0.747201\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.420253\n",
      "0.420253\n",
      "0.025\n",
      "0.025\n",
      "0.648618\n",
      "0.648618\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.488582\n",
      "0.488582\n",
      "0.975\n",
      "0.975\n",
      "0.168077\n",
      "0.168077\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.544847\n",
      "0.544847\n",
      "0.323396\n",
      "0.323396\n",
      "0.975\n",
      "0.975\n",
      "0.88256\n",
      "0.88256\n",
      "0.025\n",
      "0.025\n",
      "0.527085\n",
      "0.527085\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.939923\n",
      "0.939923\n",
      "0.120911\n",
      "0.120911\n",
      "0.712426\n",
      "0.712426\n",
      "0.025\n",
      "0.025\n",
      "0.392573\n",
      "0.392573\n",
      "0.15448\n",
      "0.15448\n",
      "0.025\n",
      "0.025\n",
      "0.651638\n",
      "0.651638\n",
      "0.108374\n",
      "0.108374\n",
      "0.0632207\n",
      "0.0632207\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.228194\n",
      "0.228194\n",
      "0.025\n",
      "0.025\n",
      "0.565806\n",
      "0.565806\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0515195\n",
      "0.0515195\n",
      "0.0384299\n",
      "0.0384299\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.200341\n",
      "0.200341\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.107155\n",
      "0.107155\n",
      "0.29651\n",
      "0.29651\n",
      "0.025\n",
      "0.025\n",
      "0.0265888\n",
      "0.0265888\n",
      "0.178725\n",
      "0.178725\n",
      "0.0722592\n",
      "0.0722592\n",
      "0.355934\n",
      "0.355934\n",
      "0.427359\n",
      "0.427359\n",
      "0.316185\n",
      "0.316185\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.276806\n",
      "0.276806\n",
      "0.903952\n",
      "0.903952\n",
      "0.025\n",
      "0.025\n",
      "0.0458743\n",
      "0.0458743\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.970433\n",
      "0.970433\n",
      "0.025\n",
      "0.025\n",
      "0.218055\n",
      "0.218055\n",
      "0.124842\n",
      "0.124842\n",
      "0.975\n",
      "0.975\n",
      "0.707166\n",
      "0.707166\n",
      "0.0670846\n",
      "0.0670846\n",
      "0.199038\n",
      "0.199038\n",
      "0.267788\n",
      "0.267788\n",
      "0.025\n",
      "0.025\n",
      "0.574705\n",
      "0.574705\n",
      "0.336584\n",
      "0.336584\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.944282\n",
      "0.944282\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.538547\n",
      "0.538547\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.11389\n",
      "0.11389\n",
      "0.412\n",
      "0.412\n",
      "0.975\n",
      "0.975\n",
      "0.143825\n",
      "0.143825\n",
      "0.025\n",
      "0.025\n",
      "0.0323451\n",
      "0.0323451\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.381628\n",
      "0.381628\n",
      "0.975\n",
      "0.975\n",
      "0.125331\n",
      "0.125331\n",
      "0.025\n",
      "0.025\n",
      "0.02999\n",
      "0.02999\n",
      "0.0443663\n",
      "0.0443663\n",
      "0.025\n",
      "0.025\n",
      "0.460855\n",
      "0.460855\n",
      "0.110391\n",
      "0.110391\n",
      "0.025\n",
      "0.025\n",
      "0.0348587\n",
      "0.0348587\n",
      "0.025\n",
      "0.025\n",
      "0.95053\n",
      "0.95053\n",
      "0.873209\n",
      "0.873209\n",
      "0.753773\n",
      "0.753773\n",
      "0.025\n",
      "0.025\n",
      "0.447824\n",
      "0.447824\n",
      "0.142704\n",
      "0.142704\n",
      "0.966902\n",
      "0.966902\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.108482\n",
      "0.108482\n",
      "0.0915507\n",
      "0.0915507\n",
      "0.0834418\n",
      "0.0834418\n",
      "0.290725\n",
      "0.290725\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0879134\n",
      "0.0879134\n",
      "0.598239\n",
      "0.598239\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0634\n",
      "0.0634\n",
      "0.975\n",
      "0.975\n",
      "0.83063\n",
      "0.83063\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.745238\n",
      "0.745238\n",
      "0.148264\n",
      "0.148264\n",
      "0.025\n",
      "0.025\n",
      "0.0801572\n",
      "0.0801572\n",
      "0.025\n",
      "0.025\n",
      "0.8166\n",
      "0.8166\n",
      "0.025\n",
      "0.025\n",
      "0.101758\n",
      "0.101758\n",
      "0.025\n",
      "0.025\n",
      "0.405573\n",
      "0.405573\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.209421\n",
      "0.209421\n",
      "0.65805\n",
      "0.65805\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.558861\n",
      "0.558861\n",
      "0.025\n",
      "0.025\n",
      "0.0427641\n",
      "0.0427641\n",
      "0.0491047\n",
      "0.0491047\n",
      "0.025\n",
      "0.025\n",
      "0.0871986\n",
      "0.0871986\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.638771\n",
      "0.638771\n",
      "0.0442217\n",
      "0.0442217\n",
      "0.025\n",
      "0.025\n",
      "0.924276\n",
      "0.924276\n",
      "0.108707\n",
      "0.108707\n",
      "0.60651\n",
      "0.60651\n",
      "0.0688764\n",
      "0.0688764\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.693923\n",
      "0.693923\n",
      "0.975\n",
      "0.975\n",
      "0.297345\n",
      "0.297345\n",
      "0.025\n",
      "0.025\n",
      "0.893054\n",
      "0.893054\n",
      "0.122161\n",
      "0.122161\n",
      "0.025\n",
      "0.025\n",
      "0.0626928\n",
      "0.0626928\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0302173\n",
      "0.0302173\n",
      "0.711273\n",
      "0.711273\n",
      "0.0373185\n",
      "0.0373185\n",
      "0.646962\n",
      "0.646962\n",
      "0.975\n",
      "0.975\n",
      "0.783237\n",
      "0.783237\n",
      "0.0436736\n",
      "0.0436736\n",
      "0.0504174\n",
      "0.0504174\n",
      "0.907899\n",
      "0.907899\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.233002\n",
      "0.233002\n",
      "0.645129\n",
      "0.645129\n",
      "0.025\n",
      "0.025\n",
      "0.105131\n",
      "0.105131\n",
      "0.258633\n",
      "0.258633\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.671103\n",
      "0.671103\n",
      "0.700112\n",
      "0.700112\n",
      "0.300814\n",
      "0.300814\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0514104\n",
      "0.0514104\n",
      "0.957426\n",
      "0.957426\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.754187\n",
      "0.754187\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0351893\n",
      "0.0351893\n",
      "0.975\n",
      "0.975\n",
      "0.194051\n",
      "0.194051\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.896118\n",
      "0.896118\n",
      "0.025\n",
      "0.025\n",
      "0.970282\n",
      "0.970282\n",
      "0.0919493\n",
      "0.0919493\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.707901\n",
      "0.707901\n",
      "0.025\n",
      "0.025\n",
      "0.853865\n",
      "0.853865\n",
      "0.755214\n",
      "0.755214\n",
      "0.232265\n",
      "0.232265\n",
      "0.0557289\n",
      "0.0557289\n",
      "0.794387\n",
      "0.794387\n",
      "0.051061\n",
      "0.051061\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.952291\n",
      "0.952291\n",
      "0.108343\n",
      "0.108343\n",
      "0.966631\n",
      "0.966631\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.367641\n",
      "0.367641\n",
      "0.025\n",
      "0.025\n",
      "0.090887\n",
      "0.090887\n",
      "0.025\n",
      "0.025\n",
      "0.426735\n",
      "0.426735\n",
      "0.025\n",
      "0.025\n",
      "0.951822\n",
      "0.951822\n",
      "0.0590411\n",
      "0.0590411\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.625202\n",
      "0.625202\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0690642\n",
      "0.0690642\n",
      "0.452895\n",
      "0.452895\n",
      "0.13212\n",
      "0.13212\n",
      "0.954584\n",
      "0.954584\n",
      "0.764659\n",
      "0.764659\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.930631\n",
      "0.930631\n",
      "0.845799\n",
      "0.845799\n",
      "0.975\n",
      "0.975\n",
      "0.168407\n",
      "0.168407\n",
      "0.103922\n",
      "0.103922\n",
      "0.13325\n",
      "0.13325\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.150035\n",
      "0.150035\n",
      "0.975\n",
      "0.975\n",
      "0.495408\n",
      "0.495408\n",
      "0.549214\n",
      "0.549214\n",
      "0.025\n",
      "0.025\n",
      "0.254437\n",
      "0.254437\n",
      "0.401513\n",
      "0.401513\n",
      "0.791651\n",
      "0.791651\n",
      "0.22608\n",
      "0.22608\n",
      "0.0737224\n",
      "0.0737224\n",
      "0.934157\n",
      "0.934157\n",
      "0.12038\n",
      "0.12038\n",
      "0.91316\n",
      "0.91316\n",
      "0.025\n",
      "0.025\n",
      "0.144181\n",
      "0.144181\n",
      "0.645706\n",
      "0.645706\n",
      "0.975\n",
      "0.975\n",
      "0.935523\n",
      "0.935523\n",
      "0.375659\n",
      "0.375659\n",
      "0.025\n",
      "0.025\n",
      "0.10507\n",
      "0.10507\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0666599\n",
      "0.0666599\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0386116\n",
      "0.0386116\n",
      "0.0748599\n",
      "0.0748599\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.879233\n",
      "0.879233\n",
      "0.0596485\n",
      "0.0596485\n",
      "0.113273\n",
      "0.113273\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.123104\n",
      "0.123104\n",
      "0.100424\n",
      "0.100424\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0292028\n",
      "0.0292028\n",
      "0.0290043\n",
      "0.0290043\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.466778\n",
      "0.466778\n",
      "0.0375052\n",
      "0.0375052\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0250287\n",
      "0.0250287\n",
      "0.507118\n",
      "0.507118\n",
      "0.850182\n",
      "0.850182\n",
      "0.025\n",
      "0.025\n",
      "0.0422422\n",
      "0.0422422\n",
      "0.0663355\n",
      "0.0663355\n",
      "0.10283\n",
      "0.10283\n",
      "0.216138\n",
      "0.216138\n",
      "0.673363\n",
      "0.673363\n",
      "0.975\n",
      "0.975\n",
      "0.0339918\n",
      "0.0339918\n",
      "0.101444\n",
      "0.101444\n",
      "0.0886294\n",
      "0.0886294\n",
      "0.0415862\n",
      "0.0415862\n",
      "0.809651\n",
      "0.809651\n",
      "0.025\n",
      "0.025\n",
      "0.634612\n",
      "0.634612\n",
      "0.025\n",
      "0.025\n",
      "0.973112\n",
      "0.973112\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.909804\n",
      "0.909804\n",
      "0.975\n",
      "0.975\n",
      "0.888514\n",
      "0.888514\n",
      "0.137049\n",
      "0.137049\n",
      "0.963064\n",
      "0.963064\n",
      "0.176812\n",
      "0.176812\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.410521\n",
      "0.410521\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.124638\n",
      "0.124638\n",
      "0.975\n",
      "0.975\n",
      "0.466217\n",
      "0.466217\n",
      "0.0941453\n",
      "0.0941453\n",
      "0.975\n",
      "0.975\n",
      "0.0983466\n",
      "0.0983466\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.136975\n",
      "0.136975\n",
      "0.0298467\n",
      "0.0298467\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.206567\n",
      "0.206567\n",
      "0.918772\n",
      "0.918772\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.554775\n",
      "0.554775\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.969382\n",
      "0.969382\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.833826\n",
      "0.833826\n",
      "0.0259117\n",
      "0.0259117\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.383169\n",
      "0.383169\n",
      "0.0485166\n",
      "0.0485166\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.939035\n",
      "0.939035\n",
      "0.025\n",
      "0.025\n",
      "0.0726859\n",
      "0.0726859\n",
      "0.310051\n",
      "0.310051\n",
      "0.0881202\n",
      "0.0881202\n",
      "0.269278\n",
      "0.269278\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.956498\n",
      "0.956498\n",
      "0.025\n",
      "0.025\n",
      "0.0585586\n",
      "0.0585586\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.145905\n",
      "0.145905\n",
      "0.025\n",
      "0.025\n",
      "0.483745\n",
      "0.483745\n",
      "0.025\n",
      "0.025\n",
      "0.623022\n",
      "0.623022\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.826381\n",
      "0.826381\n",
      "0.0455613\n",
      "0.0455613\n",
      "0.025\n",
      "0.025\n",
      "0.111809\n",
      "0.111809\n",
      "0.0770997\n",
      "0.0770997\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.139813\n",
      "0.139813\n",
      "0.025\n",
      "0.025\n",
      "0.372483\n",
      "0.372483\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.819533\n",
      "0.819533\n",
      "0.025\n",
      "0.025\n",
      "0.827802\n",
      "0.827802\n",
      "0.0766924\n",
      "0.0766924\n",
      "0.025\n",
      "0.025\n",
      "0.967211\n",
      "0.967211\n",
      "0.025\n",
      "0.025\n",
      "0.205171\n",
      "0.205171\n",
      "0.0437793\n",
      "0.0437793\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.58373\n",
      "0.58373\n",
      "0.317369\n",
      "0.317369\n",
      "0.0477684\n",
      "0.0477684\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.206945\n",
      "0.206945\n",
      "0.246033\n",
      "0.246033\n",
      "0.025\n",
      "0.025\n",
      "0.440127\n",
      "0.440127\n",
      "0.025\n",
      "0.025\n",
      "0.731592\n",
      "0.731592\n",
      "0.944198\n",
      "0.944198\n",
      "0.0521611\n",
      "0.0521611\n",
      "0.0756345\n",
      "0.0756345\n",
      "0.025\n",
      "0.025\n",
      "0.355071\n",
      "0.355071\n",
      "0.471556\n",
      "0.471556\n",
      "0.721563\n",
      "0.721563\n",
      "0.975\n",
      "0.975\n",
      "0.0970415\n",
      "0.0970415\n",
      "0.025\n",
      "0.025\n",
      "0.837095\n",
      "0.837095\n",
      "0.117003\n",
      "0.117003\n",
      "0.025\n",
      "0.025\n",
      "0.888786\n",
      "0.888786\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.483082\n",
      "0.483082\n",
      "0.0978954\n",
      "0.0978954\n",
      "0.025\n",
      "0.025\n",
      "0.759993\n",
      "0.759993\n",
      "0.557283\n",
      "0.557283\n",
      "0.13347\n",
      "0.13347\n",
      "0.025\n",
      "0.025\n",
      "0.428892\n",
      "0.428892\n",
      "0.025\n",
      "0.025\n",
      "0.0489578\n",
      "0.0489578\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.095593\n",
      "0.095593\n",
      "0.025\n",
      "0.025\n",
      "0.196068\n",
      "0.196068\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.201522\n",
      "0.201522\n",
      "0.975\n",
      "0.975\n",
      "0.595602\n",
      "0.595602\n",
      "0.025\n",
      "0.025\n",
      "0.35895\n",
      "0.35895\n",
      "0.941501\n",
      "0.941501\n",
      "0.0435193\n",
      "0.0435193\n",
      "0.0599952\n",
      "0.0599952\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.14403\n",
      "0.14403\n",
      "0.940925\n",
      "0.940925\n",
      "0.0523778\n",
      "0.0523778\n",
      "0.440918\n",
      "0.440918\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.195644\n",
      "0.195644\n",
      "0.025\n",
      "0.025\n",
      "0.22187\n",
      "0.22187\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0525805\n",
      "0.0525805\n",
      "0.10383\n",
      "0.10383\n",
      "0.331005\n",
      "0.331005\n",
      "0.975\n",
      "0.975\n",
      "0.936566\n",
      "0.936566\n",
      "0.91155\n",
      "0.91155\n",
      "0.975\n",
      "0.975\n",
      "0.0361703\n",
      "0.0361703\n",
      "0.59916\n",
      "0.59916\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.237505\n",
      "0.237505\n",
      "0.025\n",
      "0.025\n",
      "0.0535178\n",
      "0.0535178\n",
      "0.025\n",
      "0.025\n",
      "0.947068\n",
      "0.947068\n",
      "0.025\n",
      "0.025\n",
      "0.0635843\n",
      "0.0635843\n",
      "0.798147\n",
      "0.798147\n",
      "0.0275715\n",
      "0.0275715\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.932769\n",
      "0.932769\n",
      "0.861306\n",
      "0.861306\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.390821\n",
      "0.390821\n",
      "0.025\n",
      "0.025\n",
      "0.0257897\n",
      "0.0257897\n",
      "0.025\n",
      "0.025\n",
      "0.947213\n",
      "0.947213\n",
      "0.955715\n",
      "0.955715\n",
      "0.92359\n",
      "0.92359\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0944549\n",
      "0.0944549\n",
      "0.025\n",
      "0.025\n",
      "0.0720555\n",
      "0.0720555\n",
      "0.107127\n",
      "0.107127\n",
      "0.884357\n",
      "0.884357\n",
      "0.025\n",
      "0.025\n",
      "0.0934851\n",
      "0.0934851\n",
      "0.89414\n",
      "0.89414\n",
      "0.912208\n",
      "0.912208\n",
      "0.579835\n",
      "0.579835\n",
      "0.025\n",
      "0.025\n",
      "0.174455\n",
      "0.174455\n",
      "0.025\n",
      "0.025\n",
      "0.0437519\n",
      "0.0437519\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0840653\n",
      "0.0840653\n",
      "0.025\n",
      "0.025\n",
      "0.727754\n",
      "0.727754\n",
      "0.214479\n",
      "0.214479\n",
      "0.225363\n",
      "0.225363\n",
      "0.87342\n",
      "0.87342\n",
      "0.343843\n",
      "0.343843\n",
      "0.0666114\n",
      "0.0666114\n",
      "0.954111\n",
      "0.954111\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.437743\n",
      "0.437743\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.960693\n",
      "0.960693\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.895545\n",
      "0.895545\n",
      "0.025\n",
      "0.025\n",
      "0.568193\n",
      "0.568193\n",
      "0.975\n",
      "0.975\n",
      "0.845433\n",
      "0.845433\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0400003\n",
      "0.0400003\n",
      "0.025\n",
      "0.025\n",
      "0.310732\n",
      "0.310732\n",
      "0.025\n",
      "0.025\n",
      "0.17218\n",
      "0.17218\n",
      "0.0260493\n",
      "0.0260493\n",
      "0.0653918\n",
      "0.0653918\n",
      "0.50667\n",
      "0.50667\n",
      "0.743543\n",
      "0.743543\n",
      "0.0943785\n",
      "0.0943785\n",
      "0.945745\n",
      "0.945745\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.944514\n",
      "0.944514\n",
      "0.025\n",
      "0.025\n",
      "0.792085\n",
      "0.792085\n",
      "0.492235\n",
      "0.492235\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.945713\n",
      "0.945713\n",
      "0.1139\n",
      "0.1139\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.125184\n",
      "0.125184\n",
      "0.0522068\n",
      "0.0522068\n",
      "0.12973\n",
      "0.12973\n",
      "0.025\n",
      "0.025\n",
      "0.0856643\n",
      "0.0856643\n",
      "0.0892001\n",
      "0.0892001\n",
      "0.0571258\n",
      "0.0571258\n",
      "0.0627471\n",
      "0.0627471\n",
      "0.275994\n",
      "0.275994\n",
      "0.23336\n",
      "0.23336\n",
      "0.379646\n",
      "0.379646\n",
      "0.869877\n",
      "0.869877\n",
      "0.308449\n",
      "0.308449\n",
      "0.0839599\n",
      "0.0839599\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.636259\n",
      "0.636259\n",
      "0.933586\n",
      "0.933586\n",
      "0.138779\n",
      "0.138779\n",
      "0.927057\n",
      "0.927057\n",
      "0.81337\n",
      "0.81337\n",
      "0.0784469\n",
      "0.0784469\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.164041\n",
      "0.164041\n",
      "0.177312\n",
      "0.177312\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.935911\n",
      "0.935911\n",
      "0.829383\n",
      "0.829383\n",
      "0.0294573\n",
      "0.0294573\n",
      "0.0551368\n",
      "0.0551368\n",
      "0.0252043\n",
      "0.0252043\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.114663\n",
      "0.114663\n",
      "0.975\n",
      "0.975\n",
      "0.500334\n",
      "0.500334\n",
      "0.025\n",
      "0.025\n",
      "0.259529\n",
      "0.259529\n",
      "0.748062\n",
      "0.748062\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.810245\n",
      "0.810245\n",
      "0.025\n",
      "0.025\n",
      "0.0283882\n",
      "0.0283882\n",
      "0.823361\n",
      "0.823361\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.954319\n",
      "0.954319\n",
      "0.5989\n",
      "0.5989\n",
      "0.140277\n",
      "0.140277\n",
      "0.884652\n",
      "0.884652\n",
      "0.599108\n",
      "0.599108\n",
      "0.0666683\n",
      "0.0666683\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.73377\n",
      "0.73377\n",
      "0.025\n",
      "0.025\n",
      "0.240155\n",
      "0.240155\n",
      "0.025\n",
      "0.025\n",
      "0.162322\n",
      "0.162322\n",
      "0.487414\n",
      "0.487414\n",
      "0.025\n",
      "0.025\n",
      "0.110624\n",
      "0.110624\n",
      "0.455375\n",
      "0.455375\n",
      "0.025\n",
      "0.025\n",
      "0.0393615\n",
      "0.0393615\n",
      "0.025\n",
      "0.025\n",
      "0.0460302\n",
      "0.0460302\n",
      "0.025\n",
      "0.025\n",
      "0.169261\n",
      "0.169261\n",
      "0.500946\n",
      "0.500946\n",
      "0.975\n",
      "0.975\n",
      "0.216405\n",
      "0.216405\n",
      "0.372669\n",
      "0.372669\n",
      "0.025\n",
      "0.025\n",
      "0.164423\n",
      "0.164423\n",
      "0.0797544\n",
      "0.0797544\n",
      "0.025\n",
      "0.025\n",
      "0.164179\n",
      "0.164179\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.159758\n",
      "0.159758\n",
      "0.025\n",
      "0.025\n",
      "0.049253\n",
      "0.049253\n",
      "0.246741\n",
      "0.246741\n",
      "0.025\n",
      "0.025\n",
      "0.558308\n",
      "0.558308\n",
      "0.0709282\n",
      "0.0709282\n",
      "0.025\n",
      "0.025\n",
      "0.808919\n",
      "0.808919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.116055\n",
      "0.116055\n",
      "0.0372278\n",
      "0.0372278\n",
      "0.975\n",
      "0.975\n",
      "0.842792\n",
      "0.842792\n",
      "0.841917\n",
      "0.841917\n",
      "0.436151\n",
      "0.436151\n",
      "0.224939\n",
      "0.224939\n",
      "0.0670489\n",
      "0.0670489\n",
      "0.414836\n",
      "0.414836\n",
      "0.0710129\n",
      "0.0710129\n",
      "0.693863\n",
      "0.693863\n",
      "0.107211\n",
      "0.107211\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.076051\n",
      "0.076051\n",
      "0.025\n",
      "0.025\n",
      "0.0741337\n",
      "0.0741337\n",
      "0.0951103\n",
      "0.0951103\n",
      "0.0627026\n",
      "0.0627026\n",
      "0.0594068\n",
      "0.0594068\n",
      "0.025\n",
      "0.025\n",
      "0.0759522\n",
      "0.0759522\n",
      "0.19677\n",
      "0.19677\n",
      "0.025\n",
      "0.025\n",
      "0.0571028\n",
      "0.0571028\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0713704\n",
      "0.0713704\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.598842\n",
      "0.598842\n",
      "0.952286\n",
      "0.952286\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.654825\n",
      "0.654825\n",
      "0.0328933\n",
      "0.0328933\n",
      "0.174101\n",
      "0.174101\n",
      "0.0257486\n",
      "0.0257486\n",
      "0.025\n",
      "0.025\n",
      "0.207208\n",
      "0.207208\n",
      "0.025\n",
      "0.025\n",
      "0.154007\n",
      "0.154007\n",
      "0.113828\n",
      "0.113828\n",
      "0.149014\n",
      "0.149014\n",
      "0.903128\n",
      "0.903128\n",
      "0.361058\n",
      "0.361058\n",
      "0.0800546\n",
      "0.0800546\n",
      "0.850076\n",
      "0.850076\n",
      "0.025\n",
      "0.025\n",
      "0.337046\n",
      "0.337046\n",
      "0.170801\n",
      "0.170801\n",
      "0.971791\n",
      "0.971791\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.969508\n",
      "0.969508\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.353653\n",
      "0.353653\n",
      "0.0405125\n",
      "0.0405125\n",
      "0.025\n",
      "0.025\n",
      "0.0834952\n",
      "0.0834952\n",
      "0.822489\n",
      "0.822489\n",
      "0.025\n",
      "0.025\n",
      "0.0441031\n",
      "0.0441031\n",
      "0.594657\n",
      "0.594657\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.301658\n",
      "0.301658\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0457738\n",
      "0.0457738\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.895949\n",
      "0.895949\n",
      "0.965567\n",
      "0.965567\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.472067\n",
      "0.472067\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.063457\n",
      "0.063457\n",
      "0.0534692\n",
      "0.0534692\n",
      "0.944397\n",
      "0.944397\n",
      "0.0351229\n",
      "0.0351229\n",
      "0.171617\n",
      "0.171617\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.186449\n",
      "0.186449\n",
      "0.025\n",
      "0.025\n",
      "0.939146\n",
      "0.939146\n",
      "0.975\n",
      "0.975\n",
      "0.911388\n",
      "0.911388\n",
      "0.0412159\n",
      "0.0412159\n",
      "0.025\n",
      "0.025\n",
      "0.0700621\n",
      "0.0700621\n",
      "0.0937055\n",
      "0.0937055\n",
      "0.792899\n",
      "0.792899\n",
      "0.947302\n",
      "0.947302\n",
      "0.139663\n",
      "0.139663\n",
      "0.0515308\n",
      "0.0515308\n",
      "0.025\n",
      "0.025\n",
      "0.0531873\n",
      "0.0531873\n",
      "0.088018\n",
      "0.088018\n",
      "0.226369\n",
      "0.226369\n",
      "0.025\n",
      "0.025\n",
      "0.834233\n",
      "0.834233\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0338781\n",
      "0.0338781\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.896345\n",
      "0.896345\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.955448\n",
      "0.955448\n",
      "0.937007\n",
      "0.937007\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.294691\n",
      "0.294691\n",
      "0.148506\n",
      "0.148506\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.250855\n",
      "0.250855\n",
      "0.025\n",
      "0.025\n",
      "0.557961\n",
      "0.557961\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.18052\n",
      "0.18052\n",
      "0.480329\n",
      "0.480329\n",
      "0.025\n",
      "0.025\n",
      "0.280369\n",
      "0.280369\n",
      "0.0504441\n",
      "0.0504441\n",
      "0.70166\n",
      "0.70166\n",
      "0.194669\n",
      "0.194669\n",
      "0.639103\n",
      "0.639103\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.134313\n",
      "0.134313\n",
      "0.0407224\n",
      "0.0407224\n",
      "0.025\n",
      "0.025\n",
      "0.152848\n",
      "0.152848\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.50527\n",
      "0.50527\n",
      "0.025\n",
      "0.025\n",
      "0.741244\n",
      "0.741244\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.86384\n",
      "0.86384\n",
      "0.639832\n",
      "0.639832\n",
      "0.0545639\n",
      "0.0545639\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.403478\n",
      "0.403478\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.191678\n",
      "0.191678\n",
      "0.810062\n",
      "0.810062\n",
      "0.372427\n",
      "0.372427\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.173787\n",
      "0.173787\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.415165\n",
      "0.415165\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.235672\n",
      "0.235672\n",
      "0.025\n",
      "0.025\n",
      "0.0564047\n",
      "0.0564047\n",
      "0.025\n",
      "0.025\n",
      "0.177168\n",
      "0.177168\n",
      "0.749831\n",
      "0.749831\n",
      "0.0454226\n",
      "0.0454226\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.11368\n",
      "0.11368\n",
      "0.209131\n",
      "0.209131\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.138884\n",
      "0.138884\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.10665\n",
      "0.10665\n",
      "0.166399\n",
      "0.166399\n",
      "0.025\n",
      "0.025\n",
      "0.0375768\n",
      "0.0375768\n",
      "0.644745\n",
      "0.644745\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0424617\n",
      "0.0424617\n",
      "0.025\n",
      "0.025\n",
      "0.129557\n",
      "0.129557\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0677895\n",
      "0.0677895\n",
      "0.025\n",
      "0.025\n",
      "0.0565185\n",
      "0.0565185\n",
      "0.131789\n",
      "0.131789\n",
      "0.025\n",
      "0.025\n",
      "0.441886\n",
      "0.441886\n",
      "0.025\n",
      "0.025\n",
      "0.0535482\n",
      "0.0535482\n",
      "0.0657095\n",
      "0.0657095\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.554996\n",
      "0.554996\n",
      "0.340068\n",
      "0.340068\n",
      "0.885841\n",
      "0.885841\n",
      "0.975\n",
      "0.975\n",
      "0.0462527\n",
      "0.0462527\n",
      "0.0315776\n",
      "0.0315776\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0967085\n",
      "0.0967085\n",
      "0.025\n",
      "0.025\n",
      "0.968634\n",
      "0.968634\n",
      "0.025\n",
      "0.025\n",
      "0.168858\n",
      "0.168858\n",
      "0.968582\n",
      "0.968582\n",
      "0.0882198\n",
      "0.0882198\n",
      "0.025\n",
      "0.025\n",
      "0.22496\n",
      "0.22496\n",
      "0.975\n",
      "0.975\n",
      "0.0280896\n",
      "0.0280896\n",
      "0.681925\n",
      "0.681925\n",
      "0.102504\n",
      "0.102504\n",
      "0.025\n",
      "0.025\n",
      "0.396797\n",
      "0.396797\n",
      "0.567309\n",
      "0.567309\n",
      "0.0702612\n",
      "0.0702612\n",
      "0.025\n",
      "0.025\n",
      "0.0282286\n",
      "0.0282286\n",
      "0.27085\n",
      "0.27085\n",
      "0.0811811\n",
      "0.0811811\n",
      "0.025\n",
      "0.025\n",
      "0.568458\n",
      "0.568458\n",
      "0.151556\n",
      "0.151556\n",
      "0.232106\n",
      "0.232106\n",
      "0.0964609\n",
      "0.0964609\n",
      "0.027944\n",
      "0.027944\n",
      "0.025\n",
      "0.025\n",
      "0.0323815\n",
      "0.0323815\n",
      "0.025\n",
      "0.025\n",
      "0.379971\n",
      "0.379971\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0551092\n",
      "0.0551092\n",
      "0.964632\n",
      "0.964632\n",
      "0.025\n",
      "0.025\n",
      "0.284891\n",
      "0.284891\n",
      "0.025\n",
      "0.025\n",
      "0.553668\n",
      "0.553668\n",
      "0.954748\n",
      "0.954748\n",
      "0.296316\n",
      "0.296316\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.103056\n",
      "0.103056\n",
      "0.814751\n",
      "0.814751\n",
      "0.562453\n",
      "0.562453\n",
      "0.0597995\n",
      "0.0597995\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.244997\n",
      "0.244997\n",
      "0.025\n",
      "0.025\n",
      "0.196268\n",
      "0.196268\n",
      "0.485903\n",
      "0.485903\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0897788\n",
      "0.0897788\n",
      "0.025\n",
      "0.025\n",
      "0.0801161\n",
      "0.0801161\n",
      "0.025\n",
      "0.025\n",
      "0.920564\n",
      "0.920564\n",
      "0.975\n",
      "0.975\n",
      "0.0409167\n",
      "0.0409167\n",
      "0.222587\n",
      "0.222587\n",
      "0.583992\n",
      "0.583992\n",
      "0.0474322\n",
      "0.0474322\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.115315\n",
      "0.115315\n",
      "0.0587239\n",
      "0.0587239\n",
      "0.025\n",
      "0.025\n",
      "0.940674\n",
      "0.940674\n",
      "0.803769\n",
      "0.803769\n",
      "0.025\n",
      "0.025\n",
      "0.738234\n",
      "0.738234\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.848318\n",
      "0.848318\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.204966\n",
      "0.204966\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.963166\n",
      "0.963166\n",
      "0.0558794\n",
      "0.0558794\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.137268\n",
      "0.137268\n",
      "0.0729472\n",
      "0.0729472\n",
      "0.188463\n",
      "0.188463\n",
      "0.025\n",
      "0.025\n",
      "0.518954\n",
      "0.518954\n",
      "0.918498\n",
      "0.918498\n",
      "0.11493\n",
      "0.11493\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.877037\n",
      "0.877037\n",
      "0.679906\n",
      "0.679906\n",
      "0.975\n",
      "0.975\n",
      "0.552975\n",
      "0.552975\n",
      "0.402931\n",
      "0.402931\n",
      "0.025\n",
      "0.025\n",
      "0.688098\n",
      "0.688098\n",
      "0.025\n",
      "0.025\n",
      "0.73667\n",
      "0.73667\n",
      "0.975\n",
      "0.975\n",
      "0.926252\n",
      "0.926252\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0558334\n",
      "0.0558334\n",
      "0.975\n",
      "0.975\n",
      "0.520977\n",
      "0.520977\n",
      "0.025\n",
      "0.025\n",
      "0.908918\n",
      "0.908918\n",
      "0.4481\n",
      "0.4481\n",
      "0.975\n",
      "0.975\n",
      "0.573492\n",
      "0.573492\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.112924\n",
      "0.112924\n",
      "0.025\n",
      "0.025\n",
      "0.11764\n",
      "0.11764\n",
      "0.069548\n",
      "0.069548\n",
      "0.87685\n",
      "0.87685\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.141064\n",
      "0.141064\n",
      "0.254132\n",
      "0.254132\n",
      "0.025\n",
      "0.025\n",
      "0.163188\n",
      "0.163188\n",
      "0.386746\n",
      "0.386746\n",
      "0.12719\n",
      "0.12719\n",
      "0.0529428\n",
      "0.0529428\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.244611\n",
      "0.244611\n",
      "0.231204\n",
      "0.231204\n",
      "0.384407\n",
      "0.384407\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.15388\n",
      "0.15388\n",
      "0.080915\n",
      "0.080915\n",
      "0.0403977\n",
      "0.0403977\n",
      "0.613882\n",
      "0.613882\n",
      "0.101478\n",
      "0.101478\n",
      "0.085459\n",
      "0.085459\n",
      "0.975\n",
      "0.975\n",
      "0.729449\n",
      "0.729449\n",
      "0.539254\n",
      "0.539254\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.746758\n",
      "0.746758\n",
      "0.115807\n",
      "0.115807\n",
      "0.152898\n",
      "0.152898\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.336595\n",
      "0.336595\n",
      "0.149816\n",
      "0.149816\n",
      "0.0280524\n",
      "0.0280524\n",
      "0.534841\n",
      "0.534841\n",
      "0.0340438\n",
      "0.0340438\n",
      "0.0567121\n",
      "0.0567121\n",
      "0.268526\n",
      "0.268526\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0659975\n",
      "0.0659975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0783883\n",
      "0.0783883\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.238983\n",
      "0.238983\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.266031\n",
      "0.266031\n",
      "0.025\n",
      "0.025\n",
      "0.178131\n",
      "0.178131\n",
      "0.772126\n",
      "0.772126\n",
      "0.0348531\n",
      "0.0348531\n",
      "0.0302334\n",
      "0.0302334\n",
      "0.0564487\n",
      "0.0564487\n",
      "0.975\n",
      "0.975\n",
      "0.0485672\n",
      "0.0485672\n",
      "0.102445\n",
      "0.102445\n",
      "0.025\n",
      "0.025\n",
      "0.724667\n",
      "0.724667\n",
      "0.352957\n",
      "0.352957\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.115449\n",
      "0.115449\n",
      "0.224871\n",
      "0.224871\n",
      "0.0870387\n",
      "0.0870387\n",
      "0.898191\n",
      "0.898191\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.491352\n",
      "0.491352\n",
      "0.858603\n",
      "0.858603\n",
      "0.025\n",
      "0.025\n",
      "0.0291056\n",
      "0.0291056\n",
      "0.59389\n",
      "0.59389\n",
      "0.0978786\n",
      "0.0978786\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.105539\n",
      "0.105539\n",
      "0.025\n",
      "0.025\n",
      "0.233324\n",
      "0.233324\n",
      "0.604983\n",
      "0.604983\n",
      "0.975\n",
      "0.975\n",
      "0.0690905\n",
      "0.0690905\n",
      "0.087339\n",
      "0.087339\n",
      "0.167521\n",
      "0.167521\n",
      "0.493355\n",
      "0.493355\n",
      "0.025\n",
      "0.025\n",
      "0.0693562\n",
      "0.0693562\n",
      "0.025\n",
      "0.025\n",
      "0.589529\n",
      "0.589529\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.389328\n",
      "0.389328\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.180941\n",
      "0.180941\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.199027\n",
      "0.199027\n",
      "0.332126\n",
      "0.332126\n",
      "0.424015\n",
      "0.424015\n",
      "0.025\n",
      "0.025\n",
      "0.0683766\n",
      "0.0683766\n",
      "0.025\n",
      "0.025\n",
      "0.223883\n",
      "0.223883\n",
      "0.025\n",
      "0.025\n",
      "0.336913\n",
      "0.336913\n",
      "0.938577\n",
      "0.938577\n",
      "0.025\n",
      "0.025\n",
      "0.0691301\n",
      "0.0691301\n",
      "0.940898\n",
      "0.940898\n",
      "0.025\n",
      "0.025\n",
      "0.391392\n",
      "0.391392\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0779112\n",
      "0.0779112\n",
      "0.791785\n",
      "0.791785\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.828935\n",
      "0.828935\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.818894\n",
      "0.818894\n",
      "0.274655\n",
      "0.274655\n",
      "0.159741\n",
      "0.159741\n",
      "0.975\n",
      "0.975\n",
      "0.0376152\n",
      "0.0376152\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.707445\n",
      "0.707445\n",
      "0.786932\n",
      "0.786932\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0336858\n",
      "0.0336858\n",
      "0.025\n",
      "0.025\n",
      "0.194948\n",
      "0.194948\n",
      "0.025\n",
      "0.025\n",
      "0.874371\n",
      "0.874371\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.874907\n",
      "0.874907\n",
      "0.375131\n",
      "0.375131\n",
      "0.230876\n",
      "0.230876\n",
      "0.975\n",
      "0.975\n",
      "0.247722\n",
      "0.247722\n",
      "0.682712\n",
      "0.682712\n",
      "0.910829\n",
      "0.910829\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.960286\n",
      "0.960286\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.392865\n",
      "0.392865\n",
      "0.0280721\n",
      "0.0280721\n",
      "0.164255\n",
      "0.164255\n",
      "0.070767\n",
      "0.070767\n",
      "0.211458\n",
      "0.211458\n",
      "0.826145\n",
      "0.826145\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0658662\n",
      "0.0658662\n",
      "0.0620701\n",
      "0.0620701\n",
      "0.164729\n",
      "0.164729\n",
      "0.975\n",
      "0.975\n",
      "0.0691053\n",
      "0.0691053\n",
      "0.856018\n",
      "0.856018\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.115488\n",
      "0.115488\n",
      "0.104127\n",
      "0.104127\n",
      "0.025\n",
      "0.025\n",
      "0.0765478\n",
      "0.0765478\n",
      "0.888723\n",
      "0.888723\n",
      "0.025\n",
      "0.025\n",
      "0.0607917\n",
      "0.0607917\n",
      "0.767233\n",
      "0.767233\n",
      "0.043302\n",
      "0.043302\n",
      "0.306114\n",
      "0.306114\n",
      "0.0639041\n",
      "0.0639041\n",
      "0.445818\n",
      "0.445818\n",
      "0.047578\n",
      "0.047578\n",
      "0.025\n",
      "0.025\n",
      "0.0491891\n",
      "0.0491891\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0402667\n",
      "0.0402667\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.428595\n",
      "0.428595\n",
      "0.148504\n",
      "0.148504\n",
      "0.122179\n",
      "0.122179\n",
      "0.025\n",
      "0.025\n",
      "0.0774721\n",
      "0.0774721\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.255072\n",
      "0.255072\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.175752\n",
      "0.175752\n",
      "0.975\n",
      "0.975\n",
      "0.30365\n",
      "0.30365\n",
      "0.975\n",
      "0.975\n",
      "0.0719956\n",
      "0.0719956\n",
      "0.0259733\n",
      "0.0259733\n",
      "0.0456704\n",
      "0.0456704\n",
      "0.025\n",
      "0.025\n",
      "0.149843\n",
      "0.149843\n",
      "0.0797265\n",
      "0.0797265\n",
      "0.460996\n",
      "0.460996\n",
      "0.740769\n",
      "0.740769\n",
      "0.199746\n",
      "0.199746\n",
      "0.580426\n",
      "0.580426\n",
      "0.109037\n",
      "0.109037\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0746035\n",
      "0.0746035\n",
      "0.215455\n",
      "0.215455\n",
      "0.025\n",
      "0.025\n",
      "0.065461\n",
      "0.065461\n",
      "0.281203\n",
      "0.281203\n",
      "0.0360216\n",
      "0.0360216\n",
      "0.025\n",
      "0.025\n",
      "0.123016\n",
      "0.123016\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.131643\n",
      "0.131643\n",
      "0.025\n",
      "0.025\n",
      "0.778702\n",
      "0.778702\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.136722\n",
      "0.136722\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0633352\n",
      "0.0633352\n",
      "0.025\n",
      "0.025\n",
      "0.0276659\n",
      "0.0276659\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0401483\n",
      "0.0401483\n",
      "0.0373299\n",
      "0.0373299\n",
      "0.0793224\n",
      "0.0793224\n",
      "0.543793\n",
      "0.543793\n",
      "0.0394619\n",
      "0.0394619\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.189734\n",
      "0.189734\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.202235\n",
      "0.202235\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.238347\n",
      "0.238347\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0810724\n",
      "0.0810724\n",
      "0.025\n",
      "0.025\n",
      "0.529985\n",
      "0.529985\n",
      "0.0653327\n",
      "0.0653327\n",
      "0.025\n",
      "0.025\n",
      "0.0753534\n",
      "0.0753534\n",
      "0.025\n",
      "0.025\n",
      "0.672834\n",
      "0.672834\n",
      "0.025\n",
      "0.025\n",
      "0.336256\n",
      "0.336256\n",
      "0.025\n",
      "0.025\n",
      "0.566448\n",
      "0.566448\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.691831\n",
      "0.691831\n",
      "0.0290227\n",
      "0.0290227\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0285289\n",
      "0.0285289\n",
      "0.141384\n",
      "0.141384\n",
      "0.950976\n",
      "0.950976\n",
      "0.918628\n",
      "0.918628\n",
      "0.0341553\n",
      "0.0341553\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.146467\n",
      "0.146467\n",
      "0.298894\n",
      "0.298894\n",
      "0.714478\n",
      "0.714478\n",
      "0.025\n",
      "0.025\n",
      "0.0873863\n",
      "0.0873863\n",
      "0.964346\n",
      "0.964346\n",
      "0.135753\n",
      "0.135753\n",
      "0.025\n",
      "0.025\n",
      "0.89729\n",
      "0.89729\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.424324\n",
      "0.424324\n",
      "0.105509\n",
      "0.105509\n",
      "0.025\n",
      "0.025\n",
      "0.217487\n",
      "0.217487\n",
      "0.162198\n",
      "0.162198\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.966928\n",
      "0.966928\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.769101\n",
      "0.769101\n",
      "0.170887\n",
      "0.170887\n",
      "0.0719629\n",
      "0.0719629\n",
      "0.292361\n",
      "0.292361\n",
      "0.025\n",
      "0.025\n",
      "0.207066\n",
      "0.207066\n",
      "0.232739\n",
      "0.232739\n",
      "0.292347\n",
      "0.292347\n",
      "0.975\n",
      "0.975\n",
      "0.0647829\n",
      "0.0647829\n",
      "0.101833\n",
      "0.101833\n",
      "0.025\n",
      "0.025\n",
      "0.680362\n",
      "0.680362\n",
      "0.025\n",
      "0.025\n",
      "0.0848727\n",
      "0.0848727\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.037181\n",
      "0.037181\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0878466\n",
      "0.0878466\n",
      "0.0685167\n",
      "0.0685167\n",
      "0.0683971\n",
      "0.0683971\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.47262\n",
      "0.47262\n",
      "0.975\n",
      "0.975\n",
      "0.784466\n",
      "0.784466\n",
      "0.146394\n",
      "0.146394\n",
      "0.187187\n",
      "0.187187\n",
      "0.739354\n",
      "0.739354\n",
      "0.38668\n",
      "0.38668\n",
      "0.109328\n",
      "0.109328\n",
      "0.224198\n",
      "0.224198\n",
      "0.0319764\n",
      "0.0319764\n",
      "0.623188\n",
      "0.623188\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.028475\n",
      "0.028475\n",
      "0.346273\n",
      "0.346273\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.93383\n",
      "0.93383\n",
      "0.17484\n",
      "0.17484\n",
      "0.025\n",
      "0.025\n",
      "0.344705\n",
      "0.344705\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.954804\n",
      "0.954804\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.103239\n",
      "0.103239\n",
      "0.350807\n",
      "0.350807\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0709212\n",
      "0.0709212\n",
      "0.830585\n",
      "0.830585\n",
      "0.065978\n",
      "0.065978\n",
      "0.025\n",
      "0.025\n",
      "0.284647\n",
      "0.284647\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.372179\n",
      "0.372179\n",
      "0.105779\n",
      "0.105779\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.100868\n",
      "0.100868\n",
      "0.706107\n",
      "0.706107\n",
      "0.128017\n",
      "0.128017\n",
      "0.449312\n",
      "0.449312\n",
      "0.973952\n",
      "0.973952\n",
      "0.0451516\n",
      "0.0451516\n",
      "0.025\n",
      "0.025\n",
      "0.450976\n",
      "0.450976\n",
      "0.0516199\n",
      "0.0516199\n",
      "0.378593\n",
      "0.378593\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.139096\n",
      "0.139096\n",
      "0.025\n",
      "0.025\n",
      "0.292866\n",
      "0.292866\n",
      "0.923743\n",
      "0.923743\n",
      "0.025\n",
      "0.025\n",
      "0.788238\n",
      "0.788238\n",
      "0.590742\n",
      "0.590742\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.62478\n",
      "0.62478\n",
      "0.025\n",
      "0.025\n",
      "0.867043\n",
      "0.867043\n",
      "0.025\n",
      "0.025\n",
      "0.0581716\n",
      "0.0581716\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.856401\n",
      "0.856401\n",
      "0.975\n",
      "0.975\n",
      "0.901374\n",
      "0.901374\n",
      "0.901174\n",
      "0.901174\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.920481\n",
      "0.920481\n",
      "0.975\n",
      "0.975\n",
      "0.160431\n",
      "0.160431\n",
      "0.0836589\n",
      "0.0836589\n",
      "0.415662\n",
      "0.415662\n",
      "0.414733\n",
      "0.414733\n",
      "0.025\n",
      "0.025\n",
      "0.027287\n",
      "0.027287\n",
      "0.144923\n",
      "0.144923\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.957189\n",
      "0.957189\n",
      "0.140474\n",
      "0.140474\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.934023\n",
      "0.934023\n",
      "0.975\n",
      "0.975\n",
      "0.0780805\n",
      "0.0780805\n",
      "0.163986\n",
      "0.163986\n",
      "0.025\n",
      "0.025\n",
      "0.63962\n",
      "0.63962\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0413991\n",
      "0.0413991\n",
      "0.0795915\n",
      "0.0795915\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.436705\n",
      "0.436705\n",
      "0.025\n",
      "0.025\n",
      "0.769602\n",
      "0.769602\n",
      "0.025\n",
      "0.025\n",
      "0.11399\n",
      "0.11399\n",
      "0.23864\n",
      "0.23864\n",
      "0.0371324\n",
      "0.0371324\n",
      "0.025\n",
      "0.025\n",
      "0.297839\n",
      "0.297839\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.493612\n",
      "0.493612\n",
      "0.919896\n",
      "0.919896\n",
      "0.025\n",
      "0.025\n",
      "0.299748\n",
      "0.299748\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.265183\n",
      "0.265183\n",
      "0.310915\n",
      "0.310915\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.830498\n",
      "0.830498\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.51702\n",
      "0.51702\n",
      "0.025\n",
      "0.025\n",
      "0.929486\n",
      "0.929486\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0255303\n",
      "0.0255303\n",
      "0.20782\n",
      "0.20782\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.282565\n",
      "0.282565\n",
      "0.920469\n",
      "0.920469\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.966643\n",
      "0.966643\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.829467\n",
      "0.829467\n",
      "0.302345\n",
      "0.302345\n",
      "0.823523\n",
      "0.823523\n",
      "0.0434042\n",
      "0.0434042\n",
      "0.0289394\n",
      "0.0289394\n",
      "0.0688022\n",
      "0.0688022\n",
      "0.213565\n",
      "0.213565\n",
      "0.0844675\n",
      "0.0844675\n",
      "0.025\n",
      "0.025\n",
      "0.0557678\n",
      "0.0557678\n",
      "0.043675\n",
      "0.043675\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.417054\n",
      "0.417054\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0521481\n",
      "0.0521481\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.110169\n",
      "0.110169\n",
      "0.0381209\n",
      "0.0381209\n",
      "0.0595903\n",
      "0.0595903\n",
      "0.975\n",
      "0.975\n",
      "0.905279\n",
      "0.905279\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.3098\n",
      "0.3098\n",
      "0.965009\n",
      "0.965009\n",
      "0.0321717\n",
      "0.0321717\n",
      "0.025\n",
      "0.025\n",
      "0.0801627\n",
      "0.0801627\n",
      "0.975\n",
      "0.975\n",
      "0.040755\n",
      "0.040755\n",
      "0.321402\n",
      "0.321402\n",
      "0.025\n",
      "0.025\n",
      "0.282225\n",
      "0.282225\n",
      "0.75905\n",
      "0.75905\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.59064\n",
      "0.59064\n",
      "0.217143\n",
      "0.217143\n",
      "0.975\n",
      "0.975\n",
      "0.22259\n",
      "0.22259\n",
      "0.942342\n",
      "0.942342\n",
      "0.975\n",
      "0.975\n",
      "0.77894\n",
      "0.77894\n",
      "0.398714\n",
      "0.398714\n",
      "0.025\n",
      "0.025\n",
      "0.0631251\n",
      "0.0631251\n",
      "0.131596\n",
      "0.131596\n",
      "0.0552619\n",
      "0.0552619\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0647445\n",
      "0.0647445\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0420593\n",
      "0.0420593\n",
      "0.975\n",
      "0.975\n",
      "0.952722\n",
      "0.952722\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.130553\n",
      "0.130553\n",
      "0.025\n",
      "0.025\n",
      "0.221828\n",
      "0.221828\n",
      "0.467277\n",
      "0.467277\n",
      "0.025\n",
      "0.025\n",
      "0.712799\n",
      "0.712799\n",
      "0.047534\n",
      "0.047534\n",
      "0.226839\n",
      "0.226839\n",
      "0.025\n",
      "0.025\n",
      "0.613044\n",
      "0.613044\n",
      "0.025\n",
      "0.025\n",
      "0.0273308\n",
      "0.0273308\n",
      "0.0342425\n",
      "0.0342425\n",
      "0.492138\n",
      "0.492138\n",
      "0.110502\n",
      "0.110502\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.219192\n",
      "0.219192\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.315751\n",
      "0.315751\n",
      "0.025\n",
      "0.025\n",
      "0.956538\n",
      "0.956538\n",
      "0.025\n",
      "0.025\n",
      "0.130422\n",
      "0.130422\n",
      "0.514404\n",
      "0.514404\n",
      "0.0892418\n",
      "0.0892418\n",
      "0.139124\n",
      "0.139124\n",
      "0.0301149\n",
      "0.0301149\n",
      "0.975\n",
      "0.975\n",
      "0.0321846\n",
      "0.0321846\n",
      "0.553922\n",
      "0.553922\n",
      "0.756995\n",
      "0.756995\n",
      "0.0584276\n",
      "0.0584276\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.870389\n",
      "0.870389\n",
      "0.0320397\n",
      "0.0320397\n",
      "0.0365155\n",
      "0.0365155\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0398074\n",
      "0.0398074\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0765024\n",
      "0.0765024\n",
      "0.0384157\n",
      "0.0384157\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.029682\n",
      "0.029682\n",
      "0.975\n",
      "0.975\n",
      "0.972269\n",
      "0.972269\n",
      "0.682937\n",
      "0.682937\n",
      "0.025\n",
      "0.025\n",
      "0.160459\n",
      "0.160459\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.527711\n",
      "0.527711\n",
      "0.0882923\n",
      "0.0882923\n",
      "0.255211\n",
      "0.255211\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.819079\n",
      "0.819079\n",
      "0.567143\n",
      "0.567143\n",
      "0.112515\n",
      "0.112515\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.963804\n",
      "0.963804\n",
      "0.025\n",
      "0.025\n",
      "0.0257952\n",
      "0.0257952\n",
      "0.975\n",
      "0.975\n",
      "0.739228\n",
      "0.739228\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.190225\n",
      "0.190225\n",
      "0.975\n",
      "0.975\n",
      "0.0595303\n",
      "0.0595303\n",
      "0.025\n",
      "0.025\n",
      "0.0317085\n",
      "0.0317085\n",
      "0.025\n",
      "0.025\n",
      "0.0447438\n",
      "0.0447438\n",
      "0.122902\n",
      "0.122902\n",
      "0.580439\n",
      "0.580439\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.409254\n",
      "0.409254\n",
      "0.025\n",
      "0.025\n",
      "0.613633\n",
      "0.613633\n",
      "0.0299203\n",
      "0.0299203\n",
      "0.731606\n",
      "0.731606\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.389522\n",
      "0.389522\n",
      "0.876351\n",
      "0.876351\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.72146\n",
      "0.72146\n",
      "0.025\n",
      "0.025\n",
      "0.608245\n",
      "0.608245\n",
      "0.841828\n",
      "0.841828\n",
      "0.102498\n",
      "0.102498\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.318149\n",
      "0.318149\n",
      "0.0293432\n",
      "0.0293432\n",
      "0.025\n",
      "0.025\n",
      "0.222443\n",
      "0.222443\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0772268\n",
      "0.0772268\n",
      "0.025\n",
      "0.025\n",
      "0.0421935\n",
      "0.0421935\n",
      "0.975\n",
      "0.975\n",
      "0.228774\n",
      "0.228774\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.884343\n",
      "0.884343\n",
      "0.269548\n",
      "0.269548\n",
      "0.975\n",
      "0.975\n",
      "0.868114\n",
      "0.868114\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0561848\n",
      "0.0561848\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0556498\n",
      "0.0556498\n",
      "0.975\n",
      "0.975\n",
      "0.0513644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0513644\n",
      "0.300184\n",
      "0.300184\n",
      "0.025\n",
      "0.025\n",
      "0.206176\n",
      "0.206176\n",
      "0.134271\n",
      "0.134271\n",
      "0.127896\n",
      "0.127896\n",
      "0.975\n",
      "0.975\n",
      "0.453902\n",
      "0.453902\n",
      "0.665471\n",
      "0.665471\n",
      "0.106418\n",
      "0.106418\n",
      "0.861346\n",
      "0.861346\n",
      "0.0265883\n",
      "0.0265883\n",
      "0.521707\n",
      "0.521707\n",
      "0.025\n",
      "0.025\n",
      "0.18946\n",
      "0.18946\n",
      "0.0410161\n",
      "0.0410161\n",
      "0.0368347\n",
      "0.0368347\n",
      "0.108509\n",
      "0.108509\n",
      "0.100823\n",
      "0.100823\n",
      "0.9393\n",
      "0.9393\n",
      "0.895268\n",
      "0.895268\n",
      "0.356274\n",
      "0.356274\n",
      "0.356992\n",
      "0.356992\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.595665\n",
      "0.595665\n",
      "0.47533\n",
      "0.47533\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.96823\n",
      "0.96823\n",
      "0.0389544\n",
      "0.0389544\n",
      "0.9003\n",
      "0.9003\n",
      "0.398366\n",
      "0.398366\n",
      "0.132556\n",
      "0.132556\n",
      "0.145826\n",
      "0.145826\n",
      "0.212657\n",
      "0.212657\n",
      "0.119876\n",
      "0.119876\n",
      "0.025\n",
      "0.025\n",
      "0.317515\n",
      "0.317515\n",
      "0.733209\n",
      "0.733209\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.864617\n",
      "0.864617\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0553301\n",
      "0.0553301\n",
      "0.207811\n",
      "0.207811\n",
      "0.025\n",
      "0.025\n",
      "0.0733645\n",
      "0.0733645\n",
      "0.025\n",
      "0.025\n",
      "0.452914\n",
      "0.452914\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.840006\n",
      "0.840006\n",
      "0.200725\n",
      "0.200725\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.538932\n",
      "0.538932\n",
      "0.844441\n",
      "0.844441\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.278836\n",
      "0.278836\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0944638\n",
      "0.0944638\n",
      "0.0750218\n",
      "0.0750218\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.835704\n",
      "0.835704\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.535684\n",
      "0.535684\n",
      "0.793882\n",
      "0.793882\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0868481\n",
      "0.0868481\n",
      "0.230022\n",
      "0.230022\n",
      "0.975\n",
      "0.975\n",
      "0.0296306\n",
      "0.0296306\n",
      "0.129927\n",
      "0.129927\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.925417\n",
      "0.925417\n",
      "0.025\n",
      "0.025\n",
      "0.136867\n",
      "0.136867\n",
      "0.0324641\n",
      "0.0324641\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.889003\n",
      "0.889003\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.864267\n",
      "0.864267\n",
      "0.094888\n",
      "0.094888\n",
      "0.025\n",
      "0.025\n",
      "0.618126\n",
      "0.618126\n",
      "0.172967\n",
      "0.172967\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0279135\n",
      "0.0279135\n",
      "0.975\n",
      "0.975\n",
      "0.0252934\n",
      "0.0252934\n",
      "0.025\n",
      "0.025\n",
      "0.0874394\n",
      "0.0874394\n",
      "0.025\n",
      "0.025\n",
      "0.341256\n",
      "0.341256\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.032271\n",
      "0.032271\n",
      "0.973739\n",
      "0.973739\n",
      "0.560096\n",
      "0.560096\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.218397\n",
      "0.218397\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0269548\n",
      "0.0269548\n",
      "0.241762\n",
      "0.241762\n",
      "0.025\n",
      "0.025\n",
      "0.928255\n",
      "0.928255\n",
      "0.025\n",
      "0.025\n",
      "0.0314917\n",
      "0.0314917\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0301856\n",
      "0.0301856\n",
      "0.47611\n",
      "0.47611\n",
      "0.025\n",
      "0.025\n",
      "0.0713566\n",
      "0.0713566\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.25372\n",
      "0.25372\n",
      "0.258825\n",
      "0.258825\n",
      "0.0990522\n",
      "0.0990522\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.518834\n",
      "0.518834\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.587518\n",
      "0.587518\n",
      "0.190618\n",
      "0.190618\n",
      "0.0587555\n",
      "0.0587555\n",
      "0.025\n",
      "0.025\n",
      "0.031095\n",
      "0.031095\n",
      "0.585774\n",
      "0.585774\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.164474\n",
      "0.164474\n",
      "0.111352\n",
      "0.111352\n",
      "0.975\n",
      "0.975\n",
      "0.882878\n",
      "0.882878\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.222637\n",
      "0.222637\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.269117\n",
      "0.269117\n",
      "0.659934\n",
      "0.659934\n",
      "0.235557\n",
      "0.235557\n",
      "0.025\n",
      "0.025\n",
      "0.951133\n",
      "0.951133\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.562162\n",
      "0.562162\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.839319\n",
      "0.839319\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0359758\n",
      "0.0359758\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0377476\n",
      "0.0377476\n",
      "0.025\n",
      "0.025\n",
      "0.958864\n",
      "0.958864\n",
      "0.025\n",
      "0.025\n",
      "0.219215\n",
      "0.219215\n",
      "0.975\n",
      "0.975\n",
      "0.42804\n",
      "0.42804\n",
      "0.975\n",
      "0.975\n",
      "0.134327\n",
      "0.134327\n",
      "0.074812\n",
      "0.074812\n",
      "0.975\n",
      "0.975\n",
      "0.061796\n",
      "0.061796\n",
      "0.895533\n",
      "0.895533\n",
      "0.025\n",
      "0.025\n",
      "0.317557\n",
      "0.317557\n",
      "0.0505919\n",
      "0.0505919\n",
      "0.953903\n",
      "0.953903\n",
      "0.0990241\n",
      "0.0990241\n",
      "0.253674\n",
      "0.253674\n",
      "0.0424946\n",
      "0.0424946\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0578194\n",
      "0.0578194\n",
      "0.025\n",
      "0.025\n",
      "0.77952\n",
      "0.77952\n",
      "0.618737\n",
      "0.618737\n",
      "0.178037\n",
      "0.178037\n",
      "0.025\n",
      "0.025\n",
      "0.838198\n",
      "0.838198\n",
      "0.151912\n",
      "0.151912\n",
      "0.806593\n",
      "0.806593\n",
      "0.264728\n",
      "0.264728\n",
      "0.567479\n",
      "0.567479\n",
      "0.975\n",
      "0.975\n",
      "0.85106\n",
      "0.85106\n",
      "0.868369\n",
      "0.868369\n",
      "0.025\n",
      "0.025\n",
      "0.351253\n",
      "0.351253\n",
      "0.1016\n",
      "0.1016\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.25032\n",
      "0.25032\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.150894\n",
      "0.150894\n",
      "0.0604625\n",
      "0.0604625\n",
      "0.9683\n",
      "0.9683\n",
      "0.905217\n",
      "0.905217\n",
      "0.025\n",
      "0.025\n",
      "0.0883697\n",
      "0.0883697\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.222938\n",
      "0.222938\n",
      "0.0615024\n",
      "0.0615024\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.959285\n",
      "0.959285\n",
      "0.144677\n",
      "0.144677\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.115401\n",
      "0.115401\n",
      "0.68273\n",
      "0.68273\n",
      "0.122364\n",
      "0.122364\n",
      "0.186324\n",
      "0.186324\n",
      "0.263042\n",
      "0.263042\n",
      "0.964508\n",
      "0.964508\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.221921\n",
      "0.221921\n",
      "0.399216\n",
      "0.399216\n",
      "0.377078\n",
      "0.377078\n",
      "0.0342642\n",
      "0.0342642\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.959526\n",
      "0.959526\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0737093\n",
      "0.0737093\n",
      "0.025\n",
      "0.025\n",
      "0.0669521\n",
      "0.0669521\n",
      "0.227442\n",
      "0.227442\n",
      "0.831261\n",
      "0.831261\n",
      "0.163903\n",
      "0.163903\n",
      "0.450991\n",
      "0.450991\n",
      "0.025\n",
      "0.025\n",
      "0.035536\n",
      "0.035536\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.313178\n",
      "0.313178\n",
      "0.0301538\n",
      "0.0301538\n",
      "0.025\n",
      "0.025\n",
      "0.454589\n",
      "0.454589\n",
      "0.101219\n",
      "0.101219\n",
      "0.211075\n",
      "0.211075\n",
      "0.025\n",
      "0.025\n",
      "0.803036\n",
      "0.803036\n",
      "0.783288\n",
      "0.783288\n",
      "0.865299\n",
      "0.865299\n",
      "0.342009\n",
      "0.342009\n",
      "0.975\n",
      "0.975\n",
      "0.604203\n",
      "0.604203\n",
      "0.475577\n",
      "0.475577\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0781256\n",
      "0.0781256\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.96282\n",
      "0.96282\n",
      "0.221979\n",
      "0.221979\n",
      "0.814528\n",
      "0.814528\n",
      "0.0404102\n",
      "0.0404102\n",
      "0.970486\n",
      "0.970486\n",
      "0.975\n",
      "0.975\n",
      "0.068067\n",
      "0.068067\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.027301\n",
      "0.027301\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.67383\n",
      "0.67383\n",
      "0.025\n",
      "0.025\n",
      "0.971474\n",
      "0.971474\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0347869\n",
      "0.0347869\n",
      "0.0906842\n",
      "0.0906842\n",
      "0.025\n",
      "0.025\n",
      "0.179895\n",
      "0.179895\n",
      "0.0256731\n",
      "0.0256731\n",
      "0.082121\n",
      "0.082121\n",
      "0.025\n",
      "0.025\n",
      "0.481285\n",
      "0.481285\n",
      "0.0370474\n",
      "0.0370474\n",
      "0.025\n",
      "0.025\n",
      "0.609223\n",
      "0.609223\n",
      "0.025\n",
      "0.025\n",
      "0.213643\n",
      "0.213643\n",
      "0.025\n",
      "0.025\n",
      "0.0270316\n",
      "0.0270316\n",
      "0.147448\n",
      "0.147448\n",
      "0.655934\n",
      "0.655934\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.164891\n",
      "0.164891\n",
      "0.04453\n",
      "0.04453\n",
      "0.975\n",
      "0.975\n",
      "0.0323473\n",
      "0.0323473\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.241797\n",
      "0.241797\n",
      "0.875658\n",
      "0.875658\n",
      "0.025\n",
      "0.025\n",
      "0.0371841\n",
      "0.0371841\n",
      "0.962241\n",
      "0.962241\n",
      "0.975\n",
      "0.975\n",
      "0.657815\n",
      "0.657815\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.518582\n",
      "0.518582\n",
      "0.0430667\n",
      "0.0430667\n",
      "0.386886\n",
      "0.386886\n",
      "0.355065\n",
      "0.355065\n",
      "0.975\n",
      "0.975\n",
      "0.146852\n",
      "0.146852\n",
      "0.975\n",
      "0.975\n",
      "0.0506869\n",
      "0.0506869\n",
      "0.025\n",
      "0.025\n",
      "0.278688\n",
      "0.278688\n",
      "0.973904\n",
      "0.973904\n",
      "0.313476\n",
      "0.313476\n",
      "0.381579\n",
      "0.381579\n",
      "0.848301\n",
      "0.848301\n",
      "0.975\n",
      "0.975\n",
      "0.953552\n",
      "0.953552\n",
      "0.946874\n",
      "0.946874\n",
      "0.025\n",
      "0.025\n",
      "0.0833373\n",
      "0.0833373\n",
      "0.0935087\n",
      "0.0935087\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0575136\n",
      "0.0575136\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.460685\n",
      "0.460685\n",
      "0.025\n",
      "0.025\n",
      "0.0472362\n",
      "0.0472362\n",
      "0.975\n",
      "0.975\n",
      "0.321383\n",
      "0.321383\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.315613\n",
      "0.315613\n",
      "0.550645\n",
      "0.550645\n",
      "0.0943203\n",
      "0.0943203\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0524389\n",
      "0.0524389\n",
      "0.025\n",
      "0.025\n",
      "0.227639\n",
      "0.227639\n",
      "0.117115\n",
      "0.117115\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0437141\n",
      "0.0437141\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.116741\n",
      "0.116741\n",
      "0.975\n",
      "0.975\n",
      "0.0612104\n",
      "0.0612104\n",
      "0.025\n",
      "0.025\n",
      "0.20123\n",
      "0.20123\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.569271\n",
      "0.569271\n",
      "0.025\n",
      "0.025\n",
      "0.197399\n",
      "0.197399\n",
      "0.025\n",
      "0.025\n",
      "0.0939805\n",
      "0.0939805\n",
      "0.201687\n",
      "0.201687\n",
      "0.184773\n",
      "0.184773\n",
      "0.975\n",
      "0.975\n",
      "0.856288\n",
      "0.856288\n",
      "0.257127\n",
      "0.257127\n",
      "0.025\n",
      "0.025\n",
      "0.900226\n",
      "0.900226\n",
      "0.025\n",
      "0.025\n",
      "0.929138\n",
      "0.929138\n",
      "0.0579414\n",
      "0.0579414\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0369877\n",
      "0.0369877\n",
      "0.025\n",
      "0.025\n",
      "0.434904\n",
      "0.434904\n",
      "0.710618\n",
      "0.710618\n",
      "0.025\n",
      "0.025\n",
      "0.0330624\n",
      "0.0330624\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.193514\n",
      "0.193514\n",
      "0.280822\n",
      "0.280822\n",
      "0.572097\n",
      "0.572097\n",
      "0.0621329\n",
      "0.0621329\n",
      "0.0924245\n",
      "0.0924245\n",
      "0.0567633\n",
      "0.0567633\n",
      "0.025\n",
      "0.025\n",
      "0.119665\n",
      "0.119665\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.726125\n",
      "0.726125\n",
      "0.922831\n",
      "0.922831\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0261094\n",
      "0.0261094\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.685336\n",
      "0.685336\n",
      "0.339393\n",
      "0.339393\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0750859\n",
      "0.0750859\n",
      "0.370051\n",
      "0.370051\n",
      "0.025\n",
      "0.025\n",
      "0.117633\n",
      "0.117633\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0424472\n",
      "0.0424472\n",
      "0.469038\n",
      "0.469038\n",
      "0.0587953\n",
      "0.0587953\n",
      "0.025\n",
      "0.025\n",
      "0.0278128\n",
      "0.0278128\n",
      "0.305423\n",
      "0.305423\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.735877\n",
      "0.735877\n",
      "0.451709\n",
      "0.451709\n",
      "0.861459\n",
      "0.861459\n",
      "0.693922\n",
      "0.693922\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.972933\n",
      "0.972933\n",
      "0.348848\n",
      "0.348848\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.570643\n",
      "0.570643\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.820213\n",
      "0.820213\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.678362\n",
      "0.678362\n",
      "0.529153\n",
      "0.529153\n",
      "0.0539136\n",
      "0.0539136\n",
      "0.975\n",
      "0.975\n",
      "0.0397107\n",
      "0.0397107\n",
      "0.170989\n",
      "0.170989\n",
      "0.025\n",
      "0.025\n",
      "0.0349719\n",
      "0.0349719\n",
      "0.440597\n",
      "0.440597\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0810205\n",
      "0.0810205\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.922517\n",
      "0.922517\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.076327\n",
      "0.076327\n",
      "0.142613\n",
      "0.142613\n",
      "0.393704\n",
      "0.393704\n",
      "0.025\n",
      "0.025\n",
      "0.380953\n",
      "0.380953\n",
      "0.0444675\n",
      "0.0444675\n",
      "0.975\n",
      "0.975\n",
      "0.428035\n",
      "0.428035\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.832927\n",
      "0.832927\n",
      "0.0551622\n",
      "0.0551622\n",
      "0.0493721\n",
      "0.0493721\n",
      "0.0354241\n",
      "0.0354241\n",
      "0.78823\n",
      "0.78823\n",
      "0.372926\n",
      "0.372926\n",
      "0.025\n",
      "0.025\n",
      "0.0985794\n",
      "0.0985794\n",
      "0.025\n",
      "0.025\n",
      "0.259247\n",
      "0.259247\n",
      "0.025\n",
      "0.025\n",
      "0.0336022\n",
      "0.0336022\n",
      "0.025\n",
      "0.025\n",
      "0.03325\n",
      "0.03325\n",
      "0.025\n",
      "0.025\n",
      "0.325915\n",
      "0.325915\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.657315\n",
      "0.657315\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.175213\n",
      "0.175213\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0357136\n",
      "0.0357136\n",
      "0.0359083\n",
      "0.0359083\n",
      "0.0651617\n",
      "0.0651617\n",
      "0.300931\n",
      "0.300931\n",
      "0.865775\n",
      "0.865775\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.577791\n",
      "0.577791\n",
      "0.937933\n",
      "0.937933\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0340664\n",
      "0.0340664\n",
      "0.827706\n",
      "0.827706\n",
      "0.025\n",
      "0.025\n",
      "0.909672\n",
      "0.909672\n",
      "0.025\n",
      "0.025\n",
      "0.182473\n",
      "0.182473\n",
      "0.0640955\n",
      "0.0640955\n",
      "0.801224\n",
      "0.801224\n",
      "0.214676\n",
      "0.214676\n",
      "0.0684181\n",
      "0.0684181\n",
      "0.025\n",
      "0.025\n",
      "0.134051\n",
      "0.134051\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0443546\n",
      "0.0443546\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.619072\n",
      "0.619072\n",
      "0.0517969\n",
      "0.0517969\n",
      "0.266019\n",
      "0.266019\n",
      "0.025\n",
      "0.025\n",
      "0.971989\n",
      "0.971989\n",
      "0.025\n",
      "0.025\n",
      "0.321661\n",
      "0.321661\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0466117\n",
      "0.0466117\n",
      "0.025\n",
      "0.025\n",
      "0.0361992\n",
      "0.0361992\n",
      "0.917754\n",
      "0.917754\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0522755\n",
      "0.0522755\n",
      "0.272431\n",
      "0.272431\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0789397\n",
      "0.0789397\n",
      "0.08212\n",
      "0.08212\n",
      "0.0487117\n",
      "0.0487117\n",
      "0.0311269\n",
      "0.0311269\n",
      "0.025\n",
      "0.025\n",
      "0.892854\n",
      "0.892854\n",
      "0.303363\n",
      "0.303363\n",
      "0.181571\n",
      "0.181571\n",
      "0.185711\n",
      "0.185711\n",
      "0.226424\n",
      "0.226424\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.199429\n",
      "0.199429\n",
      "0.025\n",
      "0.025\n",
      "0.117202\n",
      "0.117202\n",
      "0.0674098\n",
      "0.0674098\n",
      "0.353751\n",
      "0.353751\n",
      "0.025\n",
      "0.025\n",
      "0.0278212\n",
      "0.0278212\n",
      "0.0504624\n",
      "0.0504624\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0436335\n",
      "0.0436335\n",
      "0.0405536\n",
      "0.0405536\n",
      "0.025\n",
      "0.025\n",
      "0.696205\n",
      "0.696205\n",
      "0.963093\n",
      "0.963093\n",
      "0.31415\n",
      "0.31415\n",
      "0.432084\n",
      "0.432084\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0619516\n",
      "0.0619516\n",
      "0.0299529\n",
      "0.0299529\n",
      "0.975\n",
      "0.975\n",
      "0.599909\n",
      "0.599909\n",
      "0.025\n",
      "0.025\n",
      "0.693194\n",
      "0.693194\n",
      "0.025\n",
      "0.025\n",
      "0.527683\n",
      "0.527683\n",
      "0.0598255\n",
      "0.0598255\n",
      "0.926192\n",
      "0.926192\n",
      "0.194042\n",
      "0.194042\n",
      "0.025\n",
      "0.025\n",
      "0.121357\n",
      "0.121357\n",
      "0.514014\n",
      "0.514014\n",
      "0.0575182\n",
      "0.0575182\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0328122\n",
      "0.0328122\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0291587\n",
      "0.0291587\n",
      "0.791321\n",
      "0.791321\n",
      "0.101861\n",
      "0.101861\n",
      "0.838864\n",
      "0.838864\n",
      "0.0301947\n",
      "0.0301947\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.626701\n",
      "0.626701\n",
      "0.025\n",
      "0.025\n",
      "0.603368\n",
      "0.603368\n",
      "0.20376\n",
      "0.20376\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.884643\n",
      "0.884643\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.210202\n",
      "0.210202\n",
      "0.564411\n",
      "0.564411\n",
      "0.025\n",
      "0.025\n",
      "0.0675273\n",
      "0.0675273\n",
      "0.025\n",
      "0.025\n",
      "0.822995\n",
      "0.822995\n",
      "0.324088\n",
      "0.324088\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0288655\n",
      "0.0288655\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0609331\n",
      "0.0609331\n",
      "0.549675\n",
      "0.549675\n",
      "0.529369\n",
      "0.529369\n",
      "0.154388\n",
      "0.154388\n",
      "0.025\n",
      "0.025\n",
      "0.0522097\n",
      "0.0522097\n",
      "0.113709\n",
      "0.113709\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0713767\n",
      "0.0713767\n",
      "0.0598046\n",
      "0.0598046\n",
      "0.025\n",
      "0.025\n",
      "0.146916\n",
      "0.146916\n",
      "0.225519\n",
      "0.225519\n",
      "0.110309\n",
      "0.110309\n",
      "0.145114\n",
      "0.145114\n",
      "0.185779\n",
      "0.185779\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.130077\n",
      "0.130077\n",
      "0.975\n",
      "0.975\n",
      "0.0473946\n",
      "0.0473946\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.715051\n",
      "0.715051\n",
      "0.0543233\n",
      "0.0543233\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0587418\n",
      "0.0587418\n",
      "0.025\n",
      "0.025\n",
      "0.0474638\n",
      "0.0474638\n",
      "0.975\n",
      "0.975\n",
      "0.654061\n",
      "0.654061\n",
      "0.0551166\n",
      "0.0551166\n",
      "0.0876968\n",
      "0.0876968\n",
      "0.961667\n",
      "0.961667\n",
      "0.296605\n",
      "0.296605\n",
      "0.905173\n",
      "0.905173\n",
      "0.331519\n",
      "0.331519\n",
      "0.025\n",
      "0.025\n",
      "0.287459\n",
      "0.287459\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.314775\n",
      "0.314775\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.544655\n",
      "0.544655\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0695201\n",
      "0.0695201\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.972879\n",
      "0.972879\n",
      "0.964468\n",
      "0.964468\n",
      "0.815318\n",
      "0.815318\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.655109\n",
      "0.655109\n",
      "0.0495293\n",
      "0.0495293\n",
      "0.969095\n",
      "0.969095\n",
      "0.762373\n",
      "0.762373\n",
      "0.0568272\n",
      "0.0568272\n",
      "0.975\n",
      "0.975\n",
      "0.148831\n",
      "0.148831\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0409401\n",
      "0.0409401\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.548843\n",
      "0.548843\n",
      "0.974249\n",
      "0.974249\n",
      "0.417849\n",
      "0.417849\n",
      "0.188143\n",
      "0.188143\n",
      "0.025\n",
      "0.025\n",
      "0.101007\n",
      "0.101007\n",
      "0.025\n",
      "0.025\n",
      "0.633534\n",
      "0.633534\n",
      "0.354022\n",
      "0.354022\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.050023\n",
      "0.050023\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.372001\n",
      "0.372001\n",
      "0.975\n",
      "0.975\n",
      "0.0431706\n",
      "0.0431706\n",
      "0.9652\n",
      "0.9652\n",
      "0.0660726\n",
      "0.0660726\n",
      "0.0273804\n",
      "0.0273804\n",
      "0.025\n",
      "0.025\n",
      "0.21981\n",
      "0.21981\n",
      "0.025\n",
      "0.025\n",
      "0.0596445\n",
      "0.0596445\n",
      "0.242334\n",
      "0.242334\n",
      "0.57808\n",
      "0.57808\n",
      "0.712203\n",
      "0.712203\n",
      "0.0338142\n",
      "0.0338142\n",
      "0.040342\n",
      "0.040342\n",
      "0.420787\n",
      "0.420787\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.874137\n",
      "0.874137\n",
      "0.634238\n",
      "0.634238\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.928166\n",
      "0.928166\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.160992\n",
      "0.160992\n",
      "0.97168\n",
      "0.97168\n",
      "0.975\n",
      "0.975\n",
      "0.155959\n",
      "0.155959\n",
      "0.206312\n",
      "0.206312\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.963961\n",
      "0.963961\n",
      "0.962492\n",
      "0.962492\n",
      "0.0523355\n",
      "0.0523355\n",
      "0.312722\n",
      "0.312722\n",
      "0.025\n",
      "0.025\n",
      "0.299498\n",
      "0.299498\n",
      "0.0652006\n",
      "0.0652006\n",
      "0.12769\n",
      "0.12769\n",
      "0.33193\n",
      "0.33193\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.888555\n",
      "0.888555\n",
      "0.0985158\n",
      "0.0985158\n",
      "0.025\n",
      "0.025\n",
      "0.563175\n",
      "0.563175\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0748436\n",
      "0.0748436\n",
      "0.025\n",
      "0.025\n",
      "0.332328\n",
      "0.332328\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.406448\n",
      "0.406448\n",
      "0.025\n",
      "0.025\n",
      "0.223702\n",
      "0.223702\n",
      "0.117746\n",
      "0.117746\n",
      "0.167166\n",
      "0.167166\n",
      "0.975\n",
      "0.975\n",
      "0.429425\n",
      "0.429425\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.124871\n",
      "0.124871\n",
      "0.765578\n",
      "0.765578\n",
      "0.11309\n",
      "0.11309\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.331116\n",
      "0.331116\n",
      "0.025\n",
      "0.025\n",
      "0.728138\n",
      "0.728138\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.571023\n",
      "0.571023\n",
      "0.0999065\n",
      "0.0999065\n",
      "0.801838\n",
      "0.801838\n",
      "0.025\n",
      "0.025\n",
      "0.232768\n",
      "0.232768\n",
      "0.025\n",
      "0.025\n",
      "0.0905307\n",
      "0.0905307\n",
      "0.025\n",
      "0.025\n",
      "0.0881331\n",
      "0.0881331\n",
      "0.921838\n",
      "0.921838\n",
      "0.437144\n",
      "0.437144\n",
      "0.0294058\n",
      "0.0294058\n",
      "0.025\n",
      "0.025\n",
      "0.178028\n",
      "0.178028\n",
      "0.0716918\n",
      "0.0716918\n",
      "0.0627145\n",
      "0.0627145\n",
      "0.025\n",
      "0.025\n",
      "0.0968776\n",
      "0.0968776\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.908288\n",
      "0.908288\n",
      "0.122162\n",
      "0.122162\n",
      "0.025\n",
      "0.025\n",
      "0.39298\n",
      "0.39298\n",
      "0.025\n",
      "0.025\n",
      "0.143206\n",
      "0.143206\n",
      "0.95803\n",
      "0.95803\n",
      "0.882599\n",
      "0.882599\n",
      "0.302966\n",
      "0.302966\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.297037\n",
      "0.297037\n",
      "0.025\n",
      "0.025\n",
      "0.907914\n",
      "0.907914\n",
      "0.189242\n",
      "0.189242\n",
      "0.416165\n",
      "0.416165\n",
      "0.0837828\n",
      "0.0837828\n",
      "0.966876\n",
      "0.966876\n",
      "0.025\n",
      "0.025\n",
      "0.056675\n",
      "0.056675\n",
      "0.0924983\n",
      "0.0924983\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0791392\n",
      "0.0791392\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.257356\n",
      "0.257356\n",
      "0.15098\n",
      "0.15098\n",
      "0.025\n",
      "0.025\n",
      "0.38172\n",
      "0.38172\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.438214\n",
      "0.438214\n",
      "0.561167\n",
      "0.561167\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.348624\n",
      "0.348624\n",
      "0.811411\n",
      "0.811411\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0633457\n",
      "0.0633457\n",
      "0.025\n",
      "0.025\n",
      "0.0394851\n",
      "0.0394851\n",
      "0.025\n",
      "0.025\n",
      "0.0589287\n",
      "0.0589287\n",
      "0.0326151\n",
      "0.0326151\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.229247\n",
      "0.229247\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.542155\n",
      "0.542155\n",
      "0.93831\n",
      "0.93831\n",
      "0.0912808\n",
      "0.0912808\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.768546\n",
      "0.768546\n",
      "0.437773\n",
      "0.437773\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.610351\n",
      "0.610351\n",
      "0.358898\n",
      "0.358898\n",
      "0.443569\n",
      "0.443569\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0587279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0587279\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0456951\n",
      "0.0456951\n",
      "0.69682\n",
      "0.69682\n",
      "0.0802122\n",
      "0.0802122\n",
      "0.0264434\n",
      "0.0264434\n",
      "0.434921\n",
      "0.434921\n",
      "0.025\n",
      "0.025\n",
      "0.0282373\n",
      "0.0282373\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.216246\n",
      "0.216246\n",
      "0.0506829\n",
      "0.0506829\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n"
     ]
    }
   ],
   "source": [
    "# clipping\n",
    "for p in pred_test:\n",
    "    print(p[1])\n",
    "    val = p[1]\n",
    "    \n",
    "    if val < 0.025:\n",
    "        val = 0.025\n",
    "        \n",
    "    elif val > 0.975:\n",
    "        val = 0.975\n",
    "        \n",
    "    p[1] = val\n",
    "    \n",
    "    print(p[1])\n",
    "\n",
    "model.create_submission(pred_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmWXigmFmZpm4YJiZWSYuGGZmlsn/A9Vkft84Qj/jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b4c825048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b512793c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: davemodel\n",
      "Batch Size: 32\n",
      "Epochs: 80\n",
      "Epoch 1/80\n",
      "41/40 [==============================] - 2s - loss: 0.5765 - acc: 0.6737 - val_loss: 0.6837 - val_acc: 0.5670\n",
      "Epoch 2/80\n",
      "41/40 [==============================] - 1s - loss: 0.4909 - acc: 0.7430 - val_loss: 0.6349 - val_acc: 0.6573\n",
      "Epoch 3/80\n",
      "41/40 [==============================] - 1s - loss: 0.4433 - acc: 0.7682 - val_loss: 0.6643 - val_acc: 0.6573\n",
      "Epoch 4/80\n",
      "41/40 [==============================] - 1s - loss: 0.4224 - acc: 0.7971 - val_loss: 0.6887 - val_acc: 0.6573\n",
      "Epoch 5/80\n",
      "41/40 [==============================] - 1s - loss: 0.3804 - acc: 0.8159 - val_loss: 0.6811 - val_acc: 0.6573\n",
      "Epoch 6/80\n",
      "41/40 [==============================] - 1s - loss: 0.3792 - acc: 0.8174 - val_loss: 0.8034 - val_acc: 0.6573\n",
      "Epoch 7/80\n",
      "41/40 [==============================] - 1s - loss: 0.3465 - acc: 0.8437 - val_loss: 0.9113 - val_acc: 0.6573\n",
      "Epoch 8/80\n",
      "41/40 [==============================] - 1s - loss: 0.3302 - acc: 0.8460 - val_loss: 0.9754 - val_acc: 0.6573\n",
      "Epoch 9/80\n",
      "41/40 [==============================] - 1s - loss: 0.3422 - acc: 0.8277 - val_loss: 1.0176 - val_acc: 0.6573\n",
      "Epoch 10/80\n",
      "41/40 [==============================] - 1s - loss: 0.3366 - acc: 0.8487 - val_loss: 1.0009 - val_acc: 0.6573\n",
      "Epoch 11/80\n",
      "41/40 [==============================] - 1s - loss: 0.3125 - acc: 0.8609 - val_loss: 0.8933 - val_acc: 0.6604\n",
      "Epoch 12/80\n",
      "41/40 [==============================] - 1s - loss: 0.3141 - acc: 0.8456 - val_loss: 0.7405 - val_acc: 0.6760\n",
      "Epoch 13/80\n",
      "41/40 [==============================] - 1s - loss: 0.3301 - acc: 0.8346 - val_loss: 0.4606 - val_acc: 0.7819\n",
      "Epoch 14/80\n",
      "41/40 [==============================] - 1s - loss: 0.3040 - acc: 0.8559 - val_loss: 0.3596 - val_acc: 0.8629\n",
      "Epoch 15/80\n",
      "41/40 [==============================] - 1s - loss: 0.2859 - acc: 0.8757 - val_loss: 0.3398 - val_acc: 0.8598\n",
      "Epoch 16/80\n",
      "41/40 [==============================] - 1s - loss: 0.2894 - acc: 0.8650 - val_loss: 0.3511 - val_acc: 0.8193\n",
      "Epoch 17/80\n",
      "41/40 [==============================] - 1s - loss: 0.2941 - acc: 0.8696 - val_loss: 0.3133 - val_acc: 0.8380\n",
      "Epoch 18/80\n",
      "41/40 [==============================] - 1s - loss: 0.2901 - acc: 0.8719 - val_loss: 0.3440 - val_acc: 0.8131\n",
      "Epoch 19/80\n",
      "41/40 [==============================] - 1s - loss: 0.2919 - acc: 0.8627 - val_loss: 0.3159 - val_acc: 0.8567\n",
      "Epoch 20/80\n",
      "41/40 [==============================] - 1s - loss: 0.2822 - acc: 0.8726 - val_loss: 0.3472 - val_acc: 0.8193\n",
      "Epoch 21/80\n",
      "41/40 [==============================] - 1s - loss: 0.2879 - acc: 0.8662 - val_loss: 0.3698 - val_acc: 0.8006\n",
      "Epoch 22/80\n",
      "41/40 [==============================] - 1s - loss: 0.2997 - acc: 0.8693 - val_loss: 0.3786 - val_acc: 0.8442\n",
      "Epoch 23/80\n",
      "41/40 [==============================] - 1s - loss: 0.3032 - acc: 0.8578 - val_loss: 0.3248 - val_acc: 0.8411\n",
      "Epoch 24/80\n",
      "41/40 [==============================] - 1s - loss: 0.2995 - acc: 0.8529 - val_loss: 0.3609 - val_acc: 0.8100\n",
      "Epoch 25/80\n",
      "41/40 [==============================] - 1s - loss: 0.3014 - acc: 0.8624 - val_loss: 0.2994 - val_acc: 0.8941\n",
      "Epoch 26/80\n",
      "41/40 [==============================] - 1s - loss: 0.2885 - acc: 0.8754 - val_loss: 0.3236 - val_acc: 0.8629\n",
      "Epoch 27/80\n",
      "41/40 [==============================] - 1s - loss: 0.2907 - acc: 0.8628 - val_loss: 0.3438 - val_acc: 0.8193\n",
      "Epoch 28/80\n",
      "41/40 [==============================] - 1s - loss: 0.2708 - acc: 0.8726 - val_loss: 0.3232 - val_acc: 0.8474\n",
      "Epoch 29/80\n",
      "41/40 [==============================] - 1s - loss: 0.2613 - acc: 0.8856 - val_loss: 0.2888 - val_acc: 0.8411\n",
      "Epoch 30/80\n",
      "41/40 [==============================] - 1s - loss: 0.2763 - acc: 0.8792 - val_loss: 0.3579 - val_acc: 0.8536\n",
      "Epoch 31/80\n",
      "41/40 [==============================] - 1s - loss: 0.2831 - acc: 0.8655 - val_loss: 0.3134 - val_acc: 0.8723\n",
      "Epoch 32/80\n",
      "41/40 [==============================] - 1s - loss: 0.2597 - acc: 0.8772 - val_loss: 0.2995 - val_acc: 0.9065\n",
      "Epoch 33/80\n",
      "41/40 [==============================] - 1s - loss: 0.2720 - acc: 0.8799 - val_loss: 0.2949 - val_acc: 0.8723\n",
      "Epoch 34/80\n",
      "41/40 [==============================] - 1s - loss: 0.2628 - acc: 0.8864 - val_loss: 0.2812 - val_acc: 0.8785\n",
      "Epoch 35/80\n",
      "41/40 [==============================] - 1s - loss: 0.2494 - acc: 0.8856 - val_loss: 0.3151 - val_acc: 0.8567\n",
      "Epoch 36/80\n",
      "41/40 [==============================] - 1s - loss: 0.2513 - acc: 0.8955 - val_loss: 0.3123 - val_acc: 0.8536\n",
      "Epoch 37/80\n",
      "41/40 [==============================] - 1s - loss: 0.2514 - acc: 0.8960 - val_loss: 0.3271 - val_acc: 0.8567\n",
      "Epoch 38/80\n",
      "41/40 [==============================] - 1s - loss: 0.2850 - acc: 0.8712 - val_loss: 0.2982 - val_acc: 0.8692\n",
      "Epoch 39/80\n",
      "41/40 [==============================] - 1s - loss: 0.2635 - acc: 0.8777 - val_loss: 0.3028 - val_acc: 0.8629\n",
      "Epoch 40/80\n",
      "41/40 [==============================] - 1s - loss: 0.2517 - acc: 0.8925 - val_loss: 0.2883 - val_acc: 0.8879\n",
      "Epoch 41/80\n",
      "41/40 [==============================] - 1s - loss: 0.2383 - acc: 0.9009 - val_loss: 0.3753 - val_acc: 0.8287\n",
      "Epoch 42/80\n",
      "41/40 [==============================] - 1s - loss: 0.2673 - acc: 0.8906 - val_loss: 0.3255 - val_acc: 0.8318\n",
      "Epoch 43/80\n",
      "41/40 [==============================] - 1s - loss: 0.2601 - acc: 0.8799 - val_loss: 0.2944 - val_acc: 0.8660\n",
      "Epoch 44/80\n",
      "41/40 [==============================] - 1s - loss: 0.2413 - acc: 0.9031 - val_loss: 0.2808 - val_acc: 0.8847\n",
      "Epoch 45/80\n",
      "41/40 [==============================] - 1s - loss: 0.2351 - acc: 0.9051 - val_loss: 0.2794 - val_acc: 0.8816\n",
      "Epoch 46/80\n",
      "41/40 [==============================] - 1s - loss: 0.2243 - acc: 0.9001 - val_loss: 0.3303 - val_acc: 0.8224\n",
      "Epoch 47/80\n",
      "41/40 [==============================] - 1s - loss: 0.2360 - acc: 0.8899 - val_loss: 0.3558 - val_acc: 0.8224\n",
      "Epoch 48/80\n",
      "41/40 [==============================] - 1s - loss: 0.2555 - acc: 0.8921 - val_loss: 0.2699 - val_acc: 0.8847\n",
      "Epoch 49/80\n",
      "41/40 [==============================] - 1s - loss: 0.2360 - acc: 0.9031 - val_loss: 0.3081 - val_acc: 0.8598\n",
      "Epoch 50/80\n",
      "41/40 [==============================] - 1s - loss: 0.2282 - acc: 0.9054 - val_loss: 0.3325 - val_acc: 0.8380\n",
      "Epoch 51/80\n",
      "41/40 [==============================] - 1s - loss: 0.2338 - acc: 0.9009 - val_loss: 0.3070 - val_acc: 0.8692\n",
      "Epoch 52/80\n",
      "41/40 [==============================] - 1s - loss: 0.2401 - acc: 0.8987 - val_loss: 0.2978 - val_acc: 0.9065\n",
      "Epoch 53/80\n",
      "41/40 [==============================] - 1s - loss: 0.2266 - acc: 0.9021 - val_loss: 0.2704 - val_acc: 0.8972\n",
      "Epoch 54/80\n",
      "41/40 [==============================] - 1s - loss: 0.2420 - acc: 0.8876 - val_loss: 0.2708 - val_acc: 0.9003\n",
      "Epoch 55/80\n",
      "41/40 [==============================] - 1s - loss: 0.2212 - acc: 0.9039 - val_loss: 0.2869 - val_acc: 0.8785\n",
      "Epoch 56/80\n",
      "41/40 [==============================] - 1s - loss: 0.2193 - acc: 0.9062 - val_loss: 0.3133 - val_acc: 0.8442\n",
      "Epoch 57/80\n",
      "41/40 [==============================] - 1s - loss: 0.2128 - acc: 0.9062 - val_loss: 0.2823 - val_acc: 0.8910\n",
      "Epoch 58/80\n",
      "41/40 [==============================] - 1s - loss: 0.2063 - acc: 0.9123 - val_loss: 0.3018 - val_acc: 0.8598\n",
      "Epoch 59/80\n",
      "41/40 [==============================] - 1s - loss: 0.2373 - acc: 0.9005 - val_loss: 0.3088 - val_acc: 0.8660\n",
      "Epoch 60/80\n",
      "41/40 [==============================] - 1s - loss: 0.2097 - acc: 0.9115 - val_loss: 0.3084 - val_acc: 0.8629\n",
      "Epoch 61/80\n",
      "41/40 [==============================] - 1s - loss: 0.2298 - acc: 0.8998 - val_loss: 0.2661 - val_acc: 0.9003\n",
      "Epoch 62/80\n",
      "41/40 [==============================] - 1s - loss: 0.2239 - acc: 0.8982 - val_loss: 0.2739 - val_acc: 0.8879\n",
      "Epoch 63/80\n",
      "41/40 [==============================] - 1s - loss: 0.2231 - acc: 0.9108 - val_loss: 0.2773 - val_acc: 0.8785\n",
      "Epoch 64/80\n",
      "41/40 [==============================] - 1s - loss: 0.2170 - acc: 0.8990 - val_loss: 0.2567 - val_acc: 0.8941\n",
      "Epoch 65/80\n",
      "41/40 [==============================] - 1s - loss: 0.2205 - acc: 0.8998 - val_loss: 0.2956 - val_acc: 0.8629\n",
      "Epoch 66/80\n",
      "41/40 [==============================] - 1s - loss: 0.2053 - acc: 0.9154 - val_loss: 0.3399 - val_acc: 0.8411\n",
      "Epoch 67/80\n",
      "41/40 [==============================] - 1s - loss: 0.2076 - acc: 0.9150 - val_loss: 0.3790 - val_acc: 0.8069\n",
      "Epoch 68/80\n",
      "41/40 [==============================] - 1s - loss: 0.2085 - acc: 0.9085 - val_loss: 0.2666 - val_acc: 0.8972\n",
      "Epoch 69/80\n",
      "41/40 [==============================] - 1s - loss: 0.2015 - acc: 0.9192 - val_loss: 0.2968 - val_acc: 0.8660\n",
      "Epoch 70/80\n",
      "41/40 [==============================] - 1s - loss: 0.2027 - acc: 0.9184 - val_loss: 0.3313 - val_acc: 0.8380\n",
      "Epoch 71/80\n",
      "41/40 [==============================] - 1s - loss: 0.2092 - acc: 0.9184 - val_loss: 0.2806 - val_acc: 0.8941\n",
      "Epoch 72/80\n",
      "41/40 [==============================] - 1s - loss: 0.2120 - acc: 0.9123 - val_loss: 0.2785 - val_acc: 0.8785\n",
      "Epoch 73/80\n",
      "41/40 [==============================] - 1s - loss: 0.2019 - acc: 0.9165 - val_loss: 0.3200 - val_acc: 0.8567\n",
      "Epoch 74/80\n",
      "41/40 [==============================] - 1s - loss: 0.1963 - acc: 0.9138 - val_loss: 0.2473 - val_acc: 0.9034\n",
      "Epoch 75/80\n",
      "41/40 [==============================] - 1s - loss: 0.1991 - acc: 0.9123 - val_loss: 0.3455 - val_acc: 0.8349\n",
      "Epoch 76/80\n",
      "41/40 [==============================] - 1s - loss: 0.2243 - acc: 0.9051 - val_loss: 0.3038 - val_acc: 0.8567\n",
      "Epoch 77/80\n",
      "41/40 [==============================] - 1s - loss: 0.2285 - acc: 0.9097 - val_loss: 0.2891 - val_acc: 0.8692\n",
      "Epoch 78/80\n",
      "41/40 [==============================] - 1s - loss: 0.1949 - acc: 0.9176 - val_loss: 0.3076 - val_acc: 0.8505\n",
      "Epoch 79/80\n",
      "41/40 [==============================] - 1s - loss: 0.1888 - acc: 0.9222 - val_loss: 0.3142 - val_acc: 0.8505\n",
      "Epoch 80/80\n",
      "41/40 [==============================] - 1s - loss: 0.2064 - acc: 0.9120 - val_loss: 0.2938 - val_acc: 0.8660\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wFrDNZubohy+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b5552dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTQpKKaXKaVJQSilV7v8B93C+wKL5Cq0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b5fc939b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DaveModel(Xtr, ytr, Xv, yv)\n",
    "model.train(32, 80)\n",
    "model.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Reshape\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.layers import Add, add\n",
    "from keras.layers import Multiply, multiply\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class SEResNeXt(object):\n",
    "    def __init__(self, size=96, num_classes=10, depth=64, reduction_ratio=4, num_split=8, num_block=3):\n",
    "        self.depth = depth # number of channels\n",
    "        self.ratio = reduction_ratio # ratio of channel reduction in SE module\n",
    "        self.num_split = num_split # number of splitting trees for ResNeXt (so called cardinality)\n",
    "        self.num_block = num_block # number of residual blocks\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            self.channel_axis = 1\n",
    "        else:\n",
    "            self.channel_axis = 3\n",
    "        self.model = self.build_model(Input(shape=(size,size,3)), num_classes)\n",
    "\n",
    "    def conv_bn(self, x, filters, kernel_size, stride, padding='same'):\n",
    "        '''\n",
    "        Combination of Conv and BN layers since these always appear together.\n",
    "        '''\n",
    "        x = Conv2D( filters=filters, kernel_size=[kernel_size, kernel_size]\n",
    "                               , strides=[stride, stride], padding=padding )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def activation(self, x, func='relu'):\n",
    "        '''\n",
    "        Activation layer.\n",
    "        '''\n",
    "        return Activation(func)(x)\n",
    "    \n",
    "    def channel_zeropad(self, x):\n",
    "        '''\n",
    "        Zero-padding for channle dimensions.\n",
    "        Note that padded channles are added like (Batch, H, W, 2/x + x + 2/x).\n",
    "        '''\n",
    "        shape = list(x.shape)\n",
    "        y = K.zeros_like(x)\n",
    "        \n",
    "        if self.channel_axis == 3:\n",
    "            y = y[:, :, :, :shape[self.channel_axis]//2]\n",
    "        else:\n",
    "            y = y[:, :shape[self.channel_axis]//2, :, :]\n",
    "        \n",
    "        return concatenate([y, x, y], self.channel_axis)\n",
    "    \n",
    "    def channel_zeropad_output(self, input_shape):\n",
    "        '''\n",
    "        Function for setting a channel dimension for zero padding.\n",
    "        '''\n",
    "        shape = list(input_shape)\n",
    "        shape[self.channel_axis] *= 2\n",
    "\n",
    "        return tuple(shape)\n",
    "    \n",
    "    def initial_layer(self, inputs):\n",
    "        '''\n",
    "        Initial layers includes {conv, BN, relu}.\n",
    "        '''\n",
    "        x = self.conv_bn(inputs, self.depth, 3, 1)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def transform_layer(self, x, stride):\n",
    "        '''\n",
    "        Transform layer has 2 {conv, BN, relu}.\n",
    "        '''\n",
    "        x = self.conv_bn(x, self.depth, 1, 1)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.conv_bn(x, self.depth, 3, stride)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def split_layer(self, x, stride):\n",
    "        '''\n",
    "        Parallel operation of transform layers for ResNeXt structure.\n",
    "        '''\n",
    "        splitted_branches = list()\n",
    "        for i in range(self.num_split):\n",
    "            branch = self.transform_layer(x, stride)\n",
    "            splitted_branches.append(branch)\n",
    "        \n",
    "        return concatenate(splitted_branches, axis=self.channel_axis)\n",
    "    \n",
    "    def squeeze_excitation_layer(self, x, out_dim):\n",
    "        '''\n",
    "        SE module performs inter-channel weighting.\n",
    "        '''\n",
    "        squeeze = GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        excitation = Dense(units=out_dim // self.ratio)(squeeze)\n",
    "        excitation = self.activation(excitation)\n",
    "        excitation = Dense(units=out_dim)(excitation)\n",
    "        excitation = self.activation(excitation, 'sigmoid')\n",
    "        excitation = Reshape((1,1,out_dim))(excitation)\n",
    "        \n",
    "        scale = multiply([x,excitation])\n",
    "        \n",
    "        return scale\n",
    "    \n",
    "    def residual_layer(self, x, out_dim):\n",
    "        '''\n",
    "        Residual block.\n",
    "        '''\n",
    "        for i in range(self.num_block):\n",
    "            input_dim = int(np.shape(x)[-1])\n",
    "            \n",
    "            if input_dim*2 == out_dim:\n",
    "                flag = True\n",
    "                stride = 2\n",
    "                channel = input_dim // 2\n",
    "            else:\n",
    "                flag = False\n",
    "                stride = 1\n",
    "            \n",
    "            subway_x = self.split_layer(x, stride)\n",
    "            subway_x = self.conv_bn(subway_x, out_dim, 1, 1)\n",
    "            subway_x = self.squeeze_excitation_layer(subway_x, out_dim)\n",
    "            \n",
    "            if flag:\n",
    "                pad_x = AveragePooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "                pad_x = Lambda(self.channel_zeropad, output_shape=self.channel_zeropad_output)(pad_x)\n",
    "            else:\n",
    "                pad_x = x\n",
    "            \n",
    "            x = self.activation(add([pad_x, subway_x]))\n",
    "                \n",
    "        return x\n",
    "    \n",
    "    def build_model(self, inputs, num_classes):\n",
    "        '''\n",
    "        Build a SENet model.\n",
    "        '''\n",
    "        x = self.initial_layer(inputs)\n",
    "        \n",
    "        x = self.residual_layer(x, out_dim=64)\n",
    "        x = self.residual_layer(x, out_dim=128)\n",
    "        x = self.residual_layer(x, out_dim=256)\n",
    "        \n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(units=num_classes, activation='softmax')(x)\n",
    "        \n",
    "        return Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SEResNeXtModel(DaveBaseModel):\n",
    "    def get_model(self):\n",
    "        model = SEResNeXt(75, 2)\n",
    "        \n",
    "        '''Create the FCN and return a keras model.'''\n",
    "\n",
    "#         model = Sequential()\n",
    "\n",
    "#         # Input image: 75x75x3\n",
    "#         model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "#         DaveModel.ConvBlock(model, 1, 32)\n",
    "#         # 37x37x32\n",
    "#         DaveModel.ConvBlock(model, 1, 64)\n",
    "#         # 18x18x64\n",
    "#         DaveModel.ConvBlock(model, 1, 128)\n",
    "#         # 9x9x128\n",
    "#         DaveModel.ConvBlock(model, 1, 128)\n",
    "#         # 4x4x128\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "#         model.add(GlobalAveragePooling2D())\n",
    "#         # 4x4x2\n",
    "#         model.add(Activation('softmax'))\n",
    "        \n",
    "        model.model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        return model.model\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"seresnext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SEResNeXtModel(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.train(16, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine import Layer, InputSpec\n",
    "try:\n",
    "    from keras import initializations\n",
    "except ImportError:\n",
    "    from keras import initializers as initializations\n",
    "import keras.backend as K\n",
    "\n",
    "class Scale(Layer):\n",
    "    '''Custom Layer for DenseNet used for BatchNormalization.\n",
    "    \n",
    "    Learns a set of weights and biases used for scaling the input data.\n",
    "    the output consists simply in an element-wise multiplication of the input\n",
    "    and a sum of a set of constants:\n",
    "\n",
    "        out = in * gamma + beta,\n",
    "\n",
    "    where 'gamma' and 'beta' are the weights and biases larned.\n",
    "\n",
    "    # Arguments\n",
    "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
    "            if your input tensor has shape (samples, channels, rows, cols),\n",
    "            set axis to 1 to normalize per feature map (channels axis).\n",
    "        momentum: momentum in the computation of the\n",
    "            exponential average of the mean and standard deviation\n",
    "            of the data, for feature-wise normalization.\n",
    "        weights: Initialization weights.\n",
    "            List of 2 Numpy arrays, with shapes:\n",
    "            `[(input_shape,), (input_shape,)]`\n",
    "        beta_init: name of initialization function for shift parameter\n",
    "            (see [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        gamma_init: name of initialization function for scale parameter (see\n",
    "            [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "    '''\n",
    "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
    "        self.momentum = momentum\n",
    "        self.axis = axis\n",
    "        self.beta_init = initializations.get(beta_init)\n",
    "        self.gamma_init = initializations.get(gamma_init)\n",
    "        self.initial_weights = weights\n",
    "        super(Scale, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (int(input_shape[self.axis]),)\n",
    "\n",
    "        # Tensorflow >= 1.0.0 compatibility\n",
    "        self.gamma = K.variable(self.gamma_init(shape), name='{}_gamma'.format(self.name))\n",
    "        self.beta = K.variable(self.beta_init(shape), name='{}_beta'.format(self.name))\n",
    "        #self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))\n",
    "        #self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n",
    "        self.trainable_weights = [self.gamma, self.beta]\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
    "        base_config = super(Scale, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, ZeroPadding2D\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def DenseNet(nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4, classes=1000, weights_path=None):\n",
    "    '''Instantiate the DenseNet 121 architecture,\n",
    "        # Arguments\n",
    "            nb_dense_block: number of dense blocks to add to end\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_filter: initial number of filters\n",
    "            reduction: reduction factor of transition blocks.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            classes: optional number of classes to classify images\n",
    "            weights_path: path to pre-trained weights\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "\n",
    "    # compute compression factor\n",
    "    compression = 1.0 - reduction\n",
    "\n",
    "    # Handle Dimension Ordering for different backends\n",
    "    global concat_axis\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "      concat_axis = 3\n",
    "      img_input = Input(shape=(75, 75, 3), name='data')\n",
    "    else:\n",
    "      concat_axis = 1\n",
    "      img_input = Input(shape=(3, 75, 75), name='data')\n",
    "\n",
    "    # From architecture for ImageNet (Table 1 in the paper)\n",
    "    nb_filter = 64\n",
    "    nb_layers = [6,12,24,16] # For DenseNet-121\n",
    "\n",
    "    # Initial convolution\n",
    "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
    "    x = Convolution2D(nb_filter, 7, 7, subsample=(2, 2), name='conv1', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv1_scale')(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "    x = ZeroPadding2D((1, 1), name='pool1_zeropadding')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        stage = block_idx+2\n",
    "        x, nb_filter = dense_block(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "        # Add transition_block\n",
    "        x = transition_block(x, stage, nb_filter, compression=compression, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "        nb_filter = int(nb_filter * compression)\n",
    "\n",
    "    final_stage = stage + 1\n",
    "    x, nb_filter = dense_block(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv'+str(final_stage)+'_blk_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv'+str(final_stage)+'_blk_scale')(x)\n",
    "    x = Activation('relu', name='relu'+str(final_stage)+'_blk')(x)\n",
    "    x = GlobalAveragePooling2D(name='pool'+str(final_stage))(x)\n",
    "\n",
    "    x = Dense(classes, name='fc6')(x)\n",
    "    x = Activation('softmax', name='prob')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='densenet')\n",
    "\n",
    "    if weights_path is not None:\n",
    "      model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_block(x, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):\n",
    "    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout\n",
    "        # Arguments\n",
    "            x: input tensor \n",
    "            stage: index for dense block\n",
    "            branch: layer index within each dense block\n",
    "            nb_filter: number of filters\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_' + str(branch)\n",
    "    relu_name_base = 'relu' + str(stage) + '_' + str(branch)\n",
    "\n",
    "    # 1x1 Convolution (Bottleneck layer)\n",
    "    inter_channel = nb_filter * 4  \n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_x1_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base+'_x1')(x)\n",
    "    x = Convolution2D(inter_channel, 1, 1, name=conv_name_base+'_x1', bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 3x3 Convolution\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x2_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_x2_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base+'_x2')(x)\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base+'_x2_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter, 3, 3, name=conv_name_base+'_x2', bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
    "    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout \n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_filter: number of filters\n",
    "            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_blk'\n",
    "    relu_name_base = 'relu' + str(stage) + '_blk'\n",
    "    pool_name_base = 'pool' + str(stage) \n",
    "\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base)(x)\n",
    "    x = Convolution2D(int(nb_filter * compression), 1, 1, name=conv_name_base, bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2), name=pool_name_base)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_block(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True):\n",
    "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_layers: the number of layers of conv_block to append to the model.\n",
    "            nb_filter: number of filters\n",
    "            growth_rate: growth rate\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    concat_feat = x\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        branch = i+1\n",
    "        x = conv_block(concat_feat, stage, branch, growth_rate, dropout_rate, weight_decay)\n",
    "        concat_feat = merge([concat_feat, x], mode='concat', concat_axis=concat_axis, name='concat_'+str(stage)+'_'+str(branch))\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    return concat_feat, nb_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), use_bias=False, name=\"conv1\", strides=(2, 2))`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:238: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), use_bias=False, name=\"conv2_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(640, (1, 1), use_bias=False, name=\"conv3_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_1_x1\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_13_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_13_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_14_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_14_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_15_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_15_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_16_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_16_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_17_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_17_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_18_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_18_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_19_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_19_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_20_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_20_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_21_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_21_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_22_x1\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_22_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_23_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_23_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_24_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_24_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1408, (1, 1), use_bias=False, name=\"conv4_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_13_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_13_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_14_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_14_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_15_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_15_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_16_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_16_x2\")`\n"
     ]
    }
   ],
   "source": [
    "densemodel = DenseNet(classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "data (InputLayer)                (None, 75, 75, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2D (None, 81, 81, 3)     0           data[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 38, 38, 64)    9408        conv1_zeropadding[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)    (None, 38, 38, 64)    256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv1_scale (Scale)              (None, 38, 38, 64)    128         conv1_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "relu1 (Activation)               (None, 38, 38, 64)    0           conv1_scale[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "pool1_zeropadding (ZeroPadding2D (None, 40, 40, 64)    0           relu1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)             (None, 19, 19, 64)    0           pool1_zeropadding[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x1_bn (BatchNormalizatio (None, 19, 19, 64)    256         pool1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x1_scale (Scale)         (None, 19, 19, 64)    128         conv2_1_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_1_x1 (Activation)          (None, 19, 19, 64)    0           conv2_1_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x1 (Conv2D)              (None, 19, 19, 128)   8192        relu2_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_1_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_1_x2 (Activation)          (None, 19, 19, 128)   0           conv2_1_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_1_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_1 (Merge)               (None, 19, 19, 96)    0           pool1[0][0]                      \n",
      "                                                                   conv2_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x1_bn (BatchNormalizatio (None, 19, 19, 96)    384         concat_2_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x1_scale (Scale)         (None, 19, 19, 96)    192         conv2_2_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_2_x1 (Activation)          (None, 19, 19, 96)    0           conv2_2_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x1 (Conv2D)              (None, 19, 19, 128)   12288       relu2_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_2_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_2_x2 (Activation)          (None, 19, 19, 128)   0           conv2_2_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_2_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_2 (Merge)               (None, 19, 19, 128)   0           concat_2_1[0][0]                 \n",
      "                                                                   conv2_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x1_bn (BatchNormalizatio (None, 19, 19, 128)   512         concat_2_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x1_scale (Scale)         (None, 19, 19, 128)   256         conv2_3_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_3_x1 (Activation)          (None, 19, 19, 128)   0           conv2_3_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x1 (Conv2D)              (None, 19, 19, 128)   16384       relu2_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_3_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_3_x2 (Activation)          (None, 19, 19, 128)   0           conv2_3_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_3_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_3 (Merge)               (None, 19, 19, 160)   0           concat_2_2[0][0]                 \n",
      "                                                                   conv2_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x1_bn (BatchNormalizatio (None, 19, 19, 160)   640         concat_2_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x1_scale (Scale)         (None, 19, 19, 160)   320         conv2_4_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_4_x1 (Activation)          (None, 19, 19, 160)   0           conv2_4_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x1 (Conv2D)              (None, 19, 19, 128)   20480       relu2_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_4_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_4_x2 (Activation)          (None, 19, 19, 128)   0           conv2_4_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_4_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_4 (Merge)               (None, 19, 19, 192)   0           concat_2_3[0][0]                 \n",
      "                                                                   conv2_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x1_bn (BatchNormalizatio (None, 19, 19, 192)   768         concat_2_4[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x1_scale (Scale)         (None, 19, 19, 192)   384         conv2_5_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_5_x1 (Activation)          (None, 19, 19, 192)   0           conv2_5_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x1 (Conv2D)              (None, 19, 19, 128)   24576       relu2_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_5_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_5_x2 (Activation)          (None, 19, 19, 128)   0           conv2_5_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_5_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_5 (Merge)               (None, 19, 19, 224)   0           concat_2_4[0][0]                 \n",
      "                                                                   conv2_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x1_bn (BatchNormalizatio (None, 19, 19, 224)   896         concat_2_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x1_scale (Scale)         (None, 19, 19, 224)   448         conv2_6_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_6_x1 (Activation)          (None, 19, 19, 224)   0           conv2_6_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x1 (Conv2D)              (None, 19, 19, 128)   28672       relu2_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_6_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_6_x2 (Activation)          (None, 19, 19, 128)   0           conv2_6_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_6_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_6 (Merge)               (None, 19, 19, 256)   0           concat_2_5[0][0]                 \n",
      "                                                                   conv2_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_blk_bn (BatchNormalization (None, 19, 19, 256)   1024        concat_2_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_blk_scale (Scale)          (None, 19, 19, 256)   512         conv2_blk_bn[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu2_blk (Activation)           (None, 19, 19, 256)   0           conv2_blk_scale[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2_blk (Conv2D)               (None, 19, 19, 256)   65536       relu2_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pool2 (AveragePooling2D)         (None, 9, 9, 256)     0           conv2_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x1_bn (BatchNormalizatio (None, 9, 9, 256)     1024        pool2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x1_scale (Scale)         (None, 9, 9, 256)     512         conv3_1_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_1_x1 (Activation)          (None, 9, 9, 256)     0           conv3_1_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x1 (Conv2D)              (None, 9, 9, 128)     32768       relu3_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_1_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_1_x2 (Activation)          (None, 9, 9, 128)     0           conv3_1_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_1_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_1 (Merge)               (None, 9, 9, 288)     0           pool2[0][0]                      \n",
      "                                                                   conv3_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x1_bn (BatchNormalizatio (None, 9, 9, 288)     1152        concat_3_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x1_scale (Scale)         (None, 9, 9, 288)     576         conv3_2_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_2_x1 (Activation)          (None, 9, 9, 288)     0           conv3_2_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x1 (Conv2D)              (None, 9, 9, 128)     36864       relu3_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_2_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_2_x2 (Activation)          (None, 9, 9, 128)     0           conv3_2_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_2_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_2 (Merge)               (None, 9, 9, 320)     0           concat_3_1[0][0]                 \n",
      "                                                                   conv3_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x1_bn (BatchNormalizatio (None, 9, 9, 320)     1280        concat_3_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x1_scale (Scale)         (None, 9, 9, 320)     640         conv3_3_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_3_x1 (Activation)          (None, 9, 9, 320)     0           conv3_3_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x1 (Conv2D)              (None, 9, 9, 128)     40960       relu3_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_3_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_3_x2 (Activation)          (None, 9, 9, 128)     0           conv3_3_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_3_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_3 (Merge)               (None, 9, 9, 352)     0           concat_3_2[0][0]                 \n",
      "                                                                   conv3_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x1_bn (BatchNormalizatio (None, 9, 9, 352)     1408        concat_3_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x1_scale (Scale)         (None, 9, 9, 352)     704         conv3_4_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_4_x1 (Activation)          (None, 9, 9, 352)     0           conv3_4_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x1 (Conv2D)              (None, 9, 9, 128)     45056       relu3_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_4_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_4_x2 (Activation)          (None, 9, 9, 128)     0           conv3_4_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_4_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_4 (Merge)               (None, 9, 9, 384)     0           concat_3_3[0][0]                 \n",
      "                                                                   conv3_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x1_bn (BatchNormalizatio (None, 9, 9, 384)     1536        concat_3_4[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x1_scale (Scale)         (None, 9, 9, 384)     768         conv3_5_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_5_x1 (Activation)          (None, 9, 9, 384)     0           conv3_5_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x1 (Conv2D)              (None, 9, 9, 128)     49152       relu3_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_5_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_5_x2 (Activation)          (None, 9, 9, 128)     0           conv3_5_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_5_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_5 (Merge)               (None, 9, 9, 416)     0           concat_3_4[0][0]                 \n",
      "                                                                   conv3_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x1_bn (BatchNormalizatio (None, 9, 9, 416)     1664        concat_3_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x1_scale (Scale)         (None, 9, 9, 416)     832         conv3_6_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_6_x1 (Activation)          (None, 9, 9, 416)     0           conv3_6_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x1 (Conv2D)              (None, 9, 9, 128)     53248       relu3_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_6_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_6_x2 (Activation)          (None, 9, 9, 128)     0           conv3_6_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_6_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_6 (Merge)               (None, 9, 9, 448)     0           concat_3_5[0][0]                 \n",
      "                                                                   conv3_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x1_bn (BatchNormalizatio (None, 9, 9, 448)     1792        concat_3_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x1_scale (Scale)         (None, 9, 9, 448)     896         conv3_7_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_7_x1 (Activation)          (None, 9, 9, 448)     0           conv3_7_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x1 (Conv2D)              (None, 9, 9, 128)     57344       relu3_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_7_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_7_x2 (Activation)          (None, 9, 9, 128)     0           conv3_7_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_7_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_7 (Merge)               (None, 9, 9, 480)     0           concat_3_6[0][0]                 \n",
      "                                                                   conv3_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x1_bn (BatchNormalizatio (None, 9, 9, 480)     1920        concat_3_7[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x1_scale (Scale)         (None, 9, 9, 480)     960         conv3_8_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_8_x1 (Activation)          (None, 9, 9, 480)     0           conv3_8_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x1 (Conv2D)              (None, 9, 9, 128)     61440       relu3_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_8_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_8_x2 (Activation)          (None, 9, 9, 128)     0           conv3_8_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_8_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_8 (Merge)               (None, 9, 9, 512)     0           concat_3_7[0][0]                 \n",
      "                                                                   conv3_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x1_bn (BatchNormalizatio (None, 9, 9, 512)     2048        concat_3_8[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x1_scale (Scale)         (None, 9, 9, 512)     1024        conv3_9_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_9_x1 (Activation)          (None, 9, 9, 512)     0           conv3_9_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x1 (Conv2D)              (None, 9, 9, 128)     65536       relu3_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_9_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_9_x2 (Activation)          (None, 9, 9, 128)     0           conv3_9_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_9_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_9 (Merge)               (None, 9, 9, 544)     0           concat_3_8[0][0]                 \n",
      "                                                                   conv3_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x1_bn (BatchNormalizati (None, 9, 9, 544)     2176        concat_3_9[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x1_scale (Scale)        (None, 9, 9, 544)     1088        conv3_10_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_10_x1 (Activation)         (None, 9, 9, 544)     0           conv3_10_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x1 (Conv2D)             (None, 9, 9, 128)     69632       relu3_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x2_bn (BatchNormalizati (None, 9, 9, 128)     512         conv3_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x2_scale (Scale)        (None, 9, 9, 128)     256         conv3_10_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_10_x2 (Activation)         (None, 9, 9, 128)     0           conv3_10_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x2_zeropadding (ZeroPad (None, 11, 11, 128)   0           relu3_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x2 (Conv2D)             (None, 9, 9, 32)      36864       conv3_10_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_10 (Merge)              (None, 9, 9, 576)     0           concat_3_9[0][0]                 \n",
      "                                                                   conv3_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x1_bn (BatchNormalizati (None, 9, 9, 576)     2304        concat_3_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x1_scale (Scale)        (None, 9, 9, 576)     1152        conv3_11_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_11_x1 (Activation)         (None, 9, 9, 576)     0           conv3_11_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x1 (Conv2D)             (None, 9, 9, 128)     73728       relu3_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x2_bn (BatchNormalizati (None, 9, 9, 128)     512         conv3_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x2_scale (Scale)        (None, 9, 9, 128)     256         conv3_11_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_11_x2 (Activation)         (None, 9, 9, 128)     0           conv3_11_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x2_zeropadding (ZeroPad (None, 11, 11, 128)   0           relu3_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x2 (Conv2D)             (None, 9, 9, 32)      36864       conv3_11_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_11 (Merge)              (None, 9, 9, 608)     0           concat_3_10[0][0]                \n",
      "                                                                   conv3_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x1_bn (BatchNormalizati (None, 9, 9, 608)     2432        concat_3_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x1_scale (Scale)        (None, 9, 9, 608)     1216        conv3_12_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_12_x1 (Activation)         (None, 9, 9, 608)     0           conv3_12_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x1 (Conv2D)             (None, 9, 9, 128)     77824       relu3_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x2_bn (BatchNormalizati (None, 9, 9, 128)     512         conv3_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x2_scale (Scale)        (None, 9, 9, 128)     256         conv3_12_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_12_x2 (Activation)         (None, 9, 9, 128)     0           conv3_12_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x2_zeropadding (ZeroPad (None, 11, 11, 128)   0           relu3_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x2 (Conv2D)             (None, 9, 9, 32)      36864       conv3_12_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_12 (Merge)              (None, 9, 9, 640)     0           concat_3_11[0][0]                \n",
      "                                                                   conv3_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_blk_bn (BatchNormalization (None, 9, 9, 640)     2560        concat_3_12[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_blk_scale (Scale)          (None, 9, 9, 640)     1280        conv3_blk_bn[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu3_blk (Activation)           (None, 9, 9, 640)     0           conv3_blk_scale[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv3_blk (Conv2D)               (None, 9, 9, 640)     409600      relu3_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pool3 (AveragePooling2D)         (None, 4, 4, 640)     0           conv3_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x1_bn (BatchNormalizatio (None, 4, 4, 640)     2560        pool3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x1_scale (Scale)         (None, 4, 4, 640)     1280        conv4_1_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_1_x1 (Activation)          (None, 4, 4, 640)     0           conv4_1_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x1 (Conv2D)              (None, 4, 4, 128)     81920       relu4_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_1_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_1_x2 (Activation)          (None, 4, 4, 128)     0           conv4_1_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_1_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_1 (Merge)               (None, 4, 4, 672)     0           pool3[0][0]                      \n",
      "                                                                   conv4_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x1_bn (BatchNormalizatio (None, 4, 4, 672)     2688        concat_4_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x1_scale (Scale)         (None, 4, 4, 672)     1344        conv4_2_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_2_x1 (Activation)          (None, 4, 4, 672)     0           conv4_2_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x1 (Conv2D)              (None, 4, 4, 128)     86016       relu4_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_2_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_2_x2 (Activation)          (None, 4, 4, 128)     0           conv4_2_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_2_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_2 (Merge)               (None, 4, 4, 704)     0           concat_4_1[0][0]                 \n",
      "                                                                   conv4_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x1_bn (BatchNormalizatio (None, 4, 4, 704)     2816        concat_4_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x1_scale (Scale)         (None, 4, 4, 704)     1408        conv4_3_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_3_x1 (Activation)          (None, 4, 4, 704)     0           conv4_3_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x1 (Conv2D)              (None, 4, 4, 128)     90112       relu4_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_3_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_3_x2 (Activation)          (None, 4, 4, 128)     0           conv4_3_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_3_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_3 (Merge)               (None, 4, 4, 736)     0           concat_4_2[0][0]                 \n",
      "                                                                   conv4_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x1_bn (BatchNormalizatio (None, 4, 4, 736)     2944        concat_4_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x1_scale (Scale)         (None, 4, 4, 736)     1472        conv4_4_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_4_x1 (Activation)          (None, 4, 4, 736)     0           conv4_4_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x1 (Conv2D)              (None, 4, 4, 128)     94208       relu4_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_4_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_4_x2 (Activation)          (None, 4, 4, 128)     0           conv4_4_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_4_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_4 (Merge)               (None, 4, 4, 768)     0           concat_4_3[0][0]                 \n",
      "                                                                   conv4_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x1_bn (BatchNormalizatio (None, 4, 4, 768)     3072        concat_4_4[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x1_scale (Scale)         (None, 4, 4, 768)     1536        conv4_5_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_5_x1 (Activation)          (None, 4, 4, 768)     0           conv4_5_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x1 (Conv2D)              (None, 4, 4, 128)     98304       relu4_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_5_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_5_x2 (Activation)          (None, 4, 4, 128)     0           conv4_5_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_5_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_5 (Merge)               (None, 4, 4, 800)     0           concat_4_4[0][0]                 \n",
      "                                                                   conv4_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x1_bn (BatchNormalizatio (None, 4, 4, 800)     3200        concat_4_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x1_scale (Scale)         (None, 4, 4, 800)     1600        conv4_6_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_6_x1 (Activation)          (None, 4, 4, 800)     0           conv4_6_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x1 (Conv2D)              (None, 4, 4, 128)     102400      relu4_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_6_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_6_x2 (Activation)          (None, 4, 4, 128)     0           conv4_6_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_6_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_6 (Merge)               (None, 4, 4, 832)     0           concat_4_5[0][0]                 \n",
      "                                                                   conv4_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x1_bn (BatchNormalizatio (None, 4, 4, 832)     3328        concat_4_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x1_scale (Scale)         (None, 4, 4, 832)     1664        conv4_7_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_7_x1 (Activation)          (None, 4, 4, 832)     0           conv4_7_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x1 (Conv2D)              (None, 4, 4, 128)     106496      relu4_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_7_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_7_x2 (Activation)          (None, 4, 4, 128)     0           conv4_7_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_7_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_7 (Merge)               (None, 4, 4, 864)     0           concat_4_6[0][0]                 \n",
      "                                                                   conv4_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x1_bn (BatchNormalizatio (None, 4, 4, 864)     3456        concat_4_7[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x1_scale (Scale)         (None, 4, 4, 864)     1728        conv4_8_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_8_x1 (Activation)          (None, 4, 4, 864)     0           conv4_8_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x1 (Conv2D)              (None, 4, 4, 128)     110592      relu4_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_8_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_8_x2 (Activation)          (None, 4, 4, 128)     0           conv4_8_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_8_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_8 (Merge)               (None, 4, 4, 896)     0           concat_4_7[0][0]                 \n",
      "                                                                   conv4_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x1_bn (BatchNormalizatio (None, 4, 4, 896)     3584        concat_4_8[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x1_scale (Scale)         (None, 4, 4, 896)     1792        conv4_9_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_9_x1 (Activation)          (None, 4, 4, 896)     0           conv4_9_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x1 (Conv2D)              (None, 4, 4, 128)     114688      relu4_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_9_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_9_x2 (Activation)          (None, 4, 4, 128)     0           conv4_9_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_9_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_9 (Merge)               (None, 4, 4, 928)     0           concat_4_8[0][0]                 \n",
      "                                                                   conv4_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x1_bn (BatchNormalizati (None, 4, 4, 928)     3712        concat_4_9[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x1_scale (Scale)        (None, 4, 4, 928)     1856        conv4_10_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_10_x1 (Activation)         (None, 4, 4, 928)     0           conv4_10_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x1 (Conv2D)             (None, 4, 4, 128)     118784      relu4_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_10_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_10_x2 (Activation)         (None, 4, 4, 128)     0           conv4_10_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_10_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_10 (Merge)              (None, 4, 4, 960)     0           concat_4_9[0][0]                 \n",
      "                                                                   conv4_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x1_bn (BatchNormalizati (None, 4, 4, 960)     3840        concat_4_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x1_scale (Scale)        (None, 4, 4, 960)     1920        conv4_11_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_11_x1 (Activation)         (None, 4, 4, 960)     0           conv4_11_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x1 (Conv2D)             (None, 4, 4, 128)     122880      relu4_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_11_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_11_x2 (Activation)         (None, 4, 4, 128)     0           conv4_11_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_11_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_11 (Merge)              (None, 4, 4, 992)     0           concat_4_10[0][0]                \n",
      "                                                                   conv4_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x1_bn (BatchNormalizati (None, 4, 4, 992)     3968        concat_4_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x1_scale (Scale)        (None, 4, 4, 992)     1984        conv4_12_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_12_x1 (Activation)         (None, 4, 4, 992)     0           conv4_12_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x1 (Conv2D)             (None, 4, 4, 128)     126976      relu4_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_12_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_12_x2 (Activation)         (None, 4, 4, 128)     0           conv4_12_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_12_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_12 (Merge)              (None, 4, 4, 1024)    0           concat_4_11[0][0]                \n",
      "                                                                   conv4_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x1_bn (BatchNormalizati (None, 4, 4, 1024)    4096        concat_4_12[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x1_scale (Scale)        (None, 4, 4, 1024)    2048        conv4_13_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_13_x1 (Activation)         (None, 4, 4, 1024)    0           conv4_13_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x1 (Conv2D)             (None, 4, 4, 128)     131072      relu4_13_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_13_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_13_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_13_x2 (Activation)         (None, 4, 4, 128)     0           conv4_13_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_13_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_13_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_13 (Merge)              (None, 4, 4, 1056)    0           concat_4_12[0][0]                \n",
      "                                                                   conv4_13_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x1_bn (BatchNormalizati (None, 4, 4, 1056)    4224        concat_4_13[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x1_scale (Scale)        (None, 4, 4, 1056)    2112        conv4_14_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_14_x1 (Activation)         (None, 4, 4, 1056)    0           conv4_14_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x1 (Conv2D)             (None, 4, 4, 128)     135168      relu4_14_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_14_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_14_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_14_x2 (Activation)         (None, 4, 4, 128)     0           conv4_14_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_14_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_14_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_14 (Merge)              (None, 4, 4, 1088)    0           concat_4_13[0][0]                \n",
      "                                                                   conv4_14_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x1_bn (BatchNormalizati (None, 4, 4, 1088)    4352        concat_4_14[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x1_scale (Scale)        (None, 4, 4, 1088)    2176        conv4_15_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_15_x1 (Activation)         (None, 4, 4, 1088)    0           conv4_15_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x1 (Conv2D)             (None, 4, 4, 128)     139264      relu4_15_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_15_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_15_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_15_x2 (Activation)         (None, 4, 4, 128)     0           conv4_15_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_15_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_15_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_15 (Merge)              (None, 4, 4, 1120)    0           concat_4_14[0][0]                \n",
      "                                                                   conv4_15_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x1_bn (BatchNormalizati (None, 4, 4, 1120)    4480        concat_4_15[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x1_scale (Scale)        (None, 4, 4, 1120)    2240        conv4_16_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_16_x1 (Activation)         (None, 4, 4, 1120)    0           conv4_16_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x1 (Conv2D)             (None, 4, 4, 128)     143360      relu4_16_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_16_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_16_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_16_x2 (Activation)         (None, 4, 4, 128)     0           conv4_16_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_16_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_16_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_16 (Merge)              (None, 4, 4, 1152)    0           concat_4_15[0][0]                \n",
      "                                                                   conv4_16_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x1_bn (BatchNormalizati (None, 4, 4, 1152)    4608        concat_4_16[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x1_scale (Scale)        (None, 4, 4, 1152)    2304        conv4_17_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_17_x1 (Activation)         (None, 4, 4, 1152)    0           conv4_17_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x1 (Conv2D)             (None, 4, 4, 128)     147456      relu4_17_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_17_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_17_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_17_x2 (Activation)         (None, 4, 4, 128)     0           conv4_17_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_17_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_17_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_17 (Merge)              (None, 4, 4, 1184)    0           concat_4_16[0][0]                \n",
      "                                                                   conv4_17_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x1_bn (BatchNormalizati (None, 4, 4, 1184)    4736        concat_4_17[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x1_scale (Scale)        (None, 4, 4, 1184)    2368        conv4_18_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_18_x1 (Activation)         (None, 4, 4, 1184)    0           conv4_18_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x1 (Conv2D)             (None, 4, 4, 128)     151552      relu4_18_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_18_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_18_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_18_x2 (Activation)         (None, 4, 4, 128)     0           conv4_18_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_18_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_18_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_18 (Merge)              (None, 4, 4, 1216)    0           concat_4_17[0][0]                \n",
      "                                                                   conv4_18_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x1_bn (BatchNormalizati (None, 4, 4, 1216)    4864        concat_4_18[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x1_scale (Scale)        (None, 4, 4, 1216)    2432        conv4_19_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_19_x1 (Activation)         (None, 4, 4, 1216)    0           conv4_19_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x1 (Conv2D)             (None, 4, 4, 128)     155648      relu4_19_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_19_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_19_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_19_x2 (Activation)         (None, 4, 4, 128)     0           conv4_19_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_19_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_19_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_19 (Merge)              (None, 4, 4, 1248)    0           concat_4_18[0][0]                \n",
      "                                                                   conv4_19_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x1_bn (BatchNormalizati (None, 4, 4, 1248)    4992        concat_4_19[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x1_scale (Scale)        (None, 4, 4, 1248)    2496        conv4_20_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_20_x1 (Activation)         (None, 4, 4, 1248)    0           conv4_20_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x1 (Conv2D)             (None, 4, 4, 128)     159744      relu4_20_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_20_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_20_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_20_x2 (Activation)         (None, 4, 4, 128)     0           conv4_20_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_20_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_20_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_20 (Merge)              (None, 4, 4, 1280)    0           concat_4_19[0][0]                \n",
      "                                                                   conv4_20_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x1_bn (BatchNormalizati (None, 4, 4, 1280)    5120        concat_4_20[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x1_scale (Scale)        (None, 4, 4, 1280)    2560        conv4_21_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_21_x1 (Activation)         (None, 4, 4, 1280)    0           conv4_21_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x1 (Conv2D)             (None, 4, 4, 128)     163840      relu4_21_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_21_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_21_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_21_x2 (Activation)         (None, 4, 4, 128)     0           conv4_21_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_21_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_21_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_21 (Merge)              (None, 4, 4, 1312)    0           concat_4_20[0][0]                \n",
      "                                                                   conv4_21_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x1_bn (BatchNormalizati (None, 4, 4, 1312)    5248        concat_4_21[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x1_scale (Scale)        (None, 4, 4, 1312)    2624        conv4_22_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_22_x1 (Activation)         (None, 4, 4, 1312)    0           conv4_22_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x1 (Conv2D)             (None, 4, 4, 128)     167936      relu4_22_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_22_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_22_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_22_x2 (Activation)         (None, 4, 4, 128)     0           conv4_22_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_22_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_22_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_22 (Merge)              (None, 4, 4, 1344)    0           concat_4_21[0][0]                \n",
      "                                                                   conv4_22_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x1_bn (BatchNormalizati (None, 4, 4, 1344)    5376        concat_4_22[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x1_scale (Scale)        (None, 4, 4, 1344)    2688        conv4_23_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_23_x1 (Activation)         (None, 4, 4, 1344)    0           conv4_23_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x1 (Conv2D)             (None, 4, 4, 128)     172032      relu4_23_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_23_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_23_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_23_x2 (Activation)         (None, 4, 4, 128)     0           conv4_23_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_23_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_23_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_23 (Merge)              (None, 4, 4, 1376)    0           concat_4_22[0][0]                \n",
      "                                                                   conv4_23_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x1_bn (BatchNormalizati (None, 4, 4, 1376)    5504        concat_4_23[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x1_scale (Scale)        (None, 4, 4, 1376)    2752        conv4_24_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_24_x1 (Activation)         (None, 4, 4, 1376)    0           conv4_24_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x1 (Conv2D)             (None, 4, 4, 128)     176128      relu4_24_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_24_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_24_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_24_x2 (Activation)         (None, 4, 4, 128)     0           conv4_24_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_24_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_24_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_24 (Merge)              (None, 4, 4, 1408)    0           concat_4_23[0][0]                \n",
      "                                                                   conv4_24_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_blk_bn (BatchNormalization (None, 4, 4, 1408)    5632        concat_4_24[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_blk_scale (Scale)          (None, 4, 4, 1408)    2816        conv4_blk_bn[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu4_blk (Activation)           (None, 4, 4, 1408)    0           conv4_blk_scale[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv4_blk (Conv2D)               (None, 4, 4, 1408)    1982464     relu4_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pool4 (AveragePooling2D)         (None, 2, 2, 1408)    0           conv4_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x1_bn (BatchNormalizatio (None, 2, 2, 1408)    5632        pool4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x1_scale (Scale)         (None, 2, 2, 1408)    2816        conv5_1_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_1_x1 (Activation)          (None, 2, 2, 1408)    0           conv5_1_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x1 (Conv2D)              (None, 2, 2, 128)     180224      relu5_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_1_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_1_x2 (Activation)          (None, 2, 2, 128)     0           conv5_1_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_1_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_1 (Merge)               (None, 2, 2, 1440)    0           pool4[0][0]                      \n",
      "                                                                   conv5_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x1_bn (BatchNormalizatio (None, 2, 2, 1440)    5760        concat_5_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x1_scale (Scale)         (None, 2, 2, 1440)    2880        conv5_2_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_2_x1 (Activation)          (None, 2, 2, 1440)    0           conv5_2_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x1 (Conv2D)              (None, 2, 2, 128)     184320      relu5_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_2_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_2_x2 (Activation)          (None, 2, 2, 128)     0           conv5_2_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_2_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_2 (Merge)               (None, 2, 2, 1472)    0           concat_5_1[0][0]                 \n",
      "                                                                   conv5_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x1_bn (BatchNormalizatio (None, 2, 2, 1472)    5888        concat_5_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x1_scale (Scale)         (None, 2, 2, 1472)    2944        conv5_3_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_3_x1 (Activation)          (None, 2, 2, 1472)    0           conv5_3_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x1 (Conv2D)              (None, 2, 2, 128)     188416      relu5_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_3_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_3_x2 (Activation)          (None, 2, 2, 128)     0           conv5_3_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_3_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_3 (Merge)               (None, 2, 2, 1504)    0           concat_5_2[0][0]                 \n",
      "                                                                   conv5_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x1_bn (BatchNormalizatio (None, 2, 2, 1504)    6016        concat_5_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x1_scale (Scale)         (None, 2, 2, 1504)    3008        conv5_4_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_4_x1 (Activation)          (None, 2, 2, 1504)    0           conv5_4_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x1 (Conv2D)              (None, 2, 2, 128)     192512      relu5_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_4_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_4_x2 (Activation)          (None, 2, 2, 128)     0           conv5_4_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_4_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_4 (Merge)               (None, 2, 2, 1536)    0           concat_5_3[0][0]                 \n",
      "                                                                   conv5_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x1_bn (BatchNormalizatio (None, 2, 2, 1536)    6144        concat_5_4[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x1_scale (Scale)         (None, 2, 2, 1536)    3072        conv5_5_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_5_x1 (Activation)          (None, 2, 2, 1536)    0           conv5_5_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x1 (Conv2D)              (None, 2, 2, 128)     196608      relu5_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_5_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_5_x2 (Activation)          (None, 2, 2, 128)     0           conv5_5_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_5_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_5 (Merge)               (None, 2, 2, 1568)    0           concat_5_4[0][0]                 \n",
      "                                                                   conv5_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x1_bn (BatchNormalizatio (None, 2, 2, 1568)    6272        concat_5_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x1_scale (Scale)         (None, 2, 2, 1568)    3136        conv5_6_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_6_x1 (Activation)          (None, 2, 2, 1568)    0           conv5_6_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x1 (Conv2D)              (None, 2, 2, 128)     200704      relu5_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_6_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_6_x2 (Activation)          (None, 2, 2, 128)     0           conv5_6_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_6_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_6 (Merge)               (None, 2, 2, 1600)    0           concat_5_5[0][0]                 \n",
      "                                                                   conv5_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x1_bn (BatchNormalizatio (None, 2, 2, 1600)    6400        concat_5_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x1_scale (Scale)         (None, 2, 2, 1600)    3200        conv5_7_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_7_x1 (Activation)          (None, 2, 2, 1600)    0           conv5_7_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x1 (Conv2D)              (None, 2, 2, 128)     204800      relu5_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_7_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_7_x2 (Activation)          (None, 2, 2, 128)     0           conv5_7_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_7_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_7 (Merge)               (None, 2, 2, 1632)    0           concat_5_6[0][0]                 \n",
      "                                                                   conv5_7_x2[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "conv5_8_x1_bn (BatchNormalizatio (None, 2, 2, 1632)    6528        concat_5_7[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x1_scale (Scale)         (None, 2, 2, 1632)    3264        conv5_8_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_8_x1 (Activation)          (None, 2, 2, 1632)    0           conv5_8_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x1 (Conv2D)              (None, 2, 2, 128)     208896      relu5_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_8_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_8_x2 (Activation)          (None, 2, 2, 128)     0           conv5_8_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_8_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_8 (Merge)               (None, 2, 2, 1664)    0           concat_5_7[0][0]                 \n",
      "                                                                   conv5_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x1_bn (BatchNormalizatio (None, 2, 2, 1664)    6656        concat_5_8[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x1_scale (Scale)         (None, 2, 2, 1664)    3328        conv5_9_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_9_x1 (Activation)          (None, 2, 2, 1664)    0           conv5_9_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x1 (Conv2D)              (None, 2, 2, 128)     212992      relu5_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_9_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_9_x2 (Activation)          (None, 2, 2, 128)     0           conv5_9_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_9_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_9 (Merge)               (None, 2, 2, 1696)    0           concat_5_8[0][0]                 \n",
      "                                                                   conv5_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x1_bn (BatchNormalizati (None, 2, 2, 1696)    6784        concat_5_9[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x1_scale (Scale)        (None, 2, 2, 1696)    3392        conv5_10_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_10_x1 (Activation)         (None, 2, 2, 1696)    0           conv5_10_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x1 (Conv2D)             (None, 2, 2, 128)     217088      relu5_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_10_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_10_x2 (Activation)         (None, 2, 2, 128)     0           conv5_10_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_10_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_10 (Merge)              (None, 2, 2, 1728)    0           concat_5_9[0][0]                 \n",
      "                                                                   conv5_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x1_bn (BatchNormalizati (None, 2, 2, 1728)    6912        concat_5_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x1_scale (Scale)        (None, 2, 2, 1728)    3456        conv5_11_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_11_x1 (Activation)         (None, 2, 2, 1728)    0           conv5_11_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x1 (Conv2D)             (None, 2, 2, 128)     221184      relu5_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_11_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_11_x2 (Activation)         (None, 2, 2, 128)     0           conv5_11_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_11_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_11 (Merge)              (None, 2, 2, 1760)    0           concat_5_10[0][0]                \n",
      "                                                                   conv5_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x1_bn (BatchNormalizati (None, 2, 2, 1760)    7040        concat_5_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x1_scale (Scale)        (None, 2, 2, 1760)    3520        conv5_12_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_12_x1 (Activation)         (None, 2, 2, 1760)    0           conv5_12_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x1 (Conv2D)             (None, 2, 2, 128)     225280      relu5_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_12_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_12_x2 (Activation)         (None, 2, 2, 128)     0           conv5_12_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_12_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_12 (Merge)              (None, 2, 2, 1792)    0           concat_5_11[0][0]                \n",
      "                                                                   conv5_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x1_bn (BatchNormalizati (None, 2, 2, 1792)    7168        concat_5_12[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x1_scale (Scale)        (None, 2, 2, 1792)    3584        conv5_13_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_13_x1 (Activation)         (None, 2, 2, 1792)    0           conv5_13_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x1 (Conv2D)             (None, 2, 2, 128)     229376      relu5_13_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_13_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_13_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_13_x2 (Activation)         (None, 2, 2, 128)     0           conv5_13_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_13_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_13_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_13 (Merge)              (None, 2, 2, 1824)    0           concat_5_12[0][0]                \n",
      "                                                                   conv5_13_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x1_bn (BatchNormalizati (None, 2, 2, 1824)    7296        concat_5_13[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x1_scale (Scale)        (None, 2, 2, 1824)    3648        conv5_14_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_14_x1 (Activation)         (None, 2, 2, 1824)    0           conv5_14_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x1 (Conv2D)             (None, 2, 2, 128)     233472      relu5_14_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_14_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_14_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_14_x2 (Activation)         (None, 2, 2, 128)     0           conv5_14_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_14_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_14_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_14 (Merge)              (None, 2, 2, 1856)    0           concat_5_13[0][0]                \n",
      "                                                                   conv5_14_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x1_bn (BatchNormalizati (None, 2, 2, 1856)    7424        concat_5_14[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x1_scale (Scale)        (None, 2, 2, 1856)    3712        conv5_15_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_15_x1 (Activation)         (None, 2, 2, 1856)    0           conv5_15_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x1 (Conv2D)             (None, 2, 2, 128)     237568      relu5_15_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_15_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_15_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_15_x2 (Activation)         (None, 2, 2, 128)     0           conv5_15_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_15_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_15_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_15 (Merge)              (None, 2, 2, 1888)    0           concat_5_14[0][0]                \n",
      "                                                                   conv5_15_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x1_bn (BatchNormalizati (None, 2, 2, 1888)    7552        concat_5_15[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x1_scale (Scale)        (None, 2, 2, 1888)    3776        conv5_16_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_16_x1 (Activation)         (None, 2, 2, 1888)    0           conv5_16_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x1 (Conv2D)             (None, 2, 2, 128)     241664      relu5_16_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_16_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_16_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_16_x2 (Activation)         (None, 2, 2, 128)     0           conv5_16_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_16_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_16_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_16 (Merge)              (None, 2, 2, 1920)    0           concat_5_15[0][0]                \n",
      "                                                                   conv5_16_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_blk_bn (BatchNormalization (None, 2, 2, 1920)    7680        concat_5_16[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_blk_scale (Scale)          (None, 2, 2, 1920)    3840        conv5_blk_bn[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu5_blk (Activation)           (None, 2, 2, 1920)    0           conv5_blk_scale[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "pool5 (GlobalAveragePooling2D)   (None, 1920)          0           relu5_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "fc6 (Dense)                      (None, 2)             3842        pool5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "prob (Activation)                (None, 2)             0           fc6[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 12,264,706\n",
      "Trainable params: 12,128,066\n",
      "Non-trainable params: 136,640\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseNetModel(DaveBaseModel):\n",
    "    def get_model(self):\n",
    "        model = DenseNet(classes = 2)\n",
    "        '''Create the FCN and return a keras model.'''\n",
    "\n",
    "#         model = Sequential()\n",
    "\n",
    "#         # Input image: 75x75x3\n",
    "#         model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "#         DaveModel.ConvBlock(model, 1, 32)\n",
    "#         # 37x37x32\n",
    "#         DaveModel.ConvBlock(model, 1, 64)\n",
    "#         # 18x18x64\n",
    "#         DaveModel.ConvBlock(model, 1, 128)\n",
    "#         # 9x9x128\n",
    "#         DaveModel.ConvBlock(model, 1, 128)\n",
    "#         # 4x4x128\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "#         model.add(GlobalAveragePooling2D())\n",
    "#         # 4x4x2\n",
    "#         model.add(Activation('softmax'))\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"densenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), use_bias=False, name=\"conv1\", strides=(2, 2))`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:238: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), use_bias=False, name=\"conv2_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_12_x2\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(640, (1, 1), use_bias=False, name=\"conv3_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_13_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_13_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_14_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_14_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_15_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_15_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_16_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_16_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_17_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_17_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_18_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_18_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_19_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_19_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_20_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_20_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_21_x1\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_21_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_22_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_22_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_23_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_23_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_24_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_24_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1408, (1, 1), use_bias=False, name=\"conv4_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_13_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_13_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_14_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_14_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_15_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_15_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_16_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_16_x2\")`\n"
     ]
    }
   ],
   "source": [
    "model = DenseNetModel(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: densenet\n",
      "Batch Size: 16\n",
      "Epochs: 10\n",
      "Epoch 1/10\n",
      "81/80 [==============================] - 20s - loss: 0.2359 - acc: 0.8979 - val_loss: 0.3820 - val_acc: 0.8255\n",
      "Epoch 2/10\n",
      "81/80 [==============================] - 19s - loss: 0.2159 - acc: 0.9157 - val_loss: 0.3154 - val_acc: 0.8723\n",
      "Epoch 3/10\n",
      "81/80 [==============================] - 20s - loss: 0.2274 - acc: 0.9072 - val_loss: 0.3738 - val_acc: 0.8660\n",
      "Epoch 4/10\n",
      "81/80 [==============================] - 19s - loss: 0.2318 - acc: 0.8989 - val_loss: 0.3210 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "81/80 [==============================] - 20s - loss: 0.2277 - acc: 0.9033 - val_loss: 0.4518 - val_acc: 0.8100\n",
      "Epoch 6/10\n",
      "81/80 [==============================] - 19s - loss: 0.2243 - acc: 0.9005 - val_loss: 0.3413 - val_acc: 0.8536\n",
      "Epoch 7/10\n",
      "81/80 [==============================] - 19s - loss: 0.2342 - acc: 0.9049 - val_loss: 0.3443 - val_acc: 0.8785\n",
      "Epoch 8/10\n",
      "81/80 [==============================] - 19s - loss: 0.2348 - acc: 0.9043 - val_loss: 0.4795 - val_acc: 0.7944\n",
      "Epoch 9/10\n",
      "81/80 [==============================] - 19s - loss: 0.2326 - acc: 0.8931 - val_loss: 0.7824 - val_acc: 0.7227\n",
      "Epoch 10/10\n",
      "81/80 [==============================] - 19s - loss: 0.2199 - acc: 0.9035 - val_loss: 0.3501 - val_acc: 0.8567\n"
     ]
    }
   ],
   "source": [
    "model.train(16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/BIGBALLON/cifar-10-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "\n",
    "batch_size    = 128\n",
    "epochs        = 200\n",
    "iterations    = 391\n",
    "num_classes   = 2\n",
    "log_filepath  = './lenet'\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal', input_shape=(75,75,3)))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(16, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(84, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(2, activation = 'softmax', kernel_initializer='he_normal'))\n",
    "    sgd = optimizers.SGD(lr=.01, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch <= 60:\n",
    "        return 0.05\n",
    "    if epoch <= 120:\n",
    "        return 0.01\n",
    "    if epoch <= 160:    \n",
    "        return 0.002\n",
    "    return 0.0004\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     # load data\n",
    "#     (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "#     y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#     y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "#     x_train = x_train.astype('float32')\n",
    "#     x_test = x_test.astype('float32')\n",
    "#     x_train /= 255\n",
    "#     x_test /= 255\n",
    "\n",
    "    # build network\n",
    "#     model = build_model()\n",
    "#     print(model.summary())\n",
    "#     # set callback\n",
    "#     tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
    "#     change_lr = LearningRateScheduler(scheduler)\n",
    "#     cbks = [change_lr,tb_cb]\n",
    "\n",
    "#     # start traing \n",
    "#     model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,callbacks=cbks,\n",
    "#                   validation_data=(x_test, y_test), shuffle=True)\n",
    "#     # save model\n",
    "#     model.save('lenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNetModel2(DaveBaseModel):\n",
    "    def get_model(self):\n",
    "        return build_model()\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"lenet2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LeNetModel2(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lenet2\n",
      "Batch Size: 32\n",
      "Epochs: 50\n",
      "Epoch 1/50\n",
      "41/40 [==============================] - 3s - loss: 0.3607 - acc: 0.8175 - val_loss: 0.4849 - val_acc: 0.7445\n",
      "Epoch 2/50\n",
      "41/40 [==============================] - 2s - loss: 0.3550 - acc: 0.8238 - val_loss: 0.3708 - val_acc: 0.8069\n",
      "Epoch 3/50\n",
      "41/40 [==============================] - 3s - loss: 0.2921 - acc: 0.8548 - val_loss: 0.3378 - val_acc: 0.8318\n",
      "Epoch 4/50\n",
      "41/40 [==============================] - 2s - loss: 0.3002 - acc: 0.8604 - val_loss: 0.3845 - val_acc: 0.7850\n",
      "Epoch 5/50\n",
      "41/40 [==============================] - 2s - loss: 0.3030 - acc: 0.8449 - val_loss: 0.3382 - val_acc: 0.8380\n",
      "Epoch 6/50\n",
      "41/40 [==============================] - 2s - loss: 0.3115 - acc: 0.8403 - val_loss: 0.3408 - val_acc: 0.8318\n",
      "Epoch 7/50\n",
      "41/40 [==============================] - 2s - loss: 0.3050 - acc: 0.8566 - val_loss: 0.3398 - val_acc: 0.8505\n",
      "Epoch 8/50\n",
      "41/40 [==============================] - 2s - loss: 0.2882 - acc: 0.8555 - val_loss: 0.3448 - val_acc: 0.8411\n",
      "Epoch 9/50\n",
      "41/40 [==============================] - 2s - loss: 0.2906 - acc: 0.8589 - val_loss: 0.3905 - val_acc: 0.7632\n",
      "Epoch 10/50\n",
      "41/40 [==============================] - 2s - loss: 0.3024 - acc: 0.8490 - val_loss: 0.3715 - val_acc: 0.8131\n",
      "Epoch 11/50\n",
      "41/40 [==============================] - 2s - loss: 0.3081 - acc: 0.8482 - val_loss: 0.3552 - val_acc: 0.7975\n",
      "Epoch 12/50\n",
      "41/40 [==============================] - 2s - loss: 0.2912 - acc: 0.8582 - val_loss: 0.4034 - val_acc: 0.7882\n",
      "Epoch 13/50\n",
      "41/40 [==============================] - 2s - loss: 0.2917 - acc: 0.8594 - val_loss: 0.3354 - val_acc: 0.8349\n",
      "Epoch 14/50\n",
      "41/40 [==============================] - 2s - loss: 0.2827 - acc: 0.8662 - val_loss: 0.3740 - val_acc: 0.7913\n",
      "Epoch 15/50\n",
      "41/40 [==============================] - 2s - loss: 0.3107 - acc: 0.8502 - val_loss: 0.5557 - val_acc: 0.7290\n",
      "Epoch 16/50\n",
      "41/40 [==============================] - 2s - loss: 0.3031 - acc: 0.8502 - val_loss: 0.3114 - val_acc: 0.8723\n",
      "Epoch 17/50\n",
      "41/40 [==============================] - 2s - loss: 0.3253 - acc: 0.8453 - val_loss: 0.3388 - val_acc: 0.8442\n",
      "Epoch 18/50\n",
      "41/40 [==============================] - 2s - loss: 0.3170 - acc: 0.8399 - val_loss: 0.3691 - val_acc: 0.7975\n",
      "Epoch 19/50\n",
      "41/40 [==============================] - 2s - loss: 0.3119 - acc: 0.8339 - val_loss: 0.5102 - val_acc: 0.7103\n",
      "Epoch 20/50\n",
      "41/40 [==============================] - 2s - loss: 0.3039 - acc: 0.8502 - val_loss: 0.3595 - val_acc: 0.8006\n",
      "Epoch 21/50\n",
      "41/40 [==============================] - 3s - loss: 0.2947 - acc: 0.8665 - val_loss: 0.3985 - val_acc: 0.7664\n",
      "Epoch 22/50\n",
      "41/40 [==============================] - 2s - loss: 0.2859 - acc: 0.8716 - val_loss: 0.3074 - val_acc: 0.8567\n",
      "Epoch 23/50\n",
      "41/40 [==============================] - 2s - loss: 0.2960 - acc: 0.8571 - val_loss: 0.3620 - val_acc: 0.8193\n",
      "Epoch 24/50\n",
      "41/40 [==============================] - 2s - loss: 0.2806 - acc: 0.8604 - val_loss: 0.3692 - val_acc: 0.7882\n",
      "Epoch 25/50\n",
      "41/40 [==============================] - 2s - loss: 0.2730 - acc: 0.8772 - val_loss: 0.4161 - val_acc: 0.7695\n",
      "Epoch 26/50\n",
      "41/40 [==============================] - 2s - loss: 0.2731 - acc: 0.8719 - val_loss: 0.3422 - val_acc: 0.8287\n",
      "Epoch 27/50\n",
      "41/40 [==============================] - 2s - loss: 0.2879 - acc: 0.8716 - val_loss: 0.3368 - val_acc: 0.8162\n",
      "Epoch 28/50\n",
      "41/40 [==============================] - 2s - loss: 0.2858 - acc: 0.8597 - val_loss: 0.3348 - val_acc: 0.8474\n",
      "Epoch 29/50\n",
      "41/40 [==============================] - 2s - loss: 0.2959 - acc: 0.8658 - val_loss: 0.3642 - val_acc: 0.8100\n",
      "Epoch 30/50\n",
      "41/40 [==============================] - 2s - loss: 0.2833 - acc: 0.8754 - val_loss: 0.3253 - val_acc: 0.8349\n",
      "Epoch 31/50\n",
      "41/40 [==============================] - 2s - loss: 0.2804 - acc: 0.8673 - val_loss: 0.3693 - val_acc: 0.7944\n",
      "Epoch 32/50\n",
      "41/40 [==============================] - 2s - loss: 0.2867 - acc: 0.8658 - val_loss: 0.4019 - val_acc: 0.7664\n",
      "Epoch 33/50\n",
      "41/40 [==============================] - 2s - loss: 0.2751 - acc: 0.8673 - val_loss: 0.3310 - val_acc: 0.8380\n",
      "Epoch 34/50\n",
      "41/40 [==============================] - 2s - loss: 0.2871 - acc: 0.8616 - val_loss: 0.3355 - val_acc: 0.8255\n",
      "Epoch 35/50\n",
      "41/40 [==============================] - 2s - loss: 0.2759 - acc: 0.8604 - val_loss: 0.3841 - val_acc: 0.7944\n",
      "Epoch 36/50\n",
      "41/40 [==============================] - 2s - loss: 0.2743 - acc: 0.8765 - val_loss: 0.3775 - val_acc: 0.7882\n",
      "Epoch 37/50\n",
      "41/40 [==============================] - 2s - loss: 0.2697 - acc: 0.8681 - val_loss: 0.3518 - val_acc: 0.8193\n",
      "Epoch 38/50\n",
      "41/40 [==============================] - 2s - loss: 0.2836 - acc: 0.8536 - val_loss: 0.3608 - val_acc: 0.78500.8\n",
      "Epoch 39/50\n",
      "41/40 [==============================] - 2s - loss: 0.2712 - acc: 0.8726 - val_loss: 0.4470 - val_acc: 0.7788\n",
      "Epoch 40/50\n",
      "41/40 [==============================] - 2s - loss: 0.2867 - acc: 0.8643 - val_loss: 0.4007 - val_acc: 0.8006\n",
      "Epoch 41/50\n",
      "41/40 [==============================] - 2s - loss: 0.2869 - acc: 0.8677 - val_loss: 0.3689 - val_acc: 0.7882\n",
      "Epoch 42/50\n",
      "41/40 [==============================] - 2s - loss: 0.2816 - acc: 0.8605 - val_loss: 0.4352 - val_acc: 0.7632\n",
      "Epoch 43/50\n",
      "41/40 [==============================] - 2s - loss: 0.2954 - acc: 0.8574 - val_loss: 0.3451 - val_acc: 0.8162\n",
      "Epoch 44/50\n",
      "41/40 [==============================] - 2s - loss: 0.2669 - acc: 0.8726 - val_loss: 0.3497 - val_acc: 0.8069\n",
      "Epoch 45/50\n",
      "41/40 [==============================] - 2s - loss: 0.2942 - acc: 0.8559 - val_loss: 0.3675 - val_acc: 0.7913\n",
      "Epoch 46/50\n",
      "41/40 [==============================] - 2s - loss: 0.2811 - acc: 0.8765 - val_loss: 0.3780 - val_acc: 0.8069\n",
      "Epoch 47/50\n",
      "41/40 [==============================] - 2s - loss: 0.2758 - acc: 0.8848 - val_loss: 0.3960 - val_acc: 0.7726\n",
      "Epoch 48/50\n",
      "41/40 [==============================] - 2s - loss: 0.2747 - acc: 0.8635 - val_loss: 0.3547 - val_acc: 0.8193\n",
      "Epoch 49/50\n",
      "41/40 [==============================] - 2s - loss: 0.2636 - acc: 0.8665 - val_loss: 0.4251 - val_acc: 0.7570\n",
      "Epoch 50/50\n",
      "41/40 [==============================] - 2s - loss: 0.2937 - acc: 0.8400 - val_loss: 0.3618 - val_acc: 0.8069\n"
     ]
    }
   ],
   "source": [
    "model.train(32, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.initializers import he_normal\n",
    "from keras import regularizers\n",
    "\n",
    "weight_decay       = 0.0005\n",
    "\n",
    "def color_preprocessing(x_train,x_test):\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    mean = [125.307, 122.95, 113.865]\n",
    "    std  = [62.9932, 62.0887, 66.7048]\n",
    "    for i in range(3):\n",
    "        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "    return x_train, x_test\n",
    "\n",
    "def wide_residual_network(img_input,classes_num,depth,k):\n",
    "\n",
    "    print('Wide-Resnet %dx%d' %(depth, k))\n",
    "    n_filters  = [16, 16*k, 32*k, 64*k]\n",
    "    n_stack    = (depth - 4) / 6\n",
    "    in_filters = 16\n",
    "\n",
    "    def conv3x3(x,filters):\n",
    "    \treturn Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "    \tkernel_initializer=he_normal(),\n",
    "        kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "\n",
    "    def residual_block(x,out_filters,increase_filter=False):\n",
    "        if increase_filter:\n",
    "            first_stride = (2,2)\n",
    "        else:\n",
    "            first_stride = (1,1)\n",
    "        pre_bn   = BatchNormalization()(x)\n",
    "        pre_relu = Activation('relu')(pre_bn)\n",
    "        conv_1 = Conv2D(out_filters,kernel_size=(3,3),strides=first_stride,padding='same',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(pre_relu)\n",
    "        bn_1   = BatchNormalization()(conv_1)\n",
    "        relu1  = Activation('relu')(bn_1)\n",
    "        conv_2 = Conv2D(out_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(relu1)\n",
    "        if increase_filter or in_filters != out_filters:\n",
    "            projection = Conv2D(out_filters,kernel_size=(1,1),strides=first_stride,padding='same',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "            block = add([conv_2, projection])\n",
    "        else:\n",
    "            block = add([conv_2,x])\n",
    "        return block\n",
    "\n",
    "    def wide_residual_layer(x,out_filters,increase_filter=False):\n",
    "    \tx = residual_block(x,out_filters,increase_filter)\n",
    "    \tin_filters = out_filters\n",
    "    \tfor _ in range(1,int(n_stack)):\n",
    "    \t\tx = residual_block(x,out_filters)\n",
    "    \treturn x\n",
    "\n",
    "\n",
    "    x = conv3x3(img_input,n_filters[0])\n",
    "    x = wide_residual_layer(x,n_filters[1])\n",
    "    x = wide_residual_layer(x,n_filters[2],increase_filter=True)\n",
    "    x = wide_residual_layer(x,n_filters[3],increase_filter=True)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(classes_num,activation='softmax',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WideResidualModel(DaveBaseModel):\n",
    "    depth              = 16\n",
    "    wide               = 8\n",
    "    num_classes        = 2\n",
    "    img_rows, img_cols = 75, 75\n",
    "    img_channels       = 3\n",
    "    batch_size         = 128\n",
    "    epochs             = 200\n",
    "    iterations         = 391\n",
    "    log_filepath       = r'./w_resnet/'\n",
    "    \n",
    "    def get_model(self):\n",
    "        img_input = Input(shape=(self.img_rows,self.img_cols,self.img_channels))\n",
    "        output = wide_residual_network(img_input,self.num_classes,self.depth,self.wide)\n",
    "        resnet = Model(img_input, output)\n",
    "        print(resnet.summary())\n",
    "        # set optimizer\n",
    "        resnet.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "#         sgd = optimizers.SGD(lr=.01, momentum=0.9, nesterov=True)\n",
    "#         resnet.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "        return resnet\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"wide\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr2, Xv2 = color_preprocessing(Xtr, Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide-Resnet 16x8\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_15 (InputLayer)            (None, 75, 75, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)              (None, 75, 75, 16)    448         input_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchNo (None, 75, 75, 16)    64          conv2d_490[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_474 (Activation)      (None, 75, 75, 16)    0           batch_normalization_436[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)              (None, 75, 75, 128)   18560       activation_474[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchNo (None, 75, 75, 128)   512         conv2d_491[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_475 (Activation)      (None, 75, 75, 128)   0           batch_normalization_437[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)              (None, 75, 75, 128)   147584      activation_475[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)              (None, 75, 75, 128)   2176        conv2d_490[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_63 (Add)                     (None, 75, 75, 128)   0           conv2d_492[0][0]                 \n",
      "                                                                   conv2d_493[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchNo (None, 75, 75, 128)   512         add_63[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_476 (Activation)      (None, 75, 75, 128)   0           batch_normalization_438[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)              (None, 75, 75, 128)   147584      activation_476[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchNo (None, 75, 75, 128)   512         conv2d_494[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_477 (Activation)      (None, 75, 75, 128)   0           batch_normalization_439[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)              (None, 75, 75, 128)   147584      activation_477[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)              (None, 75, 75, 128)   16512       add_63[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_64 (Add)                     (None, 75, 75, 128)   0           conv2d_495[0][0]                 \n",
      "                                                                   conv2d_496[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchNo (None, 75, 75, 128)   512         add_64[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_478 (Activation)      (None, 75, 75, 128)   0           batch_normalization_440[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)              (None, 38, 38, 256)   295168      activation_478[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchNo (None, 38, 38, 256)   1024        conv2d_497[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_479 (Activation)      (None, 38, 38, 256)   0           batch_normalization_441[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)              (None, 38, 38, 256)   590080      activation_479[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)              (None, 38, 38, 256)   33024       add_64[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_65 (Add)                     (None, 38, 38, 256)   0           conv2d_498[0][0]                 \n",
      "                                                                   conv2d_499[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchNo (None, 38, 38, 256)   1024        add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_480 (Activation)      (None, 38, 38, 256)   0           batch_normalization_442[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)              (None, 38, 38, 256)   590080      activation_480[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchNo (None, 38, 38, 256)   1024        conv2d_500[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_481 (Activation)      (None, 38, 38, 256)   0           batch_normalization_443[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)              (None, 38, 38, 256)   590080      activation_481[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)              (None, 38, 38, 256)   65792       add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_66 (Add)                     (None, 38, 38, 256)   0           conv2d_501[0][0]                 \n",
      "                                                                   conv2d_502[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchNo (None, 38, 38, 256)   1024        add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_482 (Activation)      (None, 38, 38, 256)   0           batch_normalization_444[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)              (None, 19, 19, 512)   1180160     activation_482[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchNo (None, 19, 19, 512)   2048        conv2d_503[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_483 (Activation)      (None, 19, 19, 512)   0           batch_normalization_445[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)              (None, 19, 19, 512)   2359808     activation_483[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)              (None, 19, 19, 512)   131584      add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_67 (Add)                     (None, 19, 19, 512)   0           conv2d_504[0][0]                 \n",
      "                                                                   conv2d_505[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchNo (None, 19, 19, 512)   2048        add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_484 (Activation)      (None, 19, 19, 512)   0           batch_normalization_446[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)              (None, 19, 19, 512)   2359808     activation_484[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchNo (None, 19, 19, 512)   2048        conv2d_506[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_485 (Activation)      (None, 19, 19, 512)   0           batch_normalization_447[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)              (None, 19, 19, 512)   2359808     activation_485[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)              (None, 19, 19, 512)   262656      add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_68 (Add)                     (None, 19, 19, 512)   0           conv2d_507[0][0]                 \n",
      "                                                                   conv2d_508[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchNo (None, 19, 19, 512)   2048        add_68[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_486 (Activation)      (None, 19, 19, 512)   0           batch_normalization_448[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_30 (Glo (None, 512)           0           activation_486[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_68 (Dense)                 (None, 2)             1026        global_average_pooling2d_30[0][0]\n",
      "====================================================================================================\n",
      "Total params: 11,313,922\n",
      "Trainable params: 11,306,722\n",
      "Non-trainable params: 7,200\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = WideResidualModel(Xtr2, ytr, Xv2, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: wide\n",
      "Batch Size: 32\n",
      "Epochs: 20\n",
      "Epoch 1/20\n",
      "41/40 [==============================] - 26s - loss: 1.9431 - acc: 0.7514 - val_loss: 2.0569 - val_acc: 0.6573\n",
      "Epoch 2/20\n",
      "41/40 [==============================] - 26s - loss: 1.9056 - acc: 0.7564 - val_loss: 2.7941 - val_acc: 0.6573\n",
      "Epoch 3/20\n",
      "41/40 [==============================] - 26s - loss: 1.8394 - acc: 0.7788 - val_loss: 3.7357 - val_acc: 0.6573\n",
      "Epoch 4/20\n",
      "41/40 [==============================] - 26s - loss: 1.7993 - acc: 0.7567 - val_loss: 4.6903 - val_acc: 0.6573\n",
      "Epoch 5/20\n",
      "25/40 [=================>............] - ETA: 9s - loss: 1.7423 - acc: 0.7788"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-308f050afe0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\_GithubTest\\MachineLearning\\Kaggle\\Statoil C-CORE Iceberg Classifier\\models.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, epochs, saveModel)\u001b[0m\n\u001b[0;32m     43\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                          validation_steps = len(self.Xv) / self.batch_size)\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(32, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99999642e-01,   3.94188163e-07],\n",
       "       [  9.99999285e-01,   7.67450786e-07],\n",
       "       [  9.99995112e-01,   4.87961142e-06],\n",
       "       ..., \n",
       "       [  9.99999404e-01,   5.75652166e-07],\n",
       "       [  9.99999523e-01,   4.57558031e-07],\n",
       "       [  9.99994874e-01,   5.11484541e-06]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
