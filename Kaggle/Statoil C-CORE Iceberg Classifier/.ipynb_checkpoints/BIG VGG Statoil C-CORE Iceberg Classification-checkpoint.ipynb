{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>271f93f4</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              band_1  \\\n",
       "0  [-27.878360999999998, -27.15416, -28.668615, -...   \n",
       "1  [-12.242375, -14.920304999999999, -14.920363, ...   \n",
       "2  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "\n",
       "                                              band_2        id inc_angle  \\\n",
       "0  [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913   43.9239   \n",
       "1  [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd   38.1562   \n",
       "2  [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0   45.2859   \n",
       "3  [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18   43.8306   \n",
       "4  [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4   35.6256   \n",
       "\n",
       "   is_iceberg  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_channel(band_data):\n",
    "    print(\"get_channel\")\n",
    "    band_data = np.array([np.array(band).astype(np.float32) for band in band_data])\n",
    "    \n",
    "    print(band_data.shape)\n",
    "    band_data_new = np.empty((1604, 150, 150))\n",
    "\n",
    "    for ind in range(band_data.shape[0]):\n",
    "        arr_image = band_data[ind]\n",
    "        band_data_new[ind] = (scipy.misc.fromimage(scipy.misc.toimage(arr_image.reshape(75, 75)).resize((150, 150))))\n",
    "\n",
    "    print(band_data_new.shape)\n",
    "\n",
    "    return band_data_new\n",
    "\n",
    "def concat_data(data):\n",
    "    channel1 = get_channel(data[\"band_1\"])\n",
    "    channel2 = get_channel(data[\"band_2\"])\n",
    "    channel3 = (channel1 + channel2) / 2.\n",
    "\n",
    "    return np.concatenate([channel1[:, :, :, np.newaxis], channel2[:, :, :, np.newaxis],channel3[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_channel\n",
      "(1604, 5625)\n",
      "(1604, 150, 150)\n",
      "get_channel\n",
      "(1604, 5625)\n",
      "(1604, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X_train = concat_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  69. ,  119. ,   94. ],\n",
       "        [  69. ,  119. ,   94. ],\n",
       "        [  74. ,   99. ,   86.5],\n",
       "        ..., \n",
       "        [  79. ,   99. ,   89. ],\n",
       "        [  52. ,  116. ,   84. ],\n",
       "        [  52. ,  116. ,   84. ]],\n",
       "\n",
       "       [[  69. ,  119. ,   94. ],\n",
       "        [  69. ,  119. ,   94. ],\n",
       "        [  74. ,   99. ,   86.5],\n",
       "        ..., \n",
       "        [  79. ,   99. ,   89. ],\n",
       "        [  52. ,  116. ,   84. ],\n",
       "        [  52. ,  116. ,   84. ]],\n",
       "\n",
       "       [[  64. ,   86. ,   75. ],\n",
       "        [  64. ,   86. ,   75. ],\n",
       "        [  69. ,   65. ,   67. ],\n",
       "        ..., \n",
       "        [  64. ,  110. ,   87. ],\n",
       "        [  44. ,  125. ,   84.5],\n",
       "        [  44. ,  125. ,   84.5]],\n",
       "\n",
       "       ..., \n",
       "       [[  44. ,   99. ,   71.5],\n",
       "        [  44. ,   99. ,   71.5],\n",
       "        [  69. ,   99. ,   84. ],\n",
       "        ..., \n",
       "        [  76. ,  110. ,   93. ],\n",
       "        [  72. ,   65. ,   68.5],\n",
       "        [  72. ,   65. ,   68.5]],\n",
       "\n",
       "       [[  61. ,   95. ,   78. ],\n",
       "        [  61. ,   95. ,   78. ],\n",
       "        [  76. ,  106. ,   91. ],\n",
       "        ..., \n",
       "        [  69. ,  106. ,   87.5],\n",
       "        [  67. ,  103. ,   85. ],\n",
       "        [  67. ,  103. ,   85. ]],\n",
       "\n",
       "       [[  61. ,   95. ,   78. ],\n",
       "        [  61. ,   95. ,   78. ],\n",
       "        [  76. ,  106. ,   91. ],\n",
       "        ..., \n",
       "        [  69. ,  106. ,   87.5],\n",
       "        [  67. ,  103. ,   85. ],\n",
       "        [  67. ,  103. ,   85. ]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train=train['is_iceberg']\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, y_train, random_state=1, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generators(train_data, valid_data):\n",
    "    data_gen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            rotation_range=180,\n",
    "            vertical_flip=True,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "    data_gen.fit(train_data)\n",
    "\n",
    "    val_gen = ImageDataGenerator(rescale=1./255)\n",
    "    val_gen.fit(valid_data)\n",
    "    \n",
    "    return data_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dgen, vgen = get_generators(X_train_cv, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DaveBaseModel:\n",
    "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.dgen, self.vgen = get_generators(X_train, X_valid)\n",
    "        \n",
    "    def train(self, epochs, batch_size):\n",
    "        self.model.fit_generator(self.dgen.flow(self.X_train, self.y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=len(self.X_train) / batch_size, \n",
    "                            validation_data=self.vgen.flow(self.X_valid, self.y_valid, batch_size=batch_size, shuffle=False),\n",
    "                            validation_steps = len(self.X_valid) / batch_size,\n",
    "                            epochs=epochs)\n",
    "\n",
    "class DaveVGG(DaveBaseModel):\n",
    "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
    "        DaveBaseModel.__init__(self, X_train, X_valid, y_train, y_valid)\n",
    "        vgg_model = VGG16(include_top=False, weights=None, input_shape=(150, 150, 3))\n",
    "\n",
    "        top_model = Sequential()\n",
    "        top_model.add(Flatten(input_shape=vgg_model.output_shape[1:]))\n",
    "        top_model.add(Dense(512, activation='relu'))\n",
    "        # top_model.add(Dense(512, activation='relu'))\n",
    "        # top_model.add(Dropout(0.5))\n",
    "        top_model.add(Dense(1, activation='sigmoid'))\n",
    "        # top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "        self.model = Model(inputs= vgg_model.input, outputs= top_model(vgg_model.output))\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        print(self.model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   (None, 1)                 4195329   \n",
      "=================================================================\n",
      "Total params: 18,910,017\n",
      "Trainable params: 18,910,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DaveVGG(X_train_cv, X_valid, y_train_cv, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/37 [==============================] - 16s - loss: 0.6921 - acc: 0.5237 - val_loss: 0.6785 - val_acc: 0.5312\n",
      "Epoch 2/80\n",
      "38/37 [==============================] - 15s - loss: 0.6785 - acc: 0.5374 - val_loss: 1.0349 - val_acc: 0.6135\n",
      "Epoch 3/80\n",
      "38/37 [==============================] - 15s - loss: 0.6932 - acc: 0.5251 - val_loss: 0.6915 - val_acc: 0.5611\n",
      "Epoch 4/80\n",
      "38/37 [==============================] - 15s - loss: 0.6650 - acc: 0.6145 - val_loss: 0.5965 - val_acc: 0.6933\n",
      "Epoch 5/80\n",
      "38/37 [==============================] - 15s - loss: 0.6182 - acc: 0.6370 - val_loss: 0.6873 - val_acc: 0.4988\n",
      "Epoch 6/80\n",
      "38/37 [==============================] - 15s - loss: 0.6163 - acc: 0.6243 - val_loss: 0.6129 - val_acc: 0.6384\n",
      "Epoch 7/80\n",
      "38/37 [==============================] - 15s - loss: 0.5935 - acc: 0.6633 - val_loss: 0.6294 - val_acc: 0.6409\n",
      "Epoch 8/80\n",
      "38/37 [==============================] - 15s - loss: 0.6124 - acc: 0.6191 - val_loss: 0.5942 - val_acc: 0.6484\n",
      "Epoch 9/80\n",
      "38/37 [==============================] - 15s - loss: 0.5700 - acc: 0.6707 - val_loss: 0.6098 - val_acc: 0.6808\n",
      "Epoch 10/80\n",
      "38/37 [==============================] - 15s - loss: 0.5749 - acc: 0.6715 - val_loss: 0.6136 - val_acc: 0.6683\n",
      "Epoch 11/80\n",
      "38/37 [==============================] - 15s - loss: 0.5537 - acc: 0.6902 - val_loss: 0.6613 - val_acc: 0.6708\n",
      "Epoch 12/80\n",
      "38/37 [==============================] - 15s - loss: 0.5709 - acc: 0.6811 - val_loss: 0.5827 - val_acc: 0.6584\n",
      "Epoch 13/80\n",
      "38/37 [==============================] - 15s - loss: 0.5740 - acc: 0.6764 - val_loss: 0.5974 - val_acc: 0.6384\n",
      "Epoch 14/80\n",
      "38/37 [==============================] - 15s - loss: 0.5806 - acc: 0.6828 - val_loss: 0.5997 - val_acc: 0.6708\n",
      "Epoch 15/80\n",
      "38/37 [==============================] - 15s - loss: 0.5695 - acc: 0.6795 - val_loss: 0.5717 - val_acc: 0.6733\n",
      "Epoch 16/80\n",
      "38/37 [==============================] - 15s - loss: 0.5715 - acc: 0.6688 - val_loss: 0.5867 - val_acc: 0.6833\n",
      "Epoch 17/80\n",
      "38/37 [==============================] - 15s - loss: 0.5516 - acc: 0.6819 - val_loss: 0.7729 - val_acc: 0.6434\n",
      "Epoch 18/80\n",
      "38/37 [==============================] - 15s - loss: 0.5842 - acc: 0.6622 - val_loss: 0.5564 - val_acc: 0.6808\n",
      "Epoch 19/80\n",
      "38/37 [==============================] - 15s - loss: 0.5507 - acc: 0.6869 - val_loss: 0.5950 - val_acc: 0.6683\n",
      "Epoch 20/80\n",
      "38/37 [==============================] - 15s - loss: 0.5439 - acc: 0.6745 - val_loss: 0.5323 - val_acc: 0.6933\n",
      "Epoch 21/80\n",
      "38/37 [==============================] - 16s - loss: 0.5418 - acc: 0.6866 - val_loss: 0.5646 - val_acc: 0.6958\n",
      "Epoch 22/80\n",
      "38/37 [==============================] - 15s - loss: 0.5366 - acc: 0.6756 - val_loss: 0.5575 - val_acc: 0.7357\n",
      "Epoch 23/80\n",
      "38/37 [==============================] - 15s - loss: 0.4683 - acc: 0.7650 - val_loss: 0.5447 - val_acc: 0.7132\n",
      "Epoch 24/80\n",
      "38/37 [==============================] - 15s - loss: 0.4622 - acc: 0.7804 - val_loss: 0.4379 - val_acc: 0.8030\n",
      "Epoch 25/80\n",
      "38/37 [==============================] - 15s - loss: 0.4397 - acc: 0.7880 - val_loss: 0.7065 - val_acc: 0.7531\n",
      "Epoch 26/80\n",
      "38/37 [==============================] - 15s - loss: 0.4587 - acc: 0.7982 - val_loss: 0.5679 - val_acc: 0.7681\n",
      "Epoch 27/80\n",
      "38/37 [==============================] - 16s - loss: 0.4469 - acc: 0.7817 - val_loss: 0.4060 - val_acc: 0.7930\n",
      "Epoch 28/80\n",
      "38/37 [==============================] - 16s - loss: 0.4097 - acc: 0.7963 - val_loss: 0.4034 - val_acc: 0.8130\n",
      "Epoch 29/80\n",
      "38/37 [==============================] - 16s - loss: 0.4069 - acc: 0.8048 - val_loss: 0.4441 - val_acc: 0.7805\n",
      "Epoch 30/80\n",
      "38/37 [==============================] - 16s - loss: 0.3821 - acc: 0.8127 - val_loss: 0.3926 - val_acc: 0.8229\n",
      "Epoch 31/80\n",
      "38/37 [==============================] - 16s - loss: 0.3887 - acc: 0.8086 - val_loss: 0.4203 - val_acc: 0.7930\n",
      "Epoch 32/80\n",
      "38/37 [==============================] - 16s - loss: 0.4085 - acc: 0.8012 - val_loss: 0.4518 - val_acc: 0.8005\n",
      "Epoch 33/80\n",
      "38/37 [==============================] - 16s - loss: 0.3715 - acc: 0.8168 - val_loss: 0.3931 - val_acc: 0.8105\n",
      "Epoch 34/80\n",
      "38/37 [==============================] - 16s - loss: 0.3794 - acc: 0.8138 - val_loss: 0.3730 - val_acc: 0.8354\n",
      "Epoch 35/80\n",
      "38/37 [==============================] - 16s - loss: 0.3652 - acc: 0.8229 - val_loss: 0.3481 - val_acc: 0.8204\n",
      "Epoch 36/80\n",
      "38/37 [==============================] - 16s - loss: 0.3812 - acc: 0.8053 - val_loss: 0.4656 - val_acc: 0.7880\n",
      "Epoch 37/80\n",
      "38/37 [==============================] - 16s - loss: 0.3601 - acc: 0.8292 - val_loss: 0.3819 - val_acc: 0.8180\n",
      "Epoch 38/80\n",
      "38/37 [==============================] - 16s - loss: 0.3354 - acc: 0.8418 - val_loss: 0.3607 - val_acc: 0.8379\n",
      "Epoch 39/80\n",
      "38/37 [==============================] - 16s - loss: 0.3563 - acc: 0.8237 - val_loss: 0.4228 - val_acc: 0.8180\n",
      "Epoch 40/80\n",
      "38/37 [==============================] - 16s - loss: 0.3702 - acc: 0.8330 - val_loss: 0.3361 - val_acc: 0.8379\n",
      "Epoch 41/80\n",
      "38/37 [==============================] - 16s - loss: 0.3404 - acc: 0.8401 - val_loss: 0.3603 - val_acc: 0.8329\n",
      "Epoch 42/80\n",
      "38/37 [==============================] - 18s - loss: 0.3467 - acc: 0.8344 - val_loss: 0.3296 - val_acc: 0.8529\n",
      "Epoch 43/80\n",
      "38/37 [==============================] - 17s - loss: 0.3418 - acc: 0.8404 - val_loss: 0.3322 - val_acc: 0.8454\n",
      "Epoch 44/80\n",
      "38/37 [==============================] - 17s - loss: 0.3329 - acc: 0.8432 - val_loss: 0.4957 - val_acc: 0.8030\n",
      "Epoch 45/80\n",
      "38/37 [==============================] - 17s - loss: 0.3479 - acc: 0.8311 - val_loss: 0.3343 - val_acc: 0.8279\n",
      "Epoch 46/80\n",
      "38/37 [==============================] - 17s - loss: 0.3510 - acc: 0.8305 - val_loss: 0.3143 - val_acc: 0.8429\n",
      "Epoch 47/80\n",
      "38/37 [==============================] - 17s - loss: 0.3305 - acc: 0.8338 - val_loss: 0.3126 - val_acc: 0.8454\n",
      "Epoch 48/80\n",
      "38/37 [==============================] - 17s - loss: 0.3290 - acc: 0.8448 - val_loss: 0.3451 - val_acc: 0.8329\n",
      "Epoch 49/80\n",
      "38/37 [==============================] - 17s - loss: 0.3454 - acc: 0.8352 - val_loss: 0.3574 - val_acc: 0.8204\n",
      "Epoch 50/80\n",
      "38/37 [==============================] - 17s - loss: 0.3214 - acc: 0.8379 - val_loss: 0.3750 - val_acc: 0.8254\n",
      "Epoch 51/80\n",
      "38/37 [==============================] - 17s - loss: 0.3318 - acc: 0.8366 - val_loss: 0.3164 - val_acc: 0.8304\n",
      "Epoch 52/80\n",
      "38/37 [==============================] - 17s - loss: 0.3145 - acc: 0.8467 - val_loss: 0.3889 - val_acc: 0.8304\n",
      "Epoch 53/80\n",
      "38/37 [==============================] - 17s - loss: 0.3495 - acc: 0.8415 - val_loss: 0.5315 - val_acc: 0.7830\n",
      "Epoch 54/80\n",
      "38/37 [==============================] - 17s - loss: 0.3283 - acc: 0.8418 - val_loss: 0.3944 - val_acc: 0.8279\n",
      "Epoch 55/80\n",
      "38/37 [==============================] - 17s - loss: 0.3316 - acc: 0.8478 - val_loss: 0.3128 - val_acc: 0.8728\n",
      "Epoch 56/80\n",
      "38/37 [==============================] - 17s - loss: 0.3225 - acc: 0.8462 - val_loss: 0.3390 - val_acc: 0.8454\n",
      "Epoch 57/80\n",
      "38/37 [==============================] - 17s - loss: 0.3465 - acc: 0.8421 - val_loss: 0.4333 - val_acc: 0.8080\n",
      "Epoch 58/80\n",
      "38/37 [==============================] - 17s - loss: 0.3435 - acc: 0.8396 - val_loss: 0.3218 - val_acc: 0.8329\n",
      "Epoch 59/80\n",
      "38/37 [==============================] - 17s - loss: 0.2939 - acc: 0.8637 - val_loss: 0.3501 - val_acc: 0.8155\n",
      "Epoch 60/80\n",
      "38/37 [==============================] - 17s - loss: 0.3418 - acc: 0.8522 - val_loss: 0.3573 - val_acc: 0.8379\n",
      "Epoch 61/80\n",
      "38/37 [==============================] - 18s - loss: 0.3193 - acc: 0.8558 - val_loss: 0.3366 - val_acc: 0.8304\n",
      "Epoch 62/80\n",
      "38/37 [==============================] - 16s - loss: 0.3196 - acc: 0.8522 - val_loss: 0.3502 - val_acc: 0.8279\n",
      "Epoch 63/80\n",
      "38/37 [==============================] - 17s - loss: 0.3066 - acc: 0.8610 - val_loss: 0.3229 - val_acc: 0.8529\n",
      "Epoch 64/80\n",
      "38/37 [==============================] - 17s - loss: 0.3127 - acc: 0.8451 - val_loss: 0.3262 - val_acc: 0.8429\n",
      "Epoch 65/80\n",
      "38/37 [==============================] - 17s - loss: 0.3398 - acc: 0.8563 - val_loss: 0.4135 - val_acc: 0.8554\n",
      "Epoch 66/80\n",
      "38/37 [==============================] - 17s - loss: 0.4168 - acc: 0.8251 - val_loss: 0.4121 - val_acc: 0.8304\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/37 [==============================] - 17s - loss: 0.3509 - acc: 0.8341 - val_loss: 0.3506 - val_acc: 0.8254\n",
      "Epoch 68/80\n",
      "38/37 [==============================] - 17s - loss: 0.3230 - acc: 0.8470 - val_loss: 0.3926 - val_acc: 0.8130\n",
      "Epoch 69/80\n",
      "38/37 [==============================] - 17s - loss: 0.3170 - acc: 0.8484 - val_loss: 0.4092 - val_acc: 0.8105\n",
      "Epoch 70/80\n",
      "38/37 [==============================] - 17s - loss: 0.3156 - acc: 0.8484 - val_loss: 0.3249 - val_acc: 0.8404\n",
      "Epoch 71/80\n",
      "38/37 [==============================] - 17s - loss: 0.2994 - acc: 0.8544 - val_loss: 0.3378 - val_acc: 0.8454\n",
      "Epoch 72/80\n",
      "38/37 [==============================] - 19s - loss: 0.3019 - acc: 0.8574 - val_loss: 0.4198 - val_acc: 0.8229\n",
      "Epoch 73/80\n",
      "38/37 [==============================] - 18s - loss: 0.3220 - acc: 0.8522 - val_loss: 0.3606 - val_acc: 0.8379\n",
      "Epoch 74/80\n",
      "38/37 [==============================] - 16s - loss: 0.3209 - acc: 0.8530 - val_loss: 0.3260 - val_acc: 0.8504\n",
      "Epoch 75/80\n",
      "38/37 [==============================] - 18s - loss: 0.3117 - acc: 0.8525 - val_loss: 0.3539 - val_acc: 0.8404\n",
      "Epoch 76/80\n",
      "38/37 [==============================] - 18s - loss: 0.3096 - acc: 0.8489 - val_loss: 0.3322 - val_acc: 0.8279\n",
      "Epoch 77/80\n",
      "38/37 [==============================] - 17s - loss: 0.2935 - acc: 0.8530 - val_loss: 0.3175 - val_acc: 0.8579\n",
      "Epoch 78/80\n",
      "38/37 [==============================] - 18s - loss: 0.2878 - acc: 0.8684 - val_loss: 0.3376 - val_acc: 0.8529\n",
      "Epoch 79/80\n",
      "38/37 [==============================] - 18s - loss: 0.2944 - acc: 0.8588 - val_loss: 0.3306 - val_acc: 0.8504\n",
      "Epoch 80/80\n",
      "38/37 [==============================] - 17s - loss: 0.3173 - acc: 0.8443 - val_loss: 0.3523 - val_acc: 0.8379\n"
     ]
    }
   ],
   "source": [
    "model.train(80, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "class DaveInceptionV3(DaveBaseModel):\n",
    "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
    "        DaveBaseModel.__init__(self, X_train, X_valid, y_train, y_valid)\n",
    "        v3_model = InceptionV3(include_top=False, weights=None, input_shape=(150, 150, 3))\n",
    "\n",
    "        x = v3_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(1024, activation='relu')(x)\n",
    "        predictions = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        self.model = Model(inputs=v3_model.input, outputs=predictions)\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        print(self.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_18 (InputLayer)            (None, 150, 150, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)              (None, 74, 74, 32)    864         input_18[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_565 (BatchNo (None, 74, 74, 32)    96          conv2d_565[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_565 (Activation)      (None, 74, 74, 32)    0           batch_normalization_565[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)              (None, 72, 72, 32)    9216        activation_565[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_566 (BatchNo (None, 72, 72, 32)    96          conv2d_566[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_566 (Activation)      (None, 72, 72, 32)    0           batch_normalization_566[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)              (None, 72, 72, 64)    18432       activation_566[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_567 (BatchNo (None, 72, 72, 64)    192         conv2d_567[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_567 (Activation)      (None, 72, 72, 64)    0           batch_normalization_567[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D)  (None, 35, 35, 64)    0           activation_567[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)              (None, 35, 35, 80)    5120        max_pooling2d_25[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_568 (BatchNo (None, 35, 35, 80)    240         conv2d_568[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_568 (Activation)      (None, 35, 35, 80)    0           batch_normalization_568[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)              (None, 33, 33, 192)   138240      activation_568[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_569 (BatchNo (None, 33, 33, 192)   576         conv2d_569[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_569 (Activation)      (None, 33, 33, 192)   0           batch_normalization_569[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D)  (None, 16, 16, 192)   0           activation_569[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)              (None, 16, 16, 64)    12288       max_pooling2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_573 (BatchNo (None, 16, 16, 64)    192         conv2d_573[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_573 (Activation)      (None, 16, 16, 64)    0           batch_normalization_573[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)              (None, 16, 16, 48)    9216        max_pooling2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)              (None, 16, 16, 96)    55296       activation_573[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_571 (BatchNo (None, 16, 16, 48)    144         conv2d_571[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_574 (BatchNo (None, 16, 16, 96)    288         conv2d_574[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_571 (Activation)      (None, 16, 16, 48)    0           batch_normalization_571[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_574 (Activation)      (None, 16, 16, 96)    0           batch_normalization_574[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_55 (AveragePoo (None, 16, 16, 192)   0           max_pooling2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)              (None, 16, 16, 64)    12288       max_pooling2d_26[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)              (None, 16, 16, 64)    76800       activation_571[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)              (None, 16, 16, 96)    82944       activation_574[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)              (None, 16, 16, 32)    6144        average_pooling2d_55[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_570 (BatchNo (None, 16, 16, 64)    192         conv2d_570[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_572 (BatchNo (None, 16, 16, 64)    192         conv2d_572[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_575 (BatchNo (None, 16, 16, 96)    288         conv2d_575[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_576 (BatchNo (None, 16, 16, 32)    96          conv2d_576[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_570 (Activation)      (None, 16, 16, 64)    0           batch_normalization_570[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_572 (Activation)      (None, 16, 16, 64)    0           batch_normalization_572[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_575 (Activation)      (None, 16, 16, 96)    0           batch_normalization_575[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_576 (Activation)      (None, 16, 16, 32)    0           batch_normalization_576[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, 16, 16, 256)   0           activation_570[0][0]             \n",
      "                                                                   activation_572[0][0]             \n",
      "                                                                   activation_575[0][0]             \n",
      "                                                                   activation_576[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)              (None, 16, 16, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_580 (BatchNo (None, 16, 16, 64)    192         conv2d_580[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_580 (Activation)      (None, 16, 16, 64)    0           batch_normalization_580[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)              (None, 16, 16, 48)    12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)              (None, 16, 16, 96)    55296       activation_580[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_578 (BatchNo (None, 16, 16, 48)    144         conv2d_578[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_581 (BatchNo (None, 16, 16, 96)    288         conv2d_581[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_578 (Activation)      (None, 16, 16, 48)    0           batch_normalization_578[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_581 (Activation)      (None, 16, 16, 96)    0           batch_normalization_581[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_56 (AveragePoo (None, 16, 16, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)              (None, 16, 16, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)              (None, 16, 16, 64)    76800       activation_578[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)              (None, 16, 16, 96)    82944       activation_581[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)              (None, 16, 16, 64)    16384       average_pooling2d_56[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_577 (BatchNo (None, 16, 16, 64)    192         conv2d_577[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_579 (BatchNo (None, 16, 16, 64)    192         conv2d_579[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_582 (BatchNo (None, 16, 16, 96)    288         conv2d_582[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_583 (BatchNo (None, 16, 16, 64)    192         conv2d_583[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_577 (Activation)      (None, 16, 16, 64)    0           batch_normalization_577[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_579 (Activation)      (None, 16, 16, 64)    0           batch_normalization_579[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_582 (Activation)      (None, 16, 16, 96)    0           batch_normalization_582[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_583 (Activation)      (None, 16, 16, 64)    0           batch_normalization_583[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, 16, 16, 288)   0           activation_577[0][0]             \n",
      "                                                                   activation_579[0][0]             \n",
      "                                                                   activation_582[0][0]             \n",
      "                                                                   activation_583[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)              (None, 16, 16, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchNo (None, 16, 16, 64)    192         conv2d_587[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_587 (Activation)      (None, 16, 16, 64)    0           batch_normalization_587[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)              (None, 16, 16, 48)    13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)              (None, 16, 16, 96)    55296       activation_587[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchNo (None, 16, 16, 48)    144         conv2d_585[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchNo (None, 16, 16, 96)    288         conv2d_588[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_585 (Activation)      (None, 16, 16, 48)    0           batch_normalization_585[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_588 (Activation)      (None, 16, 16, 96)    0           batch_normalization_588[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_57 (AveragePoo (None, 16, 16, 288)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)              (None, 16, 16, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)              (None, 16, 16, 64)    76800       activation_585[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)              (None, 16, 16, 96)    82944       activation_588[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)              (None, 16, 16, 64)    18432       average_pooling2d_57[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchNo (None, 16, 16, 64)    192         conv2d_584[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchNo (None, 16, 16, 64)    192         conv2d_586[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchNo (None, 16, 16, 96)    288         conv2d_589[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchNo (None, 16, 16, 64)    192         conv2d_590[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_584 (Activation)      (None, 16, 16, 64)    0           batch_normalization_584[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_586 (Activation)      (None, 16, 16, 64)    0           batch_normalization_586[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_589 (Activation)      (None, 16, 16, 96)    0           batch_normalization_589[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_590 (Activation)      (None, 16, 16, 64)    0           batch_normalization_590[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, 16, 16, 288)   0           activation_584[0][0]             \n",
      "                                                                   activation_586[0][0]             \n",
      "                                                                   activation_589[0][0]             \n",
      "                                                                   activation_590[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_592 (Conv2D)              (None, 16, 16, 64)    18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_592 (BatchNo (None, 16, 16, 64)    192         conv2d_592[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_592 (Activation)      (None, 16, 16, 64)    0           batch_normalization_592[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_593 (Conv2D)              (None, 16, 16, 96)    55296       activation_592[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_593 (BatchNo (None, 16, 16, 96)    288         conv2d_593[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_593 (Activation)      (None, 16, 16, 96)    0           batch_normalization_593[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_591 (Conv2D)              (None, 7, 7, 384)     995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_594 (Conv2D)              (None, 7, 7, 96)      82944       activation_593[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_591 (BatchNo (None, 7, 7, 384)     1152        conv2d_591[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_594 (BatchNo (None, 7, 7, 96)      288         conv2d_594[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_591 (Activation)      (None, 7, 7, 384)     0           batch_normalization_591[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_594 (Activation)      (None, 7, 7, 96)      0           batch_normalization_594[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D)  (None, 7, 7, 288)     0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, 7, 7, 768)     0           activation_591[0][0]             \n",
      "                                                                   activation_594[0][0]             \n",
      "                                                                   max_pooling2d_27[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_599 (Conv2D)              (None, 7, 7, 128)     98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_599 (BatchNo (None, 7, 7, 128)     384         conv2d_599[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_599 (Activation)      (None, 7, 7, 128)     0           batch_normalization_599[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_600 (Conv2D)              (None, 7, 7, 128)     114688      activation_599[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_600 (BatchNo (None, 7, 7, 128)     384         conv2d_600[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_600 (Activation)      (None, 7, 7, 128)     0           batch_normalization_600[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_596 (Conv2D)              (None, 7, 7, 128)     98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_601 (Conv2D)              (None, 7, 7, 128)     114688      activation_600[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_596 (BatchNo (None, 7, 7, 128)     384         conv2d_596[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_601 (BatchNo (None, 7, 7, 128)     384         conv2d_601[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_596 (Activation)      (None, 7, 7, 128)     0           batch_normalization_596[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_601 (Activation)      (None, 7, 7, 128)     0           batch_normalization_601[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_597 (Conv2D)              (None, 7, 7, 128)     114688      activation_596[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_602 (Conv2D)              (None, 7, 7, 128)     114688      activation_601[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_597 (BatchNo (None, 7, 7, 128)     384         conv2d_597[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_602 (BatchNo (None, 7, 7, 128)     384         conv2d_602[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_597 (Activation)      (None, 7, 7, 128)     0           batch_normalization_597[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_602 (Activation)      (None, 7, 7, 128)     0           batch_normalization_602[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_58 (AveragePoo (None, 7, 7, 768)     0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_595 (Conv2D)              (None, 7, 7, 192)     147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_598 (Conv2D)              (None, 7, 7, 192)     172032      activation_597[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_603 (Conv2D)              (None, 7, 7, 192)     172032      activation_602[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_604 (Conv2D)              (None, 7, 7, 192)     147456      average_pooling2d_58[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_595 (BatchNo (None, 7, 7, 192)     576         conv2d_595[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_598 (BatchNo (None, 7, 7, 192)     576         conv2d_598[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_603 (BatchNo (None, 7, 7, 192)     576         conv2d_603[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_604 (BatchNo (None, 7, 7, 192)     576         conv2d_604[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_595 (Activation)      (None, 7, 7, 192)     0           batch_normalization_595[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_598 (Activation)      (None, 7, 7, 192)     0           batch_normalization_598[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_603 (Activation)      (None, 7, 7, 192)     0           batch_normalization_603[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_604 (Activation)      (None, 7, 7, 192)     0           batch_normalization_604[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, 7, 7, 768)     0           activation_595[0][0]             \n",
      "                                                                   activation_598[0][0]             \n",
      "                                                                   activation_603[0][0]             \n",
      "                                                                   activation_604[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_609 (Conv2D)              (None, 7, 7, 160)     122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_609 (BatchNo (None, 7, 7, 160)     480         conv2d_609[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_609 (Activation)      (None, 7, 7, 160)     0           batch_normalization_609[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_610 (Conv2D)              (None, 7, 7, 160)     179200      activation_609[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchNo (None, 7, 7, 160)     480         conv2d_610[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_610 (Activation)      (None, 7, 7, 160)     0           batch_normalization_610[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_606 (Conv2D)              (None, 7, 7, 160)     122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_611 (Conv2D)              (None, 7, 7, 160)     179200      activation_610[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_606 (BatchNo (None, 7, 7, 160)     480         conv2d_606[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchNo (None, 7, 7, 160)     480         conv2d_611[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_606 (Activation)      (None, 7, 7, 160)     0           batch_normalization_606[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_611 (Activation)      (None, 7, 7, 160)     0           batch_normalization_611[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_607 (Conv2D)              (None, 7, 7, 160)     179200      activation_606[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_612 (Conv2D)              (None, 7, 7, 160)     179200      activation_611[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_607 (BatchNo (None, 7, 7, 160)     480         conv2d_607[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchNo (None, 7, 7, 160)     480         conv2d_612[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_607 (Activation)      (None, 7, 7, 160)     0           batch_normalization_607[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_612 (Activation)      (None, 7, 7, 160)     0           batch_normalization_612[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_59 (AveragePoo (None, 7, 7, 768)     0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_605 (Conv2D)              (None, 7, 7, 192)     147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_608 (Conv2D)              (None, 7, 7, 192)     215040      activation_607[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_613 (Conv2D)              (None, 7, 7, 192)     215040      activation_612[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_614 (Conv2D)              (None, 7, 7, 192)     147456      average_pooling2d_59[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_605 (BatchNo (None, 7, 7, 192)     576         conv2d_605[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_608 (BatchNo (None, 7, 7, 192)     576         conv2d_608[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchNo (None, 7, 7, 192)     576         conv2d_613[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchNo (None, 7, 7, 192)     576         conv2d_614[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_605 (Activation)      (None, 7, 7, 192)     0           batch_normalization_605[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_608 (Activation)      (None, 7, 7, 192)     0           batch_normalization_608[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_613 (Activation)      (None, 7, 7, 192)     0           batch_normalization_613[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_614 (Activation)      (None, 7, 7, 192)     0           batch_normalization_614[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, 7, 7, 768)     0           activation_605[0][0]             \n",
      "                                                                   activation_608[0][0]             \n",
      "                                                                   activation_613[0][0]             \n",
      "                                                                   activation_614[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_619 (Conv2D)              (None, 7, 7, 160)     122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchNo (None, 7, 7, 160)     480         conv2d_619[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_619 (Activation)      (None, 7, 7, 160)     0           batch_normalization_619[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_620 (Conv2D)              (None, 7, 7, 160)     179200      activation_619[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchNo (None, 7, 7, 160)     480         conv2d_620[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_620 (Activation)      (None, 7, 7, 160)     0           batch_normalization_620[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_616 (Conv2D)              (None, 7, 7, 160)     122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_621 (Conv2D)              (None, 7, 7, 160)     179200      activation_620[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchNo (None, 7, 7, 160)     480         conv2d_616[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchNo (None, 7, 7, 160)     480         conv2d_621[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_616 (Activation)      (None, 7, 7, 160)     0           batch_normalization_616[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_621 (Activation)      (None, 7, 7, 160)     0           batch_normalization_621[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_617 (Conv2D)              (None, 7, 7, 160)     179200      activation_616[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_622 (Conv2D)              (None, 7, 7, 160)     179200      activation_621[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchNo (None, 7, 7, 160)     480         conv2d_617[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchNo (None, 7, 7, 160)     480         conv2d_622[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_617 (Activation)      (None, 7, 7, 160)     0           batch_normalization_617[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_622 (Activation)      (None, 7, 7, 160)     0           batch_normalization_622[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_60 (AveragePoo (None, 7, 7, 768)     0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_615 (Conv2D)              (None, 7, 7, 192)     147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_618 (Conv2D)              (None, 7, 7, 192)     215040      activation_617[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_623 (Conv2D)              (None, 7, 7, 192)     215040      activation_622[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_624 (Conv2D)              (None, 7, 7, 192)     147456      average_pooling2d_60[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchNo (None, 7, 7, 192)     576         conv2d_615[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchNo (None, 7, 7, 192)     576         conv2d_618[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchNo (None, 7, 7, 192)     576         conv2d_623[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchNo (None, 7, 7, 192)     576         conv2d_624[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_615 (Activation)      (None, 7, 7, 192)     0           batch_normalization_615[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_618 (Activation)      (None, 7, 7, 192)     0           batch_normalization_618[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_623 (Activation)      (None, 7, 7, 192)     0           batch_normalization_623[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_624 (Activation)      (None, 7, 7, 192)     0           batch_normalization_624[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, 7, 7, 768)     0           activation_615[0][0]             \n",
      "                                                                   activation_618[0][0]             \n",
      "                                                                   activation_623[0][0]             \n",
      "                                                                   activation_624[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_629 (Conv2D)              (None, 7, 7, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchNo (None, 7, 7, 192)     576         conv2d_629[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_629 (Activation)      (None, 7, 7, 192)     0           batch_normalization_629[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_630 (Conv2D)              (None, 7, 7, 192)     258048      activation_629[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchNo (None, 7, 7, 192)     576         conv2d_630[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_630 (Activation)      (None, 7, 7, 192)     0           batch_normalization_630[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_626 (Conv2D)              (None, 7, 7, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_631 (Conv2D)              (None, 7, 7, 192)     258048      activation_630[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchNo (None, 7, 7, 192)     576         conv2d_626[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_631 (BatchNo (None, 7, 7, 192)     576         conv2d_631[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_626 (Activation)      (None, 7, 7, 192)     0           batch_normalization_626[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_631 (Activation)      (None, 7, 7, 192)     0           batch_normalization_631[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_627 (Conv2D)              (None, 7, 7, 192)     258048      activation_626[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_632 (Conv2D)              (None, 7, 7, 192)     258048      activation_631[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchNo (None, 7, 7, 192)     576         conv2d_627[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_632 (BatchNo (None, 7, 7, 192)     576         conv2d_632[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_627 (Activation)      (None, 7, 7, 192)     0           batch_normalization_627[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_632 (Activation)      (None, 7, 7, 192)     0           batch_normalization_632[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_61 (AveragePoo (None, 7, 7, 768)     0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_625 (Conv2D)              (None, 7, 7, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_628 (Conv2D)              (None, 7, 7, 192)     258048      activation_627[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_633 (Conv2D)              (None, 7, 7, 192)     258048      activation_632[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_634 (Conv2D)              (None, 7, 7, 192)     147456      average_pooling2d_61[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchNo (None, 7, 7, 192)     576         conv2d_625[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchNo (None, 7, 7, 192)     576         conv2d_628[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_633 (BatchNo (None, 7, 7, 192)     576         conv2d_633[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_634 (BatchNo (None, 7, 7, 192)     576         conv2d_634[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_625 (Activation)      (None, 7, 7, 192)     0           batch_normalization_625[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_628 (Activation)      (None, 7, 7, 192)     0           batch_normalization_628[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_633 (Activation)      (None, 7, 7, 192)     0           batch_normalization_633[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_634 (Activation)      (None, 7, 7, 192)     0           batch_normalization_634[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, 7, 7, 768)     0           activation_625[0][0]             \n",
      "                                                                   activation_628[0][0]             \n",
      "                                                                   activation_633[0][0]             \n",
      "                                                                   activation_634[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_637 (Conv2D)              (None, 7, 7, 192)     147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_637 (BatchNo (None, 7, 7, 192)     576         conv2d_637[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_637 (Activation)      (None, 7, 7, 192)     0           batch_normalization_637[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_638 (Conv2D)              (None, 7, 7, 192)     258048      activation_637[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_638 (BatchNo (None, 7, 7, 192)     576         conv2d_638[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_638 (Activation)      (None, 7, 7, 192)     0           batch_normalization_638[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_635 (Conv2D)              (None, 7, 7, 192)     147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_639 (Conv2D)              (None, 7, 7, 192)     258048      activation_638[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_635 (BatchNo (None, 7, 7, 192)     576         conv2d_635[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_639 (BatchNo (None, 7, 7, 192)     576         conv2d_639[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_635 (Activation)      (None, 7, 7, 192)     0           batch_normalization_635[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_639 (Activation)      (None, 7, 7, 192)     0           batch_normalization_639[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_636 (Conv2D)              (None, 3, 3, 320)     552960      activation_635[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_640 (Conv2D)              (None, 3, 3, 192)     331776      activation_639[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_636 (BatchNo (None, 3, 3, 320)     960         conv2d_636[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_640 (BatchNo (None, 3, 3, 192)     576         conv2d_640[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_636 (Activation)      (None, 3, 3, 320)     0           batch_normalization_636[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_640 (Activation)      (None, 3, 3, 192)     0           batch_normalization_640[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D)  (None, 3, 3, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, 3, 3, 1280)    0           activation_636[0][0]             \n",
      "                                                                   activation_640[0][0]             \n",
      "                                                                   max_pooling2d_28[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_645 (Conv2D)              (None, 3, 3, 448)     573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_645 (BatchNo (None, 3, 3, 448)     1344        conv2d_645[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_645 (Activation)      (None, 3, 3, 448)     0           batch_normalization_645[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_642 (Conv2D)              (None, 3, 3, 384)     491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_646 (Conv2D)              (None, 3, 3, 384)     1548288     activation_645[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_642 (BatchNo (None, 3, 3, 384)     1152        conv2d_642[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchNo (None, 3, 3, 384)     1152        conv2d_646[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_642 (Activation)      (None, 3, 3, 384)     0           batch_normalization_642[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_646 (Activation)      (None, 3, 3, 384)     0           batch_normalization_646[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_643 (Conv2D)              (None, 3, 3, 384)     442368      activation_642[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_644 (Conv2D)              (None, 3, 3, 384)     442368      activation_642[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_647 (Conv2D)              (None, 3, 3, 384)     442368      activation_646[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_648 (Conv2D)              (None, 3, 3, 384)     442368      activation_646[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_62 (AveragePoo (None, 3, 3, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_641 (Conv2D)              (None, 3, 3, 320)     409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_643 (BatchNo (None, 3, 3, 384)     1152        conv2d_643[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_644 (BatchNo (None, 3, 3, 384)     1152        conv2d_644[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchNo (None, 3, 3, 384)     1152        conv2d_647[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchNo (None, 3, 3, 384)     1152        conv2d_648[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_649 (Conv2D)              (None, 3, 3, 192)     245760      average_pooling2d_62[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_641 (BatchNo (None, 3, 3, 320)     960         conv2d_641[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_643 (Activation)      (None, 3, 3, 384)     0           batch_normalization_643[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_644 (Activation)      (None, 3, 3, 384)     0           batch_normalization_644[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_647 (Activation)      (None, 3, 3, 384)     0           batch_normalization_647[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_648 (Activation)      (None, 3, 3, 384)     0           batch_normalization_648[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchNo (None, 3, 3, 192)     576         conv2d_649[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_641 (Activation)      (None, 3, 3, 320)     0           batch_normalization_641[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, 3, 3, 768)     0           activation_643[0][0]             \n",
      "                                                                   activation_644[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)     (None, 3, 3, 768)     0           activation_647[0][0]             \n",
      "                                                                   activation_648[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_649 (Activation)      (None, 3, 3, 192)     0           batch_normalization_649[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, 3, 3, 2048)    0           activation_641[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_13[0][0]             \n",
      "                                                                   activation_649[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_654 (Conv2D)              (None, 3, 3, 448)     917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchNo (None, 3, 3, 448)     1344        conv2d_654[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_654 (Activation)      (None, 3, 3, 448)     0           batch_normalization_654[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_651 (Conv2D)              (None, 3, 3, 384)     786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_655 (Conv2D)              (None, 3, 3, 384)     1548288     activation_654[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchNo (None, 3, 3, 384)     1152        conv2d_651[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchNo (None, 3, 3, 384)     1152        conv2d_655[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_651 (Activation)      (None, 3, 3, 384)     0           batch_normalization_651[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_655 (Activation)      (None, 3, 3, 384)     0           batch_normalization_655[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_652 (Conv2D)              (None, 3, 3, 384)     442368      activation_651[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_653 (Conv2D)              (None, 3, 3, 384)     442368      activation_651[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_656 (Conv2D)              (None, 3, 3, 384)     442368      activation_655[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_657 (Conv2D)              (None, 3, 3, 384)     442368      activation_655[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_63 (AveragePoo (None, 3, 3, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_650 (Conv2D)              (None, 3, 3, 320)     655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchNo (None, 3, 3, 384)     1152        conv2d_652[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchNo (None, 3, 3, 384)     1152        conv2d_653[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchNo (None, 3, 3, 384)     1152        conv2d_656[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_657 (BatchNo (None, 3, 3, 384)     1152        conv2d_657[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_658 (Conv2D)              (None, 3, 3, 192)     393216      average_pooling2d_63[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchNo (None, 3, 3, 320)     960         conv2d_650[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_652 (Activation)      (None, 3, 3, 384)     0           batch_normalization_652[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_653 (Activation)      (None, 3, 3, 384)     0           batch_normalization_653[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_656 (Activation)      (None, 3, 3, 384)     0           batch_normalization_656[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_657 (Activation)      (None, 3, 3, 384)     0           batch_normalization_657[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_658 (BatchNo (None, 3, 3, 192)     576         conv2d_658[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_650 (Activation)      (None, 3, 3, 320)     0           batch_normalization_650[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 3, 3, 768)     0           activation_652[0][0]             \n",
      "                                                                   activation_653[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)     (None, 3, 3, 768)     0           activation_656[0][0]             \n",
      "                                                                   activation_657[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_658 (Activation)      (None, 3, 3, 192)     0           batch_normalization_658[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 3, 3, 2048)    0           activation_650[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_14[0][0]             \n",
      "                                                                   activation_658[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glob (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_32 (Dense)                 (None, 1024)          2098176     global_average_pooling2d_6[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_33 (Dense)                 (None, 1)             1025        dense_32[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 23,901,985\n",
      "Trainable params: 23,867,553\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DaveInceptionV3(X_train_cv, X_valid, y_train_cv, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/18 [==============================] - 33s - loss: 0.5884 - acc: 0.6658 - val_loss: 0.6964 - val_acc: 0.4688\n",
      "Epoch 2/50\n",
      "19/18 [==============================] - 8s - loss: 0.5128 - acc: 0.7380 - val_loss: 0.7057 - val_acc: 0.4688\n",
      "Epoch 3/50\n",
      "19/18 [==============================] - 8s - loss: 0.4749 - acc: 0.7724 - val_loss: 0.7530 - val_acc: 0.4688\n",
      "Epoch 4/50\n",
      "19/18 [==============================] - 8s - loss: 0.4488 - acc: 0.7827 - val_loss: 0.7502 - val_acc: 0.4688\n",
      "Epoch 5/50\n",
      "19/18 [==============================] - 8s - loss: 0.4122 - acc: 0.8112 - val_loss: 0.7164 - val_acc: 0.4688\n",
      "Epoch 6/50\n",
      "19/18 [==============================] - 8s - loss: 0.4223 - acc: 0.7954 - val_loss: 0.7506 - val_acc: 0.4688\n",
      "Epoch 7/50\n",
      "19/18 [==============================] - 8s - loss: 0.4089 - acc: 0.8007 - val_loss: 0.7704 - val_acc: 0.4688\n",
      "Epoch 8/50\n",
      "19/18 [==============================] - 8s - loss: 0.3762 - acc: 0.8139 - val_loss: 0.7695 - val_acc: 0.4688\n",
      "Epoch 9/50\n",
      "19/18 [==============================] - 8s - loss: 0.3446 - acc: 0.8308 - val_loss: 0.7517 - val_acc: 0.4688\n",
      "Epoch 10/50\n",
      "19/18 [==============================] - 8s - loss: 0.3785 - acc: 0.8246 - val_loss: 0.9003 - val_acc: 0.4688\n",
      "Epoch 11/50\n",
      "19/18 [==============================] - 8s - loss: 0.3509 - acc: 0.8264 - val_loss: 0.8551 - val_acc: 0.4688\n",
      "Epoch 12/50\n",
      "19/18 [==============================] - 8s - loss: 0.3574 - acc: 0.8213 - val_loss: 0.9263 - val_acc: 0.4688\n",
      "Epoch 13/50\n",
      "19/18 [==============================] - 8s - loss: 0.3748 - acc: 0.8104 - val_loss: 0.9842 - val_acc: 0.4688\n",
      "Epoch 14/50\n",
      "19/18 [==============================] - 8s - loss: 0.3529 - acc: 0.8339 - val_loss: 0.8216 - val_acc: 0.4738\n",
      "Epoch 15/50\n",
      "19/18 [==============================] - 8s - loss: 0.3237 - acc: 0.8451 - val_loss: 0.7388 - val_acc: 0.4763\n",
      "Epoch 16/50\n",
      "19/18 [==============================] - 8s - loss: 0.3303 - acc: 0.8349 - val_loss: 0.7604 - val_acc: 0.5162\n",
      "Epoch 17/50\n",
      "19/18 [==============================] - 8s - loss: 0.3386 - acc: 0.8425 - val_loss: 1.3385 - val_acc: 0.5312\n",
      "Epoch 18/50\n",
      "19/18 [==============================] - 8s - loss: 0.3265 - acc: 0.8456 - val_loss: 1.2097 - val_acc: 0.5312\n",
      "Epoch 19/50\n",
      "19/18 [==============================] - 8s - loss: 0.3314 - acc: 0.8411 - val_loss: 1.8268 - val_acc: 0.5312\n",
      "Epoch 20/50\n",
      "19/18 [==============================] - 8s - loss: 0.3400 - acc: 0.8390 - val_loss: 2.0033 - val_acc: 0.5312\n",
      "Epoch 21/50\n",
      "19/18 [==============================] - 8s - loss: 0.3418 - acc: 0.8326 - val_loss: 1.6567 - val_acc: 0.5312\n",
      "Epoch 22/50\n",
      "19/18 [==============================] - 8s - loss: 0.3177 - acc: 0.8511 - val_loss: 1.7734 - val_acc: 0.5312\n",
      "Epoch 23/50\n",
      "19/18 [==============================] - 8s - loss: 0.3353 - acc: 0.8532 - val_loss: 2.1195 - val_acc: 0.5312\n",
      "Epoch 24/50\n",
      "19/18 [==============================] - 8s - loss: 0.3188 - acc: 0.8532 - val_loss: 2.6438 - val_acc: 0.5312\n",
      "Epoch 25/50\n",
      "19/18 [==============================] - 8s - loss: 0.2896 - acc: 0.8665 - val_loss: 1.3316 - val_acc: 0.5461\n",
      "Epoch 26/50\n",
      "19/18 [==============================] - 8s - loss: 0.2929 - acc: 0.8663 - val_loss: 1.3064 - val_acc: 0.5387\n",
      "Epoch 27/50\n",
      "19/18 [==============================] - 8s - loss: 0.3046 - acc: 0.8633 - val_loss: 0.9955 - val_acc: 0.5885\n",
      "Epoch 28/50\n",
      "19/18 [==============================] - 8s - loss: 0.3065 - acc: 0.8579 - val_loss: 1.1456 - val_acc: 0.5786\n",
      "Epoch 29/50\n",
      "19/18 [==============================] - 8s - loss: 0.3073 - acc: 0.8596 - val_loss: 1.2574 - val_acc: 0.5661\n",
      "Epoch 30/50\n",
      "19/18 [==============================] - 8s - loss: 0.3210 - acc: 0.8483 - val_loss: 1.1932 - val_acc: 0.6085\n",
      "Epoch 31/50\n",
      "19/18 [==============================] - 8s - loss: 0.2860 - acc: 0.8717 - val_loss: 1.2273 - val_acc: 0.6334\n",
      "Epoch 32/50\n",
      "19/18 [==============================] - 8s - loss: 0.3071 - acc: 0.8563 - val_loss: 0.9103 - val_acc: 0.6409\n",
      "Epoch 33/50\n",
      "19/18 [==============================] - 8s - loss: 0.2877 - acc: 0.8698 - val_loss: 0.8296 - val_acc: 0.7082\n",
      "Epoch 34/50\n",
      "19/18 [==============================] - 8s - loss: 0.3061 - acc: 0.8606 - val_loss: 0.6659 - val_acc: 0.7032\n",
      "Epoch 35/50\n",
      "19/18 [==============================] - 8s - loss: 0.2813 - acc: 0.8688 - val_loss: 0.6823 - val_acc: 0.7157\n",
      "Epoch 36/50\n",
      "19/18 [==============================] - 8s - loss: 0.3092 - acc: 0.8507 - val_loss: 0.8374 - val_acc: 0.6908\n",
      "Epoch 37/50\n",
      "19/18 [==============================] - 8s - loss: 0.2970 - acc: 0.8655 - val_loss: 0.8519 - val_acc: 0.7182\n",
      "Epoch 38/50\n",
      "19/18 [==============================] - 8s - loss: 0.2935 - acc: 0.8664 - val_loss: 0.5276 - val_acc: 0.8005\n",
      "Epoch 39/50\n",
      "19/18 [==============================] - 8s - loss: 0.2951 - acc: 0.8600 - val_loss: 0.4228 - val_acc: 0.8055\n",
      "Epoch 40/50\n",
      "19/18 [==============================] - 8s - loss: 0.2751 - acc: 0.8764 - val_loss: 0.4983 - val_acc: 0.7805\n",
      "Epoch 41/50\n",
      "19/18 [==============================] - 8s - loss: 0.2735 - acc: 0.8737 - val_loss: 0.4967 - val_acc: 0.7980\n",
      "Epoch 42/50\n",
      "19/18 [==============================] - 8s - loss: 0.2828 - acc: 0.8694 - val_loss: 0.4929 - val_acc: 0.7980\n",
      "Epoch 43/50\n",
      "19/18 [==============================] - 8s - loss: 0.2800 - acc: 0.8834 - val_loss: 0.4269 - val_acc: 0.8055\n",
      "Epoch 44/50\n",
      "19/18 [==============================] - 8s - loss: 0.2534 - acc: 0.8949 - val_loss: 0.4298 - val_acc: 0.8379\n",
      "Epoch 45/50\n",
      "19/18 [==============================] - 8s - loss: 0.2682 - acc: 0.8844 - val_loss: 0.5466 - val_acc: 0.8080\n",
      "Epoch 46/50\n",
      "19/18 [==============================] - 8s - loss: 0.2705 - acc: 0.8793 - val_loss: 0.4504 - val_acc: 0.7905\n",
      "Epoch 47/50\n",
      "19/18 [==============================] - 8s - loss: 0.2604 - acc: 0.8832 - val_loss: 0.4681 - val_acc: 0.8354\n",
      "Epoch 48/50\n",
      "19/18 [==============================] - 8s - loss: 0.2479 - acc: 0.8894 - val_loss: 0.5659 - val_acc: 0.8130\n",
      "Epoch 49/50\n",
      "19/18 [==============================] - 8s - loss: 0.2566 - acc: 0.8791 - val_loss: 0.5144 - val_acc: 0.8155\n",
      "Epoch 50/50\n",
      "19/18 [==============================] - 8s - loss: 0.2629 - acc: 0.8791 - val_loss: 0.4907 - val_acc: 0.8329\n"
     ]
    }
   ],
   "source": [
    "model.train(50, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
