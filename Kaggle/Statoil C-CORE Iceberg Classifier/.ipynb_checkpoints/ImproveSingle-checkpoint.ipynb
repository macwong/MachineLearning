{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "import helpers\n",
    "from models import DaveModel, DaveVGG, DaveVGG19, SimpleModel, LeNetModel\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"_RawData/test.json/data/processed/test.json\")\n",
    "\n",
    "X = helpers.get_images(train)\n",
    "X_test = helpers.get_images(test)\n",
    "\n",
    "y = to_categorical(train.is_iceberg.values,num_classes=2)\n",
    "\n",
    "Xtr, Xv, ytr, yv = train_test_split(X, y, shuffle=False, test_size=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling2D\n",
    "import models\n",
    "from models import DaveBaseModel\n",
    "import helpers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16, VGG19\n",
    "import abc\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class DaveModel2(DaveBaseModel):\n",
    "    def ConvBlock(model, layers, filters):\n",
    "        '''Create [layers] layers consisting of zero padding, a convolution with [filters] 3x3 filters and batch normalization. Perform max pooling after the last layer.'''\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Conv2D(filters, (3, 3), activation='relu'))\n",
    "            model.add(BatchNormalization(axis=3))\n",
    "            model.add(Dropout(0.5))\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    def get_model(self):\n",
    "        '''Create the FCN and return a keras model.'''\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input image: 75x75x3\n",
    "        model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "        DaveModel.ConvBlock(model, 1, 64)\n",
    "        # 37x37x32\n",
    "        DaveModel.ConvBlock(model, 1, 128)\n",
    "        # 18x18x64\n",
    "        DaveModel.ConvBlock(model, 1, 256)\n",
    "        # 9x9x128\n",
    "        DaveModel.ConvBlock(model, 1, 256)\n",
    "        # 4x4x128\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        # 4x4x2\n",
    "        model.add(Activation('softmax'))\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def get_generator(self, Xtr, Xv):\n",
    "        data_gen = ImageDataGenerator(\n",
    "#                     shear_range=0.05,\n",
    "#                     zoom_range=0.01,\n",
    "                    rotation_range=180,\n",
    "                    width_shift_range=0.01,\n",
    "                    height_shift_range=0.01,\n",
    "                    vertical_flip=True,\n",
    "                    horizontal_flip=True)\n",
    "\n",
    "        data_gen.fit(Xtr)\n",
    "\n",
    "        val_gen = ImageDataGenerator()\n",
    "        val_gen.fit(Xv)\n",
    "        \n",
    "        return data_gen, val_gen\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"davemodel2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DaveModel2(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.model.load_weights(\"01 - 2137.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: davemodel2\n",
      "Batch Size: 32\n",
      "Epochs: 80\n",
      "Epoch 1/80\n",
      "41/40 [==============================] - 7s - loss: 0.5485 - acc: 0.7236 - val_loss: 0.6495 - val_acc: 0.6573\n",
      "Epoch 2/80\n",
      "41/40 [==============================] - 2s - loss: 0.4455 - acc: 0.7659 - val_loss: 0.6751 - val_acc: 0.6573\n",
      "Epoch 3/80\n",
      "41/40 [==============================] - 2s - loss: 0.3964 - acc: 0.8017 - val_loss: 0.7441 - val_acc: 0.6573\n",
      "Epoch 4/80\n",
      "41/40 [==============================] - 2s - loss: 0.3653 - acc: 0.8208 - val_loss: 0.7635 - val_acc: 0.6573\n",
      "Epoch 5/80\n",
      "41/40 [==============================] - 2s - loss: 0.3527 - acc: 0.8262 - val_loss: 1.0845 - val_acc: 0.6573\n",
      "Epoch 6/80\n",
      "41/40 [==============================] - 2s - loss: 0.3351 - acc: 0.8376 - val_loss: 1.2693 - val_acc: 0.6573\n",
      "Epoch 7/80\n",
      "41/40 [==============================] - 2s - loss: 0.3049 - acc: 0.8604 - val_loss: 1.6894 - val_acc: 0.6573\n",
      "Epoch 8/80\n",
      "41/40 [==============================] - 2s - loss: 0.3130 - acc: 0.8578 - val_loss: 2.0662 - val_acc: 0.6573\n",
      "Epoch 9/80\n",
      "41/40 [==============================] - 2s - loss: 0.3031 - acc: 0.8475 - val_loss: 2.3629 - val_acc: 0.6573\n",
      "Epoch 10/80\n",
      "41/40 [==============================] - 2s - loss: 0.2755 - acc: 0.8665 - val_loss: 2.7643 - val_acc: 0.6573\n",
      "Epoch 11/80\n",
      "41/40 [==============================] - 2s - loss: 0.2668 - acc: 0.8780 - val_loss: 2.7552 - val_acc: 0.6573\n",
      "Epoch 12/80\n",
      "41/40 [==============================] - 2s - loss: 0.2715 - acc: 0.8563 - val_loss: 1.6415 - val_acc: 0.6573\n",
      "Epoch 13/80\n",
      "41/40 [==============================] - 2s - loss: 0.2743 - acc: 0.8677 - val_loss: 1.4256 - val_acc: 0.6667\n",
      "Epoch 14/80\n",
      "41/40 [==============================] - 2s - loss: 0.2632 - acc: 0.8726 - val_loss: 0.5420 - val_acc: 0.6978\n",
      "Epoch 15/80\n",
      "41/40 [==============================] - 2s - loss: 0.2698 - acc: 0.8826 - val_loss: 0.3531 - val_acc: 0.8598\n",
      "Epoch 16/80\n",
      "41/40 [==============================] - 2s - loss: 0.2538 - acc: 0.8754 - val_loss: 0.3852 - val_acc: 0.7882\n",
      "Epoch 17/80\n",
      "41/40 [==============================] - 2s - loss: 0.2605 - acc: 0.8795 - val_loss: 0.3157 - val_acc: 0.8380\n",
      "Epoch 18/80\n",
      "41/40 [==============================] - 2s - loss: 0.2469 - acc: 0.8917 - val_loss: 0.2949 - val_acc: 0.8723\n",
      "Epoch 19/80\n",
      "41/40 [==============================] - 2s - loss: 0.2314 - acc: 0.8871 - val_loss: 0.3300 - val_acc: 0.8193\n",
      "Epoch 20/80\n",
      "41/40 [==============================] - 2s - loss: 0.2331 - acc: 0.8838 - val_loss: 0.3233 - val_acc: 0.8879\n",
      "Epoch 21/80\n",
      "41/40 [==============================] - 2s - loss: 0.2240 - acc: 0.8948 - val_loss: 0.3064 - val_acc: 0.8785\n",
      "Epoch 22/80\n",
      "41/40 [==============================] - 2s - loss: 0.2299 - acc: 0.8948 - val_loss: 0.2872 - val_acc: 0.8910\n",
      "Epoch 23/80\n",
      "41/40 [==============================] - 2s - loss: 0.2316 - acc: 0.9009 - val_loss: 0.3161 - val_acc: 0.8318\n",
      "Epoch 24/80\n",
      "41/40 [==============================] - 2s - loss: 0.2244 - acc: 0.8872 - val_loss: 0.2844 - val_acc: 0.8879\n",
      "Epoch 25/80\n",
      "41/40 [==============================] - 2s - loss: 0.2581 - acc: 0.8822 - val_loss: 0.3131 - val_acc: 0.8847\n",
      "Epoch 26/80\n",
      "41/40 [==============================] - 2s - loss: 0.2367 - acc: 0.8822 - val_loss: 0.3738 - val_acc: 0.7819\n",
      "Epoch 27/80\n",
      "41/40 [==============================] - 2s - loss: 0.2061 - acc: 0.9009 - val_loss: 0.3193 - val_acc: 0.8224\n",
      "Epoch 28/80\n",
      "41/40 [==============================] - 2s - loss: 0.2135 - acc: 0.9021 - val_loss: 0.3012 - val_acc: 0.8629\n",
      "Epoch 29/80\n",
      "41/40 [==============================] - 2s - loss: 0.2111 - acc: 0.9070 - val_loss: 0.2826 - val_acc: 0.8941\n",
      "Epoch 30/80\n",
      "41/40 [==============================] - 2s - loss: 0.1958 - acc: 0.9100 - val_loss: 0.2734 - val_acc: 0.8629\n",
      "Epoch 31/80\n",
      "41/40 [==============================] - 2s - loss: 0.1918 - acc: 0.9176 - val_loss: 0.2603 - val_acc: 0.9065\n",
      "Epoch 32/80\n",
      "41/40 [==============================] - 2s - loss: 0.1841 - acc: 0.9253 - val_loss: 0.2552 - val_acc: 0.9065\n",
      "Epoch 33/80\n",
      "41/40 [==============================] - 2s - loss: 0.1825 - acc: 0.9173 - val_loss: 0.2564 - val_acc: 0.8816\n",
      "Epoch 34/80\n",
      "41/40 [==============================] - 2s - loss: 0.1910 - acc: 0.9100 - val_loss: 0.3038 - val_acc: 0.8754\n",
      "Epoch 35/80\n",
      "41/40 [==============================] - 2s - loss: 0.1743 - acc: 0.9298 - val_loss: 0.5457 - val_acc: 0.7477\n",
      "Epoch 36/80\n",
      "41/40 [==============================] - 2s - loss: 0.1932 - acc: 0.9097 - val_loss: 0.3054 - val_acc: 0.8536\n",
      "Epoch 37/80\n",
      "41/40 [==============================] - 2s - loss: 0.1980 - acc: 0.9223 - val_loss: 0.2838 - val_acc: 0.9034\n",
      "Epoch 38/80\n",
      "41/40 [==============================] - 2s - loss: 0.1892 - acc: 0.9260 - val_loss: 0.2868 - val_acc: 0.8941\n",
      "Epoch 39/80\n",
      "41/40 [==============================] - 2s - loss: 0.1971 - acc: 0.9188 - val_loss: 0.2552 - val_acc: 0.9065\n",
      "Epoch 40/80\n",
      "41/40 [==============================] - 2s - loss: 0.1799 - acc: 0.9207 - val_loss: 0.2593 - val_acc: 0.9190\n",
      "Epoch 41/80\n",
      "41/40 [==============================] - 2s - loss: 0.1659 - acc: 0.9253 - val_loss: 0.2926 - val_acc: 0.8972\n",
      "Epoch 42/80\n",
      "41/40 [==============================] - 2s - loss: 0.1869 - acc: 0.9268 - val_loss: 0.2793 - val_acc: 0.8816\n",
      "Epoch 43/80\n",
      "41/40 [==============================] - 2s - loss: 0.1582 - acc: 0.9359 - val_loss: 0.2490 - val_acc: 0.9034\n",
      "Epoch 44/80\n",
      "41/40 [==============================] - 2s - loss: 0.1582 - acc: 0.9306 - val_loss: 0.2460 - val_acc: 0.9065\n",
      "Epoch 45/80\n",
      "41/40 [==============================] - 2s - loss: 0.1572 - acc: 0.9344 - val_loss: 0.2937 - val_acc: 0.8785\n",
      "Epoch 46/80\n",
      "41/40 [==============================] - 2s - loss: 0.1808 - acc: 0.9234 - val_loss: 0.2723 - val_acc: 0.9065\n",
      "Epoch 47/80\n",
      "41/40 [==============================] - 2s - loss: 0.1734 - acc: 0.9306 - val_loss: 0.2929 - val_acc: 0.8785\n",
      "Epoch 48/80\n",
      "41/40 [==============================] - 2s - loss: 0.1479 - acc: 0.9443 - val_loss: 0.3722 - val_acc: 0.8411\n",
      "Epoch 49/80\n",
      "41/40 [==============================] - 2s - loss: 0.1504 - acc: 0.9356 - val_loss: 0.2919 - val_acc: 0.8785\n",
      "Epoch 50/80\n",
      "41/40 [==============================] - 2s - loss: 0.1596 - acc: 0.9382 - val_loss: 0.3464 - val_acc: 0.8349\n",
      "Epoch 51/80\n",
      "41/40 [==============================] - 2s - loss: 0.1512 - acc: 0.9359 - val_loss: 0.3118 - val_acc: 0.8474\n",
      "Epoch 52/80\n",
      "41/40 [==============================] - 2s - loss: 0.1423 - acc: 0.9451 - val_loss: 0.2803 - val_acc: 0.8754\n",
      "Epoch 53/80\n",
      "41/40 [==============================] - 2s - loss: 0.1348 - acc: 0.9489 - val_loss: 0.2643 - val_acc: 0.8692\n",
      "Epoch 54/80\n",
      "41/40 [==============================] - 2s - loss: 0.1367 - acc: 0.9474 - val_loss: 0.2565 - val_acc: 0.9065\n",
      "Epoch 55/80\n",
      "41/40 [==============================] - 2s - loss: 0.1372 - acc: 0.9455 - val_loss: 0.2762 - val_acc: 0.8629\n",
      "Epoch 56/80\n",
      "41/40 [==============================] - 2s - loss: 0.1377 - acc: 0.9466 - val_loss: 0.2863 - val_acc: 0.8567\n",
      "Epoch 57/80\n",
      "41/40 [==============================] - 2s - loss: 0.1181 - acc: 0.9535 - val_loss: 0.2344 - val_acc: 0.8910\n",
      "Epoch 58/80\n",
      "41/40 [==============================] - 2s - loss: 0.1287 - acc: 0.9459 - val_loss: 0.2463 - val_acc: 0.8972\n",
      "Epoch 59/80\n",
      "41/40 [==============================] - 2s - loss: 0.1078 - acc: 0.9626 - val_loss: 0.3442 - val_acc: 0.8629\n",
      "Epoch 60/80\n",
      "41/40 [==============================] - 2s - loss: 0.1303 - acc: 0.9489 - val_loss: 0.2718 - val_acc: 0.8941\n",
      "Epoch 61/80\n",
      "41/40 [==============================] - 2s - loss: 0.1161 - acc: 0.9550 - val_loss: 0.2780 - val_acc: 0.9003\n",
      "Epoch 62/80\n",
      "41/40 [==============================] - 2s - loss: 0.1333 - acc: 0.9432 - val_loss: 0.2696 - val_acc: 0.9065\n",
      "Epoch 63/80\n",
      "41/40 [==============================] - 2s - loss: 0.1340 - acc: 0.9405 - val_loss: 0.3094 - val_acc: 0.8505\n",
      "Epoch 64/80\n",
      "41/40 [==============================] - 2s - loss: 0.1171 - acc: 0.9611 - val_loss: 0.3272 - val_acc: 0.8629\n",
      "Epoch 65/80\n",
      "41/40 [==============================] - 2s - loss: 0.1096 - acc: 0.9581 - val_loss: 0.3621 - val_acc: 0.8692\n",
      "Epoch 66/80\n",
      "41/40 [==============================] - 2s - loss: 0.1337 - acc: 0.9497 - val_loss: 0.2964 - val_acc: 0.8816\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 2s - loss: 0.1136 - acc: 0.9504 - val_loss: 0.2460 - val_acc: 0.9034\n",
      "Epoch 68/80\n",
      "41/40 [==============================] - 2s - loss: 0.1170 - acc: 0.9626 - val_loss: 0.2728 - val_acc: 0.8816\n",
      "Epoch 69/80\n",
      "41/40 [==============================] - 2s - loss: 0.1339 - acc: 0.9420 - val_loss: 0.2529 - val_acc: 0.8910\n",
      "Epoch 70/80\n",
      "41/40 [==============================] - 2s - loss: 0.1293 - acc: 0.9440 - val_loss: 0.2795 - val_acc: 0.8972\n",
      "Epoch 71/80\n",
      "41/40 [==============================] - 2s - loss: 0.1034 - acc: 0.9626 - val_loss: 0.2677 - val_acc: 0.8754\n",
      "Epoch 72/80\n",
      "41/40 [==============================] - 2s - loss: 0.1147 - acc: 0.9501 - val_loss: 0.2736 - val_acc: 0.8847\n",
      "Epoch 73/80\n",
      "41/40 [==============================] - 2s - loss: 0.1230 - acc: 0.9527 - val_loss: 0.2824 - val_acc: 0.8847\n",
      "Epoch 74/80\n",
      "41/40 [==============================] - 2s - loss: 0.1068 - acc: 0.9626 - val_loss: 0.2490 - val_acc: 0.9065\n",
      "Epoch 75/80\n",
      "41/40 [==============================] - 2s - loss: 0.1245 - acc: 0.9421 - val_loss: 0.3225 - val_acc: 0.8910\n",
      "Epoch 76/80\n",
      "41/40 [==============================] - 2s - loss: 0.1194 - acc: 0.9520 - val_loss: 0.2885 - val_acc: 0.8754\n",
      "Epoch 77/80\n",
      "41/40 [==============================] - 2s - loss: 0.1021 - acc: 0.9680 - val_loss: 0.2792 - val_acc: 0.8879\n",
      "Epoch 78/80\n",
      "41/40 [==============================] - 2s - loss: 0.0950 - acc: 0.9642 - val_loss: 0.3087 - val_acc: 0.8660\n",
      "Epoch 79/80\n",
      "41/40 [==============================] - 2s - loss: 0.0898 - acc: 0.9710 - val_loss: 0.4472 - val_acc: 0.8193\n",
      "Epoch 80/80\n",
      "41/40 [==============================] - 2s - loss: 0.1348 - acc: 0.9440 - val_loss: 0.3349 - val_acc: 0.8785\n"
     ]
    }
   ],
   "source": [
    "model.train(batch_size = 32, epochs = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYWZmDXHBMDOzhrhgmJlZQ/4fugjV73xcSWwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c8f68e0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1UZDQSmlVJv/D6ZeHnWoRTJIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ca67f91320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0369616\n",
      "0.0369616\n",
      "0.196795\n",
      "0.196795\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0312446\n",
      "0.0312446\n",
      "0.0574131\n",
      "0.0574131\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0410375\n",
      "0.0410375\n",
      "0.025\n",
      "0.025\n",
      "0.294159\n",
      "0.294159\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0808564\n",
      "0.0808564\n",
      "0.0948212\n",
      "0.0948212\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.751833\n",
      "0.751833\n",
      "0.252036\n",
      "0.252036\n",
      "0.0272324\n",
      "0.0272324\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.566309\n",
      "0.566309\n",
      "0.0661362\n",
      "0.0661362\n",
      "0.0257904\n",
      "0.0257904\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.6548\n",
      "0.6548\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.936005\n",
      "0.936005\n",
      "0.923681\n",
      "0.923681\n",
      "0.0290829\n",
      "0.0290829\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.886727\n",
      "0.886727\n",
      "0.029926\n",
      "0.029926\n",
      "0.0496582\n",
      "0.0496582\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.177203\n",
      "0.177203\n",
      "0.661889\n",
      "0.661889\n",
      "0.975\n",
      "0.975\n",
      "0.348275\n",
      "0.348275\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.166034\n",
      "0.166034\n",
      "0.975\n",
      "0.975\n",
      "0.0773542\n",
      "0.0773542\n",
      "0.123763\n",
      "0.123763\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.128248\n",
      "0.128248\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0312221\n",
      "0.0312221\n",
      "0.975\n",
      "0.975\n",
      "0.296991\n",
      "0.296991\n",
      "0.0520963\n",
      "0.0520963\n",
      "0.0545643\n",
      "0.0545643\n",
      "0.326776\n",
      "0.326776\n",
      "0.025\n",
      "0.025\n",
      "0.0376448\n",
      "0.0376448\n",
      "0.025\n",
      "0.025\n",
      "0.511582\n",
      "0.511582\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0506004\n",
      "0.0506004\n",
      "0.060948\n",
      "0.060948\n",
      "0.196591\n",
      "0.196591\n",
      "0.975\n",
      "0.975\n",
      "0.410994\n",
      "0.410994\n",
      "0.33119\n",
      "0.33119\n",
      "0.0649462\n",
      "0.0649462\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.097247\n",
      "0.097247\n",
      "0.025\n",
      "0.025\n",
      "0.287629\n",
      "0.287629\n",
      "0.025\n",
      "0.025\n",
      "0.280797\n",
      "0.280797\n",
      "0.025\n",
      "0.025\n",
      "0.4401\n",
      "0.4401\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.931019\n",
      "0.931019\n",
      "0.025\n",
      "0.025\n",
      "0.076322\n",
      "0.076322\n",
      "0.0468558\n",
      "0.0468558\n",
      "0.116452\n",
      "0.116452\n",
      "0.119902\n",
      "0.119902\n",
      "0.479691\n",
      "0.479691\n",
      "0.336317\n",
      "0.336317\n",
      "0.964458\n",
      "0.964458\n",
      "0.40006\n",
      "0.40006\n",
      "0.0873552\n",
      "0.0873552\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.317454\n",
      "0.317454\n",
      "0.142896\n",
      "0.142896\n",
      "0.975\n",
      "0.975\n",
      "0.0518816\n",
      "0.0518816\n",
      "0.154585\n",
      "0.154585\n",
      "0.025\n",
      "0.025\n",
      "0.232983\n",
      "0.232983\n",
      "0.253899\n",
      "0.253899\n",
      "0.695552\n",
      "0.695552\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0503526\n",
      "0.0503526\n",
      "0.299488\n",
      "0.299488\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.851063\n",
      "0.851063\n",
      "0.296699\n",
      "0.296699\n",
      "0.0889624\n",
      "0.0889624\n",
      "0.553978\n",
      "0.553978\n",
      "0.025\n",
      "0.025\n",
      "0.732811\n",
      "0.732811\n",
      "0.975\n",
      "0.975\n",
      "0.159874\n",
      "0.159874\n",
      "0.025\n",
      "0.025\n",
      "0.123744\n",
      "0.123744\n",
      "0.159498\n",
      "0.159498\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.107546\n",
      "0.107546\n",
      "0.025\n",
      "0.025\n",
      "0.0292534\n",
      "0.0292534\n",
      "0.0427586\n",
      "0.0427586\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0341584\n",
      "0.0341584\n",
      "0.304217\n",
      "0.304217\n",
      "0.961387\n",
      "0.961387\n",
      "0.353591\n",
      "0.353591\n",
      "0.284185\n",
      "0.284185\n",
      "0.025\n",
      "0.025\n",
      "0.627639\n",
      "0.627639\n",
      "0.025\n",
      "0.025\n",
      "0.275988\n",
      "0.275988\n",
      "0.025\n",
      "0.025\n",
      "0.0430564\n",
      "0.0430564\n",
      "0.174717\n",
      "0.174717\n",
      "0.0825035\n",
      "0.0825035\n",
      "0.025\n",
      "0.025\n",
      "0.0810577\n",
      "0.0810577\n",
      "0.025\n",
      "0.025\n",
      "0.931243\n",
      "0.931243\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.974981\n",
      "0.974981\n",
      "0.117923\n",
      "0.117923\n",
      "0.295464\n",
      "0.295464\n",
      "0.054646\n",
      "0.054646\n",
      "0.025\n",
      "0.025\n",
      "0.621482\n",
      "0.621482\n",
      "0.975\n",
      "0.975\n",
      "0.0968197\n",
      "0.0968197\n",
      "0.640787\n",
      "0.640787\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.364001\n",
      "0.364001\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.114937\n",
      "0.114937\n",
      "0.0354706\n",
      "0.0354706\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.969299\n",
      "0.969299\n",
      "0.630603\n",
      "0.630603\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0657768\n",
      "0.0657768\n",
      "0.975\n",
      "0.975\n",
      "0.855383\n",
      "0.855383\n",
      "0.025\n",
      "0.025\n",
      "0.200143\n",
      "0.200143\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0911025\n",
      "0.0911025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.292563\n",
      "0.292563\n",
      "0.025\n",
      "0.025\n",
      "0.123246\n",
      "0.123246\n",
      "0.87064\n",
      "0.87064\n",
      "0.0293348\n",
      "0.0293348\n",
      "0.025\n",
      "0.025\n",
      "0.516594\n",
      "0.516594\n",
      "0.15595\n",
      "0.15595\n",
      "0.15003\n",
      "0.15003\n",
      "0.025\n",
      "0.025\n",
      "0.02782\n",
      "0.02782\n",
      "0.182238\n",
      "0.182238\n",
      "0.783433\n",
      "0.783433\n",
      "0.025\n",
      "0.025\n",
      "0.381075\n",
      "0.381075\n",
      "0.0520871\n",
      "0.0520871\n",
      "0.025\n",
      "0.025\n",
      "0.154503\n",
      "0.154503\n",
      "0.810549\n",
      "0.810549\n",
      "0.824199\n",
      "0.824199\n",
      "0.668247\n",
      "0.668247\n",
      "0.025\n",
      "0.025\n",
      "0.455531\n",
      "0.455531\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.126891\n",
      "0.126891\n",
      "0.975\n",
      "0.975\n",
      "0.249188\n",
      "0.249188\n",
      "0.148453\n",
      "0.148453\n",
      "0.025\n",
      "0.025\n",
      "0.273874\n",
      "0.273874\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.826132\n",
      "0.826132\n",
      "0.025\n",
      "0.025\n",
      "0.0493614\n",
      "0.0493614\n",
      "0.025\n",
      "0.025\n",
      "0.0670055\n",
      "0.0670055\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.18607\n",
      "0.18607\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0345821\n",
      "0.0345821\n",
      "0.0752668\n",
      "0.0752668\n",
      "0.025\n",
      "0.025\n",
      "0.943178\n",
      "0.943178\n",
      "0.329613\n",
      "0.329613\n",
      "0.025\n",
      "0.025\n",
      "0.146025\n",
      "0.146025\n",
      "0.975\n",
      "0.975\n",
      "0.0505505\n",
      "0.0505505\n",
      "0.265704\n",
      "0.265704\n",
      "0.025\n",
      "0.025\n",
      "0.236223\n",
      "0.236223\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0786254\n",
      "0.0786254\n",
      "0.025\n",
      "0.025\n",
      "0.524849\n",
      "0.524849\n",
      "0.079105\n",
      "0.079105\n",
      "0.0614109\n",
      "0.0614109\n",
      "0.261484\n",
      "0.261484\n",
      "0.0388182\n",
      "0.0388182\n",
      "0.337566\n",
      "0.337566\n",
      "0.025\n",
      "0.025\n",
      "0.157734\n",
      "0.157734\n",
      "0.0465069\n",
      "0.0465069\n",
      "0.025\n",
      "0.025\n",
      "0.884612\n",
      "0.884612\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.268313\n",
      "0.268313\n",
      "0.975\n",
      "0.975\n",
      "0.180137\n",
      "0.180137\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.443968\n",
      "0.443968\n",
      "0.0436921\n",
      "0.0436921\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.82665\n",
      "0.82665\n",
      "0.364493\n",
      "0.364493\n",
      "0.0517582\n",
      "0.0517582\n",
      "0.025\n",
      "0.025\n",
      "0.166034\n",
      "0.166034\n",
      "0.214763\n",
      "0.214763\n",
      "0.025\n",
      "0.025\n",
      "0.599469\n",
      "0.599469\n",
      "0.025\n",
      "0.025\n",
      "0.579207\n",
      "0.579207\n",
      "0.959659\n",
      "0.959659\n",
      "0.352706\n",
      "0.352706\n",
      "0.975\n",
      "0.975\n",
      "0.80484\n",
      "0.80484\n",
      "0.975\n",
      "0.975\n",
      "0.167459\n",
      "0.167459\n",
      "0.655158\n",
      "0.655158\n",
      "0.36711\n",
      "0.36711\n",
      "0.025\n",
      "0.025\n",
      "0.179853\n",
      "0.179853\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0340626\n",
      "0.0340626\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0436926\n",
      "0.0436926\n",
      "0.196947\n",
      "0.196947\n",
      "0.607444\n",
      "0.607444\n",
      "0.177114\n",
      "0.177114\n",
      "0.946653\n",
      "0.946653\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.620643\n",
      "0.620643\n",
      "0.67199\n",
      "0.67199\n",
      "0.0784133\n",
      "0.0784133\n",
      "0.524161\n",
      "0.524161\n",
      "0.122704\n",
      "0.122704\n",
      "0.975\n",
      "0.975\n",
      "0.0535003\n",
      "0.0535003\n",
      "0.0859254\n",
      "0.0859254\n",
      "0.254673\n",
      "0.254673\n",
      "0.0362061\n",
      "0.0362061\n",
      "0.13963\n",
      "0.13963\n",
      "0.831371\n",
      "0.831371\n",
      "0.025\n",
      "0.025\n",
      "0.959215\n",
      "0.959215\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.867134\n",
      "0.867134\n",
      "0.914149\n",
      "0.914149\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.117926\n",
      "0.117926\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.748487\n",
      "0.748487\n",
      "0.025\n",
      "0.025\n",
      "0.168023\n",
      "0.168023\n",
      "0.025\n",
      "0.025\n",
      "0.0690718\n",
      "0.0690718\n",
      "0.193466\n",
      "0.193466\n",
      "0.614543\n",
      "0.614543\n",
      "0.920118\n",
      "0.920118\n",
      "0.975\n",
      "0.975\n",
      "0.0277314\n",
      "0.0277314\n",
      "0.025\n",
      "0.025\n",
      "0.082585\n",
      "0.082585\n",
      "0.548564\n",
      "0.548564\n",
      "0.258123\n",
      "0.258123\n",
      "0.108709\n",
      "0.108709\n",
      "0.975\n",
      "0.975\n",
      "0.0327292\n",
      "0.0327292\n",
      "0.025\n",
      "0.025\n",
      "0.891061\n",
      "0.891061\n",
      "0.025\n",
      "0.025\n",
      "0.132321\n",
      "0.132321\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.326728\n",
      "0.326728\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.819268\n",
      "0.819268\n",
      "0.240942\n",
      "0.240942\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0553464\n",
      "0.0553464\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0333931\n",
      "0.0333931\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.908114\n",
      "0.908114\n",
      "0.0263366\n",
      "0.0263366\n",
      "0.0824678\n",
      "0.0824678\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.936829\n",
      "0.936829\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.137253\n",
      "0.137253\n",
      "0.0695639\n",
      "0.0695639\n",
      "0.025\n",
      "0.025\n",
      "0.810749\n",
      "0.810749\n",
      "0.975\n",
      "0.975\n",
      "0.0275144\n",
      "0.0275144\n",
      "0.975\n",
      "0.975\n",
      "0.0557539\n",
      "0.0557539\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.277229\n",
      "0.277229\n",
      "0.735555\n",
      "0.735555\n",
      "0.465266\n",
      "0.465266\n",
      "0.025\n",
      "0.025\n",
      "0.190568\n",
      "0.190568\n",
      "0.31593\n",
      "0.31593\n",
      "0.025\n",
      "0.025\n",
      "0.911432\n",
      "0.911432\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.256056\n",
      "0.256056\n",
      "0.025\n",
      "0.025\n",
      "0.0307619\n",
      "0.0307619\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.571933\n",
      "0.571933\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0866958\n",
      "0.0866958\n",
      "0.025\n",
      "0.025\n",
      "0.133761\n",
      "0.133761\n",
      "0.025\n",
      "0.025\n",
      "0.167607\n",
      "0.167607\n",
      "0.0316893\n",
      "0.0316893\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.974435\n",
      "0.974435\n",
      "0.887838\n",
      "0.887838\n",
      "0.025\n",
      "0.025\n",
      "0.866287\n",
      "0.866287\n",
      "0.025\n",
      "0.025\n",
      "0.0509651\n",
      "0.0509651\n",
      "0.154548\n",
      "0.154548\n",
      "0.975\n",
      "0.975\n",
      "0.0628504\n",
      "0.0628504\n",
      "0.109726\n",
      "0.109726\n",
      "0.025\n",
      "0.025\n",
      "0.704068\n",
      "0.704068\n",
      "0.025\n",
      "0.025\n",
      "0.646006\n",
      "0.646006\n",
      "0.025\n",
      "0.025\n",
      "0.0364459\n",
      "0.0364459\n",
      "0.025\n",
      "0.025\n",
      "0.0813578\n",
      "0.0813578\n",
      "0.648537\n",
      "0.648537\n",
      "0.485814\n",
      "0.485814\n",
      "0.0366396\n",
      "0.0366396\n",
      "0.423968\n",
      "0.423968\n",
      "0.0255427\n",
      "0.0255427\n",
      "0.192713\n",
      "0.192713\n",
      "0.0661861\n",
      "0.0661861\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.96774\n",
      "0.96774\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0304085\n",
      "0.0304085\n",
      "0.907147\n",
      "0.907147\n",
      "0.975\n",
      "0.975\n",
      "0.0529763\n",
      "0.0529763\n",
      "0.60839\n",
      "0.60839\n",
      "0.025\n",
      "0.025\n",
      "0.886777\n",
      "0.886777\n",
      "0.025\n",
      "0.025\n",
      "0.0465298\n",
      "0.0465298\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0649554\n",
      "0.0649554\n",
      "0.025\n",
      "0.025\n",
      "0.351486\n",
      "0.351486\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.177699\n",
      "0.177699\n",
      "0.62872\n",
      "0.62872\n",
      "0.960601\n",
      "0.960601\n",
      "0.025\n",
      "0.025\n",
      "0.0744346\n",
      "0.0744346\n",
      "0.0570724\n",
      "0.0570724\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.401245\n",
      "0.401245\n",
      "0.732211\n",
      "0.732211\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0379352\n",
      "0.0379352\n",
      "0.975\n",
      "0.975\n",
      "0.504773\n",
      "0.504773\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0707751\n",
      "0.0707751\n",
      "0.975\n",
      "0.975\n",
      "0.0570972\n",
      "0.0570972\n",
      "0.173007\n",
      "0.173007\n",
      "0.975\n",
      "0.975\n",
      "0.0746103\n",
      "0.0746103\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.583665\n",
      "0.583665\n",
      "0.300457\n",
      "0.300457\n",
      "0.025\n",
      "0.025\n",
      "0.716339\n",
      "0.716339\n",
      "0.0936643\n",
      "0.0936643\n",
      "0.202931\n",
      "0.202931\n",
      "0.203108\n",
      "0.203108\n",
      "0.275143\n",
      "0.275143\n",
      "0.0777695\n",
      "0.0777695\n",
      "0.118204\n",
      "0.118204\n",
      "0.025\n",
      "0.025\n",
      "0.028533\n",
      "0.028533\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0392463\n",
      "0.0392463\n",
      "0.0331045\n",
      "0.0331045\n",
      "0.537005\n",
      "0.537005\n",
      "0.278391\n",
      "0.278391\n",
      "0.025\n",
      "0.025\n",
      "0.671523\n",
      "0.671523\n",
      "0.025\n",
      "0.025\n",
      "0.522223\n",
      "0.522223\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0677551\n",
      "0.0677551\n",
      "0.025\n",
      "0.025\n",
      "0.821164\n",
      "0.821164\n",
      "0.025\n",
      "0.025\n",
      "0.501144\n",
      "0.501144\n",
      "0.0941134\n",
      "0.0941134\n",
      "0.966863\n",
      "0.966863\n",
      "0.11553\n",
      "0.11553\n",
      "0.536179\n",
      "0.536179\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.124369\n",
      "0.124369\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.173567\n",
      "0.173567\n",
      "0.025\n",
      "0.025\n",
      "0.962477\n",
      "0.962477\n",
      "0.975\n",
      "0.975\n",
      "0.0389132\n",
      "0.0389132\n",
      "0.025\n",
      "0.025\n",
      "0.796702\n",
      "0.796702\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0915112\n",
      "0.0915112\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.908564\n",
      "0.908564\n",
      "0.931184\n",
      "0.931184\n",
      "0.925214\n",
      "0.925214\n",
      "0.0340234\n",
      "0.0340234\n",
      "0.025\n",
      "0.025\n",
      "0.833216\n",
      "0.833216\n",
      "0.484482\n",
      "0.484482\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.484114\n",
      "0.484114\n",
      "0.795571\n",
      "0.795571\n",
      "0.0690093\n",
      "0.0690093\n",
      "0.0649232\n",
      "0.0649232\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0809074\n",
      "0.0809074\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0320237\n",
      "0.0320237\n",
      "0.798099\n",
      "0.798099\n",
      "0.025\n",
      "0.025\n",
      "0.0935142\n",
      "0.0935142\n",
      "0.889439\n",
      "0.889439\n",
      "0.025\n",
      "0.025\n",
      "0.058514\n",
      "0.058514\n",
      "0.0484833\n",
      "0.0484833\n",
      "0.129954\n",
      "0.129954\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.939844\n",
      "0.939844\n",
      "0.769591\n",
      "0.769591\n",
      "0.0540772\n",
      "0.0540772\n",
      "0.025\n",
      "0.025\n",
      "0.0499039\n",
      "0.0499039\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0307284\n",
      "0.0307284\n",
      "0.288\n",
      "0.288\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.51689\n",
      "0.51689\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.421129\n",
      "0.421129\n",
      "0.170137\n",
      "0.170137\n",
      "0.975\n",
      "0.975\n",
      "0.12968\n",
      "0.12968\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.774387\n",
      "0.774387\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0410164\n",
      "0.0410164\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.100848\n",
      "0.100848\n",
      "0.97273\n",
      "0.97273\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0673769\n",
      "0.0673769\n",
      "0.151365\n",
      "0.151365\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.12859\n",
      "0.12859\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.750463\n",
      "0.750463\n",
      "0.443601\n",
      "0.443601\n",
      "0.156294\n",
      "0.156294\n",
      "0.0878315\n",
      "0.0878315\n",
      "0.723992\n",
      "0.723992\n",
      "0.151549\n",
      "0.151549\n",
      "0.0344036\n",
      "0.0344036\n",
      "0.0603491\n",
      "0.0603491\n",
      "0.916778\n",
      "0.916778\n",
      "0.025\n",
      "0.025\n",
      "0.0440225\n",
      "0.0440225\n",
      "0.025\n",
      "0.025\n",
      "0.07713\n",
      "0.07713\n",
      "0.025\n",
      "0.025\n",
      "0.786195\n",
      "0.786195\n",
      "0.975\n",
      "0.975\n",
      "0.130032\n",
      "0.130032\n",
      "0.167072\n",
      "0.167072\n",
      "0.0397986\n",
      "0.0397986\n",
      "0.025\n",
      "0.025\n",
      "0.218135\n",
      "0.218135\n",
      "0.114593\n",
      "0.114593\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.194471\n",
      "0.194471\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.17282\n",
      "0.17282\n",
      "0.4686\n",
      "0.4686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.118946\n",
      "0.118946\n",
      "0.941532\n",
      "0.941532\n",
      "0.13793\n",
      "0.13793\n",
      "0.13074\n",
      "0.13074\n",
      "0.919576\n",
      "0.919576\n",
      "0.509091\n",
      "0.509091\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0492613\n",
      "0.0492613\n",
      "0.025\n",
      "0.025\n",
      "0.313927\n",
      "0.313927\n",
      "0.970596\n",
      "0.970596\n",
      "0.224206\n",
      "0.224206\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.911998\n",
      "0.911998\n",
      "0.0433278\n",
      "0.0433278\n",
      "0.801345\n",
      "0.801345\n",
      "0.067093\n",
      "0.067093\n",
      "0.485473\n",
      "0.485473\n",
      "0.0878854\n",
      "0.0878854\n",
      "0.92975\n",
      "0.92975\n",
      "0.623491\n",
      "0.623491\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.19078\n",
      "0.19078\n",
      "0.025\n",
      "0.025\n",
      "0.040799\n",
      "0.040799\n",
      "0.025\n",
      "0.025\n",
      "0.60829\n",
      "0.60829\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0376866\n",
      "0.0376866\n",
      "0.975\n",
      "0.975\n",
      "0.133031\n",
      "0.133031\n",
      "0.742541\n",
      "0.742541\n",
      "0.025\n",
      "0.025\n",
      "0.0573791\n",
      "0.0573791\n",
      "0.573465\n",
      "0.573465\n",
      "0.352197\n",
      "0.352197\n",
      "0.025\n",
      "0.025\n",
      "0.0530096\n",
      "0.0530096\n",
      "0.025\n",
      "0.025\n",
      "0.96856\n",
      "0.96856\n",
      "0.187725\n",
      "0.187725\n",
      "0.131131\n",
      "0.131131\n",
      "0.591825\n",
      "0.591825\n",
      "0.281134\n",
      "0.281134\n",
      "0.103923\n",
      "0.103923\n",
      "0.0327066\n",
      "0.0327066\n",
      "0.025\n",
      "0.025\n",
      "0.113619\n",
      "0.113619\n",
      "0.961255\n",
      "0.961255\n",
      "0.937439\n",
      "0.937439\n",
      "0.358256\n",
      "0.358256\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.559745\n",
      "0.559745\n",
      "0.324155\n",
      "0.324155\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.516091\n",
      "0.516091\n",
      "0.255373\n",
      "0.255373\n",
      "0.025\n",
      "0.025\n",
      "0.404232\n",
      "0.404232\n",
      "0.285156\n",
      "0.285156\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.692047\n",
      "0.692047\n",
      "0.561544\n",
      "0.561544\n",
      "0.025\n",
      "0.025\n",
      "0.64584\n",
      "0.64584\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.338185\n",
      "0.338185\n",
      "0.025\n",
      "0.025\n",
      "0.478947\n",
      "0.478947\n",
      "0.025\n",
      "0.025\n",
      "0.564063\n",
      "0.564063\n",
      "0.43282\n",
      "0.43282\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.936683\n",
      "0.936683\n",
      "0.0328466\n",
      "0.0328466\n",
      "0.975\n",
      "0.975\n",
      "0.873238\n",
      "0.873238\n",
      "0.066912\n",
      "0.066912\n",
      "0.0858133\n",
      "0.0858133\n",
      "0.279839\n",
      "0.279839\n",
      "0.025\n",
      "0.025\n",
      "0.0371452\n",
      "0.0371452\n",
      "0.970738\n",
      "0.970738\n",
      "0.8751\n",
      "0.8751\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.110528\n",
      "0.110528\n",
      "0.522763\n",
      "0.522763\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0628513\n",
      "0.0628513\n",
      "0.652993\n",
      "0.652993\n",
      "0.025\n",
      "0.025\n",
      "0.0640371\n",
      "0.0640371\n",
      "0.679884\n",
      "0.679884\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.306434\n",
      "0.306434\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0752826\n",
      "0.0752826\n",
      "0.0952333\n",
      "0.0952333\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0947225\n",
      "0.0947225\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.111502\n",
      "0.111502\n",
      "0.025\n",
      "0.025\n",
      "0.312474\n",
      "0.312474\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.316815\n",
      "0.316815\n",
      "0.025\n",
      "0.025\n",
      "0.363134\n",
      "0.363134\n",
      "0.0275475\n",
      "0.0275475\n",
      "0.226627\n",
      "0.226627\n",
      "0.025\n",
      "0.025\n",
      "0.967602\n",
      "0.967602\n",
      "0.100786\n",
      "0.100786\n",
      "0.372055\n",
      "0.372055\n",
      "0.0687073\n",
      "0.0687073\n",
      "0.025\n",
      "0.025\n",
      "0.121857\n",
      "0.121857\n",
      "0.025\n",
      "0.025\n",
      "0.0265747\n",
      "0.0265747\n",
      "0.025\n",
      "0.025\n",
      "0.256997\n",
      "0.256997\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.892199\n",
      "0.892199\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0975805\n",
      "0.0975805\n",
      "0.975\n",
      "0.975\n",
      "0.926385\n",
      "0.926385\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.209265\n",
      "0.209265\n",
      "0.039755\n",
      "0.039755\n",
      "0.434043\n",
      "0.434043\n",
      "0.746724\n",
      "0.746724\n",
      "0.025\n",
      "0.025\n",
      "0.0429584\n",
      "0.0429584\n",
      "0.881792\n",
      "0.881792\n",
      "0.802407\n",
      "0.802407\n",
      "0.0343714\n",
      "0.0343714\n",
      "0.025\n",
      "0.025\n",
      "0.154679\n",
      "0.154679\n",
      "0.283198\n",
      "0.283198\n",
      "0.0371093\n",
      "0.0371093\n",
      "0.042224\n",
      "0.042224\n",
      "0.358213\n",
      "0.358213\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.970324\n",
      "0.970324\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.239561\n",
      "0.239561\n",
      "0.025\n",
      "0.025\n",
      "0.643351\n",
      "0.643351\n",
      "0.0573906\n",
      "0.0573906\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.430532\n",
      "0.430532\n",
      "0.0278918\n",
      "0.0278918\n",
      "0.0820525\n",
      "0.0820525\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.79261\n",
      "0.79261\n",
      "0.0591218\n",
      "0.0591218\n",
      "0.247299\n",
      "0.247299\n",
      "0.975\n",
      "0.975\n",
      "0.0913621\n",
      "0.0913621\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.677836\n",
      "0.677836\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.468939\n",
      "0.468939\n",
      "0.816381\n",
      "0.816381\n",
      "0.025\n",
      "0.025\n",
      "0.0501057\n",
      "0.0501057\n",
      "0.969464\n",
      "0.969464\n",
      "0.975\n",
      "0.975\n",
      "0.861971\n",
      "0.861971\n",
      "0.347668\n",
      "0.347668\n",
      "0.963036\n",
      "0.963036\n",
      "0.0798605\n",
      "0.0798605\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.165792\n",
      "0.165792\n",
      "0.025\n",
      "0.025\n",
      "0.326431\n",
      "0.326431\n",
      "0.169174\n",
      "0.169174\n",
      "0.975\n",
      "0.975\n",
      "0.946813\n",
      "0.946813\n",
      "0.0629756\n",
      "0.0629756\n",
      "0.025\n",
      "0.025\n",
      "0.450007\n",
      "0.450007\n",
      "0.245519\n",
      "0.245519\n",
      "0.0378778\n",
      "0.0378778\n",
      "0.248601\n",
      "0.248601\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.137742\n",
      "0.137742\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.156305\n",
      "0.156305\n",
      "0.876956\n",
      "0.876956\n",
      "0.109002\n",
      "0.109002\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.603928\n",
      "0.603928\n",
      "0.025\n",
      "0.025\n",
      "0.957017\n",
      "0.957017\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.969512\n",
      "0.969512\n",
      "0.205287\n",
      "0.205287\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.35271\n",
      "0.35271\n",
      "0.0880364\n",
      "0.0880364\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.119628\n",
      "0.119628\n",
      "0.025\n",
      "0.025\n",
      "0.626203\n",
      "0.626203\n",
      "0.60323\n",
      "0.60323\n",
      "0.678006\n",
      "0.678006\n",
      "0.168658\n",
      "0.168658\n",
      "0.103194\n",
      "0.103194\n",
      "0.025\n",
      "0.025\n",
      "0.308313\n",
      "0.308313\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.308664\n",
      "0.308664\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0818062\n",
      "0.0818062\n",
      "0.582224\n",
      "0.582224\n",
      "0.33912\n",
      "0.33912\n",
      "0.0655336\n",
      "0.0655336\n",
      "0.113946\n",
      "0.113946\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.125307\n",
      "0.125307\n",
      "0.025\n",
      "0.025\n",
      "0.426242\n",
      "0.426242\n",
      "0.772184\n",
      "0.772184\n",
      "0.685194\n",
      "0.685194\n",
      "0.27886\n",
      "0.27886\n",
      "0.025\n",
      "0.025\n",
      "0.056401\n",
      "0.056401\n",
      "0.469977\n",
      "0.469977\n",
      "0.105833\n",
      "0.105833\n",
      "0.973549\n",
      "0.973549\n",
      "0.068182\n",
      "0.068182\n",
      "0.0967624\n",
      "0.0967624\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0345436\n",
      "0.0345436\n",
      "0.380164\n",
      "0.380164\n",
      "0.029432\n",
      "0.029432\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.313126\n",
      "0.313126\n",
      "0.304906\n",
      "0.304906\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.030215\n",
      "0.030215\n",
      "0.975\n",
      "0.975\n",
      "0.916397\n",
      "0.916397\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.8739\n",
      "0.8739\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0572355\n",
      "0.0572355\n",
      "0.71612\n",
      "0.71612\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.872586\n",
      "0.872586\n",
      "0.025\n",
      "0.025\n",
      "0.465887\n",
      "0.465887\n",
      "0.623277\n",
      "0.623277\n",
      "0.025\n",
      "0.025\n",
      "0.0255094\n",
      "0.0255094\n",
      "0.025\n",
      "0.025\n",
      "0.0331633\n",
      "0.0331633\n",
      "0.025\n",
      "0.025\n",
      "0.139521\n",
      "0.139521\n",
      "0.310105\n",
      "0.310105\n",
      "0.546177\n",
      "0.546177\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0489451\n",
      "0.0489451\n",
      "0.139992\n",
      "0.139992\n",
      "0.0345411\n",
      "0.0345411\n",
      "0.025\n",
      "0.025\n",
      "0.0842865\n",
      "0.0842865\n",
      "0.0355396\n",
      "0.0355396\n",
      "0.974083\n",
      "0.974083\n",
      "0.282198\n",
      "0.282198\n",
      "0.975\n",
      "0.975\n",
      "0.13723\n",
      "0.13723\n",
      "0.0453275\n",
      "0.0453275\n",
      "0.147138\n",
      "0.147138\n",
      "0.105547\n",
      "0.105547\n",
      "0.182725\n",
      "0.182725\n",
      "0.102188\n",
      "0.102188\n",
      "0.578032\n",
      "0.578032\n",
      "0.0975033\n",
      "0.0975033\n",
      "0.941895\n",
      "0.941895\n",
      "0.950402\n",
      "0.950402\n",
      "0.915047\n",
      "0.915047\n",
      "0.025\n",
      "0.025\n",
      "0.0665274\n",
      "0.0665274\n",
      "0.154666\n",
      "0.154666\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.220107\n",
      "0.220107\n",
      "0.025\n",
      "0.025\n",
      "0.674503\n",
      "0.674503\n",
      "0.0565006\n",
      "0.0565006\n",
      "0.025\n",
      "0.025\n",
      "0.0259577\n",
      "0.0259577\n",
      "0.0619564\n",
      "0.0619564\n",
      "0.146492\n",
      "0.146492\n",
      "0.975\n",
      "0.975\n",
      "0.0484082\n",
      "0.0484082\n",
      "0.0462753\n",
      "0.0462753\n",
      "0.967776\n",
      "0.967776\n",
      "0.0591101\n",
      "0.0591101\n",
      "0.0566843\n",
      "0.0566843\n",
      "0.657549\n",
      "0.657549\n",
      "0.807325\n",
      "0.807325\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.224846\n",
      "0.224846\n",
      "0.869444\n",
      "0.869444\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0401175\n",
      "0.0401175\n",
      "0.975\n",
      "0.975\n",
      "0.775008\n",
      "0.775008\n",
      "0.025\n",
      "0.025\n",
      "0.934429\n",
      "0.934429\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0523199\n",
      "0.0523199\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0370857\n",
      "0.0370857\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.933204\n",
      "0.933204\n",
      "0.0555374\n",
      "0.0555374\n",
      "0.0906226\n",
      "0.0906226\n",
      "0.025\n",
      "0.025\n",
      "0.0461644\n",
      "0.0461644\n",
      "0.025\n",
      "0.025\n",
      "0.362824\n",
      "0.362824\n",
      "0.801346\n",
      "0.801346\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.424965\n",
      "0.424965\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.171345\n",
      "0.171345\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.40705\n",
      "0.40705\n",
      "0.0721418\n",
      "0.0721418\n",
      "0.902805\n",
      "0.902805\n",
      "0.12847\n",
      "0.12847\n",
      "0.026196\n",
      "0.026196\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.185465\n",
      "0.185465\n",
      "0.125523\n",
      "0.125523\n",
      "0.025\n",
      "0.025\n",
      "0.0353227\n",
      "0.0353227\n",
      "0.201558\n",
      "0.201558\n",
      "0.025\n",
      "0.025\n",
      "0.18803\n",
      "0.18803\n",
      "0.872867\n",
      "0.872867\n",
      "0.960995\n",
      "0.960995\n",
      "0.422881\n",
      "0.422881\n",
      "0.0759524\n",
      "0.0759524\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0954091\n",
      "0.0954091\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.436151\n",
      "0.436151\n",
      "0.025\n",
      "0.025\n",
      "0.532234\n",
      "0.532234\n",
      "0.025\n",
      "0.025\n",
      "0.0587334\n",
      "0.0587334\n",
      "0.025\n",
      "0.025\n",
      "0.831138\n",
      "0.831138\n",
      "0.025\n",
      "0.025\n",
      "0.913095\n",
      "0.913095\n",
      "0.876893\n",
      "0.876893\n",
      "0.0372732\n",
      "0.0372732\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0283849\n",
      "0.0283849\n",
      "0.0326087\n",
      "0.0326087\n",
      "0.464334\n",
      "0.464334\n",
      "0.890244\n",
      "0.890244\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.163306\n",
      "0.163306\n",
      "0.109189\n",
      "0.109189\n",
      "0.025\n",
      "0.025\n",
      "0.637838\n",
      "0.637838\n",
      "0.171889\n",
      "0.171889\n",
      "0.405085\n",
      "0.405085\n",
      "0.0368251\n",
      "0.0368251\n",
      "0.356965\n",
      "0.356965\n",
      "0.0311639\n",
      "0.0311639\n",
      "0.18988\n",
      "0.18988\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0421217\n",
      "0.0421217\n",
      "0.975\n",
      "0.975\n",
      "0.0830289\n",
      "0.0830289\n",
      "0.453201\n",
      "0.453201\n",
      "0.0545086\n",
      "0.0545086\n",
      "0.527887\n",
      "0.527887\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0488026\n",
      "0.0488026\n",
      "0.306267\n",
      "0.306267\n",
      "0.0301046\n",
      "0.0301046\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0753362\n",
      "0.0753362\n",
      "0.025\n",
      "0.025\n",
      "0.0394744\n",
      "0.0394744\n",
      "0.025\n",
      "0.025\n",
      "0.134034\n",
      "0.134034\n",
      "0.497733\n",
      "0.497733\n",
      "0.025\n",
      "0.025\n",
      "0.960677\n",
      "0.960677\n",
      "0.025\n",
      "0.025\n",
      "0.878326\n",
      "0.878326\n",
      "0.975\n",
      "0.975\n",
      "0.137718\n",
      "0.137718\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.206065\n",
      "0.206065\n",
      "0.025\n",
      "0.025\n",
      "0.872859\n",
      "0.872859\n",
      "0.106756\n",
      "0.106756\n",
      "0.150739\n",
      "0.150739\n",
      "0.0750963\n",
      "0.0750963\n",
      "0.0401085\n",
      "0.0401085\n",
      "0.0495041\n",
      "0.0495041\n",
      "0.071393\n",
      "0.071393\n",
      "0.411962\n",
      "0.411962\n",
      "0.025\n",
      "0.025\n",
      "0.742306\n",
      "0.742306\n",
      "0.207648\n",
      "0.207648\n",
      "0.514185\n",
      "0.514185\n",
      "0.297494\n",
      "0.297494\n",
      "0.0362004\n",
      "0.0362004\n",
      "0.347428\n",
      "0.347428\n",
      "0.0307124\n",
      "0.0307124\n",
      "0.347215\n",
      "0.347215\n",
      "0.365146\n",
      "0.365146\n",
      "0.025\n",
      "0.025\n",
      "0.952594\n",
      "0.952594\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0384901\n",
      "0.0384901\n",
      "0.943375\n",
      "0.943375\n",
      "0.42539\n",
      "0.42539\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.913171\n",
      "0.913171\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.115967\n",
      "0.115967\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.767188\n",
      "0.767188\n",
      "0.100868\n",
      "0.100868\n",
      "0.0330806\n",
      "0.0330806\n",
      "0.737461\n",
      "0.737461\n",
      "0.0834245\n",
      "0.0834245\n",
      "0.025\n",
      "0.025\n",
      "0.373417\n",
      "0.373417\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.928779\n",
      "0.928779\n",
      "0.025\n",
      "0.025\n",
      "0.370611\n",
      "0.370611\n",
      "0.385693\n",
      "0.385693\n",
      "0.409796\n",
      "0.409796\n",
      "0.0881976\n",
      "0.0881976\n",
      "0.0483708\n",
      "0.0483708\n",
      "0.975\n",
      "0.975\n",
      "0.112633\n",
      "0.112633\n",
      "0.025\n",
      "0.025\n",
      "0.412063\n",
      "0.412063\n",
      "0.0719155\n",
      "0.0719155\n",
      "0.340338\n",
      "0.340338\n",
      "0.176163\n",
      "0.176163\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0792373\n",
      "0.0792373\n",
      "0.0358454\n",
      "0.0358454\n",
      "0.447783\n",
      "0.447783\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.234567\n",
      "0.234567\n",
      "0.025\n",
      "0.025\n",
      "0.403825\n",
      "0.403825\n",
      "0.0280232\n",
      "0.0280232\n",
      "0.0776125\n",
      "0.0776125\n",
      "0.0663235\n",
      "0.0663235\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.250371\n",
      "0.250371\n",
      "0.091476\n",
      "0.091476\n",
      "0.025\n",
      "0.025\n",
      "0.0626365\n",
      "0.0626365\n",
      "0.0697557\n",
      "0.0697557\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.442027\n",
      "0.442027\n",
      "0.808104\n",
      "0.808104\n",
      "0.0805829\n",
      "0.0805829\n",
      "0.773955\n",
      "0.773955\n",
      "0.0756418\n",
      "0.0756418\n",
      "0.975\n",
      "0.975\n",
      "0.039206\n",
      "0.039206\n",
      "0.975\n",
      "0.975\n",
      "0.0333042\n",
      "0.0333042\n",
      "0.025\n",
      "0.025\n",
      "0.353908\n",
      "0.353908\n",
      "0.228999\n",
      "0.228999\n",
      "0.025\n",
      "0.025\n",
      "0.0523828\n",
      "0.0523828\n",
      "0.136586\n",
      "0.136586\n",
      "0.025\n",
      "0.025\n",
      "0.103392\n",
      "0.103392\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0616321\n",
      "0.0616321\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.737366\n",
      "0.737366\n",
      "0.975\n",
      "0.975\n",
      "0.617518\n",
      "0.617518\n",
      "0.0754544\n",
      "0.0754544\n",
      "0.103296\n",
      "0.103296\n",
      "0.0336334\n",
      "0.0336334\n",
      "0.383295\n",
      "0.383295\n",
      "0.025\n",
      "0.025\n",
      "0.0493521\n",
      "0.0493521\n",
      "0.514786\n",
      "0.514786\n",
      "0.959485\n",
      "0.959485\n",
      "0.400015\n",
      "0.400015\n",
      "0.388605\n",
      "0.388605\n",
      "0.954014\n",
      "0.954014\n",
      "0.975\n",
      "0.975\n",
      "0.0285653\n",
      "0.0285653\n",
      "0.975\n",
      "0.975\n",
      "0.1224\n",
      "0.1224\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.382048\n",
      "0.382048\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.515904\n",
      "0.515904\n",
      "0.25882\n",
      "0.25882\n",
      "0.025\n",
      "0.025\n",
      "0.808794\n",
      "0.808794\n",
      "0.609254\n",
      "0.609254\n",
      "0.0838904\n",
      "0.0838904\n",
      "0.358502\n",
      "0.358502\n",
      "0.46961\n",
      "0.46961\n",
      "0.0556038\n",
      "0.0556038\n",
      "0.101557\n",
      "0.101557\n",
      "0.0438747\n",
      "0.0438747\n",
      "0.975\n",
      "0.975\n",
      "0.783192\n",
      "0.783192\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0750905\n",
      "0.0750905\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0328563\n",
      "0.0328563\n",
      "0.025\n",
      "0.025\n",
      "0.172833\n",
      "0.172833\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.33227\n",
      "0.33227\n",
      "0.278297\n",
      "0.278297\n",
      "0.101695\n",
      "0.101695\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.936526\n",
      "0.936526\n",
      "0.528794\n",
      "0.528794\n",
      "0.0576089\n",
      "0.0576089\n",
      "0.025\n",
      "0.025\n",
      "0.167439\n",
      "0.167439\n",
      "0.0327141\n",
      "0.0327141\n",
      "0.025\n",
      "0.025\n",
      "0.0451623\n",
      "0.0451623\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0775102\n",
      "0.0775102\n",
      "0.10025\n",
      "0.10025\n",
      "0.025\n",
      "0.025\n",
      "0.890803\n",
      "0.890803\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.227147\n",
      "0.227147\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.03299\n",
      "0.03299\n",
      "0.975\n",
      "0.975\n",
      "0.0994213\n",
      "0.0994213\n",
      "0.0710772\n",
      "0.0710772\n",
      "0.161089\n",
      "0.161089\n",
      "0.0786228\n",
      "0.0786228\n",
      "0.229264\n",
      "0.229264\n",
      "0.975\n",
      "0.975\n",
      "0.0873316\n",
      "0.0873316\n",
      "0.975\n",
      "0.975\n",
      "0.306463\n",
      "0.306463\n",
      "0.0628164\n",
      "0.0628164\n",
      "0.025\n",
      "0.025\n",
      "0.348532\n",
      "0.348532\n",
      "0.975\n",
      "0.975\n",
      "0.0500184\n",
      "0.0500184\n",
      "0.025\n",
      "0.025\n",
      "0.826485\n",
      "0.826485\n",
      "0.0569937\n",
      "0.0569937\n",
      "0.117897\n",
      "0.117897\n",
      "0.451643\n",
      "0.451643\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.925971\n",
      "0.925971\n",
      "0.0454002\n",
      "0.0454002\n",
      "0.025\n",
      "0.025\n",
      "0.475993\n",
      "0.475993\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.475393\n",
      "0.475393\n",
      "0.312139\n",
      "0.312139\n",
      "0.305704\n",
      "0.305704\n",
      "0.025\n",
      "0.025\n",
      "0.369635\n",
      "0.369635\n",
      "0.025\n",
      "0.025\n",
      "0.0641138\n",
      "0.0641138\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.483496\n",
      "0.483496\n",
      "0.288176\n",
      "0.288176\n",
      "0.892067\n",
      "0.892067\n",
      "0.040301\n",
      "0.040301\n",
      "0.973614\n",
      "0.973614\n",
      "0.56584\n",
      "0.56584\n",
      "0.498203\n",
      "0.498203\n",
      "0.88728\n",
      "0.88728\n",
      "0.232432\n",
      "0.232432\n",
      "0.0497007\n",
      "0.0497007\n",
      "0.025\n",
      "0.025\n",
      "0.582492\n",
      "0.582492\n",
      "0.025\n",
      "0.025\n",
      "0.0332827\n",
      "0.0332827\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.806955\n",
      "0.806955\n",
      "0.371849\n",
      "0.371849\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0291111\n",
      "0.0291111\n",
      "0.025\n",
      "0.025\n",
      "0.263846\n",
      "0.263846\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.091576\n",
      "0.091576\n",
      "0.025\n",
      "0.025\n",
      "0.0854486\n",
      "0.0854486\n",
      "0.761983\n",
      "0.761983\n",
      "0.025\n",
      "0.025\n",
      "0.739335\n",
      "0.739335\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.605294\n",
      "0.605294\n",
      "0.0831745\n",
      "0.0831745\n",
      "0.500863\n",
      "0.500863\n",
      "0.025\n",
      "0.025\n",
      "0.193543\n",
      "0.193543\n",
      "0.025\n",
      "0.025\n",
      "0.0573913\n",
      "0.0573913\n",
      "0.092543\n",
      "0.092543\n",
      "0.975\n",
      "0.975\n",
      "0.0739687\n",
      "0.0739687\n",
      "0.025\n",
      "0.025\n",
      "0.0463372\n",
      "0.0463372\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.333715\n",
      "0.333715\n",
      "0.453932\n",
      "0.453932\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.726163\n",
      "0.726163\n",
      "0.125269\n",
      "0.125269\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.965285\n",
      "0.965285\n",
      "0.290261\n",
      "0.290261\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.100419\n",
      "0.100419\n",
      "0.275143\n",
      "0.275143\n",
      "0.352245\n",
      "0.352245\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.240705\n",
      "0.240705\n",
      "0.025\n",
      "0.025\n",
      "0.0679092\n",
      "0.0679092\n",
      "0.025\n",
      "0.025\n",
      "0.0674662\n",
      "0.0674662\n",
      "0.956791\n",
      "0.956791\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0488009\n",
      "0.0488009\n",
      "0.603674\n",
      "0.603674\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0426392\n",
      "0.0426392\n",
      "0.025\n",
      "0.025\n",
      "0.0385845\n",
      "0.0385845\n",
      "0.0496985\n",
      "0.0496985\n",
      "0.025\n",
      "0.025\n",
      "0.0363648\n",
      "0.0363648\n",
      "0.310345\n",
      "0.310345\n",
      "0.211053\n",
      "0.211053\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.93952\n",
      "0.93952\n",
      "0.347824\n",
      "0.347824\n",
      "0.87226\n",
      "0.87226\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.285856\n",
      "0.285856\n",
      "0.521441\n",
      "0.521441\n",
      "0.0729657\n",
      "0.0729657\n",
      "0.025\n",
      "0.025\n",
      "0.835708\n",
      "0.835708\n",
      "0.025\n",
      "0.025\n",
      "0.0313674\n",
      "0.0313674\n",
      "0.025\n",
      "0.025\n",
      "0.0517588\n",
      "0.0517588\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.129671\n",
      "0.129671\n",
      "0.025\n",
      "0.025\n",
      "0.611612\n",
      "0.611612\n",
      "0.154863\n",
      "0.154863\n",
      "0.737648\n",
      "0.737648\n",
      "0.025\n",
      "0.025\n",
      "0.76048\n",
      "0.76048\n",
      "0.0791477\n",
      "0.0791477\n",
      "0.025\n",
      "0.025\n",
      "0.0445562\n",
      "0.0445562\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0377886\n",
      "0.0377886\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.212436\n",
      "0.212436\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.153671\n",
      "0.153671\n",
      "0.0352268\n",
      "0.0352268\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0616908\n",
      "0.0616908\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0615021\n",
      "0.0615021\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.516954\n",
      "0.516954\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0445346\n",
      "0.0445346\n",
      "0.025\n",
      "0.025\n",
      "0.430255\n",
      "0.430255\n",
      "0.975\n",
      "0.975\n",
      "0.0925597\n",
      "0.0925597\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0711845\n",
      "0.0711845\n",
      "0.025\n",
      "0.025\n",
      "0.0600447\n",
      "0.0600447\n",
      "0.417712\n",
      "0.417712\n",
      "0.174348\n",
      "0.174348\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.239468\n",
      "0.239468\n",
      "0.0673221\n",
      "0.0673221\n",
      "0.025\n",
      "0.025\n",
      "0.80675\n",
      "0.80675\n",
      "0.116599\n",
      "0.116599\n",
      "0.025\n",
      "0.025\n",
      "0.777541\n",
      "0.777541\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.876585\n",
      "0.876585\n",
      "0.025\n",
      "0.025\n",
      "0.0453297\n",
      "0.0453297\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0474165\n",
      "0.0474165\n",
      "0.120324\n",
      "0.120324\n",
      "0.0462414\n",
      "0.0462414\n",
      "0.025\n",
      "0.025\n",
      "0.534697\n",
      "0.534697\n",
      "0.0373486\n",
      "0.0373486\n",
      "0.055344\n",
      "0.055344\n",
      "0.0269681\n",
      "0.0269681\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0338896\n",
      "0.0338896\n",
      "0.0421579\n",
      "0.0421579\n",
      "0.826771\n",
      "0.826771\n",
      "0.270241\n",
      "0.270241\n",
      "0.025\n",
      "0.025\n",
      "0.0625973\n",
      "0.0625973\n",
      "0.975\n",
      "0.975\n",
      "0.033007\n",
      "0.033007\n",
      "0.210476\n",
      "0.210476\n",
      "0.025\n",
      "0.025\n",
      "0.205171\n",
      "0.205171\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0797266\n",
      "0.0797266\n",
      "0.025\n",
      "0.025\n",
      "0.304455\n",
      "0.304455\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0429464\n",
      "0.0429464\n",
      "0.824947\n",
      "0.824947\n",
      "0.479639\n",
      "0.479639\n",
      "0.025\n",
      "0.025\n",
      "0.0750834\n",
      "0.0750834\n",
      "0.923757\n",
      "0.923757\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.311684\n",
      "0.311684\n",
      "0.025\n",
      "0.025\n",
      "0.0451748\n",
      "0.0451748\n",
      "0.0735013\n",
      "0.0735013\n",
      "0.975\n",
      "0.975\n",
      "0.246668\n",
      "0.246668\n",
      "0.025\n",
      "0.025\n",
      "0.81221\n",
      "0.81221\n",
      "0.025\n",
      "0.025\n",
      "0.0326182\n",
      "0.0326182\n",
      "0.329443\n",
      "0.329443\n",
      "0.025\n",
      "0.025\n",
      "0.240318\n",
      "0.240318\n",
      "0.025\n",
      "0.025\n",
      "0.0994568\n",
      "0.0994568\n",
      "0.110388\n",
      "0.110388\n",
      "0.0467875\n",
      "0.0467875\n",
      "0.702757\n",
      "0.702757\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.239728\n",
      "0.239728\n",
      "0.025\n",
      "0.025\n",
      "0.0585814\n",
      "0.0585814\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.923945\n",
      "0.923945\n",
      "0.025\n",
      "0.025\n",
      "0.701814\n",
      "0.701814\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.948874\n",
      "0.948874\n",
      "0.025\n",
      "0.025\n",
      "0.295836\n",
      "0.295836\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.165432\n",
      "0.165432\n",
      "0.975\n",
      "0.975\n",
      "0.494725\n",
      "0.494725\n",
      "0.0320517\n",
      "0.0320517\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0410475\n",
      "0.0410475\n",
      "0.025\n",
      "0.025\n",
      "0.10383\n",
      "0.10383\n",
      "0.025\n",
      "0.025\n",
      "0.324647\n",
      "0.324647\n",
      "0.746723\n",
      "0.746723\n",
      "0.271587\n",
      "0.271587\n",
      "0.924158\n",
      "0.924158\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0571879\n",
      "0.0571879\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0394386\n",
      "0.0394386\n",
      "0.975\n",
      "0.975\n",
      "0.770014\n",
      "0.770014\n",
      "0.397834\n",
      "0.397834\n",
      "0.025\n",
      "0.025\n",
      "0.198439\n",
      "0.198439\n",
      "0.313718\n",
      "0.313718\n",
      "0.859589\n",
      "0.859589\n",
      "0.176724\n",
      "0.176724\n",
      "0.400741\n",
      "0.400741\n",
      "0.933632\n",
      "0.933632\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0348973\n",
      "0.0348973\n",
      "0.127642\n",
      "0.127642\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.152935\n",
      "0.152935\n",
      "0.0469494\n",
      "0.0469494\n",
      "0.975\n",
      "0.975\n",
      "0.771605\n",
      "0.771605\n",
      "0.0568128\n",
      "0.0568128\n",
      "0.426232\n",
      "0.426232\n",
      "0.0883729\n",
      "0.0883729\n",
      "0.025\n",
      "0.025\n",
      "0.0360968\n",
      "0.0360968\n",
      "0.025\n",
      "0.025\n",
      "0.0739394\n",
      "0.0739394\n",
      "0.149915\n",
      "0.149915\n",
      "0.362952\n",
      "0.362952\n",
      "0.025\n",
      "0.025\n",
      "0.368923\n",
      "0.368923\n",
      "0.975\n",
      "0.975\n",
      "0.0923855\n",
      "0.0923855\n",
      "0.856319\n",
      "0.856319\n",
      "0.0429791\n",
      "0.0429791\n",
      "0.714354\n",
      "0.714354\n",
      "0.0488365\n",
      "0.0488365\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.232236\n",
      "0.232236\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.738004\n",
      "0.738004\n",
      "0.0404255\n",
      "0.0404255\n",
      "0.334652\n",
      "0.334652\n",
      "0.025\n",
      "0.025\n",
      "0.756728\n",
      "0.756728\n",
      "0.0734034\n",
      "0.0734034\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0436307\n",
      "0.0436307\n",
      "0.450977\n",
      "0.450977\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0380623\n",
      "0.0380623\n",
      "0.025\n",
      "0.025\n",
      "0.0515124\n",
      "0.0515124\n",
      "0.025\n",
      "0.025\n",
      "0.403898\n",
      "0.403898\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0302436\n",
      "0.0302436\n",
      "0.0327455\n",
      "0.0327455\n",
      "0.0262988\n",
      "0.0262988\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0987347\n",
      "0.0987347\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.116478\n",
      "0.116478\n",
      "0.975\n",
      "0.975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.41374\n",
      "0.41374\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.237458\n",
      "0.237458\n",
      "0.025\n",
      "0.025\n",
      "0.0798107\n",
      "0.0798107\n",
      "0.739859\n",
      "0.739859\n",
      "0.0745764\n",
      "0.0745764\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.634939\n",
      "0.634939\n",
      "0.0561586\n",
      "0.0561586\n",
      "0.0355563\n",
      "0.0355563\n",
      "0.0693463\n",
      "0.0693463\n",
      "0.441577\n",
      "0.441577\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.792871\n",
      "0.792871\n",
      "0.025\n",
      "0.025\n",
      "0.719304\n",
      "0.719304\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.890482\n",
      "0.890482\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.107179\n",
      "0.107179\n",
      "0.437344\n",
      "0.437344\n",
      "0.025\n",
      "0.025\n",
      "0.621837\n",
      "0.621837\n",
      "0.122809\n",
      "0.122809\n",
      "0.025\n",
      "0.025\n",
      "0.030401\n",
      "0.030401\n",
      "0.512112\n",
      "0.512112\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.201564\n",
      "0.201564\n",
      "0.025\n",
      "0.025\n",
      "0.074464\n",
      "0.074464\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0962858\n",
      "0.0962858\n",
      "0.70757\n",
      "0.70757\n",
      "0.025\n",
      "0.025\n",
      "0.513321\n",
      "0.513321\n",
      "0.966946\n",
      "0.966946\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.106468\n",
      "0.106468\n",
      "0.972049\n",
      "0.972049\n",
      "0.29002\n",
      "0.29002\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0518122\n",
      "0.0518122\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0346351\n",
      "0.0346351\n",
      "0.0467638\n",
      "0.0467638\n",
      "0.975\n",
      "0.975\n",
      "0.199953\n",
      "0.199953\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0597012\n",
      "0.0597012\n",
      "0.469533\n",
      "0.469533\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.208912\n",
      "0.208912\n",
      "0.0290959\n",
      "0.0290959\n",
      "0.975\n",
      "0.975\n",
      "0.0938252\n",
      "0.0938252\n",
      "0.025\n",
      "0.025\n",
      "0.682814\n",
      "0.682814\n",
      "0.025\n",
      "0.025\n",
      "0.0391792\n",
      "0.0391792\n",
      "0.240351\n",
      "0.240351\n",
      "0.025\n",
      "0.025\n",
      "0.300958\n",
      "0.300958\n",
      "0.0314736\n",
      "0.0314736\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.898881\n",
      "0.898881\n",
      "0.304127\n",
      "0.304127\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.852322\n",
      "0.852322\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.93386\n",
      "0.93386\n",
      "0.301479\n",
      "0.301479\n",
      "0.307558\n",
      "0.307558\n",
      "0.231432\n",
      "0.231432\n",
      "0.025\n",
      "0.025\n",
      "0.56413\n",
      "0.56413\n",
      "0.971958\n",
      "0.971958\n",
      "0.025\n",
      "0.025\n",
      "0.146948\n",
      "0.146948\n",
      "0.183819\n",
      "0.183819\n",
      "0.137257\n",
      "0.137257\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0970095\n",
      "0.0970095\n",
      "0.0883669\n",
      "0.0883669\n",
      "0.0873212\n",
      "0.0873212\n",
      "0.025\n",
      "0.025\n",
      "0.158528\n",
      "0.158528\n",
      "0.025\n",
      "0.025\n",
      "0.0798775\n",
      "0.0798775\n",
      "0.0938175\n",
      "0.0938175\n",
      "0.210672\n",
      "0.210672\n",
      "0.0281169\n",
      "0.0281169\n",
      "0.025\n",
      "0.025\n",
      "0.92626\n",
      "0.92626\n",
      "0.975\n",
      "0.975\n",
      "0.0501714\n",
      "0.0501714\n",
      "0.0780184\n",
      "0.0780184\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.238613\n",
      "0.238613\n",
      "0.975\n",
      "0.975\n",
      "0.0616288\n",
      "0.0616288\n",
      "0.0564132\n",
      "0.0564132\n",
      "0.0891669\n",
      "0.0891669\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0283085\n",
      "0.0283085\n",
      "0.710787\n",
      "0.710787\n",
      "0.315515\n",
      "0.315515\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.10481\n",
      "0.10481\n",
      "0.319459\n",
      "0.319459\n",
      "0.168073\n",
      "0.168073\n",
      "0.847988\n",
      "0.847988\n",
      "0.025\n",
      "0.025\n",
      "0.0252419\n",
      "0.0252419\n",
      "0.0328619\n",
      "0.0328619\n",
      "0.025\n",
      "0.025\n",
      "0.0527467\n",
      "0.0527467\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0272559\n",
      "0.0272559\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.417636\n",
      "0.417636\n",
      "0.840248\n",
      "0.840248\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0753802\n",
      "0.0753802\n",
      "0.975\n",
      "0.975\n",
      "0.530953\n",
      "0.530953\n",
      "0.0374116\n",
      "0.0374116\n",
      "0.041988\n",
      "0.041988\n",
      "0.30212\n",
      "0.30212\n",
      "0.42478\n",
      "0.42478\n",
      "0.673077\n",
      "0.673077\n",
      "0.807781\n",
      "0.807781\n",
      "0.037059\n",
      "0.037059\n",
      "0.291818\n",
      "0.291818\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0364474\n",
      "0.0364474\n",
      "0.025\n",
      "0.025\n",
      "0.381893\n",
      "0.381893\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0488404\n",
      "0.0488404\n",
      "0.636728\n",
      "0.636728\n",
      "0.0595784\n",
      "0.0595784\n",
      "0.025\n",
      "0.025\n",
      "0.520065\n",
      "0.520065\n",
      "0.025\n",
      "0.025\n",
      "0.320211\n",
      "0.320211\n",
      "0.943292\n",
      "0.943292\n",
      "0.303297\n",
      "0.303297\n",
      "0.081613\n",
      "0.081613\n",
      "0.025\n",
      "0.025\n",
      "0.0996532\n",
      "0.0996532\n",
      "0.27875\n",
      "0.27875\n",
      "0.0432952\n",
      "0.0432952\n",
      "0.0706429\n",
      "0.0706429\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.404943\n",
      "0.404943\n",
      "0.13148\n",
      "0.13148\n",
      "0.160301\n",
      "0.160301\n",
      "0.189241\n",
      "0.189241\n",
      "0.131614\n",
      "0.131614\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0263353\n",
      "0.0263353\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.286018\n",
      "0.286018\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.960625\n",
      "0.960625\n",
      "0.0906108\n",
      "0.0906108\n",
      "0.702523\n",
      "0.702523\n",
      "0.025\n",
      "0.025\n",
      "0.0944199\n",
      "0.0944199\n",
      "0.025\n",
      "0.025\n",
      "0.0906422\n",
      "0.0906422\n",
      "0.15941\n",
      "0.15941\n",
      "0.0759453\n",
      "0.0759453\n",
      "0.025\n",
      "0.025\n",
      "0.0760327\n",
      "0.0760327\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.108769\n",
      "0.108769\n",
      "0.956109\n",
      "0.956109\n",
      "0.025\n",
      "0.025\n",
      "0.26206\n",
      "0.26206\n",
      "0.32614\n",
      "0.32614\n",
      "0.0430853\n",
      "0.0430853\n",
      "0.180532\n",
      "0.180532\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.151473\n",
      "0.151473\n",
      "0.975\n",
      "0.975\n",
      "0.333906\n",
      "0.333906\n",
      "0.025\n",
      "0.025\n",
      "0.913528\n",
      "0.913528\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0620592\n",
      "0.0620592\n",
      "0.025\n",
      "0.025\n",
      "0.14514\n",
      "0.14514\n",
      "0.943846\n",
      "0.943846\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0355831\n",
      "0.0355831\n",
      "0.141398\n",
      "0.141398\n",
      "0.025\n",
      "0.025\n",
      "0.320592\n",
      "0.320592\n",
      "0.452554\n",
      "0.452554\n",
      "0.148233\n",
      "0.148233\n",
      "0.025\n",
      "0.025\n",
      "0.681578\n",
      "0.681578\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.531246\n",
      "0.531246\n",
      "0.944742\n",
      "0.944742\n",
      "0.0529352\n",
      "0.0529352\n",
      "0.559519\n",
      "0.559519\n",
      "0.0637079\n",
      "0.0637079\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.714757\n",
      "0.714757\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025903\n",
      "0.025903\n",
      "0.975\n",
      "0.975\n",
      "0.856367\n",
      "0.856367\n",
      "0.025\n",
      "0.025\n",
      "0.191\n",
      "0.191\n",
      "0.823076\n",
      "0.823076\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0600641\n",
      "0.0600641\n",
      "0.24743\n",
      "0.24743\n",
      "0.025\n",
      "0.025\n",
      "0.643392\n",
      "0.643392\n",
      "0.025\n",
      "0.025\n",
      "0.0711047\n",
      "0.0711047\n",
      "0.740583\n",
      "0.740583\n",
      "0.025\n",
      "0.025\n",
      "0.845231\n",
      "0.845231\n",
      "0.0919597\n",
      "0.0919597\n",
      "0.025\n",
      "0.025\n",
      "0.176277\n",
      "0.176277\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0569201\n",
      "0.0569201\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0257987\n",
      "0.0257987\n",
      "0.025\n",
      "0.025\n",
      "0.0493345\n",
      "0.0493345\n",
      "0.148385\n",
      "0.148385\n",
      "0.975\n",
      "0.975\n",
      "0.206092\n",
      "0.206092\n",
      "0.128137\n",
      "0.128137\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0654269\n",
      "0.0654269\n",
      "0.025\n",
      "0.025\n",
      "0.806735\n",
      "0.806735\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.962496\n",
      "0.962496\n",
      "0.122535\n",
      "0.122535\n",
      "0.132424\n",
      "0.132424\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0639895\n",
      "0.0639895\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.140106\n",
      "0.140106\n",
      "0.15194\n",
      "0.15194\n",
      "0.636576\n",
      "0.636576\n",
      "0.764547\n",
      "0.764547\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.110645\n",
      "0.110645\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0835056\n",
      "0.0835056\n",
      "0.933078\n",
      "0.933078\n",
      "0.025\n",
      "0.025\n",
      "0.0639688\n",
      "0.0639688\n",
      "0.533719\n",
      "0.533719\n",
      "0.025\n",
      "0.025\n",
      "0.455249\n",
      "0.455249\n",
      "0.161763\n",
      "0.161763\n",
      "0.0891792\n",
      "0.0891792\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.635172\n",
      "0.635172\n",
      "0.025\n",
      "0.025\n",
      "0.418532\n",
      "0.418532\n",
      "0.55122\n",
      "0.55122\n",
      "0.144311\n",
      "0.144311\n",
      "0.025\n",
      "0.025\n",
      "0.0313374\n",
      "0.0313374\n",
      "0.192968\n",
      "0.192968\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0465992\n",
      "0.0465992\n",
      "0.0460435\n",
      "0.0460435\n",
      "0.758972\n",
      "0.758972\n",
      "0.34532\n",
      "0.34532\n",
      "0.268875\n",
      "0.268875\n",
      "0.0311393\n",
      "0.0311393\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.266367\n",
      "0.266367\n",
      "0.124137\n",
      "0.124137\n",
      "0.951801\n",
      "0.951801\n",
      "0.025\n",
      "0.025\n",
      "0.357303\n",
      "0.357303\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.436917\n",
      "0.436917\n",
      "0.975\n",
      "0.975\n",
      "0.63872\n",
      "0.63872\n",
      "0.025\n",
      "0.025\n",
      "0.701744\n",
      "0.701744\n",
      "0.025\n",
      "0.025\n",
      "0.0402709\n",
      "0.0402709\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.836007\n",
      "0.836007\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.836197\n",
      "0.836197\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0810335\n",
      "0.0810335\n",
      "0.331874\n",
      "0.331874\n",
      "0.025\n",
      "0.025\n",
      "0.105065\n",
      "0.105065\n",
      "0.0558891\n",
      "0.0558891\n",
      "0.241658\n",
      "0.241658\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0313363\n",
      "0.0313363\n",
      "0.025\n",
      "0.025\n",
      "0.0451062\n",
      "0.0451062\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.39593\n",
      "0.39593\n",
      "0.0259365\n",
      "0.0259365\n",
      "0.975\n",
      "0.975\n",
      "0.962243\n",
      "0.962243\n",
      "0.975\n",
      "0.975\n",
      "0.888095\n",
      "0.888095\n",
      "0.025\n",
      "0.025\n",
      "0.255381\n",
      "0.255381\n",
      "0.025\n",
      "0.025\n",
      "0.0409548\n",
      "0.0409548\n",
      "0.0270118\n",
      "0.0270118\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0829166\n",
      "0.0829166\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.655108\n",
      "0.655108\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.243143\n",
      "0.243143\n",
      "0.170913\n",
      "0.170913\n",
      "0.975\n",
      "0.975\n",
      "0.541008\n",
      "0.541008\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0363311\n",
      "0.0363311\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.082208\n",
      "0.082208\n",
      "0.025\n",
      "0.025\n",
      "0.105489\n",
      "0.105489\n",
      "0.025\n",
      "0.025\n",
      "0.0890084\n",
      "0.0890084\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.876294\n",
      "0.876294\n",
      "0.875613\n",
      "0.875613\n",
      "0.347514\n",
      "0.347514\n",
      "0.042083\n",
      "0.042083\n",
      "0.867656\n",
      "0.867656\n",
      "0.975\n",
      "0.975\n",
      "0.221476\n",
      "0.221476\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.80654\n",
      "0.80654\n",
      "0.310011\n",
      "0.310011\n",
      "0.616426\n",
      "0.616426\n",
      "0.18757\n",
      "0.18757\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.867429\n",
      "0.867429\n",
      "0.975\n",
      "0.975\n",
      "0.267531\n",
      "0.267531\n",
      "0.025\n",
      "0.025\n",
      "0.132225\n",
      "0.132225\n",
      "0.975\n",
      "0.975\n",
      "0.0553455\n",
      "0.0553455\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.39016\n",
      "0.39016\n",
      "0.0458317\n",
      "0.0458317\n",
      "0.0540312\n",
      "0.0540312\n",
      "0.025\n",
      "0.025\n",
      "0.809592\n",
      "0.809592\n",
      "0.025\n",
      "0.025\n",
      "0.658624\n",
      "0.658624\n",
      "0.306626\n",
      "0.306626\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.4874\n",
      "0.4874\n",
      "0.1958\n",
      "0.1958\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0639933\n",
      "0.0639933\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0533263\n",
      "0.0533263\n",
      "0.140882\n",
      "0.140882\n",
      "0.439481\n",
      "0.439481\n",
      "0.352012\n",
      "0.352012\n",
      "0.025\n",
      "0.025\n",
      "0.0750718\n",
      "0.0750718\n",
      "0.653736\n",
      "0.653736\n",
      "0.0782548\n",
      "0.0782548\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0252057\n",
      "0.0252057\n",
      "0.0684062\n",
      "0.0684062\n",
      "0.963734\n",
      "0.963734\n",
      "0.195745\n",
      "0.195745\n",
      "0.025\n",
      "0.025\n",
      "0.640542\n",
      "0.640542\n",
      "0.734128\n",
      "0.734128\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.923077\n",
      "0.923077\n",
      "0.0533756\n",
      "0.0533756\n",
      "0.857612\n",
      "0.857612\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.034305\n",
      "0.034305\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.902469\n",
      "0.902469\n",
      "0.025\n",
      "0.025\n",
      "0.728699\n",
      "0.728699\n",
      "0.975\n",
      "0.975\n",
      "0.26151\n",
      "0.26151\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0270452\n",
      "0.0270452\n",
      "0.366685\n",
      "0.366685\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.164521\n",
      "0.164521\n",
      "0.025\n",
      "0.025\n",
      "0.793686\n",
      "0.793686\n",
      "0.0886385\n",
      "0.0886385\n",
      "0.312298\n",
      "0.312298\n",
      "0.070445\n",
      "0.070445\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.228794\n",
      "0.228794\n",
      "0.025\n",
      "0.025\n",
      "0.247222\n",
      "0.247222\n",
      "0.975\n",
      "0.975\n",
      "0.973223\n",
      "0.973223\n",
      "0.975\n",
      "0.975\n",
      "0.49047\n",
      "0.49047\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0415332\n",
      "0.0415332\n",
      "0.030281\n",
      "0.030281\n",
      "0.0432742\n",
      "0.0432742\n",
      "0.309868\n",
      "0.309868\n",
      "0.0331466\n",
      "0.0331466\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0392313\n",
      "0.0392313\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.362789\n",
      "0.362789\n",
      "0.025\n",
      "0.025\n",
      "0.831701\n",
      "0.831701\n",
      "0.134787\n",
      "0.134787\n",
      "0.875396\n",
      "0.875396\n",
      "0.0430372\n",
      "0.0430372\n",
      "0.025\n",
      "0.025\n",
      "0.0308116\n",
      "0.0308116\n",
      "0.850593\n",
      "0.850593\n",
      "0.952192\n",
      "0.952192\n",
      "0.286725\n",
      "0.286725\n",
      "0.0676962\n",
      "0.0676962\n",
      "0.206019\n",
      "0.206019\n",
      "0.025\n",
      "0.025\n",
      "0.570365\n",
      "0.570365\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.150789\n",
      "0.150789\n",
      "0.975\n",
      "0.975\n",
      "0.54162\n",
      "0.54162\n",
      "0.581057\n",
      "0.581057\n",
      "0.949467\n",
      "0.949467\n",
      "0.025\n",
      "0.025\n",
      "0.0658155\n",
      "0.0658155\n",
      "0.0960345\n",
      "0.0960345\n",
      "0.252282\n",
      "0.252282\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.759341\n",
      "0.759341\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0254866\n",
      "0.0254866\n",
      "0.678178\n",
      "0.678178\n",
      "0.25685\n",
      "0.25685\n",
      "0.0265456\n",
      "0.0265456\n",
      "0.025\n",
      "0.025\n",
      "0.0912571\n",
      "0.0912571\n",
      "0.025\n",
      "0.025\n",
      "0.031156\n",
      "0.031156\n",
      "0.182317\n",
      "0.182317\n",
      "0.0468731\n",
      "0.0468731\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.128511\n",
      "0.128511\n",
      "0.290316\n",
      "0.290316\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.963156\n",
      "0.963156\n",
      "0.765128\n",
      "0.765128\n",
      "0.623635\n",
      "0.623635\n",
      "0.0404787\n",
      "0.0404787\n",
      "0.039096\n",
      "0.039096\n",
      "0.025\n",
      "0.025\n",
      "0.125377\n",
      "0.125377\n",
      "0.975\n",
      "0.975\n",
      "0.0820945\n",
      "0.0820945\n",
      "0.621781\n",
      "0.621781\n",
      "0.025\n",
      "0.025\n",
      "0.618033\n",
      "0.618033\n",
      "0.0995574\n",
      "0.0995574\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.774466\n",
      "0.774466\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0812221\n",
      "0.0812221\n",
      "0.114555\n",
      "0.114555\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.129168\n",
      "0.129168\n",
      "0.476016\n",
      "0.476016\n",
      "0.025\n",
      "0.025\n",
      "0.0376909\n",
      "0.0376909\n",
      "0.0981282\n",
      "0.0981282\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0399465\n",
      "0.0399465\n",
      "0.025\n",
      "0.025\n",
      "0.891303\n",
      "0.891303\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0410399\n",
      "0.0410399\n",
      "0.744335\n",
      "0.744335\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0783011\n",
      "0.0783011\n",
      "0.124833\n",
      "0.124833\n",
      "0.0256871\n",
      "0.0256871\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.645594\n",
      "0.645594\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.19707\n",
      "0.19707\n",
      "0.025\n",
      "0.025\n",
      "0.205589\n",
      "0.205589\n",
      "0.252748\n",
      "0.252748\n",
      "0.147902\n",
      "0.147902\n",
      "0.965726\n",
      "0.965726\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.248332\n",
      "0.248332\n",
      "0.115528\n",
      "0.115528\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.952728\n",
      "0.952728\n",
      "0.163296\n",
      "0.163296\n",
      "0.38384\n",
      "0.38384\n",
      "0.975\n",
      "0.975\n",
      "0.116566\n",
      "0.116566\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.945255\n",
      "0.945255\n",
      "0.0353502\n",
      "0.0353502\n",
      "0.0287258\n",
      "0.0287258\n",
      "0.025\n",
      "0.025\n",
      "0.0535283\n",
      "0.0535283\n",
      "0.762173\n",
      "0.762173\n",
      "0.025\n",
      "0.025\n",
      "0.2859\n",
      "0.2859\n",
      "0.975\n",
      "0.975\n",
      "0.187427\n",
      "0.187427\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.24745\n",
      "0.24745\n",
      "0.114539\n",
      "0.114539\n",
      "0.975\n",
      "0.975\n",
      "0.0305547\n",
      "0.0305547\n",
      "0.256879\n",
      "0.256879\n",
      "0.813532\n",
      "0.813532\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.641702\n",
      "0.641702\n",
      "0.0864753\n",
      "0.0864753\n",
      "0.0401688\n",
      "0.0401688\n",
      "0.925726\n",
      "0.925726\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.553201\n",
      "0.553201\n",
      "0.247978\n",
      "0.247978\n",
      "0.890081\n",
      "0.890081\n",
      "0.131247\n",
      "0.131247\n",
      "0.025\n",
      "0.025\n",
      "0.951396\n",
      "0.951396\n",
      "0.189887\n",
      "0.189887\n",
      "0.143509\n",
      "0.143509\n",
      "0.723491\n",
      "0.723491\n",
      "0.597324\n",
      "0.597324\n",
      "0.17931\n",
      "0.17931\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0953556\n",
      "0.0953556\n",
      "0.304932\n",
      "0.304932\n",
      "0.975\n",
      "0.975\n",
      "0.1915\n",
      "0.1915\n",
      "0.025\n",
      "0.025\n",
      "0.675478\n",
      "0.675478\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.145431\n",
      "0.145431\n",
      "0.115988\n",
      "0.115988\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0897957\n",
      "0.0897957\n",
      "0.975\n",
      "0.975\n",
      "0.150869\n",
      "0.150869\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.107546\n",
      "0.107546\n",
      "0.201708\n",
      "0.201708\n",
      "0.975\n",
      "0.975\n",
      "0.0367246\n",
      "0.0367246\n",
      "0.606446\n",
      "0.606446\n",
      "0.300784\n",
      "0.300784\n",
      "0.417174\n",
      "0.417174\n",
      "0.025\n",
      "0.025\n",
      "0.0422994\n",
      "0.0422994\n",
      "0.327399\n",
      "0.327399\n",
      "0.149519\n",
      "0.149519\n",
      "0.809526\n",
      "0.809526\n",
      "0.042476\n",
      "0.042476\n",
      "0.441829\n",
      "0.441829\n",
      "0.6601\n",
      "0.6601\n",
      "0.025\n",
      "0.025\n",
      "0.965323\n",
      "0.965323\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.290208\n",
      "0.290208\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.186657\n",
      "0.186657\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.858429\n",
      "0.858429\n",
      "0.0670476\n",
      "0.0670476\n",
      "0.227315\n",
      "0.227315\n",
      "0.177309\n",
      "0.177309\n",
      "0.025\n",
      "0.025\n",
      "0.709173\n",
      "0.709173\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.856925\n",
      "0.856925\n",
      "0.025\n",
      "0.025\n",
      "0.0421004\n",
      "0.0421004\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0567475\n",
      "0.0567475\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.405481\n",
      "0.405481\n",
      "0.239664\n",
      "0.239664\n",
      "0.0341309\n",
      "0.0341309\n",
      "0.112351\n",
      "0.112351\n",
      "0.25996\n",
      "0.25996\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0400852\n",
      "0.0400852\n",
      "0.374525\n",
      "0.374525\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.454211\n",
      "0.454211\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.837398\n",
      "0.837398\n",
      "0.0852908\n",
      "0.0852908\n",
      "0.296261\n",
      "0.296261\n",
      "0.025\n",
      "0.025\n",
      "0.793268\n",
      "0.793268\n",
      "0.0273135\n",
      "0.0273135\n",
      "0.025\n",
      "0.025\n",
      "0.156728\n",
      "0.156728\n",
      "0.025\n",
      "0.025\n",
      "0.515492\n",
      "0.515492\n",
      "0.025\n",
      "0.025\n",
      "0.933536\n",
      "0.933536\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0733991\n",
      "0.0733991\n",
      "0.923073\n",
      "0.923073\n",
      "0.0436195\n",
      "0.0436195\n",
      "0.37411\n",
      "0.37411\n",
      "0.501401\n",
      "0.501401\n",
      "0.814243\n",
      "0.814243\n",
      "0.113202\n",
      "0.113202\n",
      "0.0418822\n",
      "0.0418822\n",
      "0.586119\n",
      "0.586119\n",
      "0.0325602\n",
      "0.0325602\n",
      "0.143989\n",
      "0.143989\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0260042\n",
      "0.0260042\n",
      "0.480513\n",
      "0.480513\n",
      "0.025\n",
      "0.025\n",
      "0.100818\n",
      "0.100818\n",
      "0.284764\n",
      "0.284764\n",
      "0.253789\n",
      "0.253789\n",
      "0.0438208\n",
      "0.0438208\n",
      "0.025\n",
      "0.025\n",
      "0.0839439\n",
      "0.0839439\n",
      "0.025\n",
      "0.025\n",
      "0.857201\n",
      "0.857201\n",
      "0.204753\n",
      "0.204753\n",
      "0.025\n",
      "0.025\n",
      "0.0272134\n",
      "0.0272134\n",
      "0.025\n",
      "0.025\n",
      "0.722347\n",
      "0.722347\n",
      "0.173608\n",
      "0.173608\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.927497\n",
      "0.927497\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.148953\n",
      "0.148953\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.161926\n",
      "0.161926\n",
      "0.885645\n",
      "0.885645\n",
      "0.870452\n",
      "0.870452\n",
      "0.025\n",
      "0.025\n",
      "0.0827202\n",
      "0.0827202\n",
      "0.025\n",
      "0.025\n",
      "0.104744\n",
      "0.104744\n",
      "0.149372\n",
      "0.149372\n",
      "0.182675\n",
      "0.182675\n",
      "0.025\n",
      "0.025\n",
      "0.365343\n",
      "0.365343\n",
      "0.943673\n",
      "0.943673\n",
      "0.148929\n",
      "0.148929\n",
      "0.914712\n",
      "0.914712\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.180752\n",
      "0.180752\n",
      "0.025\n",
      "0.025\n",
      "0.0816342\n",
      "0.0816342\n",
      "0.246378\n",
      "0.246378\n",
      "0.0383602\n",
      "0.0383602\n",
      "0.183533\n",
      "0.183533\n",
      "0.975\n",
      "0.975\n",
      "0.0874069\n",
      "0.0874069\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.163978\n",
      "0.163978\n",
      "0.025\n",
      "0.025\n",
      "0.136179\n",
      "0.136179\n",
      "0.053098\n",
      "0.053098\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.070096\n",
      "0.070096\n",
      "0.499233\n",
      "0.499233\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0411216\n",
      "0.0411216\n",
      "0.0509376\n",
      "0.0509376\n",
      "0.767193\n",
      "0.767193\n",
      "0.0306089\n",
      "0.0306089\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.950939\n",
      "0.950939\n",
      "0.025\n",
      "0.025\n",
      "0.176757\n",
      "0.176757\n",
      "0.145225\n",
      "0.145225\n",
      "0.0274093\n",
      "0.0274093\n",
      "0.0814687\n",
      "0.0814687\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0985973\n",
      "0.0985973\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.142624\n",
      "0.142624\n",
      "0.20991\n",
      "0.20991\n",
      "0.347392\n",
      "0.347392\n",
      "0.025\n",
      "0.025\n",
      "0.119105\n",
      "0.119105\n",
      "0.025\n",
      "0.025\n",
      "0.0875457\n",
      "0.0875457\n",
      "0.0470143\n",
      "0.0470143\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.318593\n",
      "0.318593\n",
      "0.0310274\n",
      "0.0310274\n",
      "0.0466496\n",
      "0.0466496\n",
      "0.244804\n",
      "0.244804\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.82949\n",
      "0.82949\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.507321\n",
      "0.507321\n",
      "0.025\n",
      "0.025\n",
      "0.405158\n",
      "0.405158\n",
      "0.306665\n",
      "0.306665\n",
      "0.025\n",
      "0.025\n",
      "0.298127\n",
      "0.298127\n",
      "0.883567\n",
      "0.883567\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0835643\n",
      "0.0835643\n",
      "0.651472\n",
      "0.651472\n",
      "0.477767\n",
      "0.477767\n",
      "0.0918732\n",
      "0.0918732\n",
      "0.329817\n",
      "0.329817\n",
      "0.975\n",
      "0.975\n",
      "0.177897\n",
      "0.177897\n",
      "0.502942\n",
      "0.502942\n",
      "0.0965111\n",
      "0.0965111\n",
      "0.025\n",
      "0.025\n",
      "0.630195\n",
      "0.630195\n",
      "0.400618\n",
      "0.400618\n",
      "0.224544\n",
      "0.224544\n",
      "0.025\n",
      "0.025\n",
      "0.401459\n",
      "0.401459\n",
      "0.369504\n",
      "0.369504\n",
      "0.278289\n",
      "0.278289\n",
      "0.975\n",
      "0.975\n",
      "0.526459\n",
      "0.526459\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0382351\n",
      "0.0382351\n",
      "0.909127\n",
      "0.909127\n",
      "0.025\n",
      "0.025\n",
      "0.231961\n",
      "0.231961\n",
      "0.277954\n",
      "0.277954\n",
      "0.309018\n",
      "0.309018\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0398786\n",
      "0.0398786\n",
      "0.025\n",
      "0.025\n",
      "0.277773\n",
      "0.277773\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0314562\n",
      "0.0314562\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.52669\n",
      "0.52669\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0290161\n",
      "0.0290161\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.942496\n",
      "0.942496\n",
      "0.025\n",
      "0.025\n",
      "0.951383\n",
      "0.951383\n",
      "0.0269003\n",
      "0.0269003\n",
      "0.025\n",
      "0.025\n",
      "0.924757\n",
      "0.924757\n",
      "0.025\n",
      "0.025\n",
      "0.347886\n",
      "0.347886\n",
      "0.843684\n",
      "0.843684\n",
      "0.975\n",
      "0.975\n",
      "0.224374\n",
      "0.224374\n",
      "0.353642\n",
      "0.353642\n",
      "0.025\n",
      "0.025\n",
      "0.131568\n",
      "0.131568\n",
      "0.025\n",
      "0.025\n",
      "0.803599\n",
      "0.803599\n",
      "0.0435528\n",
      "0.0435528\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.690885\n",
      "0.690885\n",
      "0.3525\n",
      "0.3525\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.135509\n",
      "0.135509\n",
      "0.581099\n",
      "0.581099\n",
      "0.441663\n",
      "0.441663\n",
      "0.811231\n",
      "0.811231\n",
      "0.025\n",
      "0.025\n",
      "0.554957\n",
      "0.554957\n",
      "0.639187\n",
      "0.639187\n",
      "0.025\n",
      "0.025\n",
      "0.507339\n",
      "0.507339\n",
      "0.504687\n",
      "0.504687\n",
      "0.025\n",
      "0.025\n",
      "0.438509\n",
      "0.438509\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.424166\n",
      "0.424166\n",
      "0.975\n",
      "0.975\n",
      "0.654323\n",
      "0.654323\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.110614\n",
      "0.110614\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.488293\n",
      "0.488293\n",
      "0.0421163\n",
      "0.0421163\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.177232\n",
      "0.177232\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.36852\n",
      "0.36852\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0305578\n",
      "0.0305578\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.942351\n",
      "0.942351\n",
      "0.975\n",
      "0.975\n",
      "0.41956\n",
      "0.41956\n",
      "0.0431295\n",
      "0.0431295\n",
      "0.0551725\n",
      "0.0551725\n",
      "0.025\n",
      "0.025\n",
      "0.0361746\n",
      "0.0361746\n",
      "0.975\n",
      "0.975\n",
      "0.0677846\n",
      "0.0677846\n",
      "0.312479\n",
      "0.312479\n",
      "0.025\n",
      "0.025\n",
      "0.510255\n",
      "0.510255\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.219357\n",
      "0.219357\n",
      "0.025\n",
      "0.025\n",
      "0.445593\n",
      "0.445593\n",
      "0.0253272\n",
      "0.0253272\n",
      "0.025\n",
      "0.025\n",
      "0.807908\n",
      "0.807908\n",
      "0.916692\n",
      "0.916692\n",
      "0.025\n",
      "0.025\n",
      "0.914394\n",
      "0.914394\n",
      "0.0360742\n",
      "0.0360742\n",
      "0.781854\n",
      "0.781854\n",
      "0.025\n",
      "0.025\n",
      "0.0264309\n",
      "0.0264309\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.912658\n",
      "0.912658\n",
      "0.025\n",
      "0.025\n",
      "0.127885\n",
      "0.127885\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.219231\n",
      "0.219231\n",
      "0.975\n",
      "0.975\n",
      "0.712963\n",
      "0.712963\n",
      "0.025\n",
      "0.025\n",
      "0.956146\n",
      "0.956146\n",
      "0.185915\n",
      "0.185915\n",
      "0.34287\n",
      "0.34287\n",
      "0.025\n",
      "0.025\n",
      "0.218105\n",
      "0.218105\n",
      "0.77423\n",
      "0.77423\n",
      "0.025\n",
      "0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0684632\n",
      "0.0684632\n",
      "0.955185\n",
      "0.955185\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0278371\n",
      "0.0278371\n",
      "0.0295323\n",
      "0.0295323\n",
      "0.025\n",
      "0.025\n",
      "0.0363873\n",
      "0.0363873\n",
      "0.542126\n",
      "0.542126\n",
      "0.975\n",
      "0.975\n",
      "0.187507\n",
      "0.187507\n",
      "0.025\n",
      "0.025\n",
      "0.704664\n",
      "0.704664\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.142045\n",
      "0.142045\n",
      "0.975\n",
      "0.975\n",
      "0.0300607\n",
      "0.0300607\n",
      "0.171726\n",
      "0.171726\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.320183\n",
      "0.320183\n",
      "0.863142\n",
      "0.863142\n",
      "0.380441\n",
      "0.380441\n",
      "0.025\n",
      "0.025\n",
      "0.0333543\n",
      "0.0333543\n",
      "0.025\n",
      "0.025\n",
      "0.946894\n",
      "0.946894\n",
      "0.839975\n",
      "0.839975\n",
      "0.025\n",
      "0.025\n",
      "0.357297\n",
      "0.357297\n",
      "0.025\n",
      "0.025\n",
      "0.224844\n",
      "0.224844\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.11139\n",
      "0.11139\n",
      "0.193684\n",
      "0.193684\n",
      "0.0381595\n",
      "0.0381595\n",
      "0.279878\n",
      "0.279878\n",
      "0.062404\n",
      "0.062404\n",
      "0.751801\n",
      "0.751801\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.973738\n",
      "0.973738\n",
      "0.084786\n",
      "0.084786\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.603614\n",
      "0.603614\n",
      "0.950586\n",
      "0.950586\n",
      "0.025\n",
      "0.025\n",
      "0.358568\n",
      "0.358568\n",
      "0.025\n",
      "0.025\n",
      "0.964985\n",
      "0.964985\n",
      "0.702894\n",
      "0.702894\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.190244\n",
      "0.190244\n",
      "0.697024\n",
      "0.697024\n",
      "0.96876\n",
      "0.96876\n",
      "0.025\n",
      "0.025\n",
      "0.072696\n",
      "0.072696\n",
      "0.025\n",
      "0.025\n",
      "0.222339\n",
      "0.222339\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.230516\n",
      "0.230516\n",
      "0.0651285\n",
      "0.0651285\n",
      "0.786941\n",
      "0.786941\n",
      "0.643883\n",
      "0.643883\n",
      "0.95917\n",
      "0.95917\n",
      "0.26866\n",
      "0.26866\n",
      "0.025\n",
      "0.025\n",
      "0.969457\n",
      "0.969457\n",
      "0.0358548\n",
      "0.0358548\n",
      "0.975\n",
      "0.975\n",
      "0.0474483\n",
      "0.0474483\n",
      "0.585079\n",
      "0.585079\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0255892\n",
      "0.0255892\n",
      "0.36448\n",
      "0.36448\n",
      "0.975\n",
      "0.975\n",
      "0.681236\n",
      "0.681236\n",
      "0.143833\n",
      "0.143833\n",
      "0.919982\n",
      "0.919982\n",
      "0.025\n",
      "0.025\n",
      "0.95154\n",
      "0.95154\n",
      "0.214176\n",
      "0.214176\n",
      "0.025\n",
      "0.025\n",
      "0.108889\n",
      "0.108889\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0605918\n",
      "0.0605918\n",
      "0.975\n",
      "0.975\n",
      "0.0764518\n",
      "0.0764518\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.789695\n",
      "0.789695\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.93576\n",
      "0.93576\n",
      "0.952125\n",
      "0.952125\n",
      "0.975\n",
      "0.975\n",
      "0.956019\n",
      "0.956019\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.249466\n",
      "0.249466\n",
      "0.467142\n",
      "0.467142\n",
      "0.272799\n",
      "0.272799\n",
      "0.0389637\n",
      "0.0389637\n",
      "0.893371\n",
      "0.893371\n",
      "0.225288\n",
      "0.225288\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.469647\n",
      "0.469647\n",
      "0.837819\n",
      "0.837819\n",
      "0.025\n",
      "0.025\n",
      "0.0443416\n",
      "0.0443416\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0445799\n",
      "0.0445799\n",
      "0.025\n",
      "0.025\n",
      "0.189099\n",
      "0.189099\n",
      "0.025\n",
      "0.025\n",
      "0.0547667\n",
      "0.0547667\n",
      "0.0273477\n",
      "0.0273477\n",
      "0.442972\n",
      "0.442972\n",
      "0.427708\n",
      "0.427708\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.359397\n",
      "0.359397\n",
      "0.373089\n",
      "0.373089\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0510367\n",
      "0.0510367\n",
      "0.025\n",
      "0.025\n",
      "0.380534\n",
      "0.380534\n",
      "0.0484616\n",
      "0.0484616\n",
      "0.222484\n",
      "0.222484\n",
      "0.025\n",
      "0.025\n",
      "0.232982\n",
      "0.232982\n",
      "0.025\n",
      "0.025\n",
      "0.0405266\n",
      "0.0405266\n",
      "0.025\n",
      "0.025\n",
      "0.70772\n",
      "0.70772\n",
      "0.0501412\n",
      "0.0501412\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.852433\n",
      "0.852433\n",
      "0.117555\n",
      "0.117555\n",
      "0.025\n",
      "0.025\n",
      "0.0262207\n",
      "0.0262207\n",
      "0.306579\n",
      "0.306579\n",
      "0.118343\n",
      "0.118343\n",
      "0.353167\n",
      "0.353167\n",
      "0.0617379\n",
      "0.0617379\n",
      "0.975\n",
      "0.975\n",
      "0.285478\n",
      "0.285478\n",
      "0.0313348\n",
      "0.0313348\n",
      "0.025\n",
      "0.025\n",
      "0.911831\n",
      "0.911831\n",
      "0.975\n",
      "0.975\n",
      "0.182272\n",
      "0.182272\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.272554\n",
      "0.272554\n",
      "0.025\n",
      "0.025\n",
      "0.184418\n",
      "0.184418\n",
      "0.025\n",
      "0.025\n",
      "0.0826558\n",
      "0.0826558\n",
      "0.025\n",
      "0.025\n",
      "0.340077\n",
      "0.340077\n",
      "0.419232\n",
      "0.419232\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.128774\n",
      "0.128774\n",
      "0.962117\n",
      "0.962117\n",
      "0.025\n",
      "0.025\n",
      "0.818384\n",
      "0.818384\n",
      "0.974494\n",
      "0.974494\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.525655\n",
      "0.525655\n",
      "0.765215\n",
      "0.765215\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.386371\n",
      "0.386371\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.177362\n",
      "0.177362\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.555554\n",
      "0.555554\n",
      "0.025\n",
      "0.025\n",
      "0.0688365\n",
      "0.0688365\n",
      "0.722028\n",
      "0.722028\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.414356\n",
      "0.414356\n",
      "0.0717573\n",
      "0.0717573\n",
      "0.477981\n",
      "0.477981\n",
      "0.855886\n",
      "0.855886\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0461653\n",
      "0.0461653\n",
      "0.025\n",
      "0.025\n",
      "0.860317\n",
      "0.860317\n",
      "0.0970466\n",
      "0.0970466\n",
      "0.500768\n",
      "0.500768\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.26877\n",
      "0.26877\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0400627\n",
      "0.0400627\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0754747\n",
      "0.0754747\n",
      "0.025\n",
      "0.025\n",
      "0.934523\n",
      "0.934523\n",
      "0.025\n",
      "0.025\n",
      "0.703194\n",
      "0.703194\n",
      "0.269829\n",
      "0.269829\n",
      "0.401836\n",
      "0.401836\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.118856\n",
      "0.118856\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.327491\n",
      "0.327491\n",
      "0.950746\n",
      "0.950746\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0274534\n",
      "0.0274534\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.145913\n",
      "0.145913\n",
      "0.025\n",
      "0.025\n",
      "0.0420189\n",
      "0.0420189\n",
      "0.025\n",
      "0.025\n",
      "0.106693\n",
      "0.106693\n",
      "0.082925\n",
      "0.082925\n",
      "0.025\n",
      "0.025\n",
      "0.317932\n",
      "0.317932\n",
      "0.025\n",
      "0.025\n",
      "0.0476677\n",
      "0.0476677\n",
      "0.223468\n",
      "0.223468\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0749036\n",
      "0.0749036\n",
      "0.025\n",
      "0.025\n",
      "0.78374\n",
      "0.78374\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.800654\n",
      "0.800654\n",
      "0.597856\n",
      "0.597856\n",
      "0.0323551\n",
      "0.0323551\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.62478\n",
      "0.62478\n",
      "0.551016\n",
      "0.551016\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.532164\n",
      "0.532164\n",
      "0.056336\n",
      "0.056336\n",
      "0.333275\n",
      "0.333275\n",
      "0.025\n",
      "0.025\n",
      "0.366675\n",
      "0.366675\n",
      "0.975\n",
      "0.975\n",
      "0.140127\n",
      "0.140127\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.705892\n",
      "0.705892\n",
      "0.77702\n",
      "0.77702\n",
      "0.301459\n",
      "0.301459\n",
      "0.025\n",
      "0.025\n",
      "0.0609135\n",
      "0.0609135\n",
      "0.278764\n",
      "0.278764\n",
      "0.666009\n",
      "0.666009\n",
      "0.0762559\n",
      "0.0762559\n",
      "0.971074\n",
      "0.971074\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.420674\n",
      "0.420674\n",
      "0.025\n",
      "0.025\n",
      "0.22466\n",
      "0.22466\n",
      "0.025\n",
      "0.025\n",
      "0.329281\n",
      "0.329281\n",
      "0.025\n",
      "0.025\n",
      "0.853656\n",
      "0.853656\n",
      "0.025037\n",
      "0.025037\n",
      "0.189489\n",
      "0.189489\n",
      "0.0559447\n",
      "0.0559447\n",
      "0.426875\n",
      "0.426875\n",
      "0.025\n",
      "0.025\n",
      "0.125905\n",
      "0.125905\n",
      "0.025\n",
      "0.025\n",
      "0.3086\n",
      "0.3086\n",
      "0.025\n",
      "0.025\n",
      "0.142735\n",
      "0.142735\n",
      "0.32452\n",
      "0.32452\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.165524\n",
      "0.165524\n",
      "0.560893\n",
      "0.560893\n",
      "0.0800835\n",
      "0.0800835\n",
      "0.0258746\n",
      "0.0258746\n",
      "0.215552\n",
      "0.215552\n",
      "0.735038\n",
      "0.735038\n",
      "0.737903\n",
      "0.737903\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.901241\n",
      "0.901241\n",
      "0.0677471\n",
      "0.0677471\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.165771\n",
      "0.165771\n",
      "0.975\n",
      "0.975\n",
      "0.895556\n",
      "0.895556\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0312972\n",
      "0.0312972\n",
      "0.025\n",
      "0.025\n",
      "0.0880655\n",
      "0.0880655\n",
      "0.961797\n",
      "0.961797\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.830794\n",
      "0.830794\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.628935\n",
      "0.628935\n",
      "0.0465149\n",
      "0.0465149\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0838935\n",
      "0.0838935\n",
      "0.357\n",
      "0.357\n",
      "0.0705573\n",
      "0.0705573\n",
      "0.025\n",
      "0.025\n",
      "0.256211\n",
      "0.256211\n",
      "0.025\n",
      "0.025\n",
      "0.737833\n",
      "0.737833\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0633359\n",
      "0.0633359\n",
      "0.134487\n",
      "0.134487\n",
      "0.0743221\n",
      "0.0743221\n",
      "0.025\n",
      "0.025\n",
      "0.4784\n",
      "0.4784\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.151456\n",
      "0.151456\n",
      "0.108574\n",
      "0.108574\n",
      "0.583687\n",
      "0.583687\n",
      "0.167327\n",
      "0.167327\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.524961\n",
      "0.524961\n",
      "0.0468663\n",
      "0.0468663\n",
      "0.0929866\n",
      "0.0929866\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0657189\n",
      "0.0657189\n",
      "0.339388\n",
      "0.339388\n",
      "0.130414\n",
      "0.130414\n",
      "0.025\n",
      "0.025\n",
      "0.0978297\n",
      "0.0978297\n",
      "0.0587398\n",
      "0.0587398\n",
      "0.025\n",
      "0.025\n",
      "0.0653516\n",
      "0.0653516\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0323356\n",
      "0.0323356\n",
      "0.0416976\n",
      "0.0416976\n",
      "0.025\n",
      "0.025\n",
      "0.132698\n",
      "0.132698\n",
      "0.025\n",
      "0.025\n",
      "0.0291634\n",
      "0.0291634\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0614354\n",
      "0.0614354\n",
      "0.975\n",
      "0.975\n",
      "0.0996928\n",
      "0.0996928\n",
      "0.324185\n",
      "0.324185\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.266129\n",
      "0.266129\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.3065\n",
      "0.3065\n",
      "0.025\n",
      "0.025\n",
      "0.513139\n",
      "0.513139\n",
      "0.605374\n",
      "0.605374\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0722742\n",
      "0.0722742\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.131189\n",
      "0.131189\n",
      "0.0266229\n",
      "0.0266229\n",
      "0.867626\n",
      "0.867626\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.188132\n",
      "0.188132\n",
      "0.330967\n",
      "0.330967\n",
      "0.025\n",
      "0.025\n",
      "0.0268835\n",
      "0.0268835\n",
      "0.975\n",
      "0.975\n",
      "0.0468247\n",
      "0.0468247\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.576008\n",
      "0.576008\n",
      "0.025\n",
      "0.025\n",
      "0.0695089\n",
      "0.0695089\n",
      "0.684866\n",
      "0.684866\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.712892\n",
      "0.712892\n",
      "0.771509\n",
      "0.771509\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.932317\n",
      "0.932317\n",
      "0.857705\n",
      "0.857705\n",
      "0.0250005\n",
      "0.0250005\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0258585\n",
      "0.0258585\n",
      "0.959015\n",
      "0.959015\n",
      "0.905209\n",
      "0.905209\n",
      "0.44788\n",
      "0.44788\n",
      "0.0661614\n",
      "0.0661614\n",
      "0.0433548\n",
      "0.0433548\n",
      "0.025\n",
      "0.025\n",
      "0.782924\n",
      "0.782924\n",
      "0.184979\n",
      "0.184979\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0686216\n",
      "0.0686216\n",
      "0.975\n",
      "0.975\n",
      "0.308334\n",
      "0.308334\n",
      "0.275126\n",
      "0.275126\n",
      "0.975\n",
      "0.975\n",
      "0.398844\n",
      "0.398844\n",
      "0.025\n",
      "0.025\n",
      "0.502374\n",
      "0.502374\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.535233\n",
      "0.535233\n",
      "0.025\n",
      "0.025\n",
      "0.38507\n",
      "0.38507\n",
      "0.288833\n",
      "0.288833\n",
      "0.727046\n",
      "0.727046\n",
      "0.0593317\n",
      "0.0593317\n",
      "0.025\n",
      "0.025\n",
      "0.0368682\n",
      "0.0368682\n",
      "0.138797\n",
      "0.138797\n",
      "0.025\n",
      "0.025\n",
      "0.028141\n",
      "0.028141\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0437282\n",
      "0.0437282\n",
      "0.395485\n",
      "0.395485\n",
      "0.0522516\n",
      "0.0522516\n",
      "0.025\n",
      "0.025\n",
      "0.307127\n",
      "0.307127\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.855193\n",
      "0.855193\n",
      "0.271333\n",
      "0.271333\n",
      "0.973002\n",
      "0.973002\n",
      "0.080866\n",
      "0.080866\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.207413\n",
      "0.207413\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0565451\n",
      "0.0565451\n",
      "0.705664\n",
      "0.705664\n",
      "0.975\n",
      "0.975\n",
      "0.0515103\n",
      "0.0515103\n",
      "0.975\n",
      "0.975\n",
      "0.0898166\n",
      "0.0898166\n",
      "0.0871646\n",
      "0.0871646\n",
      "0.871556\n",
      "0.871556\n",
      "0.0530683\n",
      "0.0530683\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.659665\n",
      "0.659665\n",
      "0.280387\n",
      "0.280387\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.48926\n",
      "0.48926\n",
      "0.025\n",
      "0.025\n",
      "0.0261614\n",
      "0.0261614\n",
      "0.025\n",
      "0.025\n",
      "0.0302518\n",
      "0.0302518\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.953716\n",
      "0.953716\n",
      "0.154359\n",
      "0.154359\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.37888\n",
      "0.37888\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.3403\n",
      "0.3403\n",
      "0.583481\n",
      "0.583481\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0278654\n",
      "0.0278654\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.124978\n",
      "0.124978\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.567094\n",
      "0.567094\n",
      "0.975\n",
      "0.975\n",
      "0.755085\n",
      "0.755085\n",
      "0.025\n",
      "0.025\n",
      "0.0764481\n",
      "0.0764481\n",
      "0.897545\n",
      "0.897545\n",
      "0.025\n",
      "0.025\n",
      "0.0919403\n",
      "0.0919403\n",
      "0.523993\n",
      "0.523993\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0267759\n",
      "0.0267759\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.938181\n",
      "0.938181\n",
      "0.025\n",
      "0.025\n",
      "0.0965402\n",
      "0.0965402\n",
      "0.975\n",
      "0.975\n",
      "0.829725\n",
      "0.829725\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0864505\n",
      "0.0864505\n",
      "0.0479602\n",
      "0.0479602\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.957458\n",
      "0.957458\n",
      "0.025\n",
      "0.025\n",
      "0.432378\n",
      "0.432378\n",
      "0.127842\n",
      "0.127842\n",
      "0.0588714\n",
      "0.0588714\n",
      "0.107514\n",
      "0.107514\n",
      "0.12055\n",
      "0.12055\n",
      "0.538247\n",
      "0.538247\n",
      "0.975\n",
      "0.975\n",
      "0.0573549\n",
      "0.0573549\n",
      "0.215154\n",
      "0.215154\n",
      "0.025\n",
      "0.025\n",
      "0.143137\n",
      "0.143137\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.656851\n",
      "0.656851\n",
      "0.025\n",
      "0.025\n",
      "0.724142\n",
      "0.724142\n",
      "0.025\n",
      "0.025\n",
      "0.0670848\n",
      "0.0670848\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.789721\n",
      "0.789721\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.139816\n",
      "0.139816\n",
      "0.227152\n",
      "0.227152\n",
      "0.025\n",
      "0.025\n",
      "0.789458\n",
      "0.789458\n",
      "0.960795\n",
      "0.960795\n",
      "0.027148\n",
      "0.027148\n",
      "0.158883\n",
      "0.158883\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0691558\n",
      "0.0691558\n",
      "0.975\n",
      "0.975\n",
      "0.231985\n",
      "0.231985\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.963994\n",
      "0.963994\n",
      "0.15599\n",
      "0.15599\n",
      "0.129372\n",
      "0.129372\n",
      "0.0268084\n",
      "0.0268084\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0987436\n",
      "0.0987436\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0633354\n",
      "0.0633354\n",
      "0.025\n",
      "0.025\n",
      "0.0467232\n",
      "0.0467232\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.429104\n",
      "0.429104\n",
      "0.356726\n",
      "0.356726\n",
      "0.150102\n",
      "0.150102\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.933293\n",
      "0.933293\n",
      "0.86215\n",
      "0.86215\n",
      "0.1964\n",
      "0.1964\n",
      "0.025\n",
      "0.025\n",
      "0.871948\n",
      "0.871948\n",
      "0.025\n",
      "0.025\n",
      "0.951334\n",
      "0.951334\n",
      "0.025\n",
      "0.025\n",
      "0.0580763\n",
      "0.0580763\n",
      "0.957568\n",
      "0.957568\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.535726\n",
      "0.535726\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.526351\n",
      "0.526351\n",
      "0.613604\n",
      "0.613604\n",
      "0.025\n",
      "0.025\n",
      "0.0558523\n",
      "0.0558523\n",
      "0.025\n",
      "0.025\n",
      "0.490753\n",
      "0.490753\n",
      "0.968985\n",
      "0.968985\n",
      "0.11436\n",
      "0.11436\n",
      "0.0275856\n",
      "0.0275856\n",
      "0.0533504\n",
      "0.0533504\n",
      "0.025\n",
      "0.025\n",
      "0.271552\n",
      "0.271552\n",
      "0.938524\n",
      "0.938524\n",
      "0.681947\n",
      "0.681947\n",
      "0.325564\n",
      "0.325564\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0311574\n",
      "0.0311574\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.965513\n",
      "0.965513\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.122965\n",
      "0.122965\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.934736\n",
      "0.934736\n",
      "0.0827202\n",
      "0.0827202\n",
      "0.157526\n",
      "0.157526\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.25491\n",
      "0.25491\n",
      "0.97413\n",
      "0.97413\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.610483\n",
      "0.610483\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.81174\n",
      "0.81174\n",
      "0.461784\n",
      "0.461784\n",
      "0.0377598\n",
      "0.0377598\n",
      "0.472292\n",
      "0.472292\n",
      "0.134198\n",
      "0.134198\n",
      "0.157534\n",
      "0.157534\n",
      "0.120309\n",
      "0.120309\n",
      "0.112974\n",
      "0.112974\n",
      "0.0901276\n",
      "0.0901276\n",
      "0.0433963\n",
      "0.0433963\n",
      "0.025\n",
      "0.025\n",
      "0.688457\n",
      "0.688457\n",
      "0.025\n",
      "0.025\n",
      "0.0776349\n",
      "0.0776349\n",
      "0.103108\n",
      "0.103108\n",
      "0.081968\n",
      "0.081968\n",
      "0.848386\n",
      "0.848386\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.800885\n",
      "0.800885\n",
      "0.025\n",
      "0.025\n",
      "0.3816\n",
      "0.3816\n",
      "0.842479\n",
      "0.842479\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.272951\n",
      "0.272951\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.140105\n",
      "0.140105\n",
      "0.281599\n",
      "0.281599\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.628978\n",
      "0.628978\n",
      "0.0671523\n",
      "0.0671523\n",
      "0.126032\n",
      "0.126032\n",
      "0.025\n",
      "0.025\n",
      "0.0390991\n",
      "0.0390991\n",
      "0.0455839\n",
      "0.0455839\n",
      "0.368903\n",
      "0.368903\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.96749\n",
      "0.96749\n",
      "0.910907\n",
      "0.910907\n",
      "0.165664\n",
      "0.165664\n",
      "0.025\n",
      "0.025\n",
      "0.432613\n",
      "0.432613\n",
      "0.895918\n",
      "0.895918\n",
      "0.798422\n",
      "0.798422\n",
      "0.0463021\n",
      "0.0463021\n",
      "0.025\n",
      "0.025\n",
      "0.336488\n",
      "0.336488\n",
      "0.917697\n",
      "0.917697\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.918215\n",
      "0.918215\n",
      "0.025\n",
      "0.025\n",
      "0.0265147\n",
      "0.0265147\n",
      "0.975\n",
      "0.975\n",
      "0.218386\n",
      "0.218386\n",
      "0.173513\n",
      "0.173513\n",
      "0.0257678\n",
      "0.0257678\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.972991\n",
      "0.972991\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.960248\n",
      "0.960248\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0496636\n",
      "0.0496636\n",
      "0.107655\n",
      "0.107655\n",
      "0.0395381\n",
      "0.0395381\n",
      "0.975\n",
      "0.975\n",
      "0.495289\n",
      "0.495289\n",
      "0.0310487\n",
      "0.0310487\n",
      "0.025\n",
      "0.025\n",
      "0.454072\n",
      "0.454072\n",
      "0.025\n",
      "0.025\n",
      "0.154986\n",
      "0.154986\n",
      "0.975\n",
      "0.975\n",
      "0.212067\n",
      "0.212067\n",
      "0.025\n",
      "0.025\n",
      "0.161097\n",
      "0.161097\n",
      "0.255762\n",
      "0.255762\n",
      "0.581743\n",
      "0.581743\n",
      "0.0633601\n",
      "0.0633601\n",
      "0.325587\n",
      "0.325587\n",
      "0.13083\n",
      "0.13083\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.172398\n",
      "0.172398\n",
      "0.895316\n",
      "0.895316\n",
      "0.945384\n",
      "0.945384\n",
      "0.025\n",
      "0.025\n",
      "0.0255775\n",
      "0.0255775\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.48502\n",
      "0.48502\n",
      "0.0521885\n",
      "0.0521885\n",
      "0.025\n",
      "0.025\n",
      "0.456827\n",
      "0.456827\n",
      "0.025\n",
      "0.025\n",
      "0.786471\n",
      "0.786471\n",
      "0.025\n",
      "0.025\n",
      "0.32065\n",
      "0.32065\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0550592\n",
      "0.0550592\n",
      "0.0399127\n",
      "0.0399127\n",
      "0.975\n",
      "0.975\n",
      "0.343845\n",
      "0.343845\n",
      "0.025\n",
      "0.025\n",
      "0.931919\n",
      "0.931919\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.836716\n",
      "0.836716\n",
      "0.14007\n",
      "0.14007\n",
      "0.025\n",
      "0.025\n",
      "0.224401\n",
      "0.224401\n",
      "0.0674277\n",
      "0.0674277\n",
      "0.025\n",
      "0.025\n",
      "0.251958\n",
      "0.251958\n",
      "0.0664579\n",
      "0.0664579\n",
      "0.481094\n",
      "0.481094\n",
      "0.960713\n",
      "0.960713\n",
      "0.0305288\n",
      "0.0305288\n",
      "0.443365\n",
      "0.443365\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.942358\n",
      "0.942358\n",
      "0.025\n",
      "0.025\n",
      "0.0657044\n",
      "0.0657044\n",
      "0.0940823\n",
      "0.0940823\n",
      "0.025\n",
      "0.025\n",
      "0.335483\n",
      "0.335483\n",
      "0.958135\n",
      "0.958135\n",
      "0.0371299\n",
      "0.0371299\n",
      "0.025\n",
      "0.025\n",
      "0.352224\n",
      "0.352224\n",
      "0.759785\n",
      "0.759785\n",
      "0.0975117\n",
      "0.0975117\n",
      "0.0976509\n",
      "0.0976509\n",
      "0.025\n",
      "0.025\n",
      "0.0466179\n",
      "0.0466179\n",
      "0.825747\n",
      "0.825747\n",
      "0.025\n",
      "0.025\n",
      "0.960886\n",
      "0.960886\n",
      "0.535321\n",
      "0.535321\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0831487\n",
      "0.0831487\n",
      "0.025\n",
      "0.025\n",
      "0.374806\n",
      "0.374806\n",
      "0.025\n",
      "0.025\n",
      "0.0402253\n",
      "0.0402253\n",
      "0.025\n",
      "0.025\n",
      "0.0553791\n",
      "0.0553791\n",
      "0.025\n",
      "0.025\n",
      "0.203587\n",
      "0.203587\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.593752\n",
      "0.593752\n",
      "0.025\n",
      "0.025\n",
      "0.0259421\n",
      "0.0259421\n",
      "0.025\n",
      "0.025\n",
      "0.850308\n",
      "0.850308\n",
      "0.975\n",
      "0.975\n",
      "0.0655747\n",
      "0.0655747\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0801758\n",
      "0.0801758\n",
      "0.0257494\n",
      "0.0257494\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0455244\n",
      "0.0455244\n",
      "0.025\n",
      "0.025\n",
      "0.115827\n",
      "0.115827\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.671658\n",
      "0.671658\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.140968\n",
      "0.140968\n",
      "0.973795\n",
      "0.973795\n",
      "0.0358458\n",
      "0.0358458\n",
      "0.866122\n",
      "0.866122\n",
      "0.0596341\n",
      "0.0596341\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.909849\n",
      "0.909849\n",
      "0.0284496\n",
      "0.0284496\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.80944\n",
      "0.80944\n",
      "0.0313271\n",
      "0.0313271\n",
      "0.025\n",
      "0.025\n",
      "0.202317\n",
      "0.202317\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.958478\n",
      "0.958478\n",
      "0.025\n",
      "0.025\n",
      "0.0905641\n",
      "0.0905641\n",
      "0.115826\n",
      "0.115826\n",
      "0.187598\n",
      "0.187598\n",
      "0.966436\n",
      "0.966436\n",
      "0.025\n",
      "0.025\n",
      "0.528948\n",
      "0.528948\n",
      "0.435338\n",
      "0.435338\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.038716\n",
      "0.038716\n",
      "0.0283049\n",
      "0.0283049\n",
      "0.942304\n",
      "0.942304\n",
      "0.025\n",
      "0.025\n",
      "0.895536\n",
      "0.895536\n",
      "0.793792\n",
      "0.793792\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0262231\n",
      "0.0262231\n",
      "0.025\n",
      "0.025\n",
      "0.180318\n",
      "0.180318\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0944979\n",
      "0.0944979\n",
      "0.975\n",
      "0.975\n",
      "0.95909\n",
      "0.95909\n",
      "0.141475\n",
      "0.141475\n",
      "0.025\n",
      "0.025\n",
      "0.031335\n",
      "0.031335\n",
      "0.025\n",
      "0.025\n",
      "0.261105\n",
      "0.261105\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.269556\n",
      "0.269556\n",
      "0.770163\n",
      "0.770163\n",
      "0.025\n",
      "0.025\n",
      "0.829886\n",
      "0.829886\n",
      "0.975\n",
      "0.975\n",
      "0.205742\n",
      "0.205742\n",
      "0.025\n",
      "0.025\n",
      "0.0374521\n",
      "0.0374521\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0524365\n",
      "0.0524365\n",
      "0.177615\n",
      "0.177615\n",
      "0.303049\n",
      "0.303049\n",
      "0.287757\n",
      "0.287757\n",
      "0.856942\n",
      "0.856942\n",
      "0.763129\n",
      "0.763129\n",
      "0.67287\n",
      "0.67287\n",
      "0.372288\n",
      "0.372288\n",
      "0.197844\n",
      "0.197844\n",
      "0.154401\n",
      "0.154401\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.270662\n",
      "0.270662\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.384926\n",
      "0.384926\n",
      "0.718604\n",
      "0.718604\n",
      "0.0979457\n",
      "0.0979457\n",
      "0.0583476\n",
      "0.0583476\n",
      "0.324023\n",
      "0.324023\n",
      "0.283871\n",
      "0.283871\n",
      "0.025\n",
      "0.025\n",
      "0.11419\n",
      "0.11419\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.341825\n",
      "0.341825\n",
      "0.110077\n",
      "0.110077\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.259003\n",
      "0.259003\n",
      "0.025\n",
      "0.025\n",
      "0.0474012\n",
      "0.0474012\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.618813\n",
      "0.618813\n",
      "0.0589061\n",
      "0.0589061\n",
      "0.488758\n",
      "0.488758\n",
      "0.025\n",
      "0.025\n",
      "0.0469092\n",
      "0.0469092\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.871896\n",
      "0.871896\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.10969\n",
      "0.10969\n",
      "0.025\n",
      "0.025\n",
      "0.0499955\n",
      "0.0499955\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.179519\n",
      "0.179519\n",
      "0.508498\n",
      "0.508498\n",
      "0.214736\n",
      "0.214736\n",
      "0.137213\n",
      "0.137213\n",
      "0.142417\n",
      "0.142417\n",
      "0.975\n",
      "0.975\n",
      "0.139654\n",
      "0.139654\n",
      "0.282122\n",
      "0.282122\n",
      "0.025\n",
      "0.025\n",
      "0.137926\n",
      "0.137926\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.845525\n",
      "0.845525\n",
      "0.558343\n",
      "0.558343\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.47788\n",
      "0.47788\n",
      "0.939976\n",
      "0.939976\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.10234\n",
      "0.10234\n",
      "0.025\n",
      "0.025\n",
      "0.797538\n",
      "0.797538\n",
      "0.549516\n",
      "0.549516\n",
      "0.025\n",
      "0.025\n",
      "0.185313\n",
      "0.185313\n",
      "0.025\n",
      "0.025\n",
      "0.0399893\n",
      "0.0399893\n",
      "0.0270336\n",
      "0.0270336\n",
      "0.189205\n",
      "0.189205\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0611997\n",
      "0.0611997\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.972471\n",
      "0.972471\n",
      "0.975\n",
      "0.975\n",
      "0.0771207\n",
      "0.0771207\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.863792\n",
      "0.863792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0770904\n",
      "0.0770904\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.503511\n",
      "0.503511\n",
      "0.937978\n",
      "0.937978\n",
      "0.337163\n",
      "0.337163\n",
      "0.0597975\n",
      "0.0597975\n",
      "0.685398\n",
      "0.685398\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.218216\n",
      "0.218216\n",
      "0.444544\n",
      "0.444544\n",
      "0.0323253\n",
      "0.0323253\n",
      "0.975\n",
      "0.975\n",
      "0.222656\n",
      "0.222656\n",
      "0.0361735\n",
      "0.0361735\n",
      "0.871895\n",
      "0.871895\n",
      "0.974748\n",
      "0.974748\n",
      "0.150898\n",
      "0.150898\n",
      "0.397852\n",
      "0.397852\n",
      "0.975\n",
      "0.975\n",
      "0.124952\n",
      "0.124952\n",
      "0.198408\n",
      "0.198408\n",
      "0.025\n",
      "0.025\n",
      "0.0814909\n",
      "0.0814909\n",
      "0.955749\n",
      "0.955749\n",
      "0.478331\n",
      "0.478331\n",
      "0.975\n",
      "0.975\n",
      "0.036044\n",
      "0.036044\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.46121\n",
      "0.46121\n",
      "0.12385\n",
      "0.12385\n",
      "0.025\n",
      "0.025\n",
      "0.16372\n",
      "0.16372\n",
      "0.025\n",
      "0.025\n",
      "0.0449038\n",
      "0.0449038\n",
      "0.975\n",
      "0.975\n",
      "0.860858\n",
      "0.860858\n",
      "0.101663\n",
      "0.101663\n",
      "0.0664645\n",
      "0.0664645\n",
      "0.0355116\n",
      "0.0355116\n",
      "0.025\n",
      "0.025\n",
      "0.035743\n",
      "0.035743\n",
      "0.949917\n",
      "0.949917\n",
      "0.0510591\n",
      "0.0510591\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.124609\n",
      "0.124609\n",
      "0.025\n",
      "0.025\n",
      "0.538973\n",
      "0.538973\n",
      "0.0363512\n",
      "0.0363512\n",
      "0.025\n",
      "0.025\n",
      "0.206855\n",
      "0.206855\n",
      "0.278488\n",
      "0.278488\n",
      "0.025\n",
      "0.025\n",
      "0.051896\n",
      "0.051896\n",
      "0.975\n",
      "0.975\n",
      "0.0492997\n",
      "0.0492997\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0266379\n",
      "0.0266379\n",
      "0.310162\n",
      "0.310162\n",
      "0.025\n",
      "0.025\n",
      "0.24828\n",
      "0.24828\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.218591\n",
      "0.218591\n",
      "0.293253\n",
      "0.293253\n",
      "0.975\n",
      "0.975\n",
      "0.316063\n",
      "0.316063\n",
      "0.0341562\n",
      "0.0341562\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.501424\n",
      "0.501424\n",
      "0.025\n",
      "0.025\n",
      "0.963329\n",
      "0.963329\n",
      "0.0614849\n",
      "0.0614849\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.927054\n",
      "0.927054\n",
      "0.0330891\n",
      "0.0330891\n",
      "0.025\n",
      "0.025\n",
      "0.961557\n",
      "0.961557\n",
      "0.82883\n",
      "0.82883\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0993462\n",
      "0.0993462\n",
      "0.025\n",
      "0.025\n",
      "0.666293\n",
      "0.666293\n",
      "0.828461\n",
      "0.828461\n",
      "0.025\n",
      "0.025\n",
      "0.414342\n",
      "0.414342\n",
      "0.401778\n",
      "0.401778\n",
      "0.025\n",
      "0.025\n",
      "0.0454835\n",
      "0.0454835\n",
      "0.823836\n",
      "0.823836\n",
      "0.334546\n",
      "0.334546\n",
      "0.025\n",
      "0.025\n",
      "0.26109\n",
      "0.26109\n",
      "0.0868084\n",
      "0.0868084\n",
      "0.925557\n",
      "0.925557\n",
      "0.025\n",
      "0.025\n",
      "0.157003\n",
      "0.157003\n",
      "0.063991\n",
      "0.063991\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.231507\n",
      "0.231507\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.917524\n",
      "0.917524\n",
      "0.0952478\n",
      "0.0952478\n",
      "0.0338185\n",
      "0.0338185\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0565141\n",
      "0.0565141\n",
      "0.025\n",
      "0.025\n",
      "0.241093\n",
      "0.241093\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.122177\n",
      "0.122177\n",
      "0.109996\n",
      "0.109996\n",
      "0.975\n",
      "0.975\n",
      "0.293681\n",
      "0.293681\n",
      "0.025\n",
      "0.025\n",
      "0.918366\n",
      "0.918366\n",
      "0.464912\n",
      "0.464912\n",
      "0.236134\n",
      "0.236134\n",
      "0.025\n",
      "0.025\n",
      "0.0873471\n",
      "0.0873471\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.105925\n",
      "0.105925\n",
      "0.975\n",
      "0.975\n",
      "0.972623\n",
      "0.972623\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.500781\n",
      "0.500781\n",
      "0.025\n",
      "0.025\n",
      "0.640068\n",
      "0.640068\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0351162\n",
      "0.0351162\n",
      "0.975\n",
      "0.975\n",
      "0.323243\n",
      "0.323243\n",
      "0.287449\n",
      "0.287449\n",
      "0.910494\n",
      "0.910494\n",
      "0.975\n",
      "0.975\n",
      "0.046468\n",
      "0.046468\n",
      "0.025\n",
      "0.025\n",
      "0.228073\n",
      "0.228073\n",
      "0.145321\n",
      "0.145321\n",
      "0.70025\n",
      "0.70025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.219802\n",
      "0.219802\n",
      "0.025\n",
      "0.025\n",
      "0.0704161\n",
      "0.0704161\n",
      "0.13348\n",
      "0.13348\n",
      "0.975\n",
      "0.975\n",
      "0.428605\n",
      "0.428605\n",
      "0.969706\n",
      "0.969706\n",
      "0.296337\n",
      "0.296337\n",
      "0.959355\n",
      "0.959355\n",
      "0.648231\n",
      "0.648231\n",
      "0.025\n",
      "0.025\n",
      "0.0834995\n",
      "0.0834995\n",
      "0.025\n",
      "0.025\n",
      "0.293101\n",
      "0.293101\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.502008\n",
      "0.502008\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.113381\n",
      "0.113381\n",
      "0.0274471\n",
      "0.0274471\n",
      "0.843331\n",
      "0.843331\n",
      "0.754963\n",
      "0.754963\n",
      "0.0263786\n",
      "0.0263786\n",
      "0.025\n",
      "0.025\n",
      "0.254091\n",
      "0.254091\n",
      "0.847039\n",
      "0.847039\n",
      "0.0853182\n",
      "0.0853182\n",
      "0.0612632\n",
      "0.0612632\n",
      "0.025\n",
      "0.025\n",
      "0.0393931\n",
      "0.0393931\n",
      "0.907327\n",
      "0.907327\n",
      "0.0998108\n",
      "0.0998108\n",
      "0.86027\n",
      "0.86027\n",
      "0.025\n",
      "0.025\n",
      "0.0271691\n",
      "0.0271691\n",
      "0.863551\n",
      "0.863551\n",
      "0.843593\n",
      "0.843593\n",
      "0.033898\n",
      "0.033898\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.618313\n",
      "0.618313\n",
      "0.472178\n",
      "0.472178\n",
      "0.0676753\n",
      "0.0676753\n",
      "0.0556616\n",
      "0.0556616\n",
      "0.975\n",
      "0.975\n",
      "0.0319413\n",
      "0.0319413\n",
      "0.975\n",
      "0.975\n",
      "0.851272\n",
      "0.851272\n",
      "0.242811\n",
      "0.242811\n",
      "0.934822\n",
      "0.934822\n",
      "0.181196\n",
      "0.181196\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.874738\n",
      "0.874738\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.207247\n",
      "0.207247\n",
      "0.025\n",
      "0.025\n",
      "0.972983\n",
      "0.972983\n",
      "0.202445\n",
      "0.202445\n",
      "0.772725\n",
      "0.772725\n",
      "0.965642\n",
      "0.965642\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.347498\n",
      "0.347498\n",
      "0.032868\n",
      "0.032868\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.452161\n",
      "0.452161\n",
      "0.0971501\n",
      "0.0971501\n",
      "0.104715\n",
      "0.104715\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0898292\n",
      "0.0898292\n",
      "0.873403\n",
      "0.873403\n",
      "0.174787\n",
      "0.174787\n",
      "0.0969987\n",
      "0.0969987\n",
      "0.025\n",
      "0.025\n",
      "0.424577\n",
      "0.424577\n",
      "0.152834\n",
      "0.152834\n",
      "0.0344852\n",
      "0.0344852\n",
      "0.163163\n",
      "0.163163\n",
      "0.0298843\n",
      "0.0298843\n",
      "0.618712\n",
      "0.618712\n",
      "0.718216\n",
      "0.718216\n",
      "0.025\n",
      "0.025\n",
      "0.124564\n",
      "0.124564\n",
      "0.745993\n",
      "0.745993\n",
      "0.975\n",
      "0.975\n",
      "0.960882\n",
      "0.960882\n",
      "0.685959\n",
      "0.685959\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.150962\n",
      "0.150962\n",
      "0.025\n",
      "0.025\n",
      "0.795279\n",
      "0.795279\n",
      "0.778039\n",
      "0.778039\n",
      "0.647695\n",
      "0.647695\n",
      "0.975\n",
      "0.975\n",
      "0.527155\n",
      "0.527155\n",
      "0.201481\n",
      "0.201481\n",
      "0.122725\n",
      "0.122725\n",
      "0.224514\n",
      "0.224514\n",
      "0.0839743\n",
      "0.0839743\n",
      "0.959622\n",
      "0.959622\n",
      "0.025\n",
      "0.025\n",
      "0.0281508\n",
      "0.0281508\n",
      "0.599519\n",
      "0.599519\n",
      "0.123182\n",
      "0.123182\n",
      "0.0635789\n",
      "0.0635789\n",
      "0.975\n",
      "0.975\n",
      "0.101594\n",
      "0.101594\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0360799\n",
      "0.0360799\n",
      "0.975\n",
      "0.975\n",
      "0.0777357\n",
      "0.0777357\n",
      "0.025\n",
      "0.025\n",
      "0.0415064\n",
      "0.0415064\n",
      "0.513398\n",
      "0.513398\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0530081\n",
      "0.0530081\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.586106\n",
      "0.586106\n",
      "0.089939\n",
      "0.089939\n",
      "0.203415\n",
      "0.203415\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.043306\n",
      "0.043306\n",
      "0.0460692\n",
      "0.0460692\n",
      "0.219456\n",
      "0.219456\n",
      "0.0263467\n",
      "0.0263467\n",
      "0.0724213\n",
      "0.0724213\n",
      "0.0386059\n",
      "0.0386059\n",
      "0.025\n",
      "0.025\n",
      "0.395058\n",
      "0.395058\n",
      "0.975\n",
      "0.975\n",
      "0.944706\n",
      "0.944706\n",
      "0.025\n",
      "0.025\n",
      "0.265966\n",
      "0.265966\n",
      "0.025\n",
      "0.025\n",
      "0.0353683\n",
      "0.0353683\n",
      "0.975\n",
      "0.975\n",
      "0.0495605\n",
      "0.0495605\n",
      "0.534973\n",
      "0.534973\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0362426\n",
      "0.0362426\n",
      "0.025\n",
      "0.025\n",
      "0.900764\n",
      "0.900764\n",
      "0.309174\n",
      "0.309174\n",
      "0.0734751\n",
      "0.0734751\n",
      "0.025\n",
      "0.025\n",
      "0.15087\n",
      "0.15087\n",
      "0.143585\n",
      "0.143585\n",
      "0.025\n",
      "0.025\n",
      "0.0567882\n",
      "0.0567882\n",
      "0.408838\n",
      "0.408838\n",
      "0.0989495\n",
      "0.0989495\n",
      "0.536819\n",
      "0.536819\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.568415\n",
      "0.568415\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.111304\n",
      "0.111304\n",
      "0.975\n",
      "0.975\n",
      "0.917421\n",
      "0.917421\n",
      "0.0493676\n",
      "0.0493676\n",
      "0.560791\n",
      "0.560791\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0317574\n",
      "0.0317574\n",
      "0.898859\n",
      "0.898859\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.193954\n",
      "0.193954\n",
      "0.025\n",
      "0.025\n",
      "0.322369\n",
      "0.322369\n",
      "0.025\n",
      "0.025\n",
      "0.128273\n",
      "0.128273\n",
      "0.0784413\n",
      "0.0784413\n",
      "0.441431\n",
      "0.441431\n",
      "0.975\n",
      "0.975\n",
      "0.0561619\n",
      "0.0561619\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.311771\n",
      "0.311771\n",
      "0.729807\n",
      "0.729807\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0700053\n",
      "0.0700053\n",
      "0.0762864\n",
      "0.0762864\n",
      "0.578847\n",
      "0.578847\n",
      "0.0331779\n",
      "0.0331779\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.205052\n",
      "0.205052\n",
      "0.272909\n",
      "0.272909\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.927979\n",
      "0.927979\n",
      "0.0911887\n",
      "0.0911887\n",
      "0.734376\n",
      "0.734376\n",
      "0.0718736\n",
      "0.0718736\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.946223\n",
      "0.946223\n",
      "0.516436\n",
      "0.516436\n",
      "0.453152\n",
      "0.453152\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.771076\n",
      "0.771076\n",
      "0.975\n",
      "0.975\n",
      "0.09346\n",
      "0.09346\n",
      "0.90794\n",
      "0.90794\n",
      "0.025\n",
      "0.025\n",
      "0.833598\n",
      "0.833598\n",
      "0.0401968\n",
      "0.0401968\n",
      "0.553608\n",
      "0.553608\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.174285\n",
      "0.174285\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.945423\n",
      "0.945423\n",
      "0.205692\n",
      "0.205692\n",
      "0.379539\n",
      "0.379539\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.352196\n",
      "0.352196\n",
      "0.025\n",
      "0.025\n",
      "0.0515923\n",
      "0.0515923\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0918512\n",
      "0.0918512\n",
      "0.969091\n",
      "0.969091\n",
      "0.712254\n",
      "0.712254\n",
      "0.559731\n",
      "0.559731\n",
      "0.047569\n",
      "0.047569\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.087023\n",
      "0.087023\n",
      "0.892282\n",
      "0.892282\n",
      "0.975\n",
      "0.975\n",
      "0.499653\n",
      "0.499653\n",
      "0.025\n",
      "0.025\n",
      "0.025507\n",
      "0.025507\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.388474\n",
      "0.388474\n",
      "0.240783\n",
      "0.240783\n",
      "0.975\n",
      "0.975\n",
      "0.797248\n",
      "0.797248\n",
      "0.025\n",
      "0.025\n",
      "0.462373\n",
      "0.462373\n",
      "0.975\n",
      "0.975\n",
      "0.0703594\n",
      "0.0703594\n",
      "0.025\n",
      "0.025\n",
      "0.519517\n",
      "0.519517\n",
      "0.482175\n",
      "0.482175\n",
      "0.0963517\n",
      "0.0963517\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.559074\n",
      "0.559074\n",
      "0.258353\n",
      "0.258353\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.546587\n",
      "0.546587\n",
      "0.147049\n",
      "0.147049\n",
      "0.025\n",
      "0.025\n",
      "0.0605896\n",
      "0.0605896\n",
      "0.155085\n",
      "0.155085\n",
      "0.434043\n",
      "0.434043\n",
      "0.619189\n",
      "0.619189\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.538519\n",
      "0.538519\n",
      "0.691196\n",
      "0.691196\n",
      "0.972523\n",
      "0.972523\n",
      "0.06362\n",
      "0.06362\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.483045\n",
      "0.483045\n",
      "0.188064\n",
      "0.188064\n",
      "0.11463\n",
      "0.11463\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0560995\n",
      "0.0560995\n",
      "0.0769112\n",
      "0.0769112\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.942589\n",
      "0.942589\n",
      "0.025\n",
      "0.025\n",
      "0.0339101\n",
      "0.0339101\n",
      "0.025\n",
      "0.025\n",
      "0.120343\n",
      "0.120343\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.290353\n",
      "0.290353\n",
      "0.975\n",
      "0.975\n",
      "0.369182\n",
      "0.369182\n",
      "0.025\n",
      "0.025\n",
      "0.771624\n",
      "0.771624\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0403677\n",
      "0.0403677\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0892414\n",
      "0.0892414\n",
      "0.025\n",
      "0.025\n",
      "0.435176\n",
      "0.435176\n",
      "0.025\n",
      "0.025\n",
      "0.059374\n",
      "0.059374\n",
      "0.210916\n",
      "0.210916\n",
      "0.968902\n",
      "0.968902\n",
      "0.733024\n",
      "0.733024\n",
      "0.115988\n",
      "0.115988\n",
      "0.975\n",
      "0.975\n",
      "0.58847\n",
      "0.58847\n",
      "0.0651283\n",
      "0.0651283\n",
      "0.0777706\n",
      "0.0777706\n",
      "0.72014\n",
      "0.72014\n",
      "0.0908521\n",
      "0.0908521\n",
      "0.435545\n",
      "0.435545\n",
      "0.025\n",
      "0.025\n",
      "0.126412\n",
      "0.126412\n",
      "0.975\n",
      "0.975\n",
      "0.870706\n",
      "0.870706\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0272491\n",
      "0.0272491\n",
      "0.947565\n",
      "0.947565\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.105188\n",
      "0.105188\n",
      "0.0315653\n",
      "0.0315653\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.464654\n",
      "0.464654\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0335936\n",
      "0.0335936\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.138009\n",
      "0.138009\n",
      "0.975\n",
      "0.975\n",
      "0.0512991\n",
      "0.0512991\n",
      "0.025\n",
      "0.025\n",
      "0.12191\n",
      "0.12191\n",
      "0.834585\n",
      "0.834585\n",
      "0.025\n",
      "0.025\n",
      "0.0803721\n",
      "0.0803721\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.412004\n",
      "0.412004\n",
      "0.234999\n",
      "0.234999\n",
      "0.025\n",
      "0.025\n",
      "0.0519966\n",
      "0.0519966\n",
      "0.025\n",
      "0.025\n",
      "0.20109\n",
      "0.20109\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.68932\n",
      "0.68932\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.97129\n",
      "0.97129\n",
      "0.683754\n",
      "0.683754\n",
      "0.025\n",
      "0.025\n",
      "0.374278\n",
      "0.374278\n",
      "0.0539118\n",
      "0.0539118\n",
      "0.514238\n",
      "0.514238\n",
      "0.025\n",
      "0.025\n",
      "0.605647\n",
      "0.605647\n",
      "0.612348\n",
      "0.612348\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.956115\n",
      "0.956115\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.407778\n",
      "0.407778\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.256183\n",
      "0.256183\n",
      "0.0355466\n",
      "0.0355466\n",
      "0.268579\n",
      "0.268579\n",
      "0.199831\n",
      "0.199831\n",
      "0.025\n",
      "0.025\n",
      "0.779113\n",
      "0.779113\n",
      "0.0980768\n",
      "0.0980768\n",
      "0.176685\n",
      "0.176685\n",
      "0.910737\n",
      "0.910737\n",
      "0.975\n",
      "0.975\n",
      "0.0720512\n",
      "0.0720512\n",
      "0.025\n",
      "0.025\n",
      "0.058679\n",
      "0.058679\n",
      "0.025\n",
      "0.025\n",
      "0.712917\n",
      "0.712917\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0317587\n",
      "0.0317587\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.367363\n",
      "0.367363\n",
      "0.0879731\n",
      "0.0879731\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.559285\n",
      "0.559285\n",
      "0.025\n",
      "0.025\n",
      "0.123967\n",
      "0.123967\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0264277\n",
      "0.0264277\n",
      "0.543742\n",
      "0.543742\n",
      "0.094197\n",
      "0.094197\n",
      "0.025\n",
      "0.025\n",
      "0.0937164\n",
      "0.0937164\n",
      "0.146659\n",
      "0.146659\n",
      "0.025\n",
      "0.025\n",
      "0.888275\n",
      "0.888275\n",
      "0.761232\n",
      "0.761232\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.853059\n",
      "0.853059\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0529114\n",
      "0.0529114\n",
      "0.78314\n",
      "0.78314\n",
      "0.025\n",
      "0.025\n",
      "0.960287\n",
      "0.960287\n",
      "0.932082\n",
      "0.932082\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.940726\n",
      "0.940726\n",
      "0.975\n",
      "0.975\n",
      "0.277637\n",
      "0.277637\n",
      "0.025\n",
      "0.025\n",
      "0.366264\n",
      "0.366264\n",
      "0.0415493\n",
      "0.0415493\n",
      "0.8175\n",
      "0.8175\n",
      "0.0534152\n",
      "0.0534152\n",
      "0.64388\n",
      "0.64388\n",
      "0.025\n",
      "0.025\n",
      "0.080467\n",
      "0.080467\n",
      "0.025\n",
      "0.025\n",
      "0.0656812\n",
      "0.0656812\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.214294\n",
      "0.214294\n",
      "0.118772\n",
      "0.118772\n",
      "0.577293\n",
      "0.577293\n",
      "0.975\n",
      "0.975\n",
      "0.279675\n",
      "0.279675\n",
      "0.0782158\n",
      "0.0782158\n",
      "0.573537\n",
      "0.573537\n",
      "0.0389578\n",
      "0.0389578\n",
      "0.706943\n",
      "0.706943\n",
      "0.025\n",
      "0.025\n",
      "0.916318\n",
      "0.916318\n",
      "0.101197\n",
      "0.101197\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.197108\n",
      "0.197108\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.201321\n",
      "0.201321\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.790324\n",
      "0.790324\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0820077\n",
      "0.0820077\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.933168\n",
      "0.933168\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.446508\n",
      "0.446508\n",
      "0.0278986\n",
      "0.0278986\n",
      "0.025\n",
      "0.025\n",
      "0.847965\n",
      "0.847965\n",
      "0.772402\n",
      "0.772402\n",
      "0.025\n",
      "0.025\n",
      "0.0501035\n",
      "0.0501035\n",
      "0.0955605\n",
      "0.0955605\n",
      "0.171481\n",
      "0.171481\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.116399\n",
      "0.116399\n",
      "0.025\n",
      "0.025\n",
      "0.0754582\n",
      "0.0754582\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.59198\n",
      "0.59198\n",
      "0.706028\n",
      "0.706028\n",
      "0.025\n",
      "0.025\n",
      "0.0468618\n",
      "0.0468618\n",
      "0.025\n",
      "0.025\n",
      "0.243464\n",
      "0.243464\n",
      "0.0291124\n",
      "0.0291124\n",
      "0.025\n",
      "0.025\n",
      "0.0679223\n",
      "0.0679223\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0316637\n",
      "0.0316637\n",
      "0.284029\n",
      "0.284029\n",
      "0.554524\n",
      "0.554524\n",
      "0.025\n",
      "0.025\n",
      "0.0288607\n",
      "0.0288607\n",
      "0.124645\n",
      "0.124645\n",
      "0.947853\n",
      "0.947853\n",
      "0.560281\n",
      "0.560281\n",
      "0.0742112\n",
      "0.0742112\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0619781\n",
      "0.0619781\n",
      "0.025\n",
      "0.025\n",
      "0.803131\n",
      "0.803131\n",
      "0.025\n",
      "0.025\n",
      "0.170452\n",
      "0.170452\n",
      "0.86074\n",
      "0.86074\n",
      "0.025\n",
      "0.025\n",
      "0.278668\n",
      "0.278668\n",
      "0.0864411\n",
      "0.0864411\n",
      "0.025\n",
      "0.025\n",
      "0.91344\n",
      "0.91344\n",
      "0.88876\n",
      "0.88876\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.852647\n",
      "0.852647\n",
      "0.214409\n",
      "0.214409\n",
      "0.025\n",
      "0.025\n",
      "0.0750404\n",
      "0.0750404\n",
      "0.645188\n",
      "0.645188\n",
      "0.025\n",
      "0.025\n",
      "0.90108\n",
      "0.90108\n",
      "0.975\n",
      "0.975\n",
      "0.181038\n",
      "0.181038\n",
      "0.0360808\n",
      "0.0360808\n",
      "0.963576\n",
      "0.963576\n",
      "0.025\n",
      "0.025\n",
      "0.700102\n",
      "0.700102\n",
      "0.0853435\n",
      "0.0853435\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.1038\n",
      "0.1038\n",
      "0.229465\n",
      "0.229465\n",
      "0.0405318\n",
      "0.0405318\n",
      "0.025\n",
      "0.025\n",
      "0.246817\n",
      "0.246817\n",
      "0.975\n",
      "0.975\n",
      "0.0524039\n",
      "0.0524039\n",
      "0.025\n",
      "0.025\n",
      "0.972156\n",
      "0.972156\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0328405\n",
      "0.0328405\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.262424\n",
      "0.262424\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.9722\n",
      "0.9722\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.553308\n",
      "0.553308\n",
      "0.942321\n",
      "0.942321\n",
      "0.775763\n",
      "0.775763\n",
      "0.167459\n",
      "0.167459\n",
      "0.364252\n",
      "0.364252\n",
      "0.0360666\n",
      "0.0360666\n",
      "0.120797\n",
      "0.120797\n",
      "0.371072\n",
      "0.371072\n",
      "0.106151\n",
      "0.106151\n",
      "0.934979\n",
      "0.934979\n",
      "0.614088\n",
      "0.614088\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0289989\n",
      "0.0289989\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0301031\n",
      "0.0301031\n",
      "0.975\n",
      "0.975\n",
      "0.285731\n",
      "0.285731\n",
      "0.0509939\n",
      "0.0509939\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.757235\n",
      "0.757235\n",
      "0.025\n",
      "0.025\n",
      "0.188791\n",
      "0.188791\n",
      "0.025\n",
      "0.025\n",
      "0.893668\n",
      "0.893668\n",
      "0.025\n",
      "0.025\n",
      "0.0342323\n",
      "0.0342323\n",
      "0.025\n",
      "0.025\n",
      "0.743619\n",
      "0.743619\n",
      "0.599314\n",
      "0.599314\n",
      "0.870753\n",
      "0.870753\n",
      "0.928771\n",
      "0.928771\n",
      "0.0341584\n",
      "0.0341584\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.274163\n",
      "0.274163\n",
      "0.505585\n",
      "0.505585\n",
      "0.145899\n",
      "0.145899\n",
      "0.0705745\n",
      "0.0705745\n",
      "0.975\n",
      "0.975\n",
      "0.125573\n",
      "0.125573\n",
      "0.102765\n",
      "0.102765\n",
      "0.0428208\n",
      "0.0428208\n",
      "0.975\n",
      "0.975\n",
      "0.042816\n",
      "0.042816\n",
      "0.241549\n",
      "0.241549\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0753824\n",
      "0.0753824\n",
      "0.0761062\n",
      "0.0761062\n",
      "0.025\n",
      "0.025\n",
      "0.0921264\n",
      "0.0921264\n",
      "0.605511\n",
      "0.605511\n",
      "0.025\n",
      "0.025\n",
      "0.0685093\n",
      "0.0685093\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.027425\n",
      "0.027425\n",
      "0.524769\n",
      "0.524769\n",
      "0.171519\n",
      "0.171519\n",
      "0.633294\n",
      "0.633294\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0864488\n",
      "0.0864488\n",
      "0.0481532\n",
      "0.0481532\n",
      "0.378978\n",
      "0.378978\n",
      "0.958786\n",
      "0.958786\n",
      "0.974263\n",
      "0.974263\n",
      "0.025\n",
      "0.025\n",
      "0.0461217\n",
      "0.0461217\n",
      "0.758573\n",
      "0.758573\n",
      "0.413334\n",
      "0.413334\n",
      "0.3015\n",
      "0.3015\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.431094\n",
      "0.431094\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.557591\n",
      "0.557591\n",
      "0.117397\n",
      "0.117397\n",
      "0.0586268\n",
      "0.0586268\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0427626\n",
      "0.0427626\n",
      "0.567172\n",
      "0.567172\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.22909\n",
      "0.22909\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.244584\n",
      "0.244584\n",
      "0.130172\n",
      "0.130172\n",
      "0.315398\n",
      "0.315398\n",
      "0.975\n",
      "0.975\n",
      "0.394762\n",
      "0.394762\n",
      "0.660064\n",
      "0.660064\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.170255\n",
      "0.170255\n",
      "0.033397\n",
      "0.033397\n",
      "0.025\n",
      "0.025\n",
      "0.522056\n",
      "0.522056\n",
      "0.0977854\n",
      "0.0977854\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0577406\n",
      "0.0577406\n",
      "0.0300096\n",
      "0.0300096\n",
      "0.888818\n",
      "0.888818\n",
      "0.458745\n",
      "0.458745\n",
      "0.569788\n",
      "0.569788\n",
      "0.025\n",
      "0.025\n",
      "0.128799\n",
      "0.128799\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0484496\n",
      "0.0484496\n",
      "0.0698679\n",
      "0.0698679\n",
      "0.025\n",
      "0.025\n",
      "0.119351\n",
      "0.119351\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.295758\n",
      "0.295758\n",
      "0.222908\n",
      "0.222908\n",
      "0.0509343\n",
      "0.0509343\n",
      "0.025\n",
      "0.025\n",
      "0.952633\n",
      "0.952633\n",
      "0.0303054\n",
      "0.0303054\n",
      "0.970586\n",
      "0.970586\n",
      "0.940097\n",
      "0.940097\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.139424\n",
      "0.139424\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.738804\n",
      "0.738804\n",
      "0.025\n",
      "0.025\n",
      "0.708902\n",
      "0.708902\n",
      "0.025\n",
      "0.025\n",
      "0.272006\n",
      "0.272006\n",
      "0.0463045\n",
      "0.0463045\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0411114\n",
      "0.0411114\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.457\n",
      "0.457\n",
      "0.959144\n",
      "0.959144\n",
      "0.025\n",
      "0.025\n",
      "0.392099\n",
      "0.392099\n",
      "0.337638\n",
      "0.337638\n",
      "0.262914\n",
      "0.262914\n",
      "0.025\n",
      "0.025\n",
      "0.072841\n",
      "0.072841\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.029268\n",
      "0.029268\n",
      "0.170142\n",
      "0.170142\n",
      "0.891354\n",
      "0.891354\n",
      "0.458592\n",
      "0.458592\n",
      "0.521679\n",
      "0.521679\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.952134\n",
      "0.952134\n",
      "0.025\n",
      "0.025\n",
      "0.213591\n",
      "0.213591\n",
      "0.025\n",
      "0.025\n",
      "0.263363\n",
      "0.263363\n",
      "0.240846\n",
      "0.240846\n",
      "0.173932\n",
      "0.173932\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.594379\n",
      "0.594379\n",
      "0.025\n",
      "0.025\n",
      "0.366764\n",
      "0.366764\n",
      "0.0433071\n",
      "0.0433071\n",
      "0.139153\n",
      "0.139153\n",
      "0.025\n",
      "0.025\n",
      "0.0863409\n",
      "0.0863409\n",
      "0.064286\n",
      "0.064286\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.966731\n",
      "0.966731\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0600258\n",
      "0.0600258\n",
      "0.0315699\n",
      "0.0315699\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0365049\n",
      "0.0365049\n",
      "0.975\n",
      "0.975\n",
      "0.757336\n",
      "0.757336\n",
      "0.480532\n",
      "0.480532\n",
      "0.426627\n",
      "0.426627\n",
      "0.90029\n",
      "0.90029\n",
      "0.296615\n",
      "0.296615\n",
      "0.907546\n",
      "0.907546\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.697689\n",
      "0.697689\n",
      "0.025\n",
      "0.025\n",
      "0.136582\n",
      "0.136582\n",
      "0.738181\n",
      "0.738181\n",
      "0.383041\n",
      "0.383041\n",
      "0.30519\n",
      "0.30519\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.325991\n",
      "0.325991\n",
      "0.025\n",
      "0.025\n",
      "0.581946\n",
      "0.581946\n",
      "0.247995\n",
      "0.247995\n",
      "0.025\n",
      "0.025\n",
      "0.812745\n",
      "0.812745\n",
      "0.0383915\n",
      "0.0383915\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0459654\n",
      "0.0459654\n",
      "0.94108\n",
      "0.94108\n",
      "0.946873\n",
      "0.946873\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.110791\n",
      "0.110791\n",
      "0.957686\n",
      "0.957686\n",
      "0.814561\n",
      "0.814561\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.428468\n",
      "0.428468\n",
      "0.825409\n",
      "0.825409\n",
      "0.813483\n",
      "0.813483\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0279513\n",
      "0.0279513\n",
      "0.025\n",
      "0.025\n",
      "0.330604\n",
      "0.330604\n",
      "0.80637\n",
      "0.80637\n",
      "0.975\n",
      "0.975\n",
      "0.607028\n",
      "0.607028\n",
      "0.0716694\n",
      "0.0716694\n",
      "0.0428317\n",
      "0.0428317\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.114116\n",
      "0.114116\n",
      "0.296117\n",
      "0.296117\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.120153\n",
      "0.120153\n",
      "0.166701\n",
      "0.166701\n",
      "0.975\n",
      "0.975\n",
      "0.880717\n",
      "0.880717\n",
      "0.975\n",
      "0.975\n",
      "0.0598956\n",
      "0.0598956\n",
      "0.0444398\n",
      "0.0444398\n",
      "0.968875\n",
      "0.968875\n",
      "0.0641245\n",
      "0.0641245\n",
      "0.025\n",
      "0.025\n",
      "0.774321\n",
      "0.774321\n",
      "0.525185\n",
      "0.525185\n",
      "0.307302\n",
      "0.307302\n",
      "0.0411044\n",
      "0.0411044\n",
      "0.975\n",
      "0.975\n",
      "0.0368681\n",
      "0.0368681\n",
      "0.202527\n",
      "0.202527\n",
      "0.0641484\n",
      "0.0641484\n",
      "0.238013\n",
      "0.238013\n",
      "0.142638\n",
      "0.142638\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.214538\n",
      "0.214538\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.101764\n",
      "0.101764\n",
      "0.975\n",
      "0.975\n",
      "0.0940606\n",
      "0.0940606\n",
      "0.975\n",
      "0.975\n",
      "0.173478\n",
      "0.173478\n",
      "0.025\n",
      "0.025\n",
      "0.0449594\n",
      "0.0449594\n",
      "0.0936397\n",
      "0.0936397\n",
      "0.0739184\n",
      "0.0739184\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.573242\n",
      "0.573242\n",
      "0.025\n",
      "0.025\n",
      "0.95744\n",
      "0.95744\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0544829\n",
      "0.0544829\n",
      "0.164688\n",
      "0.164688\n",
      "0.577097\n",
      "0.577097\n",
      "0.97403\n",
      "0.97403\n",
      "0.904158\n",
      "0.904158\n",
      "0.074286\n",
      "0.074286\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.251413\n",
      "0.251413\n",
      "0.0465\n",
      "0.0465\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0704653\n",
      "0.0704653\n",
      "0.025\n",
      "0.025\n",
      "0.0402858\n",
      "0.0402858\n",
      "0.460714\n",
      "0.460714\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.941521\n",
      "0.941521\n",
      "0.975\n",
      "0.975\n",
      "0.705799\n",
      "0.705799\n",
      "0.0459692\n",
      "0.0459692\n",
      "0.0711934\n",
      "0.0711934\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0638216\n",
      "0.0638216\n",
      "0.709575\n",
      "0.709575\n",
      "0.331887\n",
      "0.331887\n",
      "0.182585\n",
      "0.182585\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.473479\n",
      "0.473479\n",
      "0.108057\n",
      "0.108057\n",
      "0.025\n",
      "0.025\n",
      "0.930739\n",
      "0.930739\n",
      "0.799212\n",
      "0.799212\n",
      "0.025\n",
      "0.025\n",
      "0.0580049\n",
      "0.0580049\n",
      "0.025\n",
      "0.025\n",
      "0.88885\n",
      "0.88885\n",
      "0.160502\n",
      "0.160502\n",
      "0.121026\n",
      "0.121026\n",
      "0.272344\n",
      "0.272344\n",
      "0.135055\n",
      "0.135055\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0253756\n",
      "0.0253756\n",
      "0.735249\n",
      "0.735249\n",
      "0.0338473\n",
      "0.0338473\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.131105\n",
      "0.131105\n",
      "0.72407\n",
      "0.72407\n",
      "0.255606\n",
      "0.255606\n",
      "0.203194\n",
      "0.203194\n",
      "0.232727\n",
      "0.232727\n",
      "0.675016\n",
      "0.675016\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.227308\n",
      "0.227308\n",
      "0.784696\n",
      "0.784696\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.276938\n",
      "0.276938\n",
      "0.025\n",
      "0.025\n",
      "0.962302\n",
      "0.962302\n",
      "0.905546\n",
      "0.905546\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.934409\n",
      "0.934409\n",
      "0.025\n",
      "0.025\n",
      "0.320769\n",
      "0.320769\n",
      "0.846342\n",
      "0.846342\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.813483\n",
      "0.813483\n",
      "0.025\n",
      "0.025\n",
      "0.216679\n",
      "0.216679\n",
      "0.975\n",
      "0.975\n",
      "0.0493933\n",
      "0.0493933\n",
      "0.025\n",
      "0.025\n",
      "0.160761\n",
      "0.160761\n",
      "0.238094\n",
      "0.238094\n",
      "0.025\n",
      "0.025\n",
      "0.136805\n",
      "0.136805\n",
      "0.0296028\n",
      "0.0296028\n",
      "0.294087\n",
      "0.294087\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0260553\n",
      "0.0260553\n",
      "0.025\n",
      "0.025\n",
      "0.401346\n",
      "0.401346\n",
      "0.025\n",
      "0.025\n",
      "0.475638\n",
      "0.475638\n",
      "0.19954\n",
      "0.19954\n",
      "0.025\n",
      "0.025\n",
      "0.0718778\n",
      "0.0718778\n",
      "0.025\n",
      "0.025\n",
      "0.270847\n",
      "0.270847\n",
      "0.025\n",
      "0.025\n",
      "0.273403\n",
      "0.273403\n",
      "0.025\n",
      "0.025\n",
      "0.053655\n",
      "0.053655\n",
      "0.970964\n",
      "0.970964\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0718726\n",
      "0.0718726\n",
      "0.960448\n",
      "0.960448\n",
      "0.044542\n",
      "0.044542\n",
      "0.0326934\n",
      "0.0326934\n",
      "0.025\n",
      "0.025\n",
      "0.946941\n",
      "0.946941\n",
      "0.77784\n",
      "0.77784\n",
      "0.025\n",
      "0.025\n",
      "0.0320934\n",
      "0.0320934\n",
      "0.025\n",
      "0.025\n",
      "0.0776305\n",
      "0.0776305\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.795634\n",
      "0.795634\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.225934\n",
      "0.225934\n",
      "0.110075\n",
      "0.110075\n",
      "0.455408\n",
      "0.455408\n",
      "0.136778\n",
      "0.136778\n",
      "0.0796589\n",
      "0.0796589\n",
      "0.025\n",
      "0.025\n",
      "0.43433\n",
      "0.43433\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.417508\n",
      "0.417508\n",
      "0.975\n",
      "0.975\n",
      "0.362392\n",
      "0.362392\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.763154\n",
      "0.763154\n",
      "0.975\n",
      "0.975\n",
      "0.0408917\n",
      "0.0408917\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.046958\n",
      "0.046958\n",
      "0.025\n",
      "0.025\n",
      "0.0450665\n",
      "0.0450665\n",
      "0.219589\n",
      "0.219589\n",
      "0.765264\n",
      "0.765264\n",
      "0.140001\n",
      "0.140001\n",
      "0.0512771\n",
      "0.0512771\n",
      "0.025\n",
      "0.025\n",
      "0.12114\n",
      "0.12114\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0499786\n",
      "0.0499786\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.453727\n",
      "0.453727\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.425314\n",
      "0.425314\n",
      "0.181152\n",
      "0.181152\n",
      "0.920089\n",
      "0.920089\n",
      "0.0640439\n",
      "0.0640439\n",
      "0.0518295\n",
      "0.0518295\n",
      "0.025\n",
      "0.025\n",
      "0.116525\n",
      "0.116525\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.925253\n",
      "0.925253\n",
      "0.120181\n",
      "0.120181\n",
      "0.102861\n",
      "0.102861\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0513582\n",
      "0.0513582\n",
      "0.53823\n",
      "0.53823\n",
      "0.758333\n",
      "0.758333\n",
      "0.319238\n",
      "0.319238\n",
      "0.025\n",
      "0.025\n",
      "0.931577\n",
      "0.931577\n",
      "0.135728\n",
      "0.135728\n",
      "0.025\n",
      "0.025\n",
      "0.0922452\n",
      "0.0922452\n",
      "0.144626\n",
      "0.144626\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0629491\n",
      "0.0629491\n",
      "0.975\n",
      "0.975\n",
      "0.0742232\n",
      "0.0742232\n",
      "0.025\n",
      "0.025\n",
      "0.92948\n",
      "0.92948\n",
      "0.025\n",
      "0.025\n",
      "0.31596\n",
      "0.31596\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.891817\n",
      "0.891817\n",
      "0.172001\n",
      "0.172001\n",
      "0.025\n",
      "0.025\n",
      "0.452935\n",
      "0.452935\n",
      "0.70116\n",
      "0.70116\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.169911\n",
      "0.169911\n",
      "0.822964\n",
      "0.822964\n",
      "0.0622992\n",
      "0.0622992\n",
      "0.065597\n",
      "0.065597\n",
      "0.460594\n",
      "0.460594\n",
      "0.136571\n",
      "0.136571\n",
      "0.0363266\n",
      "0.0363266\n",
      "0.975\n",
      "0.975\n",
      "0.968794\n",
      "0.968794\n",
      "0.276041\n",
      "0.276041\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.354523\n",
      "0.354523\n",
      "0.629017\n",
      "0.629017\n",
      "0.126884\n",
      "0.126884\n",
      "0.025\n",
      "0.025\n",
      "0.968974\n",
      "0.968974\n",
      "0.31311\n",
      "0.31311\n",
      "0.025\n",
      "0.025\n",
      "0.589317\n",
      "0.589317\n",
      "0.282616\n",
      "0.282616\n",
      "0.0373633\n",
      "0.0373633\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.147157\n",
      "0.147157\n",
      "0.025\n",
      "0.025\n",
      "0.501437\n",
      "0.501437\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0434938\n",
      "0.0434938\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0953564\n",
      "0.0953564\n",
      "0.025\n",
      "0.025\n",
      "0.0280633\n",
      "0.0280633\n",
      "0.025\n",
      "0.025\n",
      "0.952343\n",
      "0.952343\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0807087\n",
      "0.0807087\n",
      "0.025\n",
      "0.025\n",
      "0.473229\n",
      "0.473229\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.170051\n",
      "0.170051\n",
      "0.697124\n",
      "0.697124\n",
      "0.308681\n",
      "0.308681\n",
      "0.415168\n",
      "0.415168\n",
      "0.17672\n",
      "0.17672\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0454353\n",
      "0.0454353\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.237851\n",
      "0.237851\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.941192\n",
      "0.941192\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.648509\n",
      "0.648509\n",
      "0.349709\n",
      "0.349709\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.208774\n",
      "0.208774\n",
      "0.821195\n",
      "0.821195\n",
      "0.436193\n",
      "0.436193\n",
      "0.025\n",
      "0.025\n",
      "0.448579\n",
      "0.448579\n",
      "0.025\n",
      "0.025\n",
      "0.0956011\n",
      "0.0956011\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0913691\n",
      "0.0913691\n",
      "0.142295\n",
      "0.142295\n",
      "0.025\n",
      "0.025\n",
      "0.420419\n",
      "0.420419\n",
      "0.975\n",
      "0.975\n",
      "0.596999\n",
      "0.596999\n",
      "0.025\n",
      "0.025\n",
      "0.858768\n",
      "0.858768\n",
      "0.862738\n",
      "0.862738\n",
      "0.812326\n",
      "0.812326\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.138447\n",
      "0.138447\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.19338\n",
      "0.19338\n",
      "0.194296\n",
      "0.194296\n",
      "0.064986\n",
      "0.064986\n",
      "0.20606\n",
      "0.20606\n",
      "0.025\n",
      "0.025\n",
      "0.189195\n",
      "0.189195\n",
      "0.236428\n",
      "0.236428\n",
      "0.0289307\n",
      "0.0289307\n",
      "0.025\n",
      "0.025\n",
      "0.94823\n",
      "0.94823\n",
      "0.174652\n",
      "0.174652\n",
      "0.170206\n",
      "0.170206\n",
      "0.0680212\n",
      "0.0680212\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.472165\n",
      "0.472165\n",
      "0.067784\n",
      "0.067784\n",
      "0.025\n",
      "0.025\n",
      "0.397585\n",
      "0.397585\n",
      "0.19255\n",
      "0.19255\n",
      "0.0545824\n",
      "0.0545824\n",
      "0.0278425\n",
      "0.0278425\n",
      "0.975\n",
      "0.975\n",
      "0.0355485\n",
      "0.0355485\n",
      "0.0595303\n",
      "0.0595303\n",
      "0.025\n",
      "0.025\n",
      "0.814144\n",
      "0.814144\n",
      "0.0783209\n",
      "0.0783209\n",
      "0.0801411\n",
      "0.0801411\n",
      "0.193321\n",
      "0.193321\n",
      "0.025\n",
      "0.025\n",
      "0.370691\n",
      "0.370691\n",
      "0.297778\n",
      "0.297778\n",
      "0.025\n",
      "0.025\n",
      "0.591696\n",
      "0.591696\n",
      "0.025\n",
      "0.025\n",
      "0.443774\n",
      "0.443774\n",
      "0.025\n",
      "0.025\n",
      "0.689981\n",
      "0.689981\n",
      "0.747201\n",
      "0.747201\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.420253\n",
      "0.420253\n",
      "0.025\n",
      "0.025\n",
      "0.648618\n",
      "0.648618\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.488582\n",
      "0.488582\n",
      "0.975\n",
      "0.975\n",
      "0.168077\n",
      "0.168077\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.544847\n",
      "0.544847\n",
      "0.323396\n",
      "0.323396\n",
      "0.975\n",
      "0.975\n",
      "0.88256\n",
      "0.88256\n",
      "0.025\n",
      "0.025\n",
      "0.527085\n",
      "0.527085\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.939923\n",
      "0.939923\n",
      "0.120911\n",
      "0.120911\n",
      "0.712426\n",
      "0.712426\n",
      "0.025\n",
      "0.025\n",
      "0.392573\n",
      "0.392573\n",
      "0.15448\n",
      "0.15448\n",
      "0.025\n",
      "0.025\n",
      "0.651638\n",
      "0.651638\n",
      "0.108374\n",
      "0.108374\n",
      "0.0632207\n",
      "0.0632207\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.228194\n",
      "0.228194\n",
      "0.025\n",
      "0.025\n",
      "0.565806\n",
      "0.565806\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0515195\n",
      "0.0515195\n",
      "0.0384299\n",
      "0.0384299\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.200341\n",
      "0.200341\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.107155\n",
      "0.107155\n",
      "0.29651\n",
      "0.29651\n",
      "0.025\n",
      "0.025\n",
      "0.0265888\n",
      "0.0265888\n",
      "0.178725\n",
      "0.178725\n",
      "0.0722592\n",
      "0.0722592\n",
      "0.355934\n",
      "0.355934\n",
      "0.427359\n",
      "0.427359\n",
      "0.316185\n",
      "0.316185\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.276806\n",
      "0.276806\n",
      "0.903952\n",
      "0.903952\n",
      "0.025\n",
      "0.025\n",
      "0.0458743\n",
      "0.0458743\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.970433\n",
      "0.970433\n",
      "0.025\n",
      "0.025\n",
      "0.218055\n",
      "0.218055\n",
      "0.124842\n",
      "0.124842\n",
      "0.975\n",
      "0.975\n",
      "0.707166\n",
      "0.707166\n",
      "0.0670846\n",
      "0.0670846\n",
      "0.199038\n",
      "0.199038\n",
      "0.267788\n",
      "0.267788\n",
      "0.025\n",
      "0.025\n",
      "0.574705\n",
      "0.574705\n",
      "0.336584\n",
      "0.336584\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.944282\n",
      "0.944282\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.538547\n",
      "0.538547\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.11389\n",
      "0.11389\n",
      "0.412\n",
      "0.412\n",
      "0.975\n",
      "0.975\n",
      "0.143825\n",
      "0.143825\n",
      "0.025\n",
      "0.025\n",
      "0.0323451\n",
      "0.0323451\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.381628\n",
      "0.381628\n",
      "0.975\n",
      "0.975\n",
      "0.125331\n",
      "0.125331\n",
      "0.025\n",
      "0.025\n",
      "0.02999\n",
      "0.02999\n",
      "0.0443663\n",
      "0.0443663\n",
      "0.025\n",
      "0.025\n",
      "0.460855\n",
      "0.460855\n",
      "0.110391\n",
      "0.110391\n",
      "0.025\n",
      "0.025\n",
      "0.0348587\n",
      "0.0348587\n",
      "0.025\n",
      "0.025\n",
      "0.95053\n",
      "0.95053\n",
      "0.873209\n",
      "0.873209\n",
      "0.753773\n",
      "0.753773\n",
      "0.025\n",
      "0.025\n",
      "0.447824\n",
      "0.447824\n",
      "0.142704\n",
      "0.142704\n",
      "0.966902\n",
      "0.966902\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.108482\n",
      "0.108482\n",
      "0.0915507\n",
      "0.0915507\n",
      "0.0834418\n",
      "0.0834418\n",
      "0.290725\n",
      "0.290725\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0879134\n",
      "0.0879134\n",
      "0.598239\n",
      "0.598239\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0634\n",
      "0.0634\n",
      "0.975\n",
      "0.975\n",
      "0.83063\n",
      "0.83063\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.745238\n",
      "0.745238\n",
      "0.148264\n",
      "0.148264\n",
      "0.025\n",
      "0.025\n",
      "0.0801572\n",
      "0.0801572\n",
      "0.025\n",
      "0.025\n",
      "0.8166\n",
      "0.8166\n",
      "0.025\n",
      "0.025\n",
      "0.101758\n",
      "0.101758\n",
      "0.025\n",
      "0.025\n",
      "0.405573\n",
      "0.405573\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.209421\n",
      "0.209421\n",
      "0.65805\n",
      "0.65805\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.558861\n",
      "0.558861\n",
      "0.025\n",
      "0.025\n",
      "0.0427641\n",
      "0.0427641\n",
      "0.0491047\n",
      "0.0491047\n",
      "0.025\n",
      "0.025\n",
      "0.0871986\n",
      "0.0871986\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.638771\n",
      "0.638771\n",
      "0.0442217\n",
      "0.0442217\n",
      "0.025\n",
      "0.025\n",
      "0.924276\n",
      "0.924276\n",
      "0.108707\n",
      "0.108707\n",
      "0.60651\n",
      "0.60651\n",
      "0.0688764\n",
      "0.0688764\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.693923\n",
      "0.693923\n",
      "0.975\n",
      "0.975\n",
      "0.297345\n",
      "0.297345\n",
      "0.025\n",
      "0.025\n",
      "0.893054\n",
      "0.893054\n",
      "0.122161\n",
      "0.122161\n",
      "0.025\n",
      "0.025\n",
      "0.0626928\n",
      "0.0626928\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0302173\n",
      "0.0302173\n",
      "0.711273\n",
      "0.711273\n",
      "0.0373185\n",
      "0.0373185\n",
      "0.646962\n",
      "0.646962\n",
      "0.975\n",
      "0.975\n",
      "0.783237\n",
      "0.783237\n",
      "0.0436736\n",
      "0.0436736\n",
      "0.0504174\n",
      "0.0504174\n",
      "0.907899\n",
      "0.907899\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.233002\n",
      "0.233002\n",
      "0.645129\n",
      "0.645129\n",
      "0.025\n",
      "0.025\n",
      "0.105131\n",
      "0.105131\n",
      "0.258633\n",
      "0.258633\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.671103\n",
      "0.671103\n",
      "0.700112\n",
      "0.700112\n",
      "0.300814\n",
      "0.300814\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0514104\n",
      "0.0514104\n",
      "0.957426\n",
      "0.957426\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.754187\n",
      "0.754187\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0351893\n",
      "0.0351893\n",
      "0.975\n",
      "0.975\n",
      "0.194051\n",
      "0.194051\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.896118\n",
      "0.896118\n",
      "0.025\n",
      "0.025\n",
      "0.970282\n",
      "0.970282\n",
      "0.0919493\n",
      "0.0919493\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.707901\n",
      "0.707901\n",
      "0.025\n",
      "0.025\n",
      "0.853865\n",
      "0.853865\n",
      "0.755214\n",
      "0.755214\n",
      "0.232265\n",
      "0.232265\n",
      "0.0557289\n",
      "0.0557289\n",
      "0.794387\n",
      "0.794387\n",
      "0.051061\n",
      "0.051061\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.952291\n",
      "0.952291\n",
      "0.108343\n",
      "0.108343\n",
      "0.966631\n",
      "0.966631\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.367641\n",
      "0.367641\n",
      "0.025\n",
      "0.025\n",
      "0.090887\n",
      "0.090887\n",
      "0.025\n",
      "0.025\n",
      "0.426735\n",
      "0.426735\n",
      "0.025\n",
      "0.025\n",
      "0.951822\n",
      "0.951822\n",
      "0.0590411\n",
      "0.0590411\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.625202\n",
      "0.625202\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0690642\n",
      "0.0690642\n",
      "0.452895\n",
      "0.452895\n",
      "0.13212\n",
      "0.13212\n",
      "0.954584\n",
      "0.954584\n",
      "0.764659\n",
      "0.764659\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.930631\n",
      "0.930631\n",
      "0.845799\n",
      "0.845799\n",
      "0.975\n",
      "0.975\n",
      "0.168407\n",
      "0.168407\n",
      "0.103922\n",
      "0.103922\n",
      "0.13325\n",
      "0.13325\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.150035\n",
      "0.150035\n",
      "0.975\n",
      "0.975\n",
      "0.495408\n",
      "0.495408\n",
      "0.549214\n",
      "0.549214\n",
      "0.025\n",
      "0.025\n",
      "0.254437\n",
      "0.254437\n",
      "0.401513\n",
      "0.401513\n",
      "0.791651\n",
      "0.791651\n",
      "0.22608\n",
      "0.22608\n",
      "0.0737224\n",
      "0.0737224\n",
      "0.934157\n",
      "0.934157\n",
      "0.12038\n",
      "0.12038\n",
      "0.91316\n",
      "0.91316\n",
      "0.025\n",
      "0.025\n",
      "0.144181\n",
      "0.144181\n",
      "0.645706\n",
      "0.645706\n",
      "0.975\n",
      "0.975\n",
      "0.935523\n",
      "0.935523\n",
      "0.375659\n",
      "0.375659\n",
      "0.025\n",
      "0.025\n",
      "0.10507\n",
      "0.10507\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0666599\n",
      "0.0666599\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0386116\n",
      "0.0386116\n",
      "0.0748599\n",
      "0.0748599\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.879233\n",
      "0.879233\n",
      "0.0596485\n",
      "0.0596485\n",
      "0.113273\n",
      "0.113273\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.123104\n",
      "0.123104\n",
      "0.100424\n",
      "0.100424\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0292028\n",
      "0.0292028\n",
      "0.0290043\n",
      "0.0290043\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.466778\n",
      "0.466778\n",
      "0.0375052\n",
      "0.0375052\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0250287\n",
      "0.0250287\n",
      "0.507118\n",
      "0.507118\n",
      "0.850182\n",
      "0.850182\n",
      "0.025\n",
      "0.025\n",
      "0.0422422\n",
      "0.0422422\n",
      "0.0663355\n",
      "0.0663355\n",
      "0.10283\n",
      "0.10283\n",
      "0.216138\n",
      "0.216138\n",
      "0.673363\n",
      "0.673363\n",
      "0.975\n",
      "0.975\n",
      "0.0339918\n",
      "0.0339918\n",
      "0.101444\n",
      "0.101444\n",
      "0.0886294\n",
      "0.0886294\n",
      "0.0415862\n",
      "0.0415862\n",
      "0.809651\n",
      "0.809651\n",
      "0.025\n",
      "0.025\n",
      "0.634612\n",
      "0.634612\n",
      "0.025\n",
      "0.025\n",
      "0.973112\n",
      "0.973112\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.909804\n",
      "0.909804\n",
      "0.975\n",
      "0.975\n",
      "0.888514\n",
      "0.888514\n",
      "0.137049\n",
      "0.137049\n",
      "0.963064\n",
      "0.963064\n",
      "0.176812\n",
      "0.176812\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.410521\n",
      "0.410521\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.124638\n",
      "0.124638\n",
      "0.975\n",
      "0.975\n",
      "0.466217\n",
      "0.466217\n",
      "0.0941453\n",
      "0.0941453\n",
      "0.975\n",
      "0.975\n",
      "0.0983466\n",
      "0.0983466\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.136975\n",
      "0.136975\n",
      "0.0298467\n",
      "0.0298467\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.206567\n",
      "0.206567\n",
      "0.918772\n",
      "0.918772\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.554775\n",
      "0.554775\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.969382\n",
      "0.969382\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.833826\n",
      "0.833826\n",
      "0.0259117\n",
      "0.0259117\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.383169\n",
      "0.383169\n",
      "0.0485166\n",
      "0.0485166\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.939035\n",
      "0.939035\n",
      "0.025\n",
      "0.025\n",
      "0.0726859\n",
      "0.0726859\n",
      "0.310051\n",
      "0.310051\n",
      "0.0881202\n",
      "0.0881202\n",
      "0.269278\n",
      "0.269278\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.956498\n",
      "0.956498\n",
      "0.025\n",
      "0.025\n",
      "0.0585586\n",
      "0.0585586\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.145905\n",
      "0.145905\n",
      "0.025\n",
      "0.025\n",
      "0.483745\n",
      "0.483745\n",
      "0.025\n",
      "0.025\n",
      "0.623022\n",
      "0.623022\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.826381\n",
      "0.826381\n",
      "0.0455613\n",
      "0.0455613\n",
      "0.025\n",
      "0.025\n",
      "0.111809\n",
      "0.111809\n",
      "0.0770997\n",
      "0.0770997\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.139813\n",
      "0.139813\n",
      "0.025\n",
      "0.025\n",
      "0.372483\n",
      "0.372483\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.819533\n",
      "0.819533\n",
      "0.025\n",
      "0.025\n",
      "0.827802\n",
      "0.827802\n",
      "0.0766924\n",
      "0.0766924\n",
      "0.025\n",
      "0.025\n",
      "0.967211\n",
      "0.967211\n",
      "0.025\n",
      "0.025\n",
      "0.205171\n",
      "0.205171\n",
      "0.0437793\n",
      "0.0437793\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.58373\n",
      "0.58373\n",
      "0.317369\n",
      "0.317369\n",
      "0.0477684\n",
      "0.0477684\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.206945\n",
      "0.206945\n",
      "0.246033\n",
      "0.246033\n",
      "0.025\n",
      "0.025\n",
      "0.440127\n",
      "0.440127\n",
      "0.025\n",
      "0.025\n",
      "0.731592\n",
      "0.731592\n",
      "0.944198\n",
      "0.944198\n",
      "0.0521611\n",
      "0.0521611\n",
      "0.0756345\n",
      "0.0756345\n",
      "0.025\n",
      "0.025\n",
      "0.355071\n",
      "0.355071\n",
      "0.471556\n",
      "0.471556\n",
      "0.721563\n",
      "0.721563\n",
      "0.975\n",
      "0.975\n",
      "0.0970415\n",
      "0.0970415\n",
      "0.025\n",
      "0.025\n",
      "0.837095\n",
      "0.837095\n",
      "0.117003\n",
      "0.117003\n",
      "0.025\n",
      "0.025\n",
      "0.888786\n",
      "0.888786\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.483082\n",
      "0.483082\n",
      "0.0978954\n",
      "0.0978954\n",
      "0.025\n",
      "0.025\n",
      "0.759993\n",
      "0.759993\n",
      "0.557283\n",
      "0.557283\n",
      "0.13347\n",
      "0.13347\n",
      "0.025\n",
      "0.025\n",
      "0.428892\n",
      "0.428892\n",
      "0.025\n",
      "0.025\n",
      "0.0489578\n",
      "0.0489578\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.095593\n",
      "0.095593\n",
      "0.025\n",
      "0.025\n",
      "0.196068\n",
      "0.196068\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.201522\n",
      "0.201522\n",
      "0.975\n",
      "0.975\n",
      "0.595602\n",
      "0.595602\n",
      "0.025\n",
      "0.025\n",
      "0.35895\n",
      "0.35895\n",
      "0.941501\n",
      "0.941501\n",
      "0.0435193\n",
      "0.0435193\n",
      "0.0599952\n",
      "0.0599952\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.14403\n",
      "0.14403\n",
      "0.940925\n",
      "0.940925\n",
      "0.0523778\n",
      "0.0523778\n",
      "0.440918\n",
      "0.440918\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.195644\n",
      "0.195644\n",
      "0.025\n",
      "0.025\n",
      "0.22187\n",
      "0.22187\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0525805\n",
      "0.0525805\n",
      "0.10383\n",
      "0.10383\n",
      "0.331005\n",
      "0.331005\n",
      "0.975\n",
      "0.975\n",
      "0.936566\n",
      "0.936566\n",
      "0.91155\n",
      "0.91155\n",
      "0.975\n",
      "0.975\n",
      "0.0361703\n",
      "0.0361703\n",
      "0.59916\n",
      "0.59916\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.237505\n",
      "0.237505\n",
      "0.025\n",
      "0.025\n",
      "0.0535178\n",
      "0.0535178\n",
      "0.025\n",
      "0.025\n",
      "0.947068\n",
      "0.947068\n",
      "0.025\n",
      "0.025\n",
      "0.0635843\n",
      "0.0635843\n",
      "0.798147\n",
      "0.798147\n",
      "0.0275715\n",
      "0.0275715\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.932769\n",
      "0.932769\n",
      "0.861306\n",
      "0.861306\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.390821\n",
      "0.390821\n",
      "0.025\n",
      "0.025\n",
      "0.0257897\n",
      "0.0257897\n",
      "0.025\n",
      "0.025\n",
      "0.947213\n",
      "0.947213\n",
      "0.955715\n",
      "0.955715\n",
      "0.92359\n",
      "0.92359\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0944549\n",
      "0.0944549\n",
      "0.025\n",
      "0.025\n",
      "0.0720555\n",
      "0.0720555\n",
      "0.107127\n",
      "0.107127\n",
      "0.884357\n",
      "0.884357\n",
      "0.025\n",
      "0.025\n",
      "0.0934851\n",
      "0.0934851\n",
      "0.89414\n",
      "0.89414\n",
      "0.912208\n",
      "0.912208\n",
      "0.579835\n",
      "0.579835\n",
      "0.025\n",
      "0.025\n",
      "0.174455\n",
      "0.174455\n",
      "0.025\n",
      "0.025\n",
      "0.0437519\n",
      "0.0437519\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0840653\n",
      "0.0840653\n",
      "0.025\n",
      "0.025\n",
      "0.727754\n",
      "0.727754\n",
      "0.214479\n",
      "0.214479\n",
      "0.225363\n",
      "0.225363\n",
      "0.87342\n",
      "0.87342\n",
      "0.343843\n",
      "0.343843\n",
      "0.0666114\n",
      "0.0666114\n",
      "0.954111\n",
      "0.954111\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.437743\n",
      "0.437743\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.960693\n",
      "0.960693\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.895545\n",
      "0.895545\n",
      "0.025\n",
      "0.025\n",
      "0.568193\n",
      "0.568193\n",
      "0.975\n",
      "0.975\n",
      "0.845433\n",
      "0.845433\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0400003\n",
      "0.0400003\n",
      "0.025\n",
      "0.025\n",
      "0.310732\n",
      "0.310732\n",
      "0.025\n",
      "0.025\n",
      "0.17218\n",
      "0.17218\n",
      "0.0260493\n",
      "0.0260493\n",
      "0.0653918\n",
      "0.0653918\n",
      "0.50667\n",
      "0.50667\n",
      "0.743543\n",
      "0.743543\n",
      "0.0943785\n",
      "0.0943785\n",
      "0.945745\n",
      "0.945745\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.944514\n",
      "0.944514\n",
      "0.025\n",
      "0.025\n",
      "0.792085\n",
      "0.792085\n",
      "0.492235\n",
      "0.492235\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.945713\n",
      "0.945713\n",
      "0.1139\n",
      "0.1139\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.125184\n",
      "0.125184\n",
      "0.0522068\n",
      "0.0522068\n",
      "0.12973\n",
      "0.12973\n",
      "0.025\n",
      "0.025\n",
      "0.0856643\n",
      "0.0856643\n",
      "0.0892001\n",
      "0.0892001\n",
      "0.0571258\n",
      "0.0571258\n",
      "0.0627471\n",
      "0.0627471\n",
      "0.275994\n",
      "0.275994\n",
      "0.23336\n",
      "0.23336\n",
      "0.379646\n",
      "0.379646\n",
      "0.869877\n",
      "0.869877\n",
      "0.308449\n",
      "0.308449\n",
      "0.0839599\n",
      "0.0839599\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.636259\n",
      "0.636259\n",
      "0.933586\n",
      "0.933586\n",
      "0.138779\n",
      "0.138779\n",
      "0.927057\n",
      "0.927057\n",
      "0.81337\n",
      "0.81337\n",
      "0.0784469\n",
      "0.0784469\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.164041\n",
      "0.164041\n",
      "0.177312\n",
      "0.177312\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.935911\n",
      "0.935911\n",
      "0.829383\n",
      "0.829383\n",
      "0.0294573\n",
      "0.0294573\n",
      "0.0551368\n",
      "0.0551368\n",
      "0.0252043\n",
      "0.0252043\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.114663\n",
      "0.114663\n",
      "0.975\n",
      "0.975\n",
      "0.500334\n",
      "0.500334\n",
      "0.025\n",
      "0.025\n",
      "0.259529\n",
      "0.259529\n",
      "0.748062\n",
      "0.748062\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.810245\n",
      "0.810245\n",
      "0.025\n",
      "0.025\n",
      "0.0283882\n",
      "0.0283882\n",
      "0.823361\n",
      "0.823361\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.954319\n",
      "0.954319\n",
      "0.5989\n",
      "0.5989\n",
      "0.140277\n",
      "0.140277\n",
      "0.884652\n",
      "0.884652\n",
      "0.599108\n",
      "0.599108\n",
      "0.0666683\n",
      "0.0666683\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.73377\n",
      "0.73377\n",
      "0.025\n",
      "0.025\n",
      "0.240155\n",
      "0.240155\n",
      "0.025\n",
      "0.025\n",
      "0.162322\n",
      "0.162322\n",
      "0.487414\n",
      "0.487414\n",
      "0.025\n",
      "0.025\n",
      "0.110624\n",
      "0.110624\n",
      "0.455375\n",
      "0.455375\n",
      "0.025\n",
      "0.025\n",
      "0.0393615\n",
      "0.0393615\n",
      "0.025\n",
      "0.025\n",
      "0.0460302\n",
      "0.0460302\n",
      "0.025\n",
      "0.025\n",
      "0.169261\n",
      "0.169261\n",
      "0.500946\n",
      "0.500946\n",
      "0.975\n",
      "0.975\n",
      "0.216405\n",
      "0.216405\n",
      "0.372669\n",
      "0.372669\n",
      "0.025\n",
      "0.025\n",
      "0.164423\n",
      "0.164423\n",
      "0.0797544\n",
      "0.0797544\n",
      "0.025\n",
      "0.025\n",
      "0.164179\n",
      "0.164179\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.159758\n",
      "0.159758\n",
      "0.025\n",
      "0.025\n",
      "0.049253\n",
      "0.049253\n",
      "0.246741\n",
      "0.246741\n",
      "0.025\n",
      "0.025\n",
      "0.558308\n",
      "0.558308\n",
      "0.0709282\n",
      "0.0709282\n",
      "0.025\n",
      "0.025\n",
      "0.808919\n",
      "0.808919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.116055\n",
      "0.116055\n",
      "0.0372278\n",
      "0.0372278\n",
      "0.975\n",
      "0.975\n",
      "0.842792\n",
      "0.842792\n",
      "0.841917\n",
      "0.841917\n",
      "0.436151\n",
      "0.436151\n",
      "0.224939\n",
      "0.224939\n",
      "0.0670489\n",
      "0.0670489\n",
      "0.414836\n",
      "0.414836\n",
      "0.0710129\n",
      "0.0710129\n",
      "0.693863\n",
      "0.693863\n",
      "0.107211\n",
      "0.107211\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.076051\n",
      "0.076051\n",
      "0.025\n",
      "0.025\n",
      "0.0741337\n",
      "0.0741337\n",
      "0.0951103\n",
      "0.0951103\n",
      "0.0627026\n",
      "0.0627026\n",
      "0.0594068\n",
      "0.0594068\n",
      "0.025\n",
      "0.025\n",
      "0.0759522\n",
      "0.0759522\n",
      "0.19677\n",
      "0.19677\n",
      "0.025\n",
      "0.025\n",
      "0.0571028\n",
      "0.0571028\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0713704\n",
      "0.0713704\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.598842\n",
      "0.598842\n",
      "0.952286\n",
      "0.952286\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.654825\n",
      "0.654825\n",
      "0.0328933\n",
      "0.0328933\n",
      "0.174101\n",
      "0.174101\n",
      "0.0257486\n",
      "0.0257486\n",
      "0.025\n",
      "0.025\n",
      "0.207208\n",
      "0.207208\n",
      "0.025\n",
      "0.025\n",
      "0.154007\n",
      "0.154007\n",
      "0.113828\n",
      "0.113828\n",
      "0.149014\n",
      "0.149014\n",
      "0.903128\n",
      "0.903128\n",
      "0.361058\n",
      "0.361058\n",
      "0.0800546\n",
      "0.0800546\n",
      "0.850076\n",
      "0.850076\n",
      "0.025\n",
      "0.025\n",
      "0.337046\n",
      "0.337046\n",
      "0.170801\n",
      "0.170801\n",
      "0.971791\n",
      "0.971791\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.969508\n",
      "0.969508\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.353653\n",
      "0.353653\n",
      "0.0405125\n",
      "0.0405125\n",
      "0.025\n",
      "0.025\n",
      "0.0834952\n",
      "0.0834952\n",
      "0.822489\n",
      "0.822489\n",
      "0.025\n",
      "0.025\n",
      "0.0441031\n",
      "0.0441031\n",
      "0.594657\n",
      "0.594657\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.301658\n",
      "0.301658\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0457738\n",
      "0.0457738\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.895949\n",
      "0.895949\n",
      "0.965567\n",
      "0.965567\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.472067\n",
      "0.472067\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.063457\n",
      "0.063457\n",
      "0.0534692\n",
      "0.0534692\n",
      "0.944397\n",
      "0.944397\n",
      "0.0351229\n",
      "0.0351229\n",
      "0.171617\n",
      "0.171617\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.186449\n",
      "0.186449\n",
      "0.025\n",
      "0.025\n",
      "0.939146\n",
      "0.939146\n",
      "0.975\n",
      "0.975\n",
      "0.911388\n",
      "0.911388\n",
      "0.0412159\n",
      "0.0412159\n",
      "0.025\n",
      "0.025\n",
      "0.0700621\n",
      "0.0700621\n",
      "0.0937055\n",
      "0.0937055\n",
      "0.792899\n",
      "0.792899\n",
      "0.947302\n",
      "0.947302\n",
      "0.139663\n",
      "0.139663\n",
      "0.0515308\n",
      "0.0515308\n",
      "0.025\n",
      "0.025\n",
      "0.0531873\n",
      "0.0531873\n",
      "0.088018\n",
      "0.088018\n",
      "0.226369\n",
      "0.226369\n",
      "0.025\n",
      "0.025\n",
      "0.834233\n",
      "0.834233\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0338781\n",
      "0.0338781\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.896345\n",
      "0.896345\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.955448\n",
      "0.955448\n",
      "0.937007\n",
      "0.937007\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.294691\n",
      "0.294691\n",
      "0.148506\n",
      "0.148506\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.250855\n",
      "0.250855\n",
      "0.025\n",
      "0.025\n",
      "0.557961\n",
      "0.557961\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.18052\n",
      "0.18052\n",
      "0.480329\n",
      "0.480329\n",
      "0.025\n",
      "0.025\n",
      "0.280369\n",
      "0.280369\n",
      "0.0504441\n",
      "0.0504441\n",
      "0.70166\n",
      "0.70166\n",
      "0.194669\n",
      "0.194669\n",
      "0.639103\n",
      "0.639103\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.134313\n",
      "0.134313\n",
      "0.0407224\n",
      "0.0407224\n",
      "0.025\n",
      "0.025\n",
      "0.152848\n",
      "0.152848\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.50527\n",
      "0.50527\n",
      "0.025\n",
      "0.025\n",
      "0.741244\n",
      "0.741244\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.86384\n",
      "0.86384\n",
      "0.639832\n",
      "0.639832\n",
      "0.0545639\n",
      "0.0545639\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.403478\n",
      "0.403478\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.191678\n",
      "0.191678\n",
      "0.810062\n",
      "0.810062\n",
      "0.372427\n",
      "0.372427\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.173787\n",
      "0.173787\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.415165\n",
      "0.415165\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.235672\n",
      "0.235672\n",
      "0.025\n",
      "0.025\n",
      "0.0564047\n",
      "0.0564047\n",
      "0.025\n",
      "0.025\n",
      "0.177168\n",
      "0.177168\n",
      "0.749831\n",
      "0.749831\n",
      "0.0454226\n",
      "0.0454226\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.11368\n",
      "0.11368\n",
      "0.209131\n",
      "0.209131\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.138884\n",
      "0.138884\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.10665\n",
      "0.10665\n",
      "0.166399\n",
      "0.166399\n",
      "0.025\n",
      "0.025\n",
      "0.0375768\n",
      "0.0375768\n",
      "0.644745\n",
      "0.644745\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0424617\n",
      "0.0424617\n",
      "0.025\n",
      "0.025\n",
      "0.129557\n",
      "0.129557\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0677895\n",
      "0.0677895\n",
      "0.025\n",
      "0.025\n",
      "0.0565185\n",
      "0.0565185\n",
      "0.131789\n",
      "0.131789\n",
      "0.025\n",
      "0.025\n",
      "0.441886\n",
      "0.441886\n",
      "0.025\n",
      "0.025\n",
      "0.0535482\n",
      "0.0535482\n",
      "0.0657095\n",
      "0.0657095\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.554996\n",
      "0.554996\n",
      "0.340068\n",
      "0.340068\n",
      "0.885841\n",
      "0.885841\n",
      "0.975\n",
      "0.975\n",
      "0.0462527\n",
      "0.0462527\n",
      "0.0315776\n",
      "0.0315776\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0967085\n",
      "0.0967085\n",
      "0.025\n",
      "0.025\n",
      "0.968634\n",
      "0.968634\n",
      "0.025\n",
      "0.025\n",
      "0.168858\n",
      "0.168858\n",
      "0.968582\n",
      "0.968582\n",
      "0.0882198\n",
      "0.0882198\n",
      "0.025\n",
      "0.025\n",
      "0.22496\n",
      "0.22496\n",
      "0.975\n",
      "0.975\n",
      "0.0280896\n",
      "0.0280896\n",
      "0.681925\n",
      "0.681925\n",
      "0.102504\n",
      "0.102504\n",
      "0.025\n",
      "0.025\n",
      "0.396797\n",
      "0.396797\n",
      "0.567309\n",
      "0.567309\n",
      "0.0702612\n",
      "0.0702612\n",
      "0.025\n",
      "0.025\n",
      "0.0282286\n",
      "0.0282286\n",
      "0.27085\n",
      "0.27085\n",
      "0.0811811\n",
      "0.0811811\n",
      "0.025\n",
      "0.025\n",
      "0.568458\n",
      "0.568458\n",
      "0.151556\n",
      "0.151556\n",
      "0.232106\n",
      "0.232106\n",
      "0.0964609\n",
      "0.0964609\n",
      "0.027944\n",
      "0.027944\n",
      "0.025\n",
      "0.025\n",
      "0.0323815\n",
      "0.0323815\n",
      "0.025\n",
      "0.025\n",
      "0.379971\n",
      "0.379971\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0551092\n",
      "0.0551092\n",
      "0.964632\n",
      "0.964632\n",
      "0.025\n",
      "0.025\n",
      "0.284891\n",
      "0.284891\n",
      "0.025\n",
      "0.025\n",
      "0.553668\n",
      "0.553668\n",
      "0.954748\n",
      "0.954748\n",
      "0.296316\n",
      "0.296316\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.103056\n",
      "0.103056\n",
      "0.814751\n",
      "0.814751\n",
      "0.562453\n",
      "0.562453\n",
      "0.0597995\n",
      "0.0597995\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.244997\n",
      "0.244997\n",
      "0.025\n",
      "0.025\n",
      "0.196268\n",
      "0.196268\n",
      "0.485903\n",
      "0.485903\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0897788\n",
      "0.0897788\n",
      "0.025\n",
      "0.025\n",
      "0.0801161\n",
      "0.0801161\n",
      "0.025\n",
      "0.025\n",
      "0.920564\n",
      "0.920564\n",
      "0.975\n",
      "0.975\n",
      "0.0409167\n",
      "0.0409167\n",
      "0.222587\n",
      "0.222587\n",
      "0.583992\n",
      "0.583992\n",
      "0.0474322\n",
      "0.0474322\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.115315\n",
      "0.115315\n",
      "0.0587239\n",
      "0.0587239\n",
      "0.025\n",
      "0.025\n",
      "0.940674\n",
      "0.940674\n",
      "0.803769\n",
      "0.803769\n",
      "0.025\n",
      "0.025\n",
      "0.738234\n",
      "0.738234\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.848318\n",
      "0.848318\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.204966\n",
      "0.204966\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.963166\n",
      "0.963166\n",
      "0.0558794\n",
      "0.0558794\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.137268\n",
      "0.137268\n",
      "0.0729472\n",
      "0.0729472\n",
      "0.188463\n",
      "0.188463\n",
      "0.025\n",
      "0.025\n",
      "0.518954\n",
      "0.518954\n",
      "0.918498\n",
      "0.918498\n",
      "0.11493\n",
      "0.11493\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.877037\n",
      "0.877037\n",
      "0.679906\n",
      "0.679906\n",
      "0.975\n",
      "0.975\n",
      "0.552975\n",
      "0.552975\n",
      "0.402931\n",
      "0.402931\n",
      "0.025\n",
      "0.025\n",
      "0.688098\n",
      "0.688098\n",
      "0.025\n",
      "0.025\n",
      "0.73667\n",
      "0.73667\n",
      "0.975\n",
      "0.975\n",
      "0.926252\n",
      "0.926252\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0558334\n",
      "0.0558334\n",
      "0.975\n",
      "0.975\n",
      "0.520977\n",
      "0.520977\n",
      "0.025\n",
      "0.025\n",
      "0.908918\n",
      "0.908918\n",
      "0.4481\n",
      "0.4481\n",
      "0.975\n",
      "0.975\n",
      "0.573492\n",
      "0.573492\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.112924\n",
      "0.112924\n",
      "0.025\n",
      "0.025\n",
      "0.11764\n",
      "0.11764\n",
      "0.069548\n",
      "0.069548\n",
      "0.87685\n",
      "0.87685\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.141064\n",
      "0.141064\n",
      "0.254132\n",
      "0.254132\n",
      "0.025\n",
      "0.025\n",
      "0.163188\n",
      "0.163188\n",
      "0.386746\n",
      "0.386746\n",
      "0.12719\n",
      "0.12719\n",
      "0.0529428\n",
      "0.0529428\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.244611\n",
      "0.244611\n",
      "0.231204\n",
      "0.231204\n",
      "0.384407\n",
      "0.384407\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.15388\n",
      "0.15388\n",
      "0.080915\n",
      "0.080915\n",
      "0.0403977\n",
      "0.0403977\n",
      "0.613882\n",
      "0.613882\n",
      "0.101478\n",
      "0.101478\n",
      "0.085459\n",
      "0.085459\n",
      "0.975\n",
      "0.975\n",
      "0.729449\n",
      "0.729449\n",
      "0.539254\n",
      "0.539254\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.746758\n",
      "0.746758\n",
      "0.115807\n",
      "0.115807\n",
      "0.152898\n",
      "0.152898\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.336595\n",
      "0.336595\n",
      "0.149816\n",
      "0.149816\n",
      "0.0280524\n",
      "0.0280524\n",
      "0.534841\n",
      "0.534841\n",
      "0.0340438\n",
      "0.0340438\n",
      "0.0567121\n",
      "0.0567121\n",
      "0.268526\n",
      "0.268526\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0659975\n",
      "0.0659975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0783883\n",
      "0.0783883\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.238983\n",
      "0.238983\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.266031\n",
      "0.266031\n",
      "0.025\n",
      "0.025\n",
      "0.178131\n",
      "0.178131\n",
      "0.772126\n",
      "0.772126\n",
      "0.0348531\n",
      "0.0348531\n",
      "0.0302334\n",
      "0.0302334\n",
      "0.0564487\n",
      "0.0564487\n",
      "0.975\n",
      "0.975\n",
      "0.0485672\n",
      "0.0485672\n",
      "0.102445\n",
      "0.102445\n",
      "0.025\n",
      "0.025\n",
      "0.724667\n",
      "0.724667\n",
      "0.352957\n",
      "0.352957\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.115449\n",
      "0.115449\n",
      "0.224871\n",
      "0.224871\n",
      "0.0870387\n",
      "0.0870387\n",
      "0.898191\n",
      "0.898191\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.491352\n",
      "0.491352\n",
      "0.858603\n",
      "0.858603\n",
      "0.025\n",
      "0.025\n",
      "0.0291056\n",
      "0.0291056\n",
      "0.59389\n",
      "0.59389\n",
      "0.0978786\n",
      "0.0978786\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.105539\n",
      "0.105539\n",
      "0.025\n",
      "0.025\n",
      "0.233324\n",
      "0.233324\n",
      "0.604983\n",
      "0.604983\n",
      "0.975\n",
      "0.975\n",
      "0.0690905\n",
      "0.0690905\n",
      "0.087339\n",
      "0.087339\n",
      "0.167521\n",
      "0.167521\n",
      "0.493355\n",
      "0.493355\n",
      "0.025\n",
      "0.025\n",
      "0.0693562\n",
      "0.0693562\n",
      "0.025\n",
      "0.025\n",
      "0.589529\n",
      "0.589529\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.389328\n",
      "0.389328\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.180941\n",
      "0.180941\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.199027\n",
      "0.199027\n",
      "0.332126\n",
      "0.332126\n",
      "0.424015\n",
      "0.424015\n",
      "0.025\n",
      "0.025\n",
      "0.0683766\n",
      "0.0683766\n",
      "0.025\n",
      "0.025\n",
      "0.223883\n",
      "0.223883\n",
      "0.025\n",
      "0.025\n",
      "0.336913\n",
      "0.336913\n",
      "0.938577\n",
      "0.938577\n",
      "0.025\n",
      "0.025\n",
      "0.0691301\n",
      "0.0691301\n",
      "0.940898\n",
      "0.940898\n",
      "0.025\n",
      "0.025\n",
      "0.391392\n",
      "0.391392\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0779112\n",
      "0.0779112\n",
      "0.791785\n",
      "0.791785\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.828935\n",
      "0.828935\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.818894\n",
      "0.818894\n",
      "0.274655\n",
      "0.274655\n",
      "0.159741\n",
      "0.159741\n",
      "0.975\n",
      "0.975\n",
      "0.0376152\n",
      "0.0376152\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.707445\n",
      "0.707445\n",
      "0.786932\n",
      "0.786932\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0336858\n",
      "0.0336858\n",
      "0.025\n",
      "0.025\n",
      "0.194948\n",
      "0.194948\n",
      "0.025\n",
      "0.025\n",
      "0.874371\n",
      "0.874371\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.874907\n",
      "0.874907\n",
      "0.375131\n",
      "0.375131\n",
      "0.230876\n",
      "0.230876\n",
      "0.975\n",
      "0.975\n",
      "0.247722\n",
      "0.247722\n",
      "0.682712\n",
      "0.682712\n",
      "0.910829\n",
      "0.910829\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.960286\n",
      "0.960286\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.392865\n",
      "0.392865\n",
      "0.0280721\n",
      "0.0280721\n",
      "0.164255\n",
      "0.164255\n",
      "0.070767\n",
      "0.070767\n",
      "0.211458\n",
      "0.211458\n",
      "0.826145\n",
      "0.826145\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0658662\n",
      "0.0658662\n",
      "0.0620701\n",
      "0.0620701\n",
      "0.164729\n",
      "0.164729\n",
      "0.975\n",
      "0.975\n",
      "0.0691053\n",
      "0.0691053\n",
      "0.856018\n",
      "0.856018\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.115488\n",
      "0.115488\n",
      "0.104127\n",
      "0.104127\n",
      "0.025\n",
      "0.025\n",
      "0.0765478\n",
      "0.0765478\n",
      "0.888723\n",
      "0.888723\n",
      "0.025\n",
      "0.025\n",
      "0.0607917\n",
      "0.0607917\n",
      "0.767233\n",
      "0.767233\n",
      "0.043302\n",
      "0.043302\n",
      "0.306114\n",
      "0.306114\n",
      "0.0639041\n",
      "0.0639041\n",
      "0.445818\n",
      "0.445818\n",
      "0.047578\n",
      "0.047578\n",
      "0.025\n",
      "0.025\n",
      "0.0491891\n",
      "0.0491891\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0402667\n",
      "0.0402667\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.428595\n",
      "0.428595\n",
      "0.148504\n",
      "0.148504\n",
      "0.122179\n",
      "0.122179\n",
      "0.025\n",
      "0.025\n",
      "0.0774721\n",
      "0.0774721\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.255072\n",
      "0.255072\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.175752\n",
      "0.175752\n",
      "0.975\n",
      "0.975\n",
      "0.30365\n",
      "0.30365\n",
      "0.975\n",
      "0.975\n",
      "0.0719956\n",
      "0.0719956\n",
      "0.0259733\n",
      "0.0259733\n",
      "0.0456704\n",
      "0.0456704\n",
      "0.025\n",
      "0.025\n",
      "0.149843\n",
      "0.149843\n",
      "0.0797265\n",
      "0.0797265\n",
      "0.460996\n",
      "0.460996\n",
      "0.740769\n",
      "0.740769\n",
      "0.199746\n",
      "0.199746\n",
      "0.580426\n",
      "0.580426\n",
      "0.109037\n",
      "0.109037\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0746035\n",
      "0.0746035\n",
      "0.215455\n",
      "0.215455\n",
      "0.025\n",
      "0.025\n",
      "0.065461\n",
      "0.065461\n",
      "0.281203\n",
      "0.281203\n",
      "0.0360216\n",
      "0.0360216\n",
      "0.025\n",
      "0.025\n",
      "0.123016\n",
      "0.123016\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.131643\n",
      "0.131643\n",
      "0.025\n",
      "0.025\n",
      "0.778702\n",
      "0.778702\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.136722\n",
      "0.136722\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0633352\n",
      "0.0633352\n",
      "0.025\n",
      "0.025\n",
      "0.0276659\n",
      "0.0276659\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0401483\n",
      "0.0401483\n",
      "0.0373299\n",
      "0.0373299\n",
      "0.0793224\n",
      "0.0793224\n",
      "0.543793\n",
      "0.543793\n",
      "0.0394619\n",
      "0.0394619\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.189734\n",
      "0.189734\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.202235\n",
      "0.202235\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.238347\n",
      "0.238347\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0810724\n",
      "0.0810724\n",
      "0.025\n",
      "0.025\n",
      "0.529985\n",
      "0.529985\n",
      "0.0653327\n",
      "0.0653327\n",
      "0.025\n",
      "0.025\n",
      "0.0753534\n",
      "0.0753534\n",
      "0.025\n",
      "0.025\n",
      "0.672834\n",
      "0.672834\n",
      "0.025\n",
      "0.025\n",
      "0.336256\n",
      "0.336256\n",
      "0.025\n",
      "0.025\n",
      "0.566448\n",
      "0.566448\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.691831\n",
      "0.691831\n",
      "0.0290227\n",
      "0.0290227\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0285289\n",
      "0.0285289\n",
      "0.141384\n",
      "0.141384\n",
      "0.950976\n",
      "0.950976\n",
      "0.918628\n",
      "0.918628\n",
      "0.0341553\n",
      "0.0341553\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.146467\n",
      "0.146467\n",
      "0.298894\n",
      "0.298894\n",
      "0.714478\n",
      "0.714478\n",
      "0.025\n",
      "0.025\n",
      "0.0873863\n",
      "0.0873863\n",
      "0.964346\n",
      "0.964346\n",
      "0.135753\n",
      "0.135753\n",
      "0.025\n",
      "0.025\n",
      "0.89729\n",
      "0.89729\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.424324\n",
      "0.424324\n",
      "0.105509\n",
      "0.105509\n",
      "0.025\n",
      "0.025\n",
      "0.217487\n",
      "0.217487\n",
      "0.162198\n",
      "0.162198\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.966928\n",
      "0.966928\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.769101\n",
      "0.769101\n",
      "0.170887\n",
      "0.170887\n",
      "0.0719629\n",
      "0.0719629\n",
      "0.292361\n",
      "0.292361\n",
      "0.025\n",
      "0.025\n",
      "0.207066\n",
      "0.207066\n",
      "0.232739\n",
      "0.232739\n",
      "0.292347\n",
      "0.292347\n",
      "0.975\n",
      "0.975\n",
      "0.0647829\n",
      "0.0647829\n",
      "0.101833\n",
      "0.101833\n",
      "0.025\n",
      "0.025\n",
      "0.680362\n",
      "0.680362\n",
      "0.025\n",
      "0.025\n",
      "0.0848727\n",
      "0.0848727\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.037181\n",
      "0.037181\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0878466\n",
      "0.0878466\n",
      "0.0685167\n",
      "0.0685167\n",
      "0.0683971\n",
      "0.0683971\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.47262\n",
      "0.47262\n",
      "0.975\n",
      "0.975\n",
      "0.784466\n",
      "0.784466\n",
      "0.146394\n",
      "0.146394\n",
      "0.187187\n",
      "0.187187\n",
      "0.739354\n",
      "0.739354\n",
      "0.38668\n",
      "0.38668\n",
      "0.109328\n",
      "0.109328\n",
      "0.224198\n",
      "0.224198\n",
      "0.0319764\n",
      "0.0319764\n",
      "0.623188\n",
      "0.623188\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.028475\n",
      "0.028475\n",
      "0.346273\n",
      "0.346273\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.93383\n",
      "0.93383\n",
      "0.17484\n",
      "0.17484\n",
      "0.025\n",
      "0.025\n",
      "0.344705\n",
      "0.344705\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.954804\n",
      "0.954804\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.103239\n",
      "0.103239\n",
      "0.350807\n",
      "0.350807\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0709212\n",
      "0.0709212\n",
      "0.830585\n",
      "0.830585\n",
      "0.065978\n",
      "0.065978\n",
      "0.025\n",
      "0.025\n",
      "0.284647\n",
      "0.284647\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.372179\n",
      "0.372179\n",
      "0.105779\n",
      "0.105779\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.100868\n",
      "0.100868\n",
      "0.706107\n",
      "0.706107\n",
      "0.128017\n",
      "0.128017\n",
      "0.449312\n",
      "0.449312\n",
      "0.973952\n",
      "0.973952\n",
      "0.0451516\n",
      "0.0451516\n",
      "0.025\n",
      "0.025\n",
      "0.450976\n",
      "0.450976\n",
      "0.0516199\n",
      "0.0516199\n",
      "0.378593\n",
      "0.378593\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.139096\n",
      "0.139096\n",
      "0.025\n",
      "0.025\n",
      "0.292866\n",
      "0.292866\n",
      "0.923743\n",
      "0.923743\n",
      "0.025\n",
      "0.025\n",
      "0.788238\n",
      "0.788238\n",
      "0.590742\n",
      "0.590742\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.62478\n",
      "0.62478\n",
      "0.025\n",
      "0.025\n",
      "0.867043\n",
      "0.867043\n",
      "0.025\n",
      "0.025\n",
      "0.0581716\n",
      "0.0581716\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.856401\n",
      "0.856401\n",
      "0.975\n",
      "0.975\n",
      "0.901374\n",
      "0.901374\n",
      "0.901174\n",
      "0.901174\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.920481\n",
      "0.920481\n",
      "0.975\n",
      "0.975\n",
      "0.160431\n",
      "0.160431\n",
      "0.0836589\n",
      "0.0836589\n",
      "0.415662\n",
      "0.415662\n",
      "0.414733\n",
      "0.414733\n",
      "0.025\n",
      "0.025\n",
      "0.027287\n",
      "0.027287\n",
      "0.144923\n",
      "0.144923\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.957189\n",
      "0.957189\n",
      "0.140474\n",
      "0.140474\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.934023\n",
      "0.934023\n",
      "0.975\n",
      "0.975\n",
      "0.0780805\n",
      "0.0780805\n",
      "0.163986\n",
      "0.163986\n",
      "0.025\n",
      "0.025\n",
      "0.63962\n",
      "0.63962\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0413991\n",
      "0.0413991\n",
      "0.0795915\n",
      "0.0795915\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.436705\n",
      "0.436705\n",
      "0.025\n",
      "0.025\n",
      "0.769602\n",
      "0.769602\n",
      "0.025\n",
      "0.025\n",
      "0.11399\n",
      "0.11399\n",
      "0.23864\n",
      "0.23864\n",
      "0.0371324\n",
      "0.0371324\n",
      "0.025\n",
      "0.025\n",
      "0.297839\n",
      "0.297839\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.493612\n",
      "0.493612\n",
      "0.919896\n",
      "0.919896\n",
      "0.025\n",
      "0.025\n",
      "0.299748\n",
      "0.299748\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.265183\n",
      "0.265183\n",
      "0.310915\n",
      "0.310915\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.830498\n",
      "0.830498\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.51702\n",
      "0.51702\n",
      "0.025\n",
      "0.025\n",
      "0.929486\n",
      "0.929486\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0255303\n",
      "0.0255303\n",
      "0.20782\n",
      "0.20782\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.282565\n",
      "0.282565\n",
      "0.920469\n",
      "0.920469\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.966643\n",
      "0.966643\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.829467\n",
      "0.829467\n",
      "0.302345\n",
      "0.302345\n",
      "0.823523\n",
      "0.823523\n",
      "0.0434042\n",
      "0.0434042\n",
      "0.0289394\n",
      "0.0289394\n",
      "0.0688022\n",
      "0.0688022\n",
      "0.213565\n",
      "0.213565\n",
      "0.0844675\n",
      "0.0844675\n",
      "0.025\n",
      "0.025\n",
      "0.0557678\n",
      "0.0557678\n",
      "0.043675\n",
      "0.043675\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.417054\n",
      "0.417054\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0521481\n",
      "0.0521481\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.110169\n",
      "0.110169\n",
      "0.0381209\n",
      "0.0381209\n",
      "0.0595903\n",
      "0.0595903\n",
      "0.975\n",
      "0.975\n",
      "0.905279\n",
      "0.905279\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.3098\n",
      "0.3098\n",
      "0.965009\n",
      "0.965009\n",
      "0.0321717\n",
      "0.0321717\n",
      "0.025\n",
      "0.025\n",
      "0.0801627\n",
      "0.0801627\n",
      "0.975\n",
      "0.975\n",
      "0.040755\n",
      "0.040755\n",
      "0.321402\n",
      "0.321402\n",
      "0.025\n",
      "0.025\n",
      "0.282225\n",
      "0.282225\n",
      "0.75905\n",
      "0.75905\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.59064\n",
      "0.59064\n",
      "0.217143\n",
      "0.217143\n",
      "0.975\n",
      "0.975\n",
      "0.22259\n",
      "0.22259\n",
      "0.942342\n",
      "0.942342\n",
      "0.975\n",
      "0.975\n",
      "0.77894\n",
      "0.77894\n",
      "0.398714\n",
      "0.398714\n",
      "0.025\n",
      "0.025\n",
      "0.0631251\n",
      "0.0631251\n",
      "0.131596\n",
      "0.131596\n",
      "0.0552619\n",
      "0.0552619\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0647445\n",
      "0.0647445\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0420593\n",
      "0.0420593\n",
      "0.975\n",
      "0.975\n",
      "0.952722\n",
      "0.952722\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.130553\n",
      "0.130553\n",
      "0.025\n",
      "0.025\n",
      "0.221828\n",
      "0.221828\n",
      "0.467277\n",
      "0.467277\n",
      "0.025\n",
      "0.025\n",
      "0.712799\n",
      "0.712799\n",
      "0.047534\n",
      "0.047534\n",
      "0.226839\n",
      "0.226839\n",
      "0.025\n",
      "0.025\n",
      "0.613044\n",
      "0.613044\n",
      "0.025\n",
      "0.025\n",
      "0.0273308\n",
      "0.0273308\n",
      "0.0342425\n",
      "0.0342425\n",
      "0.492138\n",
      "0.492138\n",
      "0.110502\n",
      "0.110502\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.219192\n",
      "0.219192\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.315751\n",
      "0.315751\n",
      "0.025\n",
      "0.025\n",
      "0.956538\n",
      "0.956538\n",
      "0.025\n",
      "0.025\n",
      "0.130422\n",
      "0.130422\n",
      "0.514404\n",
      "0.514404\n",
      "0.0892418\n",
      "0.0892418\n",
      "0.139124\n",
      "0.139124\n",
      "0.0301149\n",
      "0.0301149\n",
      "0.975\n",
      "0.975\n",
      "0.0321846\n",
      "0.0321846\n",
      "0.553922\n",
      "0.553922\n",
      "0.756995\n",
      "0.756995\n",
      "0.0584276\n",
      "0.0584276\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.870389\n",
      "0.870389\n",
      "0.0320397\n",
      "0.0320397\n",
      "0.0365155\n",
      "0.0365155\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0398074\n",
      "0.0398074\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0765024\n",
      "0.0765024\n",
      "0.0384157\n",
      "0.0384157\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.029682\n",
      "0.029682\n",
      "0.975\n",
      "0.975\n",
      "0.972269\n",
      "0.972269\n",
      "0.682937\n",
      "0.682937\n",
      "0.025\n",
      "0.025\n",
      "0.160459\n",
      "0.160459\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.527711\n",
      "0.527711\n",
      "0.0882923\n",
      "0.0882923\n",
      "0.255211\n",
      "0.255211\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.819079\n",
      "0.819079\n",
      "0.567143\n",
      "0.567143\n",
      "0.112515\n",
      "0.112515\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.963804\n",
      "0.963804\n",
      "0.025\n",
      "0.025\n",
      "0.0257952\n",
      "0.0257952\n",
      "0.975\n",
      "0.975\n",
      "0.739228\n",
      "0.739228\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.190225\n",
      "0.190225\n",
      "0.975\n",
      "0.975\n",
      "0.0595303\n",
      "0.0595303\n",
      "0.025\n",
      "0.025\n",
      "0.0317085\n",
      "0.0317085\n",
      "0.025\n",
      "0.025\n",
      "0.0447438\n",
      "0.0447438\n",
      "0.122902\n",
      "0.122902\n",
      "0.580439\n",
      "0.580439\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.409254\n",
      "0.409254\n",
      "0.025\n",
      "0.025\n",
      "0.613633\n",
      "0.613633\n",
      "0.0299203\n",
      "0.0299203\n",
      "0.731606\n",
      "0.731606\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.389522\n",
      "0.389522\n",
      "0.876351\n",
      "0.876351\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.72146\n",
      "0.72146\n",
      "0.025\n",
      "0.025\n",
      "0.608245\n",
      "0.608245\n",
      "0.841828\n",
      "0.841828\n",
      "0.102498\n",
      "0.102498\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.318149\n",
      "0.318149\n",
      "0.0293432\n",
      "0.0293432\n",
      "0.025\n",
      "0.025\n",
      "0.222443\n",
      "0.222443\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0772268\n",
      "0.0772268\n",
      "0.025\n",
      "0.025\n",
      "0.0421935\n",
      "0.0421935\n",
      "0.975\n",
      "0.975\n",
      "0.228774\n",
      "0.228774\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.884343\n",
      "0.884343\n",
      "0.269548\n",
      "0.269548\n",
      "0.975\n",
      "0.975\n",
      "0.868114\n",
      "0.868114\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0561848\n",
      "0.0561848\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0556498\n",
      "0.0556498\n",
      "0.975\n",
      "0.975\n",
      "0.0513644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0513644\n",
      "0.300184\n",
      "0.300184\n",
      "0.025\n",
      "0.025\n",
      "0.206176\n",
      "0.206176\n",
      "0.134271\n",
      "0.134271\n",
      "0.127896\n",
      "0.127896\n",
      "0.975\n",
      "0.975\n",
      "0.453902\n",
      "0.453902\n",
      "0.665471\n",
      "0.665471\n",
      "0.106418\n",
      "0.106418\n",
      "0.861346\n",
      "0.861346\n",
      "0.0265883\n",
      "0.0265883\n",
      "0.521707\n",
      "0.521707\n",
      "0.025\n",
      "0.025\n",
      "0.18946\n",
      "0.18946\n",
      "0.0410161\n",
      "0.0410161\n",
      "0.0368347\n",
      "0.0368347\n",
      "0.108509\n",
      "0.108509\n",
      "0.100823\n",
      "0.100823\n",
      "0.9393\n",
      "0.9393\n",
      "0.895268\n",
      "0.895268\n",
      "0.356274\n",
      "0.356274\n",
      "0.356992\n",
      "0.356992\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.595665\n",
      "0.595665\n",
      "0.47533\n",
      "0.47533\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.96823\n",
      "0.96823\n",
      "0.0389544\n",
      "0.0389544\n",
      "0.9003\n",
      "0.9003\n",
      "0.398366\n",
      "0.398366\n",
      "0.132556\n",
      "0.132556\n",
      "0.145826\n",
      "0.145826\n",
      "0.212657\n",
      "0.212657\n",
      "0.119876\n",
      "0.119876\n",
      "0.025\n",
      "0.025\n",
      "0.317515\n",
      "0.317515\n",
      "0.733209\n",
      "0.733209\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.864617\n",
      "0.864617\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0553301\n",
      "0.0553301\n",
      "0.207811\n",
      "0.207811\n",
      "0.025\n",
      "0.025\n",
      "0.0733645\n",
      "0.0733645\n",
      "0.025\n",
      "0.025\n",
      "0.452914\n",
      "0.452914\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.840006\n",
      "0.840006\n",
      "0.200725\n",
      "0.200725\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.538932\n",
      "0.538932\n",
      "0.844441\n",
      "0.844441\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.278836\n",
      "0.278836\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0944638\n",
      "0.0944638\n",
      "0.0750218\n",
      "0.0750218\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.835704\n",
      "0.835704\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.535684\n",
      "0.535684\n",
      "0.793882\n",
      "0.793882\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0868481\n",
      "0.0868481\n",
      "0.230022\n",
      "0.230022\n",
      "0.975\n",
      "0.975\n",
      "0.0296306\n",
      "0.0296306\n",
      "0.129927\n",
      "0.129927\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.925417\n",
      "0.925417\n",
      "0.025\n",
      "0.025\n",
      "0.136867\n",
      "0.136867\n",
      "0.0324641\n",
      "0.0324641\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.889003\n",
      "0.889003\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.864267\n",
      "0.864267\n",
      "0.094888\n",
      "0.094888\n",
      "0.025\n",
      "0.025\n",
      "0.618126\n",
      "0.618126\n",
      "0.172967\n",
      "0.172967\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0279135\n",
      "0.0279135\n",
      "0.975\n",
      "0.975\n",
      "0.0252934\n",
      "0.0252934\n",
      "0.025\n",
      "0.025\n",
      "0.0874394\n",
      "0.0874394\n",
      "0.025\n",
      "0.025\n",
      "0.341256\n",
      "0.341256\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.032271\n",
      "0.032271\n",
      "0.973739\n",
      "0.973739\n",
      "0.560096\n",
      "0.560096\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.218397\n",
      "0.218397\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0269548\n",
      "0.0269548\n",
      "0.241762\n",
      "0.241762\n",
      "0.025\n",
      "0.025\n",
      "0.928255\n",
      "0.928255\n",
      "0.025\n",
      "0.025\n",
      "0.0314917\n",
      "0.0314917\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0301856\n",
      "0.0301856\n",
      "0.47611\n",
      "0.47611\n",
      "0.025\n",
      "0.025\n",
      "0.0713566\n",
      "0.0713566\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.25372\n",
      "0.25372\n",
      "0.258825\n",
      "0.258825\n",
      "0.0990522\n",
      "0.0990522\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.518834\n",
      "0.518834\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.587518\n",
      "0.587518\n",
      "0.190618\n",
      "0.190618\n",
      "0.0587555\n",
      "0.0587555\n",
      "0.025\n",
      "0.025\n",
      "0.031095\n",
      "0.031095\n",
      "0.585774\n",
      "0.585774\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.164474\n",
      "0.164474\n",
      "0.111352\n",
      "0.111352\n",
      "0.975\n",
      "0.975\n",
      "0.882878\n",
      "0.882878\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.222637\n",
      "0.222637\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.269117\n",
      "0.269117\n",
      "0.659934\n",
      "0.659934\n",
      "0.235557\n",
      "0.235557\n",
      "0.025\n",
      "0.025\n",
      "0.951133\n",
      "0.951133\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.562162\n",
      "0.562162\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.839319\n",
      "0.839319\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0359758\n",
      "0.0359758\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0377476\n",
      "0.0377476\n",
      "0.025\n",
      "0.025\n",
      "0.958864\n",
      "0.958864\n",
      "0.025\n",
      "0.025\n",
      "0.219215\n",
      "0.219215\n",
      "0.975\n",
      "0.975\n",
      "0.42804\n",
      "0.42804\n",
      "0.975\n",
      "0.975\n",
      "0.134327\n",
      "0.134327\n",
      "0.074812\n",
      "0.074812\n",
      "0.975\n",
      "0.975\n",
      "0.061796\n",
      "0.061796\n",
      "0.895533\n",
      "0.895533\n",
      "0.025\n",
      "0.025\n",
      "0.317557\n",
      "0.317557\n",
      "0.0505919\n",
      "0.0505919\n",
      "0.953903\n",
      "0.953903\n",
      "0.0990241\n",
      "0.0990241\n",
      "0.253674\n",
      "0.253674\n",
      "0.0424946\n",
      "0.0424946\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0578194\n",
      "0.0578194\n",
      "0.025\n",
      "0.025\n",
      "0.77952\n",
      "0.77952\n",
      "0.618737\n",
      "0.618737\n",
      "0.178037\n",
      "0.178037\n",
      "0.025\n",
      "0.025\n",
      "0.838198\n",
      "0.838198\n",
      "0.151912\n",
      "0.151912\n",
      "0.806593\n",
      "0.806593\n",
      "0.264728\n",
      "0.264728\n",
      "0.567479\n",
      "0.567479\n",
      "0.975\n",
      "0.975\n",
      "0.85106\n",
      "0.85106\n",
      "0.868369\n",
      "0.868369\n",
      "0.025\n",
      "0.025\n",
      "0.351253\n",
      "0.351253\n",
      "0.1016\n",
      "0.1016\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.25032\n",
      "0.25032\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.150894\n",
      "0.150894\n",
      "0.0604625\n",
      "0.0604625\n",
      "0.9683\n",
      "0.9683\n",
      "0.905217\n",
      "0.905217\n",
      "0.025\n",
      "0.025\n",
      "0.0883697\n",
      "0.0883697\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.222938\n",
      "0.222938\n",
      "0.0615024\n",
      "0.0615024\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.959285\n",
      "0.959285\n",
      "0.144677\n",
      "0.144677\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.115401\n",
      "0.115401\n",
      "0.68273\n",
      "0.68273\n",
      "0.122364\n",
      "0.122364\n",
      "0.186324\n",
      "0.186324\n",
      "0.263042\n",
      "0.263042\n",
      "0.964508\n",
      "0.964508\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.221921\n",
      "0.221921\n",
      "0.399216\n",
      "0.399216\n",
      "0.377078\n",
      "0.377078\n",
      "0.0342642\n",
      "0.0342642\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.959526\n",
      "0.959526\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0737093\n",
      "0.0737093\n",
      "0.025\n",
      "0.025\n",
      "0.0669521\n",
      "0.0669521\n",
      "0.227442\n",
      "0.227442\n",
      "0.831261\n",
      "0.831261\n",
      "0.163903\n",
      "0.163903\n",
      "0.450991\n",
      "0.450991\n",
      "0.025\n",
      "0.025\n",
      "0.035536\n",
      "0.035536\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.313178\n",
      "0.313178\n",
      "0.0301538\n",
      "0.0301538\n",
      "0.025\n",
      "0.025\n",
      "0.454589\n",
      "0.454589\n",
      "0.101219\n",
      "0.101219\n",
      "0.211075\n",
      "0.211075\n",
      "0.025\n",
      "0.025\n",
      "0.803036\n",
      "0.803036\n",
      "0.783288\n",
      "0.783288\n",
      "0.865299\n",
      "0.865299\n",
      "0.342009\n",
      "0.342009\n",
      "0.975\n",
      "0.975\n",
      "0.604203\n",
      "0.604203\n",
      "0.475577\n",
      "0.475577\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0781256\n",
      "0.0781256\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.96282\n",
      "0.96282\n",
      "0.221979\n",
      "0.221979\n",
      "0.814528\n",
      "0.814528\n",
      "0.0404102\n",
      "0.0404102\n",
      "0.970486\n",
      "0.970486\n",
      "0.975\n",
      "0.975\n",
      "0.068067\n",
      "0.068067\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.027301\n",
      "0.027301\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.67383\n",
      "0.67383\n",
      "0.025\n",
      "0.025\n",
      "0.971474\n",
      "0.971474\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0347869\n",
      "0.0347869\n",
      "0.0906842\n",
      "0.0906842\n",
      "0.025\n",
      "0.025\n",
      "0.179895\n",
      "0.179895\n",
      "0.0256731\n",
      "0.0256731\n",
      "0.082121\n",
      "0.082121\n",
      "0.025\n",
      "0.025\n",
      "0.481285\n",
      "0.481285\n",
      "0.0370474\n",
      "0.0370474\n",
      "0.025\n",
      "0.025\n",
      "0.609223\n",
      "0.609223\n",
      "0.025\n",
      "0.025\n",
      "0.213643\n",
      "0.213643\n",
      "0.025\n",
      "0.025\n",
      "0.0270316\n",
      "0.0270316\n",
      "0.147448\n",
      "0.147448\n",
      "0.655934\n",
      "0.655934\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.164891\n",
      "0.164891\n",
      "0.04453\n",
      "0.04453\n",
      "0.975\n",
      "0.975\n",
      "0.0323473\n",
      "0.0323473\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.241797\n",
      "0.241797\n",
      "0.875658\n",
      "0.875658\n",
      "0.025\n",
      "0.025\n",
      "0.0371841\n",
      "0.0371841\n",
      "0.962241\n",
      "0.962241\n",
      "0.975\n",
      "0.975\n",
      "0.657815\n",
      "0.657815\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.518582\n",
      "0.518582\n",
      "0.0430667\n",
      "0.0430667\n",
      "0.386886\n",
      "0.386886\n",
      "0.355065\n",
      "0.355065\n",
      "0.975\n",
      "0.975\n",
      "0.146852\n",
      "0.146852\n",
      "0.975\n",
      "0.975\n",
      "0.0506869\n",
      "0.0506869\n",
      "0.025\n",
      "0.025\n",
      "0.278688\n",
      "0.278688\n",
      "0.973904\n",
      "0.973904\n",
      "0.313476\n",
      "0.313476\n",
      "0.381579\n",
      "0.381579\n",
      "0.848301\n",
      "0.848301\n",
      "0.975\n",
      "0.975\n",
      "0.953552\n",
      "0.953552\n",
      "0.946874\n",
      "0.946874\n",
      "0.025\n",
      "0.025\n",
      "0.0833373\n",
      "0.0833373\n",
      "0.0935087\n",
      "0.0935087\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0575136\n",
      "0.0575136\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.460685\n",
      "0.460685\n",
      "0.025\n",
      "0.025\n",
      "0.0472362\n",
      "0.0472362\n",
      "0.975\n",
      "0.975\n",
      "0.321383\n",
      "0.321383\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.315613\n",
      "0.315613\n",
      "0.550645\n",
      "0.550645\n",
      "0.0943203\n",
      "0.0943203\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0524389\n",
      "0.0524389\n",
      "0.025\n",
      "0.025\n",
      "0.227639\n",
      "0.227639\n",
      "0.117115\n",
      "0.117115\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0437141\n",
      "0.0437141\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.116741\n",
      "0.116741\n",
      "0.975\n",
      "0.975\n",
      "0.0612104\n",
      "0.0612104\n",
      "0.025\n",
      "0.025\n",
      "0.20123\n",
      "0.20123\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.569271\n",
      "0.569271\n",
      "0.025\n",
      "0.025\n",
      "0.197399\n",
      "0.197399\n",
      "0.025\n",
      "0.025\n",
      "0.0939805\n",
      "0.0939805\n",
      "0.201687\n",
      "0.201687\n",
      "0.184773\n",
      "0.184773\n",
      "0.975\n",
      "0.975\n",
      "0.856288\n",
      "0.856288\n",
      "0.257127\n",
      "0.257127\n",
      "0.025\n",
      "0.025\n",
      "0.900226\n",
      "0.900226\n",
      "0.025\n",
      "0.025\n",
      "0.929138\n",
      "0.929138\n",
      "0.0579414\n",
      "0.0579414\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0369877\n",
      "0.0369877\n",
      "0.025\n",
      "0.025\n",
      "0.434904\n",
      "0.434904\n",
      "0.710618\n",
      "0.710618\n",
      "0.025\n",
      "0.025\n",
      "0.0330624\n",
      "0.0330624\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.193514\n",
      "0.193514\n",
      "0.280822\n",
      "0.280822\n",
      "0.572097\n",
      "0.572097\n",
      "0.0621329\n",
      "0.0621329\n",
      "0.0924245\n",
      "0.0924245\n",
      "0.0567633\n",
      "0.0567633\n",
      "0.025\n",
      "0.025\n",
      "0.119665\n",
      "0.119665\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.726125\n",
      "0.726125\n",
      "0.922831\n",
      "0.922831\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.0261094\n",
      "0.0261094\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.685336\n",
      "0.685336\n",
      "0.339393\n",
      "0.339393\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0750859\n",
      "0.0750859\n",
      "0.370051\n",
      "0.370051\n",
      "0.025\n",
      "0.025\n",
      "0.117633\n",
      "0.117633\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0424472\n",
      "0.0424472\n",
      "0.469038\n",
      "0.469038\n",
      "0.0587953\n",
      "0.0587953\n",
      "0.025\n",
      "0.025\n",
      "0.0278128\n",
      "0.0278128\n",
      "0.305423\n",
      "0.305423\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.735877\n",
      "0.735877\n",
      "0.451709\n",
      "0.451709\n",
      "0.861459\n",
      "0.861459\n",
      "0.693922\n",
      "0.693922\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.972933\n",
      "0.972933\n",
      "0.348848\n",
      "0.348848\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.570643\n",
      "0.570643\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.820213\n",
      "0.820213\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.678362\n",
      "0.678362\n",
      "0.529153\n",
      "0.529153\n",
      "0.0539136\n",
      "0.0539136\n",
      "0.975\n",
      "0.975\n",
      "0.0397107\n",
      "0.0397107\n",
      "0.170989\n",
      "0.170989\n",
      "0.025\n",
      "0.025\n",
      "0.0349719\n",
      "0.0349719\n",
      "0.440597\n",
      "0.440597\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0810205\n",
      "0.0810205\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.922517\n",
      "0.922517\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.076327\n",
      "0.076327\n",
      "0.142613\n",
      "0.142613\n",
      "0.393704\n",
      "0.393704\n",
      "0.025\n",
      "0.025\n",
      "0.380953\n",
      "0.380953\n",
      "0.0444675\n",
      "0.0444675\n",
      "0.975\n",
      "0.975\n",
      "0.428035\n",
      "0.428035\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.832927\n",
      "0.832927\n",
      "0.0551622\n",
      "0.0551622\n",
      "0.0493721\n",
      "0.0493721\n",
      "0.0354241\n",
      "0.0354241\n",
      "0.78823\n",
      "0.78823\n",
      "0.372926\n",
      "0.372926\n",
      "0.025\n",
      "0.025\n",
      "0.0985794\n",
      "0.0985794\n",
      "0.025\n",
      "0.025\n",
      "0.259247\n",
      "0.259247\n",
      "0.025\n",
      "0.025\n",
      "0.0336022\n",
      "0.0336022\n",
      "0.025\n",
      "0.025\n",
      "0.03325\n",
      "0.03325\n",
      "0.025\n",
      "0.025\n",
      "0.325915\n",
      "0.325915\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.657315\n",
      "0.657315\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.175213\n",
      "0.175213\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0357136\n",
      "0.0357136\n",
      "0.0359083\n",
      "0.0359083\n",
      "0.0651617\n",
      "0.0651617\n",
      "0.300931\n",
      "0.300931\n",
      "0.865775\n",
      "0.865775\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.577791\n",
      "0.577791\n",
      "0.937933\n",
      "0.937933\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0340664\n",
      "0.0340664\n",
      "0.827706\n",
      "0.827706\n",
      "0.025\n",
      "0.025\n",
      "0.909672\n",
      "0.909672\n",
      "0.025\n",
      "0.025\n",
      "0.182473\n",
      "0.182473\n",
      "0.0640955\n",
      "0.0640955\n",
      "0.801224\n",
      "0.801224\n",
      "0.214676\n",
      "0.214676\n",
      "0.0684181\n",
      "0.0684181\n",
      "0.025\n",
      "0.025\n",
      "0.134051\n",
      "0.134051\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0443546\n",
      "0.0443546\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.619072\n",
      "0.619072\n",
      "0.0517969\n",
      "0.0517969\n",
      "0.266019\n",
      "0.266019\n",
      "0.025\n",
      "0.025\n",
      "0.971989\n",
      "0.971989\n",
      "0.025\n",
      "0.025\n",
      "0.321661\n",
      "0.321661\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0466117\n",
      "0.0466117\n",
      "0.025\n",
      "0.025\n",
      "0.0361992\n",
      "0.0361992\n",
      "0.917754\n",
      "0.917754\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0522755\n",
      "0.0522755\n",
      "0.272431\n",
      "0.272431\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0789397\n",
      "0.0789397\n",
      "0.08212\n",
      "0.08212\n",
      "0.0487117\n",
      "0.0487117\n",
      "0.0311269\n",
      "0.0311269\n",
      "0.025\n",
      "0.025\n",
      "0.892854\n",
      "0.892854\n",
      "0.303363\n",
      "0.303363\n",
      "0.181571\n",
      "0.181571\n",
      "0.185711\n",
      "0.185711\n",
      "0.226424\n",
      "0.226424\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.199429\n",
      "0.199429\n",
      "0.025\n",
      "0.025\n",
      "0.117202\n",
      "0.117202\n",
      "0.0674098\n",
      "0.0674098\n",
      "0.353751\n",
      "0.353751\n",
      "0.025\n",
      "0.025\n",
      "0.0278212\n",
      "0.0278212\n",
      "0.0504624\n",
      "0.0504624\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0436335\n",
      "0.0436335\n",
      "0.0405536\n",
      "0.0405536\n",
      "0.025\n",
      "0.025\n",
      "0.696205\n",
      "0.696205\n",
      "0.963093\n",
      "0.963093\n",
      "0.31415\n",
      "0.31415\n",
      "0.432084\n",
      "0.432084\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0619516\n",
      "0.0619516\n",
      "0.0299529\n",
      "0.0299529\n",
      "0.975\n",
      "0.975\n",
      "0.599909\n",
      "0.599909\n",
      "0.025\n",
      "0.025\n",
      "0.693194\n",
      "0.693194\n",
      "0.025\n",
      "0.025\n",
      "0.527683\n",
      "0.527683\n",
      "0.0598255\n",
      "0.0598255\n",
      "0.926192\n",
      "0.926192\n",
      "0.194042\n",
      "0.194042\n",
      "0.025\n",
      "0.025\n",
      "0.121357\n",
      "0.121357\n",
      "0.514014\n",
      "0.514014\n",
      "0.0575182\n",
      "0.0575182\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0328122\n",
      "0.0328122\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0291587\n",
      "0.0291587\n",
      "0.791321\n",
      "0.791321\n",
      "0.101861\n",
      "0.101861\n",
      "0.838864\n",
      "0.838864\n",
      "0.0301947\n",
      "0.0301947\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.626701\n",
      "0.626701\n",
      "0.025\n",
      "0.025\n",
      "0.603368\n",
      "0.603368\n",
      "0.20376\n",
      "0.20376\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.884643\n",
      "0.884643\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.210202\n",
      "0.210202\n",
      "0.564411\n",
      "0.564411\n",
      "0.025\n",
      "0.025\n",
      "0.0675273\n",
      "0.0675273\n",
      "0.025\n",
      "0.025\n",
      "0.822995\n",
      "0.822995\n",
      "0.324088\n",
      "0.324088\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0288655\n",
      "0.0288655\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0609331\n",
      "0.0609331\n",
      "0.549675\n",
      "0.549675\n",
      "0.529369\n",
      "0.529369\n",
      "0.154388\n",
      "0.154388\n",
      "0.025\n",
      "0.025\n",
      "0.0522097\n",
      "0.0522097\n",
      "0.113709\n",
      "0.113709\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0713767\n",
      "0.0713767\n",
      "0.0598046\n",
      "0.0598046\n",
      "0.025\n",
      "0.025\n",
      "0.146916\n",
      "0.146916\n",
      "0.225519\n",
      "0.225519\n",
      "0.110309\n",
      "0.110309\n",
      "0.145114\n",
      "0.145114\n",
      "0.185779\n",
      "0.185779\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.130077\n",
      "0.130077\n",
      "0.975\n",
      "0.975\n",
      "0.0473946\n",
      "0.0473946\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.715051\n",
      "0.715051\n",
      "0.0543233\n",
      "0.0543233\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.0587418\n",
      "0.0587418\n",
      "0.025\n",
      "0.025\n",
      "0.0474638\n",
      "0.0474638\n",
      "0.975\n",
      "0.975\n",
      "0.654061\n",
      "0.654061\n",
      "0.0551166\n",
      "0.0551166\n",
      "0.0876968\n",
      "0.0876968\n",
      "0.961667\n",
      "0.961667\n",
      "0.296605\n",
      "0.296605\n",
      "0.905173\n",
      "0.905173\n",
      "0.331519\n",
      "0.331519\n",
      "0.025\n",
      "0.025\n",
      "0.287459\n",
      "0.287459\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.314775\n",
      "0.314775\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.544655\n",
      "0.544655\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0695201\n",
      "0.0695201\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.972879\n",
      "0.972879\n",
      "0.964468\n",
      "0.964468\n",
      "0.815318\n",
      "0.815318\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.655109\n",
      "0.655109\n",
      "0.0495293\n",
      "0.0495293\n",
      "0.969095\n",
      "0.969095\n",
      "0.762373\n",
      "0.762373\n",
      "0.0568272\n",
      "0.0568272\n",
      "0.975\n",
      "0.975\n",
      "0.148831\n",
      "0.148831\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0409401\n",
      "0.0409401\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.548843\n",
      "0.548843\n",
      "0.974249\n",
      "0.974249\n",
      "0.417849\n",
      "0.417849\n",
      "0.188143\n",
      "0.188143\n",
      "0.025\n",
      "0.025\n",
      "0.101007\n",
      "0.101007\n",
      "0.025\n",
      "0.025\n",
      "0.633534\n",
      "0.633534\n",
      "0.354022\n",
      "0.354022\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.050023\n",
      "0.050023\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.372001\n",
      "0.372001\n",
      "0.975\n",
      "0.975\n",
      "0.0431706\n",
      "0.0431706\n",
      "0.9652\n",
      "0.9652\n",
      "0.0660726\n",
      "0.0660726\n",
      "0.0273804\n",
      "0.0273804\n",
      "0.025\n",
      "0.025\n",
      "0.21981\n",
      "0.21981\n",
      "0.025\n",
      "0.025\n",
      "0.0596445\n",
      "0.0596445\n",
      "0.242334\n",
      "0.242334\n",
      "0.57808\n",
      "0.57808\n",
      "0.712203\n",
      "0.712203\n",
      "0.0338142\n",
      "0.0338142\n",
      "0.040342\n",
      "0.040342\n",
      "0.420787\n",
      "0.420787\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.874137\n",
      "0.874137\n",
      "0.634238\n",
      "0.634238\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.928166\n",
      "0.928166\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.160992\n",
      "0.160992\n",
      "0.97168\n",
      "0.97168\n",
      "0.975\n",
      "0.975\n",
      "0.155959\n",
      "0.155959\n",
      "0.206312\n",
      "0.206312\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.963961\n",
      "0.963961\n",
      "0.962492\n",
      "0.962492\n",
      "0.0523355\n",
      "0.0523355\n",
      "0.312722\n",
      "0.312722\n",
      "0.025\n",
      "0.025\n",
      "0.299498\n",
      "0.299498\n",
      "0.0652006\n",
      "0.0652006\n",
      "0.12769\n",
      "0.12769\n",
      "0.33193\n",
      "0.33193\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.888555\n",
      "0.888555\n",
      "0.0985158\n",
      "0.0985158\n",
      "0.025\n",
      "0.025\n",
      "0.563175\n",
      "0.563175\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0748436\n",
      "0.0748436\n",
      "0.025\n",
      "0.025\n",
      "0.332328\n",
      "0.332328\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.406448\n",
      "0.406448\n",
      "0.025\n",
      "0.025\n",
      "0.223702\n",
      "0.223702\n",
      "0.117746\n",
      "0.117746\n",
      "0.167166\n",
      "0.167166\n",
      "0.975\n",
      "0.975\n",
      "0.429425\n",
      "0.429425\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.124871\n",
      "0.124871\n",
      "0.765578\n",
      "0.765578\n",
      "0.11309\n",
      "0.11309\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.331116\n",
      "0.331116\n",
      "0.025\n",
      "0.025\n",
      "0.728138\n",
      "0.728138\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.571023\n",
      "0.571023\n",
      "0.0999065\n",
      "0.0999065\n",
      "0.801838\n",
      "0.801838\n",
      "0.025\n",
      "0.025\n",
      "0.232768\n",
      "0.232768\n",
      "0.025\n",
      "0.025\n",
      "0.0905307\n",
      "0.0905307\n",
      "0.025\n",
      "0.025\n",
      "0.0881331\n",
      "0.0881331\n",
      "0.921838\n",
      "0.921838\n",
      "0.437144\n",
      "0.437144\n",
      "0.0294058\n",
      "0.0294058\n",
      "0.025\n",
      "0.025\n",
      "0.178028\n",
      "0.178028\n",
      "0.0716918\n",
      "0.0716918\n",
      "0.0627145\n",
      "0.0627145\n",
      "0.025\n",
      "0.025\n",
      "0.0968776\n",
      "0.0968776\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.908288\n",
      "0.908288\n",
      "0.122162\n",
      "0.122162\n",
      "0.025\n",
      "0.025\n",
      "0.39298\n",
      "0.39298\n",
      "0.025\n",
      "0.025\n",
      "0.143206\n",
      "0.143206\n",
      "0.95803\n",
      "0.95803\n",
      "0.882599\n",
      "0.882599\n",
      "0.302966\n",
      "0.302966\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.297037\n",
      "0.297037\n",
      "0.025\n",
      "0.025\n",
      "0.907914\n",
      "0.907914\n",
      "0.189242\n",
      "0.189242\n",
      "0.416165\n",
      "0.416165\n",
      "0.0837828\n",
      "0.0837828\n",
      "0.966876\n",
      "0.966876\n",
      "0.025\n",
      "0.025\n",
      "0.056675\n",
      "0.056675\n",
      "0.0924983\n",
      "0.0924983\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0791392\n",
      "0.0791392\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.257356\n",
      "0.257356\n",
      "0.15098\n",
      "0.15098\n",
      "0.025\n",
      "0.025\n",
      "0.38172\n",
      "0.38172\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.975\n",
      "0.438214\n",
      "0.438214\n",
      "0.561167\n",
      "0.561167\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.348624\n",
      "0.348624\n",
      "0.811411\n",
      "0.811411\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0633457\n",
      "0.0633457\n",
      "0.025\n",
      "0.025\n",
      "0.0394851\n",
      "0.0394851\n",
      "0.025\n",
      "0.025\n",
      "0.0589287\n",
      "0.0589287\n",
      "0.0326151\n",
      "0.0326151\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.229247\n",
      "0.229247\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.542155\n",
      "0.542155\n",
      "0.93831\n",
      "0.93831\n",
      "0.0912808\n",
      "0.0912808\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.768546\n",
      "0.768546\n",
      "0.437773\n",
      "0.437773\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.610351\n",
      "0.610351\n",
      "0.358898\n",
      "0.358898\n",
      "0.443569\n",
      "0.443569\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.025\n",
      "0.0587279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0587279\n",
      "0.025\n",
      "0.025\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.0456951\n",
      "0.0456951\n",
      "0.69682\n",
      "0.69682\n",
      "0.0802122\n",
      "0.0802122\n",
      "0.0264434\n",
      "0.0264434\n",
      "0.434921\n",
      "0.434921\n",
      "0.025\n",
      "0.025\n",
      "0.0282373\n",
      "0.0282373\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n",
      "0.216246\n",
      "0.216246\n",
      "0.0506829\n",
      "0.0506829\n",
      "0.975\n",
      "0.975\n",
      "0.025\n",
      "0.025\n"
     ]
    }
   ],
   "source": [
    "# clipping\n",
    "for p in pred_test:\n",
    "    print(p[1])\n",
    "    val = p[1]\n",
    "    \n",
    "    if val < 0.025:\n",
    "        val = 0.025\n",
    "        \n",
    "    elif val > 0.975:\n",
    "        val = 0.975\n",
    "        \n",
    "    p[1] = val\n",
    "    \n",
    "    print(p[1])\n",
    "\n",
    "model.create_submission(pred_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmWXigmFmZpm4YJiZWSYuGGZmlsn/A9Vkft84Qj/jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b4c825048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b512793c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: davemodel\n",
      "Batch Size: 32\n",
      "Epochs: 80\n",
      "Epoch 1/80\n",
      "41/40 [==============================] - 2s - loss: 0.5765 - acc: 0.6737 - val_loss: 0.6837 - val_acc: 0.5670\n",
      "Epoch 2/80\n",
      "41/40 [==============================] - 1s - loss: 0.4909 - acc: 0.7430 - val_loss: 0.6349 - val_acc: 0.6573\n",
      "Epoch 3/80\n",
      "41/40 [==============================] - 1s - loss: 0.4433 - acc: 0.7682 - val_loss: 0.6643 - val_acc: 0.6573\n",
      "Epoch 4/80\n",
      "41/40 [==============================] - 1s - loss: 0.4224 - acc: 0.7971 - val_loss: 0.6887 - val_acc: 0.6573\n",
      "Epoch 5/80\n",
      "41/40 [==============================] - 1s - loss: 0.3804 - acc: 0.8159 - val_loss: 0.6811 - val_acc: 0.6573\n",
      "Epoch 6/80\n",
      "41/40 [==============================] - 1s - loss: 0.3792 - acc: 0.8174 - val_loss: 0.8034 - val_acc: 0.6573\n",
      "Epoch 7/80\n",
      "41/40 [==============================] - 1s - loss: 0.3465 - acc: 0.8437 - val_loss: 0.9113 - val_acc: 0.6573\n",
      "Epoch 8/80\n",
      "41/40 [==============================] - 1s - loss: 0.3302 - acc: 0.8460 - val_loss: 0.9754 - val_acc: 0.6573\n",
      "Epoch 9/80\n",
      "41/40 [==============================] - 1s - loss: 0.3422 - acc: 0.8277 - val_loss: 1.0176 - val_acc: 0.6573\n",
      "Epoch 10/80\n",
      "41/40 [==============================] - 1s - loss: 0.3366 - acc: 0.8487 - val_loss: 1.0009 - val_acc: 0.6573\n",
      "Epoch 11/80\n",
      "41/40 [==============================] - 1s - loss: 0.3125 - acc: 0.8609 - val_loss: 0.8933 - val_acc: 0.6604\n",
      "Epoch 12/80\n",
      "41/40 [==============================] - 1s - loss: 0.3141 - acc: 0.8456 - val_loss: 0.7405 - val_acc: 0.6760\n",
      "Epoch 13/80\n",
      "41/40 [==============================] - 1s - loss: 0.3301 - acc: 0.8346 - val_loss: 0.4606 - val_acc: 0.7819\n",
      "Epoch 14/80\n",
      "41/40 [==============================] - 1s - loss: 0.3040 - acc: 0.8559 - val_loss: 0.3596 - val_acc: 0.8629\n",
      "Epoch 15/80\n",
      "41/40 [==============================] - 1s - loss: 0.2859 - acc: 0.8757 - val_loss: 0.3398 - val_acc: 0.8598\n",
      "Epoch 16/80\n",
      "41/40 [==============================] - 1s - loss: 0.2894 - acc: 0.8650 - val_loss: 0.3511 - val_acc: 0.8193\n",
      "Epoch 17/80\n",
      "41/40 [==============================] - 1s - loss: 0.2941 - acc: 0.8696 - val_loss: 0.3133 - val_acc: 0.8380\n",
      "Epoch 18/80\n",
      "41/40 [==============================] - 1s - loss: 0.2901 - acc: 0.8719 - val_loss: 0.3440 - val_acc: 0.8131\n",
      "Epoch 19/80\n",
      "41/40 [==============================] - 1s - loss: 0.2919 - acc: 0.8627 - val_loss: 0.3159 - val_acc: 0.8567\n",
      "Epoch 20/80\n",
      "41/40 [==============================] - 1s - loss: 0.2822 - acc: 0.8726 - val_loss: 0.3472 - val_acc: 0.8193\n",
      "Epoch 21/80\n",
      "41/40 [==============================] - 1s - loss: 0.2879 - acc: 0.8662 - val_loss: 0.3698 - val_acc: 0.8006\n",
      "Epoch 22/80\n",
      "41/40 [==============================] - 1s - loss: 0.2997 - acc: 0.8693 - val_loss: 0.3786 - val_acc: 0.8442\n",
      "Epoch 23/80\n",
      "41/40 [==============================] - 1s - loss: 0.3032 - acc: 0.8578 - val_loss: 0.3248 - val_acc: 0.8411\n",
      "Epoch 24/80\n",
      "41/40 [==============================] - 1s - loss: 0.2995 - acc: 0.8529 - val_loss: 0.3609 - val_acc: 0.8100\n",
      "Epoch 25/80\n",
      "41/40 [==============================] - 1s - loss: 0.3014 - acc: 0.8624 - val_loss: 0.2994 - val_acc: 0.8941\n",
      "Epoch 26/80\n",
      "41/40 [==============================] - 1s - loss: 0.2885 - acc: 0.8754 - val_loss: 0.3236 - val_acc: 0.8629\n",
      "Epoch 27/80\n",
      "41/40 [==============================] - 1s - loss: 0.2907 - acc: 0.8628 - val_loss: 0.3438 - val_acc: 0.8193\n",
      "Epoch 28/80\n",
      "41/40 [==============================] - 1s - loss: 0.2708 - acc: 0.8726 - val_loss: 0.3232 - val_acc: 0.8474\n",
      "Epoch 29/80\n",
      "41/40 [==============================] - 1s - loss: 0.2613 - acc: 0.8856 - val_loss: 0.2888 - val_acc: 0.8411\n",
      "Epoch 30/80\n",
      "41/40 [==============================] - 1s - loss: 0.2763 - acc: 0.8792 - val_loss: 0.3579 - val_acc: 0.8536\n",
      "Epoch 31/80\n",
      "41/40 [==============================] - 1s - loss: 0.2831 - acc: 0.8655 - val_loss: 0.3134 - val_acc: 0.8723\n",
      "Epoch 32/80\n",
      "41/40 [==============================] - 1s - loss: 0.2597 - acc: 0.8772 - val_loss: 0.2995 - val_acc: 0.9065\n",
      "Epoch 33/80\n",
      "41/40 [==============================] - 1s - loss: 0.2720 - acc: 0.8799 - val_loss: 0.2949 - val_acc: 0.8723\n",
      "Epoch 34/80\n",
      "41/40 [==============================] - 1s - loss: 0.2628 - acc: 0.8864 - val_loss: 0.2812 - val_acc: 0.8785\n",
      "Epoch 35/80\n",
      "41/40 [==============================] - 1s - loss: 0.2494 - acc: 0.8856 - val_loss: 0.3151 - val_acc: 0.8567\n",
      "Epoch 36/80\n",
      "41/40 [==============================] - 1s - loss: 0.2513 - acc: 0.8955 - val_loss: 0.3123 - val_acc: 0.8536\n",
      "Epoch 37/80\n",
      "41/40 [==============================] - 1s - loss: 0.2514 - acc: 0.8960 - val_loss: 0.3271 - val_acc: 0.8567\n",
      "Epoch 38/80\n",
      "41/40 [==============================] - 1s - loss: 0.2850 - acc: 0.8712 - val_loss: 0.2982 - val_acc: 0.8692\n",
      "Epoch 39/80\n",
      "41/40 [==============================] - 1s - loss: 0.2635 - acc: 0.8777 - val_loss: 0.3028 - val_acc: 0.8629\n",
      "Epoch 40/80\n",
      "41/40 [==============================] - 1s - loss: 0.2517 - acc: 0.8925 - val_loss: 0.2883 - val_acc: 0.8879\n",
      "Epoch 41/80\n",
      "41/40 [==============================] - 1s - loss: 0.2383 - acc: 0.9009 - val_loss: 0.3753 - val_acc: 0.8287\n",
      "Epoch 42/80\n",
      "41/40 [==============================] - 1s - loss: 0.2673 - acc: 0.8906 - val_loss: 0.3255 - val_acc: 0.8318\n",
      "Epoch 43/80\n",
      "41/40 [==============================] - 1s - loss: 0.2601 - acc: 0.8799 - val_loss: 0.2944 - val_acc: 0.8660\n",
      "Epoch 44/80\n",
      "41/40 [==============================] - 1s - loss: 0.2413 - acc: 0.9031 - val_loss: 0.2808 - val_acc: 0.8847\n",
      "Epoch 45/80\n",
      "41/40 [==============================] - 1s - loss: 0.2351 - acc: 0.9051 - val_loss: 0.2794 - val_acc: 0.8816\n",
      "Epoch 46/80\n",
      "41/40 [==============================] - 1s - loss: 0.2243 - acc: 0.9001 - val_loss: 0.3303 - val_acc: 0.8224\n",
      "Epoch 47/80\n",
      "41/40 [==============================] - 1s - loss: 0.2360 - acc: 0.8899 - val_loss: 0.3558 - val_acc: 0.8224\n",
      "Epoch 48/80\n",
      "41/40 [==============================] - 1s - loss: 0.2555 - acc: 0.8921 - val_loss: 0.2699 - val_acc: 0.8847\n",
      "Epoch 49/80\n",
      "41/40 [==============================] - 1s - loss: 0.2360 - acc: 0.9031 - val_loss: 0.3081 - val_acc: 0.8598\n",
      "Epoch 50/80\n",
      "41/40 [==============================] - 1s - loss: 0.2282 - acc: 0.9054 - val_loss: 0.3325 - val_acc: 0.8380\n",
      "Epoch 51/80\n",
      "41/40 [==============================] - 1s - loss: 0.2338 - acc: 0.9009 - val_loss: 0.3070 - val_acc: 0.8692\n",
      "Epoch 52/80\n",
      "41/40 [==============================] - 1s - loss: 0.2401 - acc: 0.8987 - val_loss: 0.2978 - val_acc: 0.9065\n",
      "Epoch 53/80\n",
      "41/40 [==============================] - 1s - loss: 0.2266 - acc: 0.9021 - val_loss: 0.2704 - val_acc: 0.8972\n",
      "Epoch 54/80\n",
      "41/40 [==============================] - 1s - loss: 0.2420 - acc: 0.8876 - val_loss: 0.2708 - val_acc: 0.9003\n",
      "Epoch 55/80\n",
      "41/40 [==============================] - 1s - loss: 0.2212 - acc: 0.9039 - val_loss: 0.2869 - val_acc: 0.8785\n",
      "Epoch 56/80\n",
      "41/40 [==============================] - 1s - loss: 0.2193 - acc: 0.9062 - val_loss: 0.3133 - val_acc: 0.8442\n",
      "Epoch 57/80\n",
      "41/40 [==============================] - 1s - loss: 0.2128 - acc: 0.9062 - val_loss: 0.2823 - val_acc: 0.8910\n",
      "Epoch 58/80\n",
      "41/40 [==============================] - 1s - loss: 0.2063 - acc: 0.9123 - val_loss: 0.3018 - val_acc: 0.8598\n",
      "Epoch 59/80\n",
      "41/40 [==============================] - 1s - loss: 0.2373 - acc: 0.9005 - val_loss: 0.3088 - val_acc: 0.8660\n",
      "Epoch 60/80\n",
      "41/40 [==============================] - 1s - loss: 0.2097 - acc: 0.9115 - val_loss: 0.3084 - val_acc: 0.8629\n",
      "Epoch 61/80\n",
      "41/40 [==============================] - 1s - loss: 0.2298 - acc: 0.8998 - val_loss: 0.2661 - val_acc: 0.9003\n",
      "Epoch 62/80\n",
      "41/40 [==============================] - 1s - loss: 0.2239 - acc: 0.8982 - val_loss: 0.2739 - val_acc: 0.8879\n",
      "Epoch 63/80\n",
      "41/40 [==============================] - 1s - loss: 0.2231 - acc: 0.9108 - val_loss: 0.2773 - val_acc: 0.8785\n",
      "Epoch 64/80\n",
      "41/40 [==============================] - 1s - loss: 0.2170 - acc: 0.8990 - val_loss: 0.2567 - val_acc: 0.8941\n",
      "Epoch 65/80\n",
      "41/40 [==============================] - 1s - loss: 0.2205 - acc: 0.8998 - val_loss: 0.2956 - val_acc: 0.8629\n",
      "Epoch 66/80\n",
      "41/40 [==============================] - 1s - loss: 0.2053 - acc: 0.9154 - val_loss: 0.3399 - val_acc: 0.8411\n",
      "Epoch 67/80\n",
      "41/40 [==============================] - 1s - loss: 0.2076 - acc: 0.9150 - val_loss: 0.3790 - val_acc: 0.8069\n",
      "Epoch 68/80\n",
      "41/40 [==============================] - 1s - loss: 0.2085 - acc: 0.9085 - val_loss: 0.2666 - val_acc: 0.8972\n",
      "Epoch 69/80\n",
      "41/40 [==============================] - 1s - loss: 0.2015 - acc: 0.9192 - val_loss: 0.2968 - val_acc: 0.8660\n",
      "Epoch 70/80\n",
      "41/40 [==============================] - 1s - loss: 0.2027 - acc: 0.9184 - val_loss: 0.3313 - val_acc: 0.8380\n",
      "Epoch 71/80\n",
      "41/40 [==============================] - 1s - loss: 0.2092 - acc: 0.9184 - val_loss: 0.2806 - val_acc: 0.8941\n",
      "Epoch 72/80\n",
      "41/40 [==============================] - 1s - loss: 0.2120 - acc: 0.9123 - val_loss: 0.2785 - val_acc: 0.8785\n",
      "Epoch 73/80\n",
      "41/40 [==============================] - 1s - loss: 0.2019 - acc: 0.9165 - val_loss: 0.3200 - val_acc: 0.8567\n",
      "Epoch 74/80\n",
      "41/40 [==============================] - 1s - loss: 0.1963 - acc: 0.9138 - val_loss: 0.2473 - val_acc: 0.9034\n",
      "Epoch 75/80\n",
      "41/40 [==============================] - 1s - loss: 0.1991 - acc: 0.9123 - val_loss: 0.3455 - val_acc: 0.8349\n",
      "Epoch 76/80\n",
      "41/40 [==============================] - 1s - loss: 0.2243 - acc: 0.9051 - val_loss: 0.3038 - val_acc: 0.8567\n",
      "Epoch 77/80\n",
      "41/40 [==============================] - 1s - loss: 0.2285 - acc: 0.9097 - val_loss: 0.2891 - val_acc: 0.8692\n",
      "Epoch 78/80\n",
      "41/40 [==============================] - 1s - loss: 0.1949 - acc: 0.9176 - val_loss: 0.3076 - val_acc: 0.8505\n",
      "Epoch 79/80\n",
      "41/40 [==============================] - 1s - loss: 0.1888 - acc: 0.9222 - val_loss: 0.3142 - val_acc: 0.8505\n",
      "Epoch 80/80\n",
      "41/40 [==============================] - 1s - loss: 0.2064 - acc: 0.9120 - val_loss: 0.2938 - val_acc: 0.8660\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wFrDNZubohy+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b5552dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTQpKKaXKaVJQSilV7v8B93C+wKL5Cq0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26b5fc939b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DaveModel(Xtr, ytr, Xv, yv)\n",
    "model.train(32, 80)\n",
    "model.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Reshape\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.layers import Add, add\n",
    "from keras.layers import Multiply, multiply\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class SEResNeXt(object):\n",
    "    def __init__(self, size=96, num_classes=10, depth=64, reduction_ratio=4, num_split=8, num_block=3):\n",
    "        self.depth = depth # number of channels\n",
    "        self.ratio = reduction_ratio # ratio of channel reduction in SE module\n",
    "        self.num_split = num_split # number of splitting trees for ResNeXt (so called cardinality)\n",
    "        self.num_block = num_block # number of residual blocks\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            self.channel_axis = 1\n",
    "        else:\n",
    "            self.channel_axis = 3\n",
    "        self.model = self.build_model(Input(shape=(size,size,3)), num_classes)\n",
    "\n",
    "    def conv_bn(self, x, filters, kernel_size, stride, padding='same'):\n",
    "        '''\n",
    "        Combination of Conv and BN layers since these always appear together.\n",
    "        '''\n",
    "        x = Conv2D( filters=filters, kernel_size=[kernel_size, kernel_size]\n",
    "                               , strides=[stride, stride], padding=padding )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def activation(self, x, func='relu'):\n",
    "        '''\n",
    "        Activation layer.\n",
    "        '''\n",
    "        return Activation(func)(x)\n",
    "    \n",
    "    def channel_zeropad(self, x):\n",
    "        '''\n",
    "        Zero-padding for channle dimensions.\n",
    "        Note that padded channles are added like (Batch, H, W, 2/x + x + 2/x).\n",
    "        '''\n",
    "        shape = list(x.shape)\n",
    "        y = K.zeros_like(x)\n",
    "        \n",
    "        if self.channel_axis == 3:\n",
    "            y = y[:, :, :, :shape[self.channel_axis]//2]\n",
    "        else:\n",
    "            y = y[:, :shape[self.channel_axis]//2, :, :]\n",
    "        \n",
    "        return concatenate([y, x, y], self.channel_axis)\n",
    "    \n",
    "    def channel_zeropad_output(self, input_shape):\n",
    "        '''\n",
    "        Function for setting a channel dimension for zero padding.\n",
    "        '''\n",
    "        shape = list(input_shape)\n",
    "        shape[self.channel_axis] *= 2\n",
    "\n",
    "        return tuple(shape)\n",
    "    \n",
    "    def initial_layer(self, inputs):\n",
    "        '''\n",
    "        Initial layers includes {conv, BN, relu}.\n",
    "        '''\n",
    "        x = self.conv_bn(inputs, self.depth, 3, 1)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def transform_layer(self, x, stride):\n",
    "        '''\n",
    "        Transform layer has 2 {conv, BN, relu}.\n",
    "        '''\n",
    "        x = self.conv_bn(x, self.depth, 1, 1)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.conv_bn(x, self.depth, 3, stride)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def split_layer(self, x, stride):\n",
    "        '''\n",
    "        Parallel operation of transform layers for ResNeXt structure.\n",
    "        '''\n",
    "        splitted_branches = list()\n",
    "        for i in range(self.num_split):\n",
    "            branch = self.transform_layer(x, stride)\n",
    "            splitted_branches.append(branch)\n",
    "        \n",
    "        return concatenate(splitted_branches, axis=self.channel_axis)\n",
    "    \n",
    "    def squeeze_excitation_layer(self, x, out_dim):\n",
    "        '''\n",
    "        SE module performs inter-channel weighting.\n",
    "        '''\n",
    "        squeeze = GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        excitation = Dense(units=out_dim // self.ratio)(squeeze)\n",
    "        excitation = self.activation(excitation)\n",
    "        excitation = Dense(units=out_dim)(excitation)\n",
    "        excitation = self.activation(excitation, 'sigmoid')\n",
    "        excitation = Reshape((1,1,out_dim))(excitation)\n",
    "        \n",
    "        scale = multiply([x,excitation])\n",
    "        \n",
    "        return scale\n",
    "    \n",
    "    def residual_layer(self, x, out_dim):\n",
    "        '''\n",
    "        Residual block.\n",
    "        '''\n",
    "        for i in range(self.num_block):\n",
    "            input_dim = int(np.shape(x)[-1])\n",
    "            \n",
    "            if input_dim*2 == out_dim:\n",
    "                flag = True\n",
    "                stride = 2\n",
    "                channel = input_dim // 2\n",
    "            else:\n",
    "                flag = False\n",
    "                stride = 1\n",
    "            \n",
    "            subway_x = self.split_layer(x, stride)\n",
    "            subway_x = self.conv_bn(subway_x, out_dim, 1, 1)\n",
    "            subway_x = self.squeeze_excitation_layer(subway_x, out_dim)\n",
    "            \n",
    "            if flag:\n",
    "                pad_x = AveragePooling2D(pool_size=(2,2), strides=(2,2), padding='same')(x)\n",
    "                pad_x = Lambda(self.channel_zeropad, output_shape=self.channel_zeropad_output)(pad_x)\n",
    "            else:\n",
    "                pad_x = x\n",
    "            \n",
    "            x = self.activation(add([pad_x, subway_x]))\n",
    "                \n",
    "        return x\n",
    "    \n",
    "    def build_model(self, inputs, num_classes):\n",
    "        '''\n",
    "        Build a SENet model.\n",
    "        '''\n",
    "        x = self.initial_layer(inputs)\n",
    "        \n",
    "        x = self.residual_layer(x, out_dim=64)\n",
    "        x = self.residual_layer(x, out_dim=128)\n",
    "        x = self.residual_layer(x, out_dim=256)\n",
    "        \n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(units=num_classes, activation='softmax')(x)\n",
    "        \n",
    "        return Model(inputs, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SEResNeXtModel(DaveBaseModel):\n",
    "    def get_model(self):\n",
    "        model = SEResNeXt(75, 2)\n",
    "        \n",
    "        '''Create the FCN and return a keras model.'''\n",
    "\n",
    "#         model = Sequential()\n",
    "\n",
    "#         # Input image: 75x75x3\n",
    "#         model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "#         DaveModel.ConvBlock(model, 1, 32)\n",
    "#         # 37x37x32\n",
    "#         DaveModel.ConvBlock(model, 1, 64)\n",
    "#         # 18x18x64\n",
    "#         DaveModel.ConvBlock(model, 1, 128)\n",
    "#         # 9x9x128\n",
    "#         DaveModel.ConvBlock(model, 1, 128)\n",
    "#         # 4x4x128\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "#         model.add(GlobalAveragePooling2D())\n",
    "#         # 4x4x2\n",
    "#         model.add(Activation('softmax'))\n",
    "        \n",
    "        model.model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        return model.model\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"seresnext\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SEResNeXtModel(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.train(16, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.engine import Layer, InputSpec\n",
    "try:\n",
    "    from keras import initializations\n",
    "except ImportError:\n",
    "    from keras import initializers as initializations\n",
    "import keras.backend as K\n",
    "\n",
    "class Scale(Layer):\n",
    "    '''Custom Layer for DenseNet used for BatchNormalization.\n",
    "    \n",
    "    Learns a set of weights and biases used for scaling the input data.\n",
    "    the output consists simply in an element-wise multiplication of the input\n",
    "    and a sum of a set of constants:\n",
    "\n",
    "        out = in * gamma + beta,\n",
    "\n",
    "    where 'gamma' and 'beta' are the weights and biases larned.\n",
    "\n",
    "    # Arguments\n",
    "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
    "            if your input tensor has shape (samples, channels, rows, cols),\n",
    "            set axis to 1 to normalize per feature map (channels axis).\n",
    "        momentum: momentum in the computation of the\n",
    "            exponential average of the mean and standard deviation\n",
    "            of the data, for feature-wise normalization.\n",
    "        weights: Initialization weights.\n",
    "            List of 2 Numpy arrays, with shapes:\n",
    "            `[(input_shape,), (input_shape,)]`\n",
    "        beta_init: name of initialization function for shift parameter\n",
    "            (see [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "        gamma_init: name of initialization function for scale parameter (see\n",
    "            [initializations](../initializations.md)), or alternatively,\n",
    "            Theano/TensorFlow function to use for weights initialization.\n",
    "            This parameter is only relevant if you don't pass a `weights` argument.\n",
    "    '''\n",
    "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
    "        self.momentum = momentum\n",
    "        self.axis = axis\n",
    "        self.beta_init = initializations.get(beta_init)\n",
    "        self.gamma_init = initializations.get(gamma_init)\n",
    "        self.initial_weights = weights\n",
    "        super(Scale, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        shape = (int(input_shape[self.axis]),)\n",
    "\n",
    "        # Tensorflow >= 1.0.0 compatibility\n",
    "        self.gamma = K.variable(self.gamma_init(shape), name='{}_gamma'.format(self.name))\n",
    "        self.beta = K.variable(self.beta_init(shape), name='{}_beta'.format(self.name))\n",
    "        #self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))\n",
    "        #self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n",
    "        self.trainable_weights = [self.gamma, self.beta]\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        broadcast_shape = [1] * len(input_shape)\n",
    "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
    "\n",
    "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
    "        return out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
    "        base_config = super(Scale, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, ZeroPadding2D\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def DenseNet(nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4, classes=1000, weights_path=None):\n",
    "    '''Instantiate the DenseNet 121 architecture,\n",
    "        # Arguments\n",
    "            nb_dense_block: number of dense blocks to add to end\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_filter: initial number of filters\n",
    "            reduction: reduction factor of transition blocks.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            classes: optional number of classes to classify images\n",
    "            weights_path: path to pre-trained weights\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "\n",
    "    # compute compression factor\n",
    "    compression = 1.0 - reduction\n",
    "\n",
    "    # Handle Dimension Ordering for different backends\n",
    "    global concat_axis\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "      concat_axis = 3\n",
    "      img_input = Input(shape=(75, 75, 3), name='data')\n",
    "    else:\n",
    "      concat_axis = 1\n",
    "      img_input = Input(shape=(3, 75, 75), name='data')\n",
    "\n",
    "    # From architecture for ImageNet (Table 1 in the paper)\n",
    "    nb_filter = 64\n",
    "    nb_layers = [6,12,24,16] # For DenseNet-121\n",
    "\n",
    "    # Initial convolution\n",
    "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
    "    x = Convolution2D(nb_filter, 7, 7, subsample=(2, 2), name='conv1', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv1_scale')(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "    x = ZeroPadding2D((1, 1), name='pool1_zeropadding')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        stage = block_idx+2\n",
    "        x, nb_filter = dense_block(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "        # Add transition_block\n",
    "        x = transition_block(x, stage, nb_filter, compression=compression, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "        nb_filter = int(nb_filter * compression)\n",
    "\n",
    "    final_stage = stage + 1\n",
    "    x, nb_filter = dense_block(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv'+str(final_stage)+'_blk_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv'+str(final_stage)+'_blk_scale')(x)\n",
    "    x = Activation('relu', name='relu'+str(final_stage)+'_blk')(x)\n",
    "    x = GlobalAveragePooling2D(name='pool'+str(final_stage))(x)\n",
    "\n",
    "    x = Dense(classes, name='fc6')(x)\n",
    "    x = Activation('softmax', name='prob')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='densenet')\n",
    "\n",
    "    if weights_path is not None:\n",
    "      model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_block(x, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):\n",
    "    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout\n",
    "        # Arguments\n",
    "            x: input tensor \n",
    "            stage: index for dense block\n",
    "            branch: layer index within each dense block\n",
    "            nb_filter: number of filters\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_' + str(branch)\n",
    "    relu_name_base = 'relu' + str(stage) + '_' + str(branch)\n",
    "\n",
    "    # 1x1 Convolution (Bottleneck layer)\n",
    "    inter_channel = nb_filter * 4  \n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_x1_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base+'_x1')(x)\n",
    "    x = Convolution2D(inter_channel, 1, 1, name=conv_name_base+'_x1', bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 3x3 Convolution\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x2_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_x2_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base+'_x2')(x)\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base+'_x2_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter, 3, 3, name=conv_name_base+'_x2', bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
    "    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout \n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_filter: number of filters\n",
    "            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_blk'\n",
    "    relu_name_base = 'relu' + str(stage) + '_blk'\n",
    "    pool_name_base = 'pool' + str(stage) \n",
    "\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base)(x)\n",
    "    x = Convolution2D(int(nb_filter * compression), 1, 1, name=conv_name_base, bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2), name=pool_name_base)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_block(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True):\n",
    "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_layers: the number of layers of conv_block to append to the model.\n",
    "            nb_filter: number of filters\n",
    "            growth_rate: growth rate\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    concat_feat = x\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        branch = i+1\n",
    "        x = conv_block(concat_feat, stage, branch, growth_rate, dropout_rate, weight_decay)\n",
    "        concat_feat = merge([concat_feat, x], mode='concat', concat_axis=concat_axis, name='concat_'+str(stage)+'_'+str(branch))\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    return concat_feat, nb_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), use_bias=False, name=\"conv1\", strides=(2, 2))`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:238: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), use_bias=False, name=\"conv2_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(640, (1, 1), use_bias=False, name=\"conv3_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_1_x1\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_13_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_13_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_14_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_14_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_15_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_15_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_16_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_16_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_17_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_17_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_18_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_18_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_19_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_19_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_20_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_20_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_21_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_21_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_22_x1\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_22_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_23_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_23_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_24_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_24_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1408, (1, 1), use_bias=False, name=\"conv4_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_13_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_13_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_14_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_14_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_15_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_15_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_16_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_16_x2\")`\n"
     ]
    }
   ],
   "source": [
    "densemodel = DenseNet(classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "data (InputLayer)                (None, 75, 75, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2D (None, 81, 81, 3)     0           data[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 38, 38, 64)    9408        conv1_zeropadding[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)    (None, 38, 38, 64)    256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv1_scale (Scale)              (None, 38, 38, 64)    128         conv1_bn[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "relu1 (Activation)               (None, 38, 38, 64)    0           conv1_scale[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "pool1_zeropadding (ZeroPadding2D (None, 40, 40, 64)    0           relu1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)             (None, 19, 19, 64)    0           pool1_zeropadding[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x1_bn (BatchNormalizatio (None, 19, 19, 64)    256         pool1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x1_scale (Scale)         (None, 19, 19, 64)    128         conv2_1_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_1_x1 (Activation)          (None, 19, 19, 64)    0           conv2_1_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x1 (Conv2D)              (None, 19, 19, 128)   8192        relu2_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_1_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_1_x2 (Activation)          (None, 19, 19, 128)   0           conv2_1_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_1_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_1 (Merge)               (None, 19, 19, 96)    0           pool1[0][0]                      \n",
      "                                                                   conv2_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x1_bn (BatchNormalizatio (None, 19, 19, 96)    384         concat_2_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x1_scale (Scale)         (None, 19, 19, 96)    192         conv2_2_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_2_x1 (Activation)          (None, 19, 19, 96)    0           conv2_2_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x1 (Conv2D)              (None, 19, 19, 128)   12288       relu2_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_2_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_2_x2 (Activation)          (None, 19, 19, 128)   0           conv2_2_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_2_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_2 (Merge)               (None, 19, 19, 128)   0           concat_2_1[0][0]                 \n",
      "                                                                   conv2_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x1_bn (BatchNormalizatio (None, 19, 19, 128)   512         concat_2_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x1_scale (Scale)         (None, 19, 19, 128)   256         conv2_3_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_3_x1 (Activation)          (None, 19, 19, 128)   0           conv2_3_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x1 (Conv2D)              (None, 19, 19, 128)   16384       relu2_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_3_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_3_x2 (Activation)          (None, 19, 19, 128)   0           conv2_3_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_3_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_3_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_3 (Merge)               (None, 19, 19, 160)   0           concat_2_2[0][0]                 \n",
      "                                                                   conv2_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x1_bn (BatchNormalizatio (None, 19, 19, 160)   640         concat_2_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x1_scale (Scale)         (None, 19, 19, 160)   320         conv2_4_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_4_x1 (Activation)          (None, 19, 19, 160)   0           conv2_4_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x1 (Conv2D)              (None, 19, 19, 128)   20480       relu2_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_4_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_4_x2 (Activation)          (None, 19, 19, 128)   0           conv2_4_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_4_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_4_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_4 (Merge)               (None, 19, 19, 192)   0           concat_2_3[0][0]                 \n",
      "                                                                   conv2_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x1_bn (BatchNormalizatio (None, 19, 19, 192)   768         concat_2_4[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x1_scale (Scale)         (None, 19, 19, 192)   384         conv2_5_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_5_x1 (Activation)          (None, 19, 19, 192)   0           conv2_5_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x1 (Conv2D)              (None, 19, 19, 128)   24576       relu2_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_5_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_5_x2 (Activation)          (None, 19, 19, 128)   0           conv2_5_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_5_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_5_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_5 (Merge)               (None, 19, 19, 224)   0           concat_2_4[0][0]                 \n",
      "                                                                   conv2_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x1_bn (BatchNormalizatio (None, 19, 19, 224)   896         concat_2_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x1_scale (Scale)         (None, 19, 19, 224)   448         conv2_6_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_6_x1 (Activation)          (None, 19, 19, 224)   0           conv2_6_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x1 (Conv2D)              (None, 19, 19, 128)   28672       relu2_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x2_bn (BatchNormalizatio (None, 19, 19, 128)   512         conv2_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x2_scale (Scale)         (None, 19, 19, 128)   256         conv2_6_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu2_6_x2 (Activation)          (None, 19, 19, 128)   0           conv2_6_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x2_zeropadding (ZeroPadd (None, 21, 21, 128)   0           relu2_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_6_x2 (Conv2D)              (None, 19, 19, 32)    36864       conv2_6_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_2_6 (Merge)               (None, 19, 19, 256)   0           concat_2_5[0][0]                 \n",
      "                                                                   conv2_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_blk_bn (BatchNormalization (None, 19, 19, 256)   1024        concat_2_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2_blk_scale (Scale)          (None, 19, 19, 256)   512         conv2_blk_bn[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu2_blk (Activation)           (None, 19, 19, 256)   0           conv2_blk_scale[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2_blk (Conv2D)               (None, 19, 19, 256)   65536       relu2_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pool2 (AveragePooling2D)         (None, 9, 9, 256)     0           conv2_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x1_bn (BatchNormalizatio (None, 9, 9, 256)     1024        pool2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x1_scale (Scale)         (None, 9, 9, 256)     512         conv3_1_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_1_x1 (Activation)          (None, 9, 9, 256)     0           conv3_1_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x1 (Conv2D)              (None, 9, 9, 128)     32768       relu3_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_1_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_1_x2 (Activation)          (None, 9, 9, 128)     0           conv3_1_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_1_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_1 (Merge)               (None, 9, 9, 288)     0           pool2[0][0]                      \n",
      "                                                                   conv3_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x1_bn (BatchNormalizatio (None, 9, 9, 288)     1152        concat_3_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x1_scale (Scale)         (None, 9, 9, 288)     576         conv3_2_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_2_x1 (Activation)          (None, 9, 9, 288)     0           conv3_2_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x1 (Conv2D)              (None, 9, 9, 128)     36864       relu3_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_2_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_2_x2 (Activation)          (None, 9, 9, 128)     0           conv3_2_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_2_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_2 (Merge)               (None, 9, 9, 320)     0           concat_3_1[0][0]                 \n",
      "                                                                   conv3_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x1_bn (BatchNormalizatio (None, 9, 9, 320)     1280        concat_3_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x1_scale (Scale)         (None, 9, 9, 320)     640         conv3_3_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_3_x1 (Activation)          (None, 9, 9, 320)     0           conv3_3_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x1 (Conv2D)              (None, 9, 9, 128)     40960       relu3_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_3_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_3_x2 (Activation)          (None, 9, 9, 128)     0           conv3_3_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_3_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_3_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_3 (Merge)               (None, 9, 9, 352)     0           concat_3_2[0][0]                 \n",
      "                                                                   conv3_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x1_bn (BatchNormalizatio (None, 9, 9, 352)     1408        concat_3_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x1_scale (Scale)         (None, 9, 9, 352)     704         conv3_4_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_4_x1 (Activation)          (None, 9, 9, 352)     0           conv3_4_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x1 (Conv2D)              (None, 9, 9, 128)     45056       relu3_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_4_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_4_x2 (Activation)          (None, 9, 9, 128)     0           conv3_4_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_4_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_4_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_4 (Merge)               (None, 9, 9, 384)     0           concat_3_3[0][0]                 \n",
      "                                                                   conv3_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x1_bn (BatchNormalizatio (None, 9, 9, 384)     1536        concat_3_4[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x1_scale (Scale)         (None, 9, 9, 384)     768         conv3_5_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_5_x1 (Activation)          (None, 9, 9, 384)     0           conv3_5_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x1 (Conv2D)              (None, 9, 9, 128)     49152       relu3_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_5_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_5_x2 (Activation)          (None, 9, 9, 128)     0           conv3_5_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_5_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_5_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_5 (Merge)               (None, 9, 9, 416)     0           concat_3_4[0][0]                 \n",
      "                                                                   conv3_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x1_bn (BatchNormalizatio (None, 9, 9, 416)     1664        concat_3_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x1_scale (Scale)         (None, 9, 9, 416)     832         conv3_6_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_6_x1 (Activation)          (None, 9, 9, 416)     0           conv3_6_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x1 (Conv2D)              (None, 9, 9, 128)     53248       relu3_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_6_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_6_x2 (Activation)          (None, 9, 9, 128)     0           conv3_6_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_6_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_6_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_6 (Merge)               (None, 9, 9, 448)     0           concat_3_5[0][0]                 \n",
      "                                                                   conv3_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x1_bn (BatchNormalizatio (None, 9, 9, 448)     1792        concat_3_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x1_scale (Scale)         (None, 9, 9, 448)     896         conv3_7_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_7_x1 (Activation)          (None, 9, 9, 448)     0           conv3_7_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x1 (Conv2D)              (None, 9, 9, 128)     57344       relu3_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_7_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_7_x2 (Activation)          (None, 9, 9, 128)     0           conv3_7_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_7_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_7_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_7 (Merge)               (None, 9, 9, 480)     0           concat_3_6[0][0]                 \n",
      "                                                                   conv3_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x1_bn (BatchNormalizatio (None, 9, 9, 480)     1920        concat_3_7[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x1_scale (Scale)         (None, 9, 9, 480)     960         conv3_8_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_8_x1 (Activation)          (None, 9, 9, 480)     0           conv3_8_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x1 (Conv2D)              (None, 9, 9, 128)     61440       relu3_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_8_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_8_x2 (Activation)          (None, 9, 9, 128)     0           conv3_8_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_8_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_8_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_8 (Merge)               (None, 9, 9, 512)     0           concat_3_7[0][0]                 \n",
      "                                                                   conv3_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x1_bn (BatchNormalizatio (None, 9, 9, 512)     2048        concat_3_8[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x1_scale (Scale)         (None, 9, 9, 512)     1024        conv3_9_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_9_x1 (Activation)          (None, 9, 9, 512)     0           conv3_9_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x1 (Conv2D)              (None, 9, 9, 128)     65536       relu3_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x2_bn (BatchNormalizatio (None, 9, 9, 128)     512         conv3_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x2_scale (Scale)         (None, 9, 9, 128)     256         conv3_9_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu3_9_x2 (Activation)          (None, 9, 9, 128)     0           conv3_9_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x2_zeropadding (ZeroPadd (None, 11, 11, 128)   0           relu3_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_9_x2 (Conv2D)              (None, 9, 9, 32)      36864       conv3_9_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_9 (Merge)               (None, 9, 9, 544)     0           concat_3_8[0][0]                 \n",
      "                                                                   conv3_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x1_bn (BatchNormalizati (None, 9, 9, 544)     2176        concat_3_9[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x1_scale (Scale)        (None, 9, 9, 544)     1088        conv3_10_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_10_x1 (Activation)         (None, 9, 9, 544)     0           conv3_10_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x1 (Conv2D)             (None, 9, 9, 128)     69632       relu3_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x2_bn (BatchNormalizati (None, 9, 9, 128)     512         conv3_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x2_scale (Scale)        (None, 9, 9, 128)     256         conv3_10_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_10_x2 (Activation)         (None, 9, 9, 128)     0           conv3_10_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x2_zeropadding (ZeroPad (None, 11, 11, 128)   0           relu3_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_10_x2 (Conv2D)             (None, 9, 9, 32)      36864       conv3_10_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_10 (Merge)              (None, 9, 9, 576)     0           concat_3_9[0][0]                 \n",
      "                                                                   conv3_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x1_bn (BatchNormalizati (None, 9, 9, 576)     2304        concat_3_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x1_scale (Scale)        (None, 9, 9, 576)     1152        conv3_11_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_11_x1 (Activation)         (None, 9, 9, 576)     0           conv3_11_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x1 (Conv2D)             (None, 9, 9, 128)     73728       relu3_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x2_bn (BatchNormalizati (None, 9, 9, 128)     512         conv3_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x2_scale (Scale)        (None, 9, 9, 128)     256         conv3_11_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_11_x2 (Activation)         (None, 9, 9, 128)     0           conv3_11_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x2_zeropadding (ZeroPad (None, 11, 11, 128)   0           relu3_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_11_x2 (Conv2D)             (None, 9, 9, 32)      36864       conv3_11_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_11 (Merge)              (None, 9, 9, 608)     0           concat_3_10[0][0]                \n",
      "                                                                   conv3_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x1_bn (BatchNormalizati (None, 9, 9, 608)     2432        concat_3_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x1_scale (Scale)        (None, 9, 9, 608)     1216        conv3_12_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_12_x1 (Activation)         (None, 9, 9, 608)     0           conv3_12_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x1 (Conv2D)             (None, 9, 9, 128)     77824       relu3_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x2_bn (BatchNormalizati (None, 9, 9, 128)     512         conv3_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x2_scale (Scale)        (None, 9, 9, 128)     256         conv3_12_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu3_12_x2 (Activation)         (None, 9, 9, 128)     0           conv3_12_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x2_zeropadding (ZeroPad (None, 11, 11, 128)   0           relu3_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_12_x2 (Conv2D)             (None, 9, 9, 32)      36864       conv3_12_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_3_12 (Merge)              (None, 9, 9, 640)     0           concat_3_11[0][0]                \n",
      "                                                                   conv3_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_blk_bn (BatchNormalization (None, 9, 9, 640)     2560        concat_3_12[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv3_blk_scale (Scale)          (None, 9, 9, 640)     1280        conv3_blk_bn[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu3_blk (Activation)           (None, 9, 9, 640)     0           conv3_blk_scale[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv3_blk (Conv2D)               (None, 9, 9, 640)     409600      relu3_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pool3 (AveragePooling2D)         (None, 4, 4, 640)     0           conv3_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x1_bn (BatchNormalizatio (None, 4, 4, 640)     2560        pool3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x1_scale (Scale)         (None, 4, 4, 640)     1280        conv4_1_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_1_x1 (Activation)          (None, 4, 4, 640)     0           conv4_1_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x1 (Conv2D)              (None, 4, 4, 128)     81920       relu4_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_1_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_1_x2 (Activation)          (None, 4, 4, 128)     0           conv4_1_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_1_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_1 (Merge)               (None, 4, 4, 672)     0           pool3[0][0]                      \n",
      "                                                                   conv4_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x1_bn (BatchNormalizatio (None, 4, 4, 672)     2688        concat_4_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x1_scale (Scale)         (None, 4, 4, 672)     1344        conv4_2_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_2_x1 (Activation)          (None, 4, 4, 672)     0           conv4_2_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x1 (Conv2D)              (None, 4, 4, 128)     86016       relu4_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_2_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_2_x2 (Activation)          (None, 4, 4, 128)     0           conv4_2_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_2_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_2 (Merge)               (None, 4, 4, 704)     0           concat_4_1[0][0]                 \n",
      "                                                                   conv4_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x1_bn (BatchNormalizatio (None, 4, 4, 704)     2816        concat_4_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x1_scale (Scale)         (None, 4, 4, 704)     1408        conv4_3_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_3_x1 (Activation)          (None, 4, 4, 704)     0           conv4_3_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x1 (Conv2D)              (None, 4, 4, 128)     90112       relu4_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_3_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_3_x2 (Activation)          (None, 4, 4, 128)     0           conv4_3_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_3_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_3_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_3 (Merge)               (None, 4, 4, 736)     0           concat_4_2[0][0]                 \n",
      "                                                                   conv4_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x1_bn (BatchNormalizatio (None, 4, 4, 736)     2944        concat_4_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x1_scale (Scale)         (None, 4, 4, 736)     1472        conv4_4_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_4_x1 (Activation)          (None, 4, 4, 736)     0           conv4_4_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x1 (Conv2D)              (None, 4, 4, 128)     94208       relu4_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_4_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_4_x2 (Activation)          (None, 4, 4, 128)     0           conv4_4_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_4_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_4_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_4 (Merge)               (None, 4, 4, 768)     0           concat_4_3[0][0]                 \n",
      "                                                                   conv4_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x1_bn (BatchNormalizatio (None, 4, 4, 768)     3072        concat_4_4[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x1_scale (Scale)         (None, 4, 4, 768)     1536        conv4_5_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_5_x1 (Activation)          (None, 4, 4, 768)     0           conv4_5_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x1 (Conv2D)              (None, 4, 4, 128)     98304       relu4_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_5_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_5_x2 (Activation)          (None, 4, 4, 128)     0           conv4_5_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_5_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_5_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_5 (Merge)               (None, 4, 4, 800)     0           concat_4_4[0][0]                 \n",
      "                                                                   conv4_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x1_bn (BatchNormalizatio (None, 4, 4, 800)     3200        concat_4_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x1_scale (Scale)         (None, 4, 4, 800)     1600        conv4_6_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_6_x1 (Activation)          (None, 4, 4, 800)     0           conv4_6_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x1 (Conv2D)              (None, 4, 4, 128)     102400      relu4_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_6_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_6_x2 (Activation)          (None, 4, 4, 128)     0           conv4_6_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_6_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_6_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_6 (Merge)               (None, 4, 4, 832)     0           concat_4_5[0][0]                 \n",
      "                                                                   conv4_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x1_bn (BatchNormalizatio (None, 4, 4, 832)     3328        concat_4_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x1_scale (Scale)         (None, 4, 4, 832)     1664        conv4_7_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_7_x1 (Activation)          (None, 4, 4, 832)     0           conv4_7_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x1 (Conv2D)              (None, 4, 4, 128)     106496      relu4_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_7_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_7_x2 (Activation)          (None, 4, 4, 128)     0           conv4_7_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_7_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_7_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_7 (Merge)               (None, 4, 4, 864)     0           concat_4_6[0][0]                 \n",
      "                                                                   conv4_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x1_bn (BatchNormalizatio (None, 4, 4, 864)     3456        concat_4_7[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x1_scale (Scale)         (None, 4, 4, 864)     1728        conv4_8_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_8_x1 (Activation)          (None, 4, 4, 864)     0           conv4_8_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x1 (Conv2D)              (None, 4, 4, 128)     110592      relu4_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_8_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_8_x2 (Activation)          (None, 4, 4, 128)     0           conv4_8_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_8_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_8_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_8 (Merge)               (None, 4, 4, 896)     0           concat_4_7[0][0]                 \n",
      "                                                                   conv4_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x1_bn (BatchNormalizatio (None, 4, 4, 896)     3584        concat_4_8[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x1_scale (Scale)         (None, 4, 4, 896)     1792        conv4_9_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_9_x1 (Activation)          (None, 4, 4, 896)     0           conv4_9_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x1 (Conv2D)              (None, 4, 4, 128)     114688      relu4_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x2_bn (BatchNormalizatio (None, 4, 4, 128)     512         conv4_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x2_scale (Scale)         (None, 4, 4, 128)     256         conv4_9_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu4_9_x2 (Activation)          (None, 4, 4, 128)     0           conv4_9_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x2_zeropadding (ZeroPadd (None, 6, 6, 128)     0           relu4_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_9_x2 (Conv2D)              (None, 4, 4, 32)      36864       conv4_9_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_9 (Merge)               (None, 4, 4, 928)     0           concat_4_8[0][0]                 \n",
      "                                                                   conv4_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x1_bn (BatchNormalizati (None, 4, 4, 928)     3712        concat_4_9[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x1_scale (Scale)        (None, 4, 4, 928)     1856        conv4_10_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_10_x1 (Activation)         (None, 4, 4, 928)     0           conv4_10_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x1 (Conv2D)             (None, 4, 4, 128)     118784      relu4_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_10_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_10_x2 (Activation)         (None, 4, 4, 128)     0           conv4_10_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_10_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_10_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_10 (Merge)              (None, 4, 4, 960)     0           concat_4_9[0][0]                 \n",
      "                                                                   conv4_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x1_bn (BatchNormalizati (None, 4, 4, 960)     3840        concat_4_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x1_scale (Scale)        (None, 4, 4, 960)     1920        conv4_11_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_11_x1 (Activation)         (None, 4, 4, 960)     0           conv4_11_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x1 (Conv2D)             (None, 4, 4, 128)     122880      relu4_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_11_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_11_x2 (Activation)         (None, 4, 4, 128)     0           conv4_11_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_11_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_11_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_11 (Merge)              (None, 4, 4, 992)     0           concat_4_10[0][0]                \n",
      "                                                                   conv4_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x1_bn (BatchNormalizati (None, 4, 4, 992)     3968        concat_4_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x1_scale (Scale)        (None, 4, 4, 992)     1984        conv4_12_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_12_x1 (Activation)         (None, 4, 4, 992)     0           conv4_12_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x1 (Conv2D)             (None, 4, 4, 128)     126976      relu4_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_12_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_12_x2 (Activation)         (None, 4, 4, 128)     0           conv4_12_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_12_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_12_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_12 (Merge)              (None, 4, 4, 1024)    0           concat_4_11[0][0]                \n",
      "                                                                   conv4_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x1_bn (BatchNormalizati (None, 4, 4, 1024)    4096        concat_4_12[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x1_scale (Scale)        (None, 4, 4, 1024)    2048        conv4_13_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_13_x1 (Activation)         (None, 4, 4, 1024)    0           conv4_13_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x1 (Conv2D)             (None, 4, 4, 128)     131072      relu4_13_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_13_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_13_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_13_x2 (Activation)         (None, 4, 4, 128)     0           conv4_13_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_13_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_13_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_13_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_13 (Merge)              (None, 4, 4, 1056)    0           concat_4_12[0][0]                \n",
      "                                                                   conv4_13_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x1_bn (BatchNormalizati (None, 4, 4, 1056)    4224        concat_4_13[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x1_scale (Scale)        (None, 4, 4, 1056)    2112        conv4_14_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_14_x1 (Activation)         (None, 4, 4, 1056)    0           conv4_14_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x1 (Conv2D)             (None, 4, 4, 128)     135168      relu4_14_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_14_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_14_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_14_x2 (Activation)         (None, 4, 4, 128)     0           conv4_14_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_14_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_14_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_14_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_14 (Merge)              (None, 4, 4, 1088)    0           concat_4_13[0][0]                \n",
      "                                                                   conv4_14_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x1_bn (BatchNormalizati (None, 4, 4, 1088)    4352        concat_4_14[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x1_scale (Scale)        (None, 4, 4, 1088)    2176        conv4_15_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_15_x1 (Activation)         (None, 4, 4, 1088)    0           conv4_15_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x1 (Conv2D)             (None, 4, 4, 128)     139264      relu4_15_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_15_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_15_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_15_x2 (Activation)         (None, 4, 4, 128)     0           conv4_15_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_15_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_15_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_15_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_15 (Merge)              (None, 4, 4, 1120)    0           concat_4_14[0][0]                \n",
      "                                                                   conv4_15_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x1_bn (BatchNormalizati (None, 4, 4, 1120)    4480        concat_4_15[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x1_scale (Scale)        (None, 4, 4, 1120)    2240        conv4_16_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_16_x1 (Activation)         (None, 4, 4, 1120)    0           conv4_16_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x1 (Conv2D)             (None, 4, 4, 128)     143360      relu4_16_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_16_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_16_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_16_x2 (Activation)         (None, 4, 4, 128)     0           conv4_16_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_16_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_16_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_16_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_16 (Merge)              (None, 4, 4, 1152)    0           concat_4_15[0][0]                \n",
      "                                                                   conv4_16_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x1_bn (BatchNormalizati (None, 4, 4, 1152)    4608        concat_4_16[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x1_scale (Scale)        (None, 4, 4, 1152)    2304        conv4_17_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_17_x1 (Activation)         (None, 4, 4, 1152)    0           conv4_17_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x1 (Conv2D)             (None, 4, 4, 128)     147456      relu4_17_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_17_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_17_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_17_x2 (Activation)         (None, 4, 4, 128)     0           conv4_17_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_17_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_17_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_17_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_17 (Merge)              (None, 4, 4, 1184)    0           concat_4_16[0][0]                \n",
      "                                                                   conv4_17_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x1_bn (BatchNormalizati (None, 4, 4, 1184)    4736        concat_4_17[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x1_scale (Scale)        (None, 4, 4, 1184)    2368        conv4_18_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_18_x1 (Activation)         (None, 4, 4, 1184)    0           conv4_18_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x1 (Conv2D)             (None, 4, 4, 128)     151552      relu4_18_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_18_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_18_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_18_x2 (Activation)         (None, 4, 4, 128)     0           conv4_18_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_18_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_18_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_18_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_18 (Merge)              (None, 4, 4, 1216)    0           concat_4_17[0][0]                \n",
      "                                                                   conv4_18_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x1_bn (BatchNormalizati (None, 4, 4, 1216)    4864        concat_4_18[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x1_scale (Scale)        (None, 4, 4, 1216)    2432        conv4_19_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_19_x1 (Activation)         (None, 4, 4, 1216)    0           conv4_19_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x1 (Conv2D)             (None, 4, 4, 128)     155648      relu4_19_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_19_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_19_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_19_x2 (Activation)         (None, 4, 4, 128)     0           conv4_19_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_19_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_19_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_19_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_19 (Merge)              (None, 4, 4, 1248)    0           concat_4_18[0][0]                \n",
      "                                                                   conv4_19_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x1_bn (BatchNormalizati (None, 4, 4, 1248)    4992        concat_4_19[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x1_scale (Scale)        (None, 4, 4, 1248)    2496        conv4_20_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_20_x1 (Activation)         (None, 4, 4, 1248)    0           conv4_20_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x1 (Conv2D)             (None, 4, 4, 128)     159744      relu4_20_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_20_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_20_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_20_x2 (Activation)         (None, 4, 4, 128)     0           conv4_20_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_20_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_20_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_20_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_20 (Merge)              (None, 4, 4, 1280)    0           concat_4_19[0][0]                \n",
      "                                                                   conv4_20_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x1_bn (BatchNormalizati (None, 4, 4, 1280)    5120        concat_4_20[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x1_scale (Scale)        (None, 4, 4, 1280)    2560        conv4_21_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_21_x1 (Activation)         (None, 4, 4, 1280)    0           conv4_21_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x1 (Conv2D)             (None, 4, 4, 128)     163840      relu4_21_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_21_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_21_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_21_x2 (Activation)         (None, 4, 4, 128)     0           conv4_21_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_21_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_21_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_21_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_21 (Merge)              (None, 4, 4, 1312)    0           concat_4_20[0][0]                \n",
      "                                                                   conv4_21_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x1_bn (BatchNormalizati (None, 4, 4, 1312)    5248        concat_4_21[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x1_scale (Scale)        (None, 4, 4, 1312)    2624        conv4_22_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_22_x1 (Activation)         (None, 4, 4, 1312)    0           conv4_22_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x1 (Conv2D)             (None, 4, 4, 128)     167936      relu4_22_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_22_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_22_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_22_x2 (Activation)         (None, 4, 4, 128)     0           conv4_22_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_22_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_22_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_22_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_22 (Merge)              (None, 4, 4, 1344)    0           concat_4_21[0][0]                \n",
      "                                                                   conv4_22_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x1_bn (BatchNormalizati (None, 4, 4, 1344)    5376        concat_4_22[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x1_scale (Scale)        (None, 4, 4, 1344)    2688        conv4_23_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_23_x1 (Activation)         (None, 4, 4, 1344)    0           conv4_23_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x1 (Conv2D)             (None, 4, 4, 128)     172032      relu4_23_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_23_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_23_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_23_x2 (Activation)         (None, 4, 4, 128)     0           conv4_23_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_23_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_23_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_23_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_23 (Merge)              (None, 4, 4, 1376)    0           concat_4_22[0][0]                \n",
      "                                                                   conv4_23_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x1_bn (BatchNormalizati (None, 4, 4, 1376)    5504        concat_4_23[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x1_scale (Scale)        (None, 4, 4, 1376)    2752        conv4_24_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_24_x1 (Activation)         (None, 4, 4, 1376)    0           conv4_24_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x1 (Conv2D)             (None, 4, 4, 128)     176128      relu4_24_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x2_bn (BatchNormalizati (None, 4, 4, 128)     512         conv4_24_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x2_scale (Scale)        (None, 4, 4, 128)     256         conv4_24_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu4_24_x2 (Activation)         (None, 4, 4, 128)     0           conv4_24_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x2_zeropadding (ZeroPad (None, 6, 6, 128)     0           relu4_24_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_24_x2 (Conv2D)             (None, 4, 4, 32)      36864       conv4_24_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_4_24 (Merge)              (None, 4, 4, 1408)    0           concat_4_23[0][0]                \n",
      "                                                                   conv4_24_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_blk_bn (BatchNormalization (None, 4, 4, 1408)    5632        concat_4_24[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv4_blk_scale (Scale)          (None, 4, 4, 1408)    2816        conv4_blk_bn[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu4_blk (Activation)           (None, 4, 4, 1408)    0           conv4_blk_scale[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv4_blk (Conv2D)               (None, 4, 4, 1408)    1982464     relu4_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "pool4 (AveragePooling2D)         (None, 2, 2, 1408)    0           conv4_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x1_bn (BatchNormalizatio (None, 2, 2, 1408)    5632        pool4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x1_scale (Scale)         (None, 2, 2, 1408)    2816        conv5_1_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_1_x1 (Activation)          (None, 2, 2, 1408)    0           conv5_1_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x1 (Conv2D)              (None, 2, 2, 128)     180224      relu5_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_1_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_1_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_1_x2 (Activation)          (None, 2, 2, 128)     0           conv5_1_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_1_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_1 (Merge)               (None, 2, 2, 1440)    0           pool4[0][0]                      \n",
      "                                                                   conv5_1_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x1_bn (BatchNormalizatio (None, 2, 2, 1440)    5760        concat_5_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x1_scale (Scale)         (None, 2, 2, 1440)    2880        conv5_2_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_2_x1 (Activation)          (None, 2, 2, 1440)    0           conv5_2_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x1 (Conv2D)              (None, 2, 2, 128)     184320      relu5_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_2_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_2_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_2_x2 (Activation)          (None, 2, 2, 128)     0           conv5_2_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_2_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_2 (Merge)               (None, 2, 2, 1472)    0           concat_5_1[0][0]                 \n",
      "                                                                   conv5_2_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x1_bn (BatchNormalizatio (None, 2, 2, 1472)    5888        concat_5_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x1_scale (Scale)         (None, 2, 2, 1472)    2944        conv5_3_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_3_x1 (Activation)          (None, 2, 2, 1472)    0           conv5_3_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x1 (Conv2D)              (None, 2, 2, 128)     188416      relu5_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_3_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_3_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_3_x2 (Activation)          (None, 2, 2, 128)     0           conv5_3_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_3_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_3_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_3 (Merge)               (None, 2, 2, 1504)    0           concat_5_2[0][0]                 \n",
      "                                                                   conv5_3_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x1_bn (BatchNormalizatio (None, 2, 2, 1504)    6016        concat_5_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x1_scale (Scale)         (None, 2, 2, 1504)    3008        conv5_4_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_4_x1 (Activation)          (None, 2, 2, 1504)    0           conv5_4_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x1 (Conv2D)              (None, 2, 2, 128)     192512      relu5_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_4_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_4_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_4_x2 (Activation)          (None, 2, 2, 128)     0           conv5_4_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_4_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_4_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_4 (Merge)               (None, 2, 2, 1536)    0           concat_5_3[0][0]                 \n",
      "                                                                   conv5_4_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x1_bn (BatchNormalizatio (None, 2, 2, 1536)    6144        concat_5_4[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x1_scale (Scale)         (None, 2, 2, 1536)    3072        conv5_5_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_5_x1 (Activation)          (None, 2, 2, 1536)    0           conv5_5_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x1 (Conv2D)              (None, 2, 2, 128)     196608      relu5_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_5_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_5_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_5_x2 (Activation)          (None, 2, 2, 128)     0           conv5_5_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_5_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_5_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_5 (Merge)               (None, 2, 2, 1568)    0           concat_5_4[0][0]                 \n",
      "                                                                   conv5_5_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x1_bn (BatchNormalizatio (None, 2, 2, 1568)    6272        concat_5_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x1_scale (Scale)         (None, 2, 2, 1568)    3136        conv5_6_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_6_x1 (Activation)          (None, 2, 2, 1568)    0           conv5_6_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x1 (Conv2D)              (None, 2, 2, 128)     200704      relu5_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_6_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_6_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_6_x2 (Activation)          (None, 2, 2, 128)     0           conv5_6_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_6_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_6_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_6 (Merge)               (None, 2, 2, 1600)    0           concat_5_5[0][0]                 \n",
      "                                                                   conv5_6_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x1_bn (BatchNormalizatio (None, 2, 2, 1600)    6400        concat_5_6[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x1_scale (Scale)         (None, 2, 2, 1600)    3200        conv5_7_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_7_x1 (Activation)          (None, 2, 2, 1600)    0           conv5_7_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x1 (Conv2D)              (None, 2, 2, 128)     204800      relu5_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_7_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_7_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_7_x2 (Activation)          (None, 2, 2, 128)     0           conv5_7_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_7_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_7_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_7_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_7 (Merge)               (None, 2, 2, 1632)    0           concat_5_6[0][0]                 \n",
      "                                                                   conv5_7_x2[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "conv5_8_x1_bn (BatchNormalizatio (None, 2, 2, 1632)    6528        concat_5_7[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x1_scale (Scale)         (None, 2, 2, 1632)    3264        conv5_8_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_8_x1 (Activation)          (None, 2, 2, 1632)    0           conv5_8_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x1 (Conv2D)              (None, 2, 2, 128)     208896      relu5_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_8_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_8_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_8_x2 (Activation)          (None, 2, 2, 128)     0           conv5_8_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_8_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_8_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_8 (Merge)               (None, 2, 2, 1664)    0           concat_5_7[0][0]                 \n",
      "                                                                   conv5_8_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x1_bn (BatchNormalizatio (None, 2, 2, 1664)    6656        concat_5_8[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x1_scale (Scale)         (None, 2, 2, 1664)    3328        conv5_9_x1_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_9_x1 (Activation)          (None, 2, 2, 1664)    0           conv5_9_x1_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x1 (Conv2D)              (None, 2, 2, 128)     212992      relu5_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x2_bn (BatchNormalizatio (None, 2, 2, 128)     512         conv5_9_x1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x2_scale (Scale)         (None, 2, 2, 128)     256         conv5_9_x2_bn[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "relu5_9_x2 (Activation)          (None, 2, 2, 128)     0           conv5_9_x2_scale[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x2_zeropadding (ZeroPadd (None, 4, 4, 128)     0           relu5_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_9_x2 (Conv2D)              (None, 2, 2, 32)      36864       conv5_9_x2_zeropadding[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_9 (Merge)               (None, 2, 2, 1696)    0           concat_5_8[0][0]                 \n",
      "                                                                   conv5_9_x2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x1_bn (BatchNormalizati (None, 2, 2, 1696)    6784        concat_5_9[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x1_scale (Scale)        (None, 2, 2, 1696)    3392        conv5_10_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_10_x1 (Activation)         (None, 2, 2, 1696)    0           conv5_10_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x1 (Conv2D)             (None, 2, 2, 128)     217088      relu5_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_10_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_10_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_10_x2 (Activation)         (None, 2, 2, 128)     0           conv5_10_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_10_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_10_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_10 (Merge)              (None, 2, 2, 1728)    0           concat_5_9[0][0]                 \n",
      "                                                                   conv5_10_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x1_bn (BatchNormalizati (None, 2, 2, 1728)    6912        concat_5_10[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x1_scale (Scale)        (None, 2, 2, 1728)    3456        conv5_11_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_11_x1 (Activation)         (None, 2, 2, 1728)    0           conv5_11_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x1 (Conv2D)             (None, 2, 2, 128)     221184      relu5_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_11_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_11_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_11_x2 (Activation)         (None, 2, 2, 128)     0           conv5_11_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_11_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_11_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_11 (Merge)              (None, 2, 2, 1760)    0           concat_5_10[0][0]                \n",
      "                                                                   conv5_11_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x1_bn (BatchNormalizati (None, 2, 2, 1760)    7040        concat_5_11[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x1_scale (Scale)        (None, 2, 2, 1760)    3520        conv5_12_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_12_x1 (Activation)         (None, 2, 2, 1760)    0           conv5_12_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x1 (Conv2D)             (None, 2, 2, 128)     225280      relu5_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_12_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_12_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_12_x2 (Activation)         (None, 2, 2, 128)     0           conv5_12_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_12_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_12_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_12 (Merge)              (None, 2, 2, 1792)    0           concat_5_11[0][0]                \n",
      "                                                                   conv5_12_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x1_bn (BatchNormalizati (None, 2, 2, 1792)    7168        concat_5_12[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x1_scale (Scale)        (None, 2, 2, 1792)    3584        conv5_13_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_13_x1 (Activation)         (None, 2, 2, 1792)    0           conv5_13_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x1 (Conv2D)             (None, 2, 2, 128)     229376      relu5_13_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_13_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_13_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_13_x2 (Activation)         (None, 2, 2, 128)     0           conv5_13_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_13_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_13_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_13_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_13 (Merge)              (None, 2, 2, 1824)    0           concat_5_12[0][0]                \n",
      "                                                                   conv5_13_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x1_bn (BatchNormalizati (None, 2, 2, 1824)    7296        concat_5_13[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x1_scale (Scale)        (None, 2, 2, 1824)    3648        conv5_14_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_14_x1 (Activation)         (None, 2, 2, 1824)    0           conv5_14_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x1 (Conv2D)             (None, 2, 2, 128)     233472      relu5_14_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_14_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_14_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_14_x2 (Activation)         (None, 2, 2, 128)     0           conv5_14_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_14_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_14_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_14_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_14 (Merge)              (None, 2, 2, 1856)    0           concat_5_13[0][0]                \n",
      "                                                                   conv5_14_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x1_bn (BatchNormalizati (None, 2, 2, 1856)    7424        concat_5_14[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x1_scale (Scale)        (None, 2, 2, 1856)    3712        conv5_15_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_15_x1 (Activation)         (None, 2, 2, 1856)    0           conv5_15_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x1 (Conv2D)             (None, 2, 2, 128)     237568      relu5_15_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_15_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_15_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_15_x2 (Activation)         (None, 2, 2, 128)     0           conv5_15_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_15_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_15_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_15_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_15 (Merge)              (None, 2, 2, 1888)    0           concat_5_14[0][0]                \n",
      "                                                                   conv5_15_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x1_bn (BatchNormalizati (None, 2, 2, 1888)    7552        concat_5_15[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x1_scale (Scale)        (None, 2, 2, 1888)    3776        conv5_16_x1_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_16_x1 (Activation)         (None, 2, 2, 1888)    0           conv5_16_x1_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x1 (Conv2D)             (None, 2, 2, 128)     241664      relu5_16_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x2_bn (BatchNormalizati (None, 2, 2, 128)     512         conv5_16_x1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x2_scale (Scale)        (None, 2, 2, 128)     256         conv5_16_x2_bn[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "relu5_16_x2 (Activation)         (None, 2, 2, 128)     0           conv5_16_x2_scale[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x2_zeropadding (ZeroPad (None, 4, 4, 128)     0           relu5_16_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_16_x2 (Conv2D)             (None, 2, 2, 32)      36864       conv5_16_x2_zeropadding[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "concat_5_16 (Merge)              (None, 2, 2, 1920)    0           concat_5_15[0][0]                \n",
      "                                                                   conv5_16_x2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_blk_bn (BatchNormalization (None, 2, 2, 1920)    7680        concat_5_16[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv5_blk_scale (Scale)          (None, 2, 2, 1920)    3840        conv5_blk_bn[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "relu5_blk (Activation)           (None, 2, 2, 1920)    0           conv5_blk_scale[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "pool5 (GlobalAveragePooling2D)   (None, 1920)          0           relu5_blk[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "fc6 (Dense)                      (None, 2)             3842        pool5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "prob (Activation)                (None, 2)             0           fc6[0][0]                        \n",
      "====================================================================================================\n",
      "Total params: 12,264,706\n",
      "Trainable params: 12,128,066\n",
      "Non-trainable params: 136,640\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseNetModel(DaveBaseModel):\n",
    "    def get_model(self):\n",
    "        model = DenseNet(classes = 2)\n",
    "        '''Create the FCN and return a keras model.'''\n",
    "\n",
    "#         model = Sequential()\n",
    "\n",
    "#         # Input image: 75x75x3\n",
    "#         model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n",
    "#         DaveModel.ConvBlock(model, 1, 32)\n",
    "#         # 37x37x32\n",
    "#         DaveModel.ConvBlock(model, 1, 64)\n",
    "#         # 18x18x64\n",
    "#         DaveModel.ConvBlock(model, 1, 128)\n",
    "#         # 9x9x128\n",
    "#         DaveModel.ConvBlock(model, 1, 128)\n",
    "#         # 4x4x128\n",
    "#         model.add(ZeroPadding2D((1, 1)))\n",
    "#         model.add(Conv2D(2, (3, 3), activation='relu'))\n",
    "#         model.add(GlobalAveragePooling2D())\n",
    "#         # 4x4x2\n",
    "#         model.add(Activation('softmax'))\n",
    "        \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"densenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:118: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), use_bias=False, name=\"conv1\", strides=(2, 2))`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:238: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv2_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv2_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), use_bias=False, name=\"conv2_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv3_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv3_12_x2\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(640, (1, 1), use_bias=False, name=\"conv3_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_13_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_13_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_14_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_14_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_15_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_15_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_16_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_16_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_17_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_17_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_18_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_18_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_19_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_19_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_20_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_20_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_21_x1\")`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_21_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_22_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_22_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_23_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_23_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv4_24_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv4_24_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:209: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1408, (1, 1), use_bias=False, name=\"conv4_blk\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_1_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_1_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_2_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_2_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_3_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_3_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_4_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_4_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_5_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_5_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_6_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_6_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_7_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_7_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_8_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_8_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_9_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_9_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_10_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_10_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_11_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_11_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_12_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_12_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_13_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_13_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_14_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_14_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_15_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_15_x2\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:172: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), use_bias=False, name=\"conv5_16_x1\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), use_bias=False, name=\"conv5_16_x2\")`\n"
     ]
    }
   ],
   "source": [
    "model = DenseNetModel(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: densenet\n",
      "Batch Size: 16\n",
      "Epochs: 10\n",
      "Epoch 1/10\n",
      "81/80 [==============================] - 20s - loss: 0.2359 - acc: 0.8979 - val_loss: 0.3820 - val_acc: 0.8255\n",
      "Epoch 2/10\n",
      "81/80 [==============================] - 19s - loss: 0.2159 - acc: 0.9157 - val_loss: 0.3154 - val_acc: 0.8723\n",
      "Epoch 3/10\n",
      "81/80 [==============================] - 20s - loss: 0.2274 - acc: 0.9072 - val_loss: 0.3738 - val_acc: 0.8660\n",
      "Epoch 4/10\n",
      "81/80 [==============================] - 19s - loss: 0.2318 - acc: 0.8989 - val_loss: 0.3210 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "81/80 [==============================] - 20s - loss: 0.2277 - acc: 0.9033 - val_loss: 0.4518 - val_acc: 0.8100\n",
      "Epoch 6/10\n",
      "81/80 [==============================] - 19s - loss: 0.2243 - acc: 0.9005 - val_loss: 0.3413 - val_acc: 0.8536\n",
      "Epoch 7/10\n",
      "81/80 [==============================] - 19s - loss: 0.2342 - acc: 0.9049 - val_loss: 0.3443 - val_acc: 0.8785\n",
      "Epoch 8/10\n",
      "81/80 [==============================] - 19s - loss: 0.2348 - acc: 0.9043 - val_loss: 0.4795 - val_acc: 0.7944\n",
      "Epoch 9/10\n",
      "81/80 [==============================] - 19s - loss: 0.2326 - acc: 0.8931 - val_loss: 0.7824 - val_acc: 0.7227\n",
      "Epoch 10/10\n",
      "81/80 [==============================] - 19s - loss: 0.2199 - acc: 0.9035 - val_loss: 0.3501 - val_acc: 0.8567\n"
     ]
    }
   ],
   "source": [
    "model.train(16, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/BIGBALLON/cifar-10-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard\n",
    "\n",
    "batch_size    = 128\n",
    "epochs        = 200\n",
    "iterations    = 391\n",
    "num_classes   = 2\n",
    "log_filepath  = './lenet'\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal', input_shape=(75,75,3)))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(16, (5, 5), padding='valid', activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(120, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(84, activation = 'relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dense(2, activation = 'softmax', kernel_initializer='he_normal'))\n",
    "    sgd = optimizers.SGD(lr=.01, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch <= 60:\n",
    "        return 0.05\n",
    "    if epoch <= 120:\n",
    "        return 0.01\n",
    "    if epoch <= 160:    \n",
    "        return 0.002\n",
    "    return 0.0004\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     # load data\n",
    "#     (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "#     y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#     y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "#     x_train = x_train.astype('float32')\n",
    "#     x_test = x_test.astype('float32')\n",
    "#     x_train /= 255\n",
    "#     x_test /= 255\n",
    "\n",
    "    # build network\n",
    "#     model = build_model()\n",
    "#     print(model.summary())\n",
    "#     # set callback\n",
    "#     tb_cb = TensorBoard(log_dir=log_filepath, histogram_freq=0)\n",
    "#     change_lr = LearningRateScheduler(scheduler)\n",
    "#     cbks = [change_lr,tb_cb]\n",
    "\n",
    "#     # start traing \n",
    "#     model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,callbacks=cbks,\n",
    "#                   validation_data=(x_test, y_test), shuffle=True)\n",
    "#     # save model\n",
    "#     model.save('lenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNetModel2(DaveBaseModel):\n",
    "    def get_model(self):\n",
    "        return build_model()\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"lenet2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LeNetModel2(Xtr, ytr, Xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lenet2\n",
      "Batch Size: 32\n",
      "Epochs: 50\n",
      "Epoch 1/50\n",
      "41/40 [==============================] - 3s - loss: 0.3607 - acc: 0.8175 - val_loss: 0.4849 - val_acc: 0.7445\n",
      "Epoch 2/50\n",
      "41/40 [==============================] - 2s - loss: 0.3550 - acc: 0.8238 - val_loss: 0.3708 - val_acc: 0.8069\n",
      "Epoch 3/50\n",
      "41/40 [==============================] - 3s - loss: 0.2921 - acc: 0.8548 - val_loss: 0.3378 - val_acc: 0.8318\n",
      "Epoch 4/50\n",
      "41/40 [==============================] - 2s - loss: 0.3002 - acc: 0.8604 - val_loss: 0.3845 - val_acc: 0.7850\n",
      "Epoch 5/50\n",
      "41/40 [==============================] - 2s - loss: 0.3030 - acc: 0.8449 - val_loss: 0.3382 - val_acc: 0.8380\n",
      "Epoch 6/50\n",
      "41/40 [==============================] - 2s - loss: 0.3115 - acc: 0.8403 - val_loss: 0.3408 - val_acc: 0.8318\n",
      "Epoch 7/50\n",
      "41/40 [==============================] - 2s - loss: 0.3050 - acc: 0.8566 - val_loss: 0.3398 - val_acc: 0.8505\n",
      "Epoch 8/50\n",
      "41/40 [==============================] - 2s - loss: 0.2882 - acc: 0.8555 - val_loss: 0.3448 - val_acc: 0.8411\n",
      "Epoch 9/50\n",
      "41/40 [==============================] - 2s - loss: 0.2906 - acc: 0.8589 - val_loss: 0.3905 - val_acc: 0.7632\n",
      "Epoch 10/50\n",
      "41/40 [==============================] - 2s - loss: 0.3024 - acc: 0.8490 - val_loss: 0.3715 - val_acc: 0.8131\n",
      "Epoch 11/50\n",
      "41/40 [==============================] - 2s - loss: 0.3081 - acc: 0.8482 - val_loss: 0.3552 - val_acc: 0.7975\n",
      "Epoch 12/50\n",
      "41/40 [==============================] - 2s - loss: 0.2912 - acc: 0.8582 - val_loss: 0.4034 - val_acc: 0.7882\n",
      "Epoch 13/50\n",
      "41/40 [==============================] - 2s - loss: 0.2917 - acc: 0.8594 - val_loss: 0.3354 - val_acc: 0.8349\n",
      "Epoch 14/50\n",
      "41/40 [==============================] - 2s - loss: 0.2827 - acc: 0.8662 - val_loss: 0.3740 - val_acc: 0.7913\n",
      "Epoch 15/50\n",
      "41/40 [==============================] - 2s - loss: 0.3107 - acc: 0.8502 - val_loss: 0.5557 - val_acc: 0.7290\n",
      "Epoch 16/50\n",
      "41/40 [==============================] - 2s - loss: 0.3031 - acc: 0.8502 - val_loss: 0.3114 - val_acc: 0.8723\n",
      "Epoch 17/50\n",
      "41/40 [==============================] - 2s - loss: 0.3253 - acc: 0.8453 - val_loss: 0.3388 - val_acc: 0.8442\n",
      "Epoch 18/50\n",
      "41/40 [==============================] - 2s - loss: 0.3170 - acc: 0.8399 - val_loss: 0.3691 - val_acc: 0.7975\n",
      "Epoch 19/50\n",
      "41/40 [==============================] - 2s - loss: 0.3119 - acc: 0.8339 - val_loss: 0.5102 - val_acc: 0.7103\n",
      "Epoch 20/50\n",
      "41/40 [==============================] - 2s - loss: 0.3039 - acc: 0.8502 - val_loss: 0.3595 - val_acc: 0.8006\n",
      "Epoch 21/50\n",
      "41/40 [==============================] - 3s - loss: 0.2947 - acc: 0.8665 - val_loss: 0.3985 - val_acc: 0.7664\n",
      "Epoch 22/50\n",
      "41/40 [==============================] - 2s - loss: 0.2859 - acc: 0.8716 - val_loss: 0.3074 - val_acc: 0.8567\n",
      "Epoch 23/50\n",
      "41/40 [==============================] - 2s - loss: 0.2960 - acc: 0.8571 - val_loss: 0.3620 - val_acc: 0.8193\n",
      "Epoch 24/50\n",
      "41/40 [==============================] - 2s - loss: 0.2806 - acc: 0.8604 - val_loss: 0.3692 - val_acc: 0.7882\n",
      "Epoch 25/50\n",
      "41/40 [==============================] - 2s - loss: 0.2730 - acc: 0.8772 - val_loss: 0.4161 - val_acc: 0.7695\n",
      "Epoch 26/50\n",
      "41/40 [==============================] - 2s - loss: 0.2731 - acc: 0.8719 - val_loss: 0.3422 - val_acc: 0.8287\n",
      "Epoch 27/50\n",
      "41/40 [==============================] - 2s - loss: 0.2879 - acc: 0.8716 - val_loss: 0.3368 - val_acc: 0.8162\n",
      "Epoch 28/50\n",
      "41/40 [==============================] - 2s - loss: 0.2858 - acc: 0.8597 - val_loss: 0.3348 - val_acc: 0.8474\n",
      "Epoch 29/50\n",
      "41/40 [==============================] - 2s - loss: 0.2959 - acc: 0.8658 - val_loss: 0.3642 - val_acc: 0.8100\n",
      "Epoch 30/50\n",
      "41/40 [==============================] - 2s - loss: 0.2833 - acc: 0.8754 - val_loss: 0.3253 - val_acc: 0.8349\n",
      "Epoch 31/50\n",
      "41/40 [==============================] - 2s - loss: 0.2804 - acc: 0.8673 - val_loss: 0.3693 - val_acc: 0.7944\n",
      "Epoch 32/50\n",
      "41/40 [==============================] - 2s - loss: 0.2867 - acc: 0.8658 - val_loss: 0.4019 - val_acc: 0.7664\n",
      "Epoch 33/50\n",
      "41/40 [==============================] - 2s - loss: 0.2751 - acc: 0.8673 - val_loss: 0.3310 - val_acc: 0.8380\n",
      "Epoch 34/50\n",
      "41/40 [==============================] - 2s - loss: 0.2871 - acc: 0.8616 - val_loss: 0.3355 - val_acc: 0.8255\n",
      "Epoch 35/50\n",
      "41/40 [==============================] - 2s - loss: 0.2759 - acc: 0.8604 - val_loss: 0.3841 - val_acc: 0.7944\n",
      "Epoch 36/50\n",
      "41/40 [==============================] - 2s - loss: 0.2743 - acc: 0.8765 - val_loss: 0.3775 - val_acc: 0.7882\n",
      "Epoch 37/50\n",
      "41/40 [==============================] - 2s - loss: 0.2697 - acc: 0.8681 - val_loss: 0.3518 - val_acc: 0.8193\n",
      "Epoch 38/50\n",
      "41/40 [==============================] - 2s - loss: 0.2836 - acc: 0.8536 - val_loss: 0.3608 - val_acc: 0.78500.8\n",
      "Epoch 39/50\n",
      "41/40 [==============================] - 2s - loss: 0.2712 - acc: 0.8726 - val_loss: 0.4470 - val_acc: 0.7788\n",
      "Epoch 40/50\n",
      "41/40 [==============================] - 2s - loss: 0.2867 - acc: 0.8643 - val_loss: 0.4007 - val_acc: 0.8006\n",
      "Epoch 41/50\n",
      "41/40 [==============================] - 2s - loss: 0.2869 - acc: 0.8677 - val_loss: 0.3689 - val_acc: 0.7882\n",
      "Epoch 42/50\n",
      "41/40 [==============================] - 2s - loss: 0.2816 - acc: 0.8605 - val_loss: 0.4352 - val_acc: 0.7632\n",
      "Epoch 43/50\n",
      "41/40 [==============================] - 2s - loss: 0.2954 - acc: 0.8574 - val_loss: 0.3451 - val_acc: 0.8162\n",
      "Epoch 44/50\n",
      "41/40 [==============================] - 2s - loss: 0.2669 - acc: 0.8726 - val_loss: 0.3497 - val_acc: 0.8069\n",
      "Epoch 45/50\n",
      "41/40 [==============================] - 2s - loss: 0.2942 - acc: 0.8559 - val_loss: 0.3675 - val_acc: 0.7913\n",
      "Epoch 46/50\n",
      "41/40 [==============================] - 2s - loss: 0.2811 - acc: 0.8765 - val_loss: 0.3780 - val_acc: 0.8069\n",
      "Epoch 47/50\n",
      "41/40 [==============================] - 2s - loss: 0.2758 - acc: 0.8848 - val_loss: 0.3960 - val_acc: 0.7726\n",
      "Epoch 48/50\n",
      "41/40 [==============================] - 2s - loss: 0.2747 - acc: 0.8635 - val_loss: 0.3547 - val_acc: 0.8193\n",
      "Epoch 49/50\n",
      "41/40 [==============================] - 2s - loss: 0.2636 - acc: 0.8665 - val_loss: 0.4251 - val_acc: 0.7570\n",
      "Epoch 50/50\n",
      "41/40 [==============================] - 2s - loss: 0.2937 - acc: 0.8400 - val_loss: 0.3618 - val_acc: 0.8069\n"
     ]
    }
   ],
   "source": [
    "model.train(32, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.initializers import he_normal\n",
    "from keras import regularizers\n",
    "\n",
    "weight_decay       = 0.0005\n",
    "\n",
    "def color_preprocessing(x_train,x_test):\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    mean = [125.307, 122.95, 113.865]\n",
    "    std  = [62.9932, 62.0887, 66.7048]\n",
    "    for i in range(3):\n",
    "        x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
    "        x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
    "\n",
    "    return x_train, x_test\n",
    "\n",
    "def wide_residual_network(img_input,classes_num,depth,k):\n",
    "\n",
    "    print('Wide-Resnet %dx%d' %(depth, k))\n",
    "    n_filters  = [16, 16*k, 32*k, 64*k]\n",
    "    n_stack    = (depth - 4) / 6\n",
    "    in_filters = 16\n",
    "\n",
    "    def conv3x3(x,filters):\n",
    "    \treturn Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1), padding='same',\n",
    "    \tkernel_initializer=he_normal(),\n",
    "        kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "\n",
    "    def residual_block(x,out_filters,increase_filter=False):\n",
    "        if increase_filter:\n",
    "            first_stride = (2,2)\n",
    "        else:\n",
    "            first_stride = (1,1)\n",
    "        pre_bn   = BatchNormalization()(x)\n",
    "        pre_relu = Activation('relu')(pre_bn)\n",
    "        conv_1 = Conv2D(out_filters,kernel_size=(3,3),strides=first_stride,padding='same',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(pre_relu)\n",
    "        bn_1   = BatchNormalization()(conv_1)\n",
    "        relu1  = Activation('relu')(bn_1)\n",
    "        conv_2 = Conv2D(out_filters, kernel_size=(3,3), strides=(1,1), padding='same', kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(relu1)\n",
    "        if increase_filter or in_filters != out_filters:\n",
    "            projection = Conv2D(out_filters,kernel_size=(1,1),strides=first_stride,padding='same',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "            block = add([conv_2, projection])\n",
    "        else:\n",
    "            block = add([conv_2,x])\n",
    "        return block\n",
    "\n",
    "    def wide_residual_layer(x,out_filters,increase_filter=False):\n",
    "    \tx = residual_block(x,out_filters,increase_filter)\n",
    "    \tin_filters = out_filters\n",
    "    \tfor _ in range(1,int(n_stack)):\n",
    "    \t\tx = residual_block(x,out_filters)\n",
    "    \treturn x\n",
    "\n",
    "\n",
    "    x = conv3x3(img_input,n_filters[0])\n",
    "    x = wide_residual_layer(x,n_filters[1])\n",
    "    x = wide_residual_layer(x,n_filters[2],increase_filter=True)\n",
    "    x = wide_residual_layer(x,n_filters[3],increase_filter=True)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(classes_num,activation='softmax',kernel_initializer=he_normal(),kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WideResidualModel(DaveBaseModel):\n",
    "    depth              = 16\n",
    "    wide               = 8\n",
    "    num_classes        = 2\n",
    "    img_rows, img_cols = 75, 75\n",
    "    img_channels       = 3\n",
    "    batch_size         = 128\n",
    "    epochs             = 200\n",
    "    iterations         = 391\n",
    "    log_filepath       = r'./w_resnet/'\n",
    "    \n",
    "    def get_model(self):\n",
    "        img_input = Input(shape=(self.img_rows,self.img_cols,self.img_channels))\n",
    "        output = wide_residual_network(img_input,self.num_classes,self.depth,self.wide)\n",
    "        resnet = Model(img_input, output)\n",
    "        print(resnet.summary())\n",
    "        # set optimizer\n",
    "        resnet.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "#         sgd = optimizers.SGD(lr=.01, momentum=0.9, nesterov=True)\n",
    "#         resnet.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "        return resnet\n",
    "    \n",
    "    def get_name(self):\n",
    "        return \"wide\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr2, Xv2 = color_preprocessing(Xtr, Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide-Resnet 16x8\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_15 (InputLayer)            (None, 75, 75, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)              (None, 75, 75, 16)    448         input_15[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchNo (None, 75, 75, 16)    64          conv2d_490[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_474 (Activation)      (None, 75, 75, 16)    0           batch_normalization_436[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)              (None, 75, 75, 128)   18560       activation_474[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchNo (None, 75, 75, 128)   512         conv2d_491[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_475 (Activation)      (None, 75, 75, 128)   0           batch_normalization_437[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)              (None, 75, 75, 128)   147584      activation_475[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)              (None, 75, 75, 128)   2176        conv2d_490[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_63 (Add)                     (None, 75, 75, 128)   0           conv2d_492[0][0]                 \n",
      "                                                                   conv2d_493[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchNo (None, 75, 75, 128)   512         add_63[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_476 (Activation)      (None, 75, 75, 128)   0           batch_normalization_438[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)              (None, 75, 75, 128)   147584      activation_476[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchNo (None, 75, 75, 128)   512         conv2d_494[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_477 (Activation)      (None, 75, 75, 128)   0           batch_normalization_439[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)              (None, 75, 75, 128)   147584      activation_477[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)              (None, 75, 75, 128)   16512       add_63[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_64 (Add)                     (None, 75, 75, 128)   0           conv2d_495[0][0]                 \n",
      "                                                                   conv2d_496[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchNo (None, 75, 75, 128)   512         add_64[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_478 (Activation)      (None, 75, 75, 128)   0           batch_normalization_440[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)              (None, 38, 38, 256)   295168      activation_478[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchNo (None, 38, 38, 256)   1024        conv2d_497[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_479 (Activation)      (None, 38, 38, 256)   0           batch_normalization_441[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)              (None, 38, 38, 256)   590080      activation_479[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)              (None, 38, 38, 256)   33024       add_64[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_65 (Add)                     (None, 38, 38, 256)   0           conv2d_498[0][0]                 \n",
      "                                                                   conv2d_499[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchNo (None, 38, 38, 256)   1024        add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_480 (Activation)      (None, 38, 38, 256)   0           batch_normalization_442[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)              (None, 38, 38, 256)   590080      activation_480[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchNo (None, 38, 38, 256)   1024        conv2d_500[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_481 (Activation)      (None, 38, 38, 256)   0           batch_normalization_443[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)              (None, 38, 38, 256)   590080      activation_481[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)              (None, 38, 38, 256)   65792       add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_66 (Add)                     (None, 38, 38, 256)   0           conv2d_501[0][0]                 \n",
      "                                                                   conv2d_502[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchNo (None, 38, 38, 256)   1024        add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_482 (Activation)      (None, 38, 38, 256)   0           batch_normalization_444[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)              (None, 19, 19, 512)   1180160     activation_482[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchNo (None, 19, 19, 512)   2048        conv2d_503[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_483 (Activation)      (None, 19, 19, 512)   0           batch_normalization_445[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)              (None, 19, 19, 512)   2359808     activation_483[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)              (None, 19, 19, 512)   131584      add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_67 (Add)                     (None, 19, 19, 512)   0           conv2d_504[0][0]                 \n",
      "                                                                   conv2d_505[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchNo (None, 19, 19, 512)   2048        add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_484 (Activation)      (None, 19, 19, 512)   0           batch_normalization_446[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)              (None, 19, 19, 512)   2359808     activation_484[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchNo (None, 19, 19, 512)   2048        conv2d_506[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_485 (Activation)      (None, 19, 19, 512)   0           batch_normalization_447[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)              (None, 19, 19, 512)   2359808     activation_485[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)              (None, 19, 19, 512)   262656      add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_68 (Add)                     (None, 19, 19, 512)   0           conv2d_507[0][0]                 \n",
      "                                                                   conv2d_508[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchNo (None, 19, 19, 512)   2048        add_68[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_486 (Activation)      (None, 19, 19, 512)   0           batch_normalization_448[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_30 (Glo (None, 512)           0           activation_486[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_68 (Dense)                 (None, 2)             1026        global_average_pooling2d_30[0][0]\n",
      "====================================================================================================\n",
      "Total params: 11,313,922\n",
      "Trainable params: 11,306,722\n",
      "Non-trainable params: 7,200\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = WideResidualModel(Xtr2, ytr, Xv2, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: wide\n",
      "Batch Size: 32\n",
      "Epochs: 20\n",
      "Epoch 1/20\n",
      "41/40 [==============================] - 26s - loss: 1.9431 - acc: 0.7514 - val_loss: 2.0569 - val_acc: 0.6573\n",
      "Epoch 2/20\n",
      "41/40 [==============================] - 26s - loss: 1.9056 - acc: 0.7564 - val_loss: 2.7941 - val_acc: 0.6573\n",
      "Epoch 3/20\n",
      "41/40 [==============================] - 26s - loss: 1.8394 - acc: 0.7788 - val_loss: 3.7357 - val_acc: 0.6573\n",
      "Epoch 4/20\n",
      "41/40 [==============================] - 26s - loss: 1.7993 - acc: 0.7567 - val_loss: 4.6903 - val_acc: 0.6573\n",
      "Epoch 5/20\n",
      "25/40 [=================>............] - ETA: 9s - loss: 1.7423 - acc: 0.7788"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-308f050afe0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\_GithubTest\\MachineLearning\\Kaggle\\Statoil C-CORE Iceberg Classifier\\models.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, epochs, saveModel)\u001b[0m\n\u001b[0;32m     43\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                          validation_steps = len(self.Xv) / self.batch_size)\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1838\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1839\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1840\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1563\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2268\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(32, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99999642e-01,   3.94188163e-07],\n",
       "       [  9.99999285e-01,   7.67450786e-07],\n",
       "       [  9.99995112e-01,   4.87961142e-06],\n",
       "       ..., \n",
       "       [  9.99999404e-01,   5.75652166e-07],\n",
       "       [  9.99999523e-01,   4.57558031e-07],\n",
       "       [  9.99994874e-01,   5.11484541e-06]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
