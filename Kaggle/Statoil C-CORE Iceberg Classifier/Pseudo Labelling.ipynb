{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "import helpers\n",
    "from models import DaveModel, DaveVGG, DaveVGG19, SimpleModel, LeNetModel\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = helpers.get_images(train)\n",
    "X_test = helpers.get_images(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = to_categorical(train.is_iceberg.values,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xtr, Xv, ytr, yv = train_test_split(X, y, shuffle=False, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRunner = Trainer(X, y, [\n",
    "    DaveModel(),\n",
    "    DaveVGG(),\n",
    "    DaveVGG19(),\n",
    "    LeNetModel()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRunner.models[0].model.load_weights(\"davemodel20171203-181713.h5\")\n",
    "trainRunner.models[1].model.load_weights(\"vgg20171203-182704.h5\")\n",
    "trainRunner.models[2].model.load_weights(\"vgg1920171203-183725.h5\")\n",
    "trainRunner.models[3].model.load_weights(\"lenet20171203-184024.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davemodel\n",
      "vgg\n",
      "vgg19\n",
      "lenet\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "for model in trainRunner.models:\n",
    "    name = model.get_name()\n",
    "    print(name)\n",
    "    test = model.model.predict(X_test)\n",
    "    results[name] = test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>davemodel</th>\n",
       "      <th>vgg</th>\n",
       "      <th>vgg19</th>\n",
       "      <th>lenet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.904778</td>\n",
       "      <td>0.506920</td>\n",
       "      <td>0.729676</td>\n",
       "      <td>0.523765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.686788</td>\n",
       "      <td>0.277934</td>\n",
       "      <td>0.972092</td>\n",
       "      <td>0.611775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994779</td>\n",
       "      <td>0.248336</td>\n",
       "      <td>0.985353</td>\n",
       "      <td>0.991685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.011655</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.004780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.968177</td>\n",
       "      <td>0.280054</td>\n",
       "      <td>0.898017</td>\n",
       "      <td>0.604213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   davemodel       vgg     vgg19     lenet\n",
       "0   0.904778  0.506920  0.729676  0.523765\n",
       "1   0.686788  0.277934  0.972092  0.611775\n",
       "2   0.994779  0.248336  0.985353  0.991685\n",
       "3   0.001994  0.011655  0.003505  0.004780\n",
       "4   0.968177  0.280054  0.898017  0.604213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()\n",
    "\n",
    "# results.iloc[:, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results[\"very_positive\"] = results.apply(lambda x: x[\"davemodel\"] > 0.5 and x[\"vgg\"] > 0.5 and x[\"vgg19\"] > 0.5 and x[\"lenet\"] > 0.5, axis = 1)\n",
    "results[\"very_negative\"] = results.apply(lambda x: x[\"davemodel\"] <= 0.5 and x[\"vgg\"] <= 0.5 and x[\"vgg19\"] <= 0.5 and x[\"lenet\"] <= 0.5, axis = 1)\n",
    "results[\"definitive\"] = results[\"very_positive\"] | results[\"very_negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results.head()\n",
    "# results[results[\"definitive\"]]\n",
    "# results[results[\"very_positive\"] != True & results[\"very_negative\"] != True]\n",
    "\n",
    "def get_score(value):\n",
    "    score = 0\n",
    "    \n",
    "    if value > 0.5:\n",
    "        score += 1\n",
    "    else:\n",
    "        score -= 1\n",
    "        \n",
    "    return score\n",
    "\n",
    "def get_label(score):\n",
    "    label = -1\n",
    "    \n",
    "    if score > 0:\n",
    "        label = 1\n",
    "    elif score < 0:\n",
    "        label = 0\n",
    "        \n",
    "    return label\n",
    "\n",
    "results[\"score\"] = results.apply(lambda x: get_score(x[\"davemodel\"]) + get_score(x[\"vgg\"]) + get_score(x[\"vgg19\"]) + get_score(x[\"lenet\"]), axis = 1)\n",
    "\n",
    "results[\"label\"] = results.apply(lambda x: get_label(x[\"score\"]), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6984, 75, 75, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pseudo = X_test[results[\"label\"] >= 0]\n",
    "y_train_pseudo = results[results[\"label\"] >= 0][\"label\"]\n",
    "X_train_pseudo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytr\n",
    "results[results[\"label\"] >= 0][\"label\"]\n",
    "\n",
    "y_train_pseudo = np.array(pd.get_dummies(results[results[\"label\"] >= 0][\"label\"]))\n",
    "# y_train_pseudo = np.zeros((6984, 2))\n",
    "y_train_pseudo\n",
    "results[results[\"label\"] >= 0][\"label\"]\n",
    "# results.iloc[0]\n",
    "# results[results[\"label\"] >= 0][\"label\"]\n",
    "\n",
    "test = []\n",
    "stuff = results[results[\"label\"] >= 0][\"label\"]\n",
    "\n",
    "for record in stuff:\n",
    "    if record == 0:\n",
    "        test.append([0., 1.])\n",
    "    elif record == 1:\n",
    "        test.append([1., 0.])\n",
    "\n",
    "y_train_pseudo = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6984, 75, 75, 3)\n",
      "(6984, 2)\n",
      "(1283, 75, 75, 3)\n",
      "(1283, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pseudo.shape)\n",
    "print(y_train_pseudo.shape)\n",
    "print(Xtr.shape)\n",
    "print(ytr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr_p, Xv_p, ytr_p, yv_p = train_test_split(X_train_pseudo, y_train_pseudo, shuffle=False, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRunner = Trainer([\n",
    "    DaveModel(Xtr_p, ytr_p, Xv_p, yv_p),\n",
    "    DaveVGG(Xtr_p, ytr_p, Xv_p, yv_p),\n",
    "    DaveVGG19(Xtr_p, ytr_p, Xv_p, yv_p),\n",
    "    LeNetModel(Xtr_p, ytr_p, Xv_p, yv_p)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: davemodel\n",
      "Batch Size: 32\n",
      "Epochs: 50\n",
      "Epoch 1/50\n",
      "175/174 [==============================] - 9s - loss: 0.3322 - acc: 0.8443 - val_loss: 0.6399 - val_acc: 0.7130\n",
      "Epoch 2/50\n",
      "175/174 [==============================] - 7s - loss: 0.2456 - acc: 0.8905 - val_loss: 0.5322 - val_acc: 0.7373\n",
      "Epoch 3/50\n",
      "175/174 [==============================] - 7s - loss: 0.2094 - acc: 0.9063 - val_loss: 0.2100 - val_acc: 0.9055\n",
      "Epoch 4/50\n",
      "175/174 [==============================] - 7s - loss: 0.1850 - acc: 0.9214 - val_loss: 0.1649 - val_acc: 0.9291\n",
      "Epoch 5/50\n",
      "175/174 [==============================] - 7s - loss: 0.1698 - acc: 0.9238 - val_loss: 0.1522 - val_acc: 0.9377\n",
      "Epoch 6/50\n",
      "175/174 [==============================] - 7s - loss: 0.1676 - acc: 0.9266 - val_loss: 0.1367 - val_acc: 0.9356\n",
      "Epoch 7/50\n",
      "175/174 [==============================] - 7s - loss: 0.1512 - acc: 0.9333 - val_loss: 0.1475 - val_acc: 0.9413\n",
      "Epoch 8/50\n",
      "175/174 [==============================] - 7s - loss: 0.1513 - acc: 0.9342 - val_loss: 0.1358 - val_acc: 0.9363\n",
      "Epoch 9/50\n",
      "175/174 [==============================] - 7s - loss: 0.1418 - acc: 0.9393 - val_loss: 0.1351 - val_acc: 0.9349\n",
      "Epoch 10/50\n",
      "175/174 [==============================] - 7s - loss: 0.1390 - acc: 0.9383 - val_loss: 0.1382 - val_acc: 0.9399\n",
      "Epoch 11/50\n",
      "175/174 [==============================] - 7s - loss: 0.1356 - acc: 0.9410 - val_loss: 0.1280 - val_acc: 0.9463\n",
      "Epoch 12/50\n",
      "175/174 [==============================] - 7s - loss: 0.1337 - acc: 0.9436 - val_loss: 0.1139 - val_acc: 0.9578\n",
      "Epoch 13/50\n",
      "175/174 [==============================] - 7s - loss: 0.1313 - acc: 0.9445 - val_loss: 0.1101 - val_acc: 0.9621\n",
      "Epoch 14/50\n",
      "175/174 [==============================] - 7s - loss: 0.1253 - acc: 0.9479 - val_loss: 0.1163 - val_acc: 0.9470\n",
      "Epoch 15/50\n",
      "175/174 [==============================] - 7s - loss: 0.1218 - acc: 0.9464 - val_loss: 0.1150 - val_acc: 0.9485\n",
      "Epoch 16/50\n",
      "175/174 [==============================] - 7s - loss: 0.1218 - acc: 0.9499 - val_loss: 0.1103 - val_acc: 0.9585\n",
      "Epoch 17/50\n",
      "175/174 [==============================] - 7s - loss: 0.1199 - acc: 0.9515 - val_loss: 0.1084 - val_acc: 0.9528\n",
      "Epoch 18/50\n",
      "175/174 [==============================] - 7s - loss: 0.1136 - acc: 0.9549 - val_loss: 0.1060 - val_acc: 0.9535\n",
      "Epoch 19/50\n",
      "175/174 [==============================] - 7s - loss: 0.1181 - acc: 0.9523 - val_loss: 0.0954 - val_acc: 0.9613\n",
      "Epoch 20/50\n",
      "175/174 [==============================] - 7s - loss: 0.1089 - acc: 0.9541 - val_loss: 0.1116 - val_acc: 0.9556\n",
      "Epoch 21/50\n",
      "175/174 [==============================] - 7s - loss: 0.1100 - acc: 0.9529 - val_loss: 0.1124 - val_acc: 0.9528\n",
      "Epoch 22/50\n",
      "175/174 [==============================] - 7s - loss: 0.1098 - acc: 0.9559 - val_loss: 0.0995 - val_acc: 0.9613\n",
      "Epoch 23/50\n",
      "175/174 [==============================] - 7s - loss: 0.1098 - acc: 0.9570 - val_loss: 0.1632 - val_acc: 0.9341\n",
      "Epoch 24/50\n",
      "175/174 [==============================] - 7s - loss: 0.1117 - acc: 0.9541 - val_loss: 0.0941 - val_acc: 0.9656\n",
      "Epoch 25/50\n",
      "175/174 [==============================] - 7s - loss: 0.1039 - acc: 0.9570 - val_loss: 0.0915 - val_acc: 0.9664\n",
      "Epoch 26/50\n",
      "175/174 [==============================] - 7s - loss: 0.1005 - acc: 0.9580 - val_loss: 0.1197 - val_acc: 0.9492\n",
      "Epoch 27/50\n",
      "175/174 [==============================] - 7s - loss: 0.1088 - acc: 0.9541 - val_loss: 0.0991 - val_acc: 0.9592\n",
      "Epoch 28/50\n",
      "175/174 [==============================] - 7s - loss: 0.0978 - acc: 0.9601 - val_loss: 0.0888 - val_acc: 0.9685\n",
      "Epoch 29/50\n",
      "175/174 [==============================] - 7s - loss: 0.0972 - acc: 0.9611 - val_loss: 0.0976 - val_acc: 0.9571\n",
      "Epoch 30/50\n",
      "175/174 [==============================] - 7s - loss: 0.0972 - acc: 0.9599 - val_loss: 0.0886 - val_acc: 0.9664\n",
      "Epoch 31/50\n",
      "175/174 [==============================] - 7s - loss: 0.0954 - acc: 0.9602 - val_loss: 0.1029 - val_acc: 0.9585\n",
      "Epoch 32/50\n",
      "175/174 [==============================] - 7s - loss: 0.1030 - acc: 0.9607 - val_loss: 0.0894 - val_acc: 0.9556\n",
      "Epoch 33/50\n",
      "175/174 [==============================] - 7s - loss: 0.0989 - acc: 0.9593 - val_loss: 0.0968 - val_acc: 0.9613\n",
      "Epoch 34/50\n",
      "175/174 [==============================] - 7s - loss: 0.0945 - acc: 0.9608 - val_loss: 0.0826 - val_acc: 0.9707\n",
      "Epoch 35/50\n",
      "175/174 [==============================] - 7s - loss: 0.0926 - acc: 0.9612 - val_loss: 0.0774 - val_acc: 0.9699\n",
      "Epoch 36/50\n",
      "175/174 [==============================] - 7s - loss: 0.0935 - acc: 0.9614 - val_loss: 0.0952 - val_acc: 0.9613\n",
      "Epoch 37/50\n",
      "175/174 [==============================] - 7s - loss: 0.0918 - acc: 0.9605 - val_loss: 0.1071 - val_acc: 0.9571\n",
      "Epoch 38/50\n",
      "175/174 [==============================] - 7s - loss: 0.0860 - acc: 0.9649 - val_loss: 0.0775 - val_acc: 0.9721\n",
      "Epoch 39/50\n",
      "175/174 [==============================] - 7s - loss: 0.0871 - acc: 0.9634 - val_loss: 0.0874 - val_acc: 0.9635\n",
      "Epoch 40/50\n",
      "175/174 [==============================] - 7s - loss: 0.0902 - acc: 0.9640 - val_loss: 0.0898 - val_acc: 0.9571\n",
      "Epoch 41/50\n",
      "175/174 [==============================] - 7s - loss: 0.0872 - acc: 0.9650 - val_loss: 0.0982 - val_acc: 0.9571\n",
      "Epoch 42/50\n",
      "175/174 [==============================] - 7s - loss: 0.0805 - acc: 0.9675 - val_loss: 0.1056 - val_acc: 0.9606\n",
      "Epoch 43/50\n",
      "175/174 [==============================] - 7s - loss: 0.0860 - acc: 0.9646 - val_loss: 0.1553 - val_acc: 0.9356\n",
      "Epoch 44/50\n",
      "175/174 [==============================] - 7s - loss: 0.0854 - acc: 0.9673 - val_loss: 0.0817 - val_acc: 0.9692\n",
      "Epoch 45/50\n",
      "175/174 [==============================] - 7s - loss: 0.0874 - acc: 0.9661 - val_loss: 0.0786 - val_acc: 0.9721\n",
      "Epoch 46/50\n",
      "175/174 [==============================] - 7s - loss: 0.0863 - acc: 0.9657 - val_loss: 0.0727 - val_acc: 0.9785\n",
      "Epoch 47/50\n",
      "175/174 [==============================] - 7s - loss: 0.0856 - acc: 0.9665 - val_loss: 0.0968 - val_acc: 0.9635\n",
      "Epoch 48/50\n",
      "175/174 [==============================] - 7s - loss: 0.0821 - acc: 0.9661 - val_loss: 0.0917 - val_acc: 0.9628\n",
      "Epoch 49/50\n",
      "175/174 [==============================] - 7s - loss: 0.0833 - acc: 0.9664 - val_loss: 0.1090 - val_acc: 0.9542\n",
      "Epoch 50/50\n",
      "175/174 [==============================] - 7s - loss: 0.0846 - acc: 0.9652 - val_loss: 0.0857 - val_acc: 0.9664\n",
      "Model: vgg\n",
      "Batch Size: 32\n",
      "Epochs: 50\n",
      "Epoch 1/50\n",
      "175/174 [==============================] - 27s - loss: 0.4703 - acc: 0.7913 - val_loss: 0.3235 - val_acc: 0.8776\n",
      "Epoch 2/50\n",
      "175/174 [==============================] - 25s - loss: 0.2987 - acc: 0.8779 - val_loss: 0.2525 - val_acc: 0.9098\n",
      "Epoch 3/50\n",
      "175/174 [==============================] - 25s - loss: 0.2440 - acc: 0.9007 - val_loss: 0.2139 - val_acc: 0.9098\n",
      "Epoch 4/50\n",
      "175/174 [==============================] - 25s - loss: 0.2149 - acc: 0.9162 - val_loss: 0.2333 - val_acc: 0.9191\n",
      "Epoch 5/50\n",
      "175/174 [==============================] - 25s - loss: 0.2101 - acc: 0.9054 - val_loss: 0.2627 - val_acc: 0.8754\n",
      "Epoch 6/50\n",
      "175/174 [==============================] - 25s - loss: 0.1979 - acc: 0.9220 - val_loss: 0.2823 - val_acc: 0.8712\n",
      "Epoch 7/50\n",
      "175/174 [==============================] - 25s - loss: 0.1854 - acc: 0.9264 - val_loss: 0.1713 - val_acc: 0.9356\n",
      "Epoch 8/50\n",
      "175/174 [==============================] - 25s - loss: 0.1760 - acc: 0.9321 - val_loss: 0.1636 - val_acc: 0.9449\n",
      "Epoch 9/50\n",
      "175/174 [==============================] - 25s - loss: 0.1759 - acc: 0.9316 - val_loss: 0.1258 - val_acc: 0.9549\n",
      "Epoch 10/50\n",
      "175/174 [==============================] - 25s - loss: 0.1644 - acc: 0.9352 - val_loss: 0.1896 - val_acc: 0.9349\n",
      "Epoch 11/50\n",
      "175/174 [==============================] - 25s - loss: 0.1611 - acc: 0.9336 - val_loss: 0.1253 - val_acc: 0.9542\n",
      "Epoch 12/50\n",
      "175/174 [==============================] - 25s - loss: 0.1430 - acc: 0.9408 - val_loss: 0.1207 - val_acc: 0.9563\n",
      "Epoch 13/50\n",
      "175/174 [==============================] - 25s - loss: 0.1548 - acc: 0.9402 - val_loss: 0.1401 - val_acc: 0.9492\n",
      "Epoch 14/50\n",
      "175/174 [==============================] - 25s - loss: 0.1445 - acc: 0.9436 - val_loss: 0.1181 - val_acc: 0.9520\n",
      "Epoch 15/50\n",
      "175/174 [==============================] - 25s - loss: 0.1460 - acc: 0.9412 - val_loss: 0.1595 - val_acc: 0.9263\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/174 [==============================] - 25s - loss: 0.1425 - acc: 0.9382 - val_loss: 0.1419 - val_acc: 0.9456\n",
      "Epoch 17/50\n",
      "175/174 [==============================] - 25s - loss: 0.1392 - acc: 0.9470 - val_loss: 0.1098 - val_acc: 0.9599\n",
      "Epoch 18/50\n",
      "175/174 [==============================] - 25s - loss: 0.1397 - acc: 0.9454 - val_loss: 0.1360 - val_acc: 0.9528\n",
      "Epoch 19/50\n",
      "175/174 [==============================] - 25s - loss: 0.1400 - acc: 0.9438 - val_loss: 0.1419 - val_acc: 0.9463\n",
      "Epoch 20/50\n",
      "175/174 [==============================] - 25s - loss: 0.1296 - acc: 0.9460 - val_loss: 0.1424 - val_acc: 0.9463\n",
      "Epoch 21/50\n",
      "175/174 [==============================] - 25s - loss: 0.1222 - acc: 0.9517 - val_loss: 0.1486 - val_acc: 0.9413\n",
      "Epoch 22/50\n",
      "175/174 [==============================] - 25s - loss: 0.1264 - acc: 0.9481 - val_loss: 0.1282 - val_acc: 0.9463\n",
      "Epoch 23/50\n",
      "175/174 [==============================] - 25s - loss: 0.1316 - acc: 0.9474 - val_loss: 0.1178 - val_acc: 0.9556\n",
      "Epoch 24/50\n",
      "175/174 [==============================] - 25s - loss: 0.1303 - acc: 0.9480 - val_loss: 0.1054 - val_acc: 0.9578\n",
      "Epoch 25/50\n",
      "175/174 [==============================] - 25s - loss: 0.1162 - acc: 0.9539 - val_loss: 0.0798 - val_acc: 0.9692\n",
      "Epoch 26/50\n",
      "175/174 [==============================] - 25s - loss: 0.1134 - acc: 0.9529 - val_loss: 0.1121 - val_acc: 0.9563\n",
      "Epoch 27/50\n",
      "175/174 [==============================] - 25s - loss: 0.1124 - acc: 0.9509 - val_loss: 0.1143 - val_acc: 0.9392\n",
      "Epoch 28/50\n",
      "175/174 [==============================] - 25s - loss: 0.1164 - acc: 0.9559 - val_loss: 0.1037 - val_acc: 0.9613\n",
      "Epoch 29/50\n",
      "175/174 [==============================] - 25s - loss: 0.1180 - acc: 0.9520 - val_loss: 0.0864 - val_acc: 0.9692\n",
      "Epoch 30/50\n",
      "175/174 [==============================] - 25s - loss: 0.1176 - acc: 0.9547 - val_loss: 0.1550 - val_acc: 0.9449\n",
      "Epoch 31/50\n",
      "175/174 [==============================] - 25s - loss: 0.1221 - acc: 0.9534 - val_loss: 0.1002 - val_acc: 0.9599\n",
      "Epoch 32/50\n",
      "175/174 [==============================] - 25s - loss: 0.1078 - acc: 0.9576 - val_loss: 0.0870 - val_acc: 0.9664\n",
      "Epoch 33/50\n",
      "175/174 [==============================] - 25s - loss: 0.1160 - acc: 0.9545 - val_loss: 0.0797 - val_acc: 0.9714\n",
      "Epoch 34/50\n",
      "175/174 [==============================] - 25s - loss: 0.1057 - acc: 0.9571 - val_loss: 0.1107 - val_acc: 0.9549\n",
      "Epoch 35/50\n",
      "175/174 [==============================] - 25s - loss: 0.1057 - acc: 0.9598 - val_loss: 0.1051 - val_acc: 0.9656\n",
      "Epoch 36/50\n",
      "175/174 [==============================] - 25s - loss: 0.0982 - acc: 0.9587 - val_loss: 0.0874 - val_acc: 0.9664\n",
      "Epoch 37/50\n",
      "175/174 [==============================] - 25s - loss: 0.0984 - acc: 0.9614 - val_loss: 0.0895 - val_acc: 0.9735\n",
      "Epoch 38/50\n",
      "175/174 [==============================] - 25s - loss: 0.1024 - acc: 0.9595 - val_loss: 0.1220 - val_acc: 0.9463\n",
      "Epoch 39/50\n",
      "175/174 [==============================] - 25s - loss: 0.1068 - acc: 0.9604 - val_loss: 0.0951 - val_acc: 0.9664\n",
      "Epoch 40/50\n",
      "175/174 [==============================] - 25s - loss: 0.1003 - acc: 0.9609 - val_loss: 0.1013 - val_acc: 0.9728\n",
      "Epoch 41/50\n",
      "175/174 [==============================] - 25s - loss: 0.0974 - acc: 0.9612 - val_loss: 0.1037 - val_acc: 0.9613\n",
      "Epoch 42/50\n",
      "175/174 [==============================] - 25s - loss: 0.1024 - acc: 0.9595 - val_loss: 0.0966 - val_acc: 0.9656\n",
      "Epoch 43/50\n",
      "175/174 [==============================] - 25s - loss: 0.0902 - acc: 0.9648 - val_loss: 0.0769 - val_acc: 0.9728\n",
      "Epoch 44/50\n",
      "175/174 [==============================] - 25s - loss: 0.1068 - acc: 0.9579 - val_loss: 0.0842 - val_acc: 0.9721\n",
      "Epoch 45/50\n",
      "175/174 [==============================] - 25s - loss: 0.0906 - acc: 0.9639 - val_loss: 0.0721 - val_acc: 0.9728\n",
      "Epoch 46/50\n",
      "175/174 [==============================] - 25s - loss: 0.0886 - acc: 0.9670 - val_loss: 0.1016 - val_acc: 0.9592\n",
      "Epoch 47/50\n",
      "175/174 [==============================] - 25s - loss: 0.0983 - acc: 0.9609 - val_loss: 0.1021 - val_acc: 0.9613\n",
      "Epoch 48/50\n",
      "175/174 [==============================] - 25s - loss: 0.0853 - acc: 0.9651 - val_loss: 0.0671 - val_acc: 0.9771\n",
      "Epoch 49/50\n",
      "175/174 [==============================] - 25s - loss: 0.0876 - acc: 0.9648 - val_loss: 0.0835 - val_acc: 0.9714\n",
      "Epoch 50/50\n",
      "175/174 [==============================] - 25s - loss: 0.0887 - acc: 0.9627 - val_loss: 0.0990 - val_acc: 0.9671\n",
      "Model: vgg19\n",
      "Batch Size: 32\n",
      "Epochs: 50\n",
      "Epoch 1/50\n",
      "175/174 [==============================] - 27s - loss: 0.5144 - acc: 0.7733 - val_loss: 0.3690 - val_acc: 0.8447\n",
      "Epoch 2/50\n",
      "175/174 [==============================] - 26s - loss: 0.3211 - acc: 0.8652 - val_loss: 0.2910 - val_acc: 0.8819\n",
      "Epoch 3/50\n",
      "175/174 [==============================] - 26s - loss: 0.2947 - acc: 0.8793 - val_loss: 0.2588 - val_acc: 0.9141\n",
      "Epoch 4/50\n",
      "175/174 [==============================] - 26s - loss: 0.2243 - acc: 0.9133 - val_loss: 0.2367 - val_acc: 0.9055\n",
      "Epoch 5/50\n",
      "175/174 [==============================] - 26s - loss: 0.2163 - acc: 0.9224 - val_loss: 0.1722 - val_acc: 0.9392\n",
      "Epoch 6/50\n",
      "175/174 [==============================] - 26s - loss: 0.1954 - acc: 0.9191 - val_loss: 0.1979 - val_acc: 0.9220\n",
      "Epoch 7/50\n",
      "175/174 [==============================] - 26s - loss: 0.1861 - acc: 0.9228 - val_loss: 0.2008 - val_acc: 0.9277\n",
      "Epoch 8/50\n",
      "175/174 [==============================] - 26s - loss: 0.1750 - acc: 0.9323 - val_loss: 0.1669 - val_acc: 0.9270\n",
      "Epoch 9/50\n",
      "175/174 [==============================] - 26s - loss: 0.1651 - acc: 0.9311 - val_loss: 0.1337 - val_acc: 0.9470\n",
      "Epoch 10/50\n",
      "175/174 [==============================] - 26s - loss: 0.1690 - acc: 0.9350 - val_loss: 0.1846 - val_acc: 0.9363\n",
      "Epoch 11/50\n",
      "175/174 [==============================] - 26s - loss: 0.1646 - acc: 0.9350 - val_loss: 0.1723 - val_acc: 0.9327\n",
      "Epoch 12/50\n",
      "175/174 [==============================] - 26s - loss: 0.1655 - acc: 0.9383 - val_loss: 0.1180 - val_acc: 0.9556\n",
      "Epoch 13/50\n",
      "175/174 [==============================] - 26s - loss: 0.1524 - acc: 0.9408 - val_loss: 0.1540 - val_acc: 0.9456\n",
      "Epoch 14/50\n",
      "175/174 [==============================] - 26s - loss: 0.1371 - acc: 0.9447 - val_loss: 0.1149 - val_acc: 0.9520\n",
      "Epoch 15/50\n",
      "175/174 [==============================] - 26s - loss: 0.1477 - acc: 0.9400 - val_loss: 0.1146 - val_acc: 0.9506\n",
      "Epoch 16/50\n",
      "175/174 [==============================] - 26s - loss: 0.1439 - acc: 0.9429 - val_loss: 0.0992 - val_acc: 0.9592\n",
      "Epoch 17/50\n",
      "175/174 [==============================] - 26s - loss: 0.1350 - acc: 0.9465 - val_loss: 0.1788 - val_acc: 0.9377\n",
      "Epoch 18/50\n",
      "175/174 [==============================] - 26s - loss: 0.1354 - acc: 0.9465 - val_loss: 0.1116 - val_acc: 0.9535\n",
      "Epoch 19/50\n",
      "175/174 [==============================] - 26s - loss: 0.1189 - acc: 0.9554 - val_loss: 0.1084 - val_acc: 0.9649\n",
      "Epoch 20/50\n",
      "175/174 [==============================] - 26s - loss: 0.1201 - acc: 0.9531 - val_loss: 0.0971 - val_acc: 0.9606\n",
      "Epoch 21/50\n",
      "175/174 [==============================] - 26s - loss: 0.1364 - acc: 0.9461 - val_loss: 0.1192 - val_acc: 0.9535\n",
      "Epoch 22/50\n",
      "175/174 [==============================] - 26s - loss: 0.1225 - acc: 0.9524 - val_loss: 0.1035 - val_acc: 0.9664\n",
      "Epoch 23/50\n",
      "175/174 [==============================] - 26s - loss: 0.1210 - acc: 0.9528 - val_loss: 0.1036 - val_acc: 0.9613\n",
      "Epoch 24/50\n",
      "175/174 [==============================] - 26s - loss: 0.1238 - acc: 0.9536 - val_loss: 0.1358 - val_acc: 0.9356\n",
      "Epoch 25/50\n",
      "175/174 [==============================] - 26s - loss: 0.1170 - acc: 0.9525 - val_loss: 0.0883 - val_acc: 0.9671\n",
      "Epoch 26/50\n",
      "175/174 [==============================] - 26s - loss: 0.1175 - acc: 0.9517 - val_loss: 0.0836 - val_acc: 0.9699\n",
      "Epoch 27/50\n",
      "175/174 [==============================] - 26s - loss: 0.1104 - acc: 0.9545 - val_loss: 0.1267 - val_acc: 0.9463\n",
      "Epoch 28/50\n",
      "175/174 [==============================] - 26s - loss: 0.1240 - acc: 0.9504 - val_loss: 0.0913 - val_acc: 0.9664\n",
      "Epoch 29/50\n",
      "175/174 [==============================] - 26s - loss: 0.1083 - acc: 0.9562 - val_loss: 0.1241 - val_acc: 0.9513\n",
      "Epoch 30/50\n",
      "175/174 [==============================] - 26s - loss: 0.1010 - acc: 0.9595 - val_loss: 0.1069 - val_acc: 0.9592\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/174 [==============================] - 26s - loss: 0.1118 - acc: 0.9545 - val_loss: 0.1098 - val_acc: 0.9506\n",
      "Epoch 32/50\n",
      "175/174 [==============================] - 26s - loss: 0.1104 - acc: 0.9594 - val_loss: 0.0806 - val_acc: 0.9671\n",
      "Epoch 33/50\n",
      "175/174 [==============================] - 26s - loss: 0.1115 - acc: 0.9557 - val_loss: 0.0942 - val_acc: 0.9578\n",
      "Epoch 34/50\n",
      "175/174 [==============================] - 26s - loss: 0.1084 - acc: 0.9546 - val_loss: 0.0939 - val_acc: 0.9613\n",
      "Epoch 35/50\n",
      "175/174 [==============================] - 26s - loss: 0.1027 - acc: 0.9614 - val_loss: 0.1160 - val_acc: 0.9635\n",
      "Epoch 36/50\n",
      "175/174 [==============================] - 26s - loss: 0.1046 - acc: 0.9588 - val_loss: 0.0919 - val_acc: 0.9628\n",
      "Epoch 37/50\n",
      "175/174 [==============================] - 26s - loss: 0.1004 - acc: 0.9587 - val_loss: 0.0963 - val_acc: 0.9599\n",
      "Epoch 38/50\n",
      "175/174 [==============================] - 26s - loss: 0.0943 - acc: 0.9624 - val_loss: 0.0789 - val_acc: 0.9656\n",
      "Epoch 39/50\n",
      "175/174 [==============================] - 26s - loss: 0.1108 - acc: 0.9562 - val_loss: 0.0825 - val_acc: 0.9714\n",
      "Epoch 40/50\n",
      "175/174 [==============================] - 26s - loss: 0.1049 - acc: 0.9607 - val_loss: 0.0894 - val_acc: 0.9678\n",
      "Epoch 41/50\n",
      "175/174 [==============================] - 26s - loss: 0.1012 - acc: 0.9595 - val_loss: 0.0825 - val_acc: 0.9678\n",
      "Epoch 42/50\n",
      "175/174 [==============================] - 26s - loss: 0.0946 - acc: 0.9601 - val_loss: 0.0890 - val_acc: 0.9685\n",
      "Epoch 43/50\n",
      "175/174 [==============================] - 26s - loss: 0.0937 - acc: 0.9595 - val_loss: 0.0932 - val_acc: 0.9613\n",
      "Epoch 44/50\n",
      "175/174 [==============================] - 26s - loss: 0.0944 - acc: 0.9609 - val_loss: 0.0740 - val_acc: 0.9707\n",
      "Epoch 45/50\n",
      "175/174 [==============================] - 26s - loss: 0.0956 - acc: 0.9601 - val_loss: 0.0784 - val_acc: 0.9664\n",
      "Epoch 46/50\n",
      "175/174 [==============================] - 26s - loss: 0.0879 - acc: 0.9652 - val_loss: 0.0844 - val_acc: 0.9628\n",
      "Epoch 47/50\n",
      "175/174 [==============================] - 26s - loss: 0.0871 - acc: 0.9640 - val_loss: 0.0681 - val_acc: 0.9699\n",
      "Epoch 48/50\n",
      "175/174 [==============================] - 26s - loss: 0.0924 - acc: 0.9636 - val_loss: 0.0715 - val_acc: 0.9735\n",
      "Epoch 49/50\n",
      "175/174 [==============================] - 26s - loss: 0.0920 - acc: 0.9629 - val_loss: 0.0837 - val_acc: 0.9671\n",
      "Epoch 50/50\n",
      "175/174 [==============================] - 26s - loss: 0.0921 - acc: 0.9624 - val_loss: 0.0852 - val_acc: 0.9721\n",
      "Model: lenet\n",
      "Batch Size: 32\n",
      "Epochs: 50\n",
      "Epoch 1/50\n",
      "175/174 [==============================] - 8s - loss: 0.4870 - acc: 0.7833 - val_loss: 0.4383 - val_acc: 0.8103\n",
      "Epoch 2/50\n",
      "175/174 [==============================] - 7s - loss: 0.3829 - acc: 0.8305 - val_loss: 0.3257 - val_acc: 0.8497\n",
      "Epoch 3/50\n",
      "175/174 [==============================] - 7s - loss: 0.3135 - acc: 0.8547 - val_loss: 0.2928 - val_acc: 0.8669\n",
      "Epoch 4/50\n",
      "175/174 [==============================] - 7s - loss: 0.2758 - acc: 0.8756 - val_loss: 0.3031 - val_acc: 0.8604\n",
      "Epoch 5/50\n",
      "175/174 [==============================] - 7s - loss: 0.2428 - acc: 0.8938 - val_loss: 0.2381 - val_acc: 0.9098\n",
      "Epoch 6/50\n",
      "175/174 [==============================] - 8s - loss: 0.2286 - acc: 0.9026 - val_loss: 0.2118 - val_acc: 0.9198\n",
      "Epoch 7/50\n",
      "175/174 [==============================] - 7s - loss: 0.2123 - acc: 0.9095 - val_loss: 0.1851 - val_acc: 0.9270\n",
      "Epoch 8/50\n",
      "175/174 [==============================] - 8s - loss: 0.2083 - acc: 0.9198 - val_loss: 0.1955 - val_acc: 0.9241\n",
      "Epoch 9/50\n",
      "175/174 [==============================] - 7s - loss: 0.1899 - acc: 0.9234 - val_loss: 0.1881 - val_acc: 0.9134\n",
      "Epoch 10/50\n",
      "175/174 [==============================] - 6s - loss: 0.1932 - acc: 0.9203 - val_loss: 0.1763 - val_acc: 0.9313\n",
      "Epoch 11/50\n",
      "175/174 [==============================] - 6s - loss: 0.1807 - acc: 0.9246 - val_loss: 0.1540 - val_acc: 0.9377\n",
      "Epoch 12/50\n",
      "175/174 [==============================] - 7s - loss: 0.1763 - acc: 0.9237 - val_loss: 0.1515 - val_acc: 0.9370\n",
      "Epoch 13/50\n",
      "175/174 [==============================] - 7s - loss: 0.1655 - acc: 0.9312 - val_loss: 0.1665 - val_acc: 0.9377\n",
      "Epoch 14/50\n",
      "175/174 [==============================] - 7s - loss: 0.1654 - acc: 0.9300 - val_loss: 0.1527 - val_acc: 0.9399\n",
      "Epoch 15/50\n",
      "175/174 [==============================] - 6s - loss: 0.1629 - acc: 0.9309 - val_loss: 0.1440 - val_acc: 0.9363\n",
      "Epoch 16/50\n",
      "175/174 [==============================] - 7s - loss: 0.1596 - acc: 0.9315 - val_loss: 0.1465 - val_acc: 0.9406\n",
      "Epoch 17/50\n",
      "175/174 [==============================] - 6s - loss: 0.1562 - acc: 0.9336 - val_loss: 0.1303 - val_acc: 0.9435\n",
      "Epoch 18/50\n",
      "175/174 [==============================] - 7s - loss: 0.1503 - acc: 0.9364 - val_loss: 0.1322 - val_acc: 0.9477\n",
      "Epoch 19/50\n",
      "175/174 [==============================] - 7s - loss: 0.1528 - acc: 0.9347 - val_loss: 0.1261 - val_acc: 0.9506\n",
      "Epoch 20/50\n",
      "175/174 [==============================] - 7s - loss: 0.1503 - acc: 0.9383 - val_loss: 0.1442 - val_acc: 0.9435\n",
      "Epoch 21/50\n",
      "175/174 [==============================] - 7s - loss: 0.1499 - acc: 0.9397 - val_loss: 0.1594 - val_acc: 0.9427\n",
      "Epoch 22/50\n",
      "175/174 [==============================] - 7s - loss: 0.1505 - acc: 0.9379 - val_loss: 0.1293 - val_acc: 0.9485\n",
      "Epoch 23/50\n",
      "175/174 [==============================] - 6s - loss: 0.1424 - acc: 0.9401 - val_loss: 0.1354 - val_acc: 0.9420\n",
      "Epoch 24/50\n",
      "175/174 [==============================] - 6s - loss: 0.1422 - acc: 0.9405 - val_loss: 0.1236 - val_acc: 0.9506\n",
      "Epoch 25/50\n",
      "175/174 [==============================] - 7s - loss: 0.1409 - acc: 0.9416 - val_loss: 0.1186 - val_acc: 0.9556\n",
      "Epoch 26/50\n",
      "175/174 [==============================] - 6s - loss: 0.1371 - acc: 0.9425 - val_loss: 0.1306 - val_acc: 0.9406\n",
      "Epoch 27/50\n",
      "175/174 [==============================] - 7s - loss: 0.1361 - acc: 0.9442 - val_loss: 0.1141 - val_acc: 0.9513\n",
      "Epoch 28/50\n",
      "175/174 [==============================] - 7s - loss: 0.1277 - acc: 0.9461 - val_loss: 0.1115 - val_acc: 0.9513\n",
      "Epoch 29/50\n",
      "175/174 [==============================] - 7s - loss: 0.1321 - acc: 0.9437 - val_loss: 0.1138 - val_acc: 0.9535\n",
      "Epoch 30/50\n",
      "175/174 [==============================] - 7s - loss: 0.1320 - acc: 0.9467 - val_loss: 0.1153 - val_acc: 0.9528\n",
      "Epoch 31/50\n",
      "175/174 [==============================] - 6s - loss: 0.1355 - acc: 0.9420 - val_loss: 0.1119 - val_acc: 0.9520\n",
      "Epoch 32/50\n",
      "175/174 [==============================] - 6s - loss: 0.1286 - acc: 0.9472 - val_loss: 0.1197 - val_acc: 0.9485\n",
      "Epoch 33/50\n",
      "175/174 [==============================] - 6s - loss: 0.1368 - acc: 0.9436 - val_loss: 0.1540 - val_acc: 0.9413\n",
      "Epoch 34/50\n",
      "175/174 [==============================] - 6s - loss: 0.1265 - acc: 0.9495 - val_loss: 0.1047 - val_acc: 0.9606\n",
      "Epoch 35/50\n",
      "175/174 [==============================] - 6s - loss: 0.1292 - acc: 0.9467 - val_loss: 0.1125 - val_acc: 0.9535\n",
      "Epoch 36/50\n",
      "175/174 [==============================] - 6s - loss: 0.1181 - acc: 0.9539 - val_loss: 0.1499 - val_acc: 0.9341\n",
      "Epoch 37/50\n",
      "175/174 [==============================] - 6s - loss: 0.1271 - acc: 0.9461 - val_loss: 0.1135 - val_acc: 0.9578\n",
      "Epoch 38/50\n",
      "175/174 [==============================] - 6s - loss: 0.1196 - acc: 0.9501 - val_loss: 0.0987 - val_acc: 0.9592\n",
      "Epoch 39/50\n",
      "175/174 [==============================] - 6s - loss: 0.1212 - acc: 0.9533 - val_loss: 0.1000 - val_acc: 0.9613\n",
      "Epoch 40/50\n",
      "175/174 [==============================] - 6s - loss: 0.1195 - acc: 0.9484 - val_loss: 0.1074 - val_acc: 0.9520\n",
      "Epoch 41/50\n",
      "175/174 [==============================] - 7s - loss: 0.1245 - acc: 0.9502 - val_loss: 0.1554 - val_acc: 0.9320\n",
      "Epoch 42/50\n",
      "175/174 [==============================] - 6s - loss: 0.1130 - acc: 0.9559 - val_loss: 0.1535 - val_acc: 0.9270\n",
      "Epoch 43/50\n",
      "175/174 [==============================] - 6s - loss: 0.1080 - acc: 0.9580 - val_loss: 0.1122 - val_acc: 0.9571\n",
      "Epoch 44/50\n",
      "175/174 [==============================] - 7s - loss: 0.1112 - acc: 0.9533 - val_loss: 0.1057 - val_acc: 0.9563\n",
      "Epoch 45/50\n",
      "175/174 [==============================] - 7s - loss: 0.1105 - acc: 0.9552 - val_loss: 0.1086 - val_acc: 0.9578\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/174 [==============================] - 7s - loss: 0.1047 - acc: 0.9574 - val_loss: 0.1137 - val_acc: 0.9477\n",
      "Epoch 47/50\n",
      "175/174 [==============================] - 6s - loss: 0.1129 - acc: 0.9517 - val_loss: 0.0976 - val_acc: 0.9606\n",
      "Epoch 48/50\n",
      "175/174 [==============================] - 7s - loss: 0.1126 - acc: 0.9541 - val_loss: 0.0954 - val_acc: 0.9585\n",
      "Epoch 49/50\n",
      "175/174 [==============================] - 6s - loss: 0.1177 - acc: 0.9529 - val_loss: 0.1001 - val_acc: 0.9621\n",
      "Epoch 50/50\n",
      "175/174 [==============================] - 7s - loss: 0.1076 - acc: 0.9573 - val_loss: 0.1056 - val_acc: 0.9613\n"
     ]
    }
   ],
   "source": [
    "trainRunner.train(epoch = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# After this, let's try and predict the non-definitive data, and see if it's now definitive\n",
    "predict = []\n",
    "# X_test = helpers.get_images(test)\n",
    "blah = X_test[results[\"label\"] < 0]\n",
    "\n",
    "for model in trainRunner.models:\n",
    "    pred_gen = ImageDataGenerator()\n",
    "    predict.append(model.model.predict_generator(pred_gen.flow(blah, batch_size=32, shuffle = False), len(blah) / 32))\n",
    "\n",
    "#     if submit:\n",
    "#         self.create_submission(predict, test)\n",
    "#     predict.append(model.predict(blah))\n",
    "    \n",
    "# Also, do a predict and submit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davemodel\n",
      "vgg\n",
      "vgg19\n",
      "lenet\n"
     ]
    }
   ],
   "source": [
    "results2 = pd.DataFrame()\n",
    "\n",
    "for model2 in trainRunner.models:\n",
    "    name = model2.get_name()\n",
    "    print(name)\n",
    "    test2 = model2.model.predict(blah)\n",
    "    results2[name] = test2[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>davemodel</th>\n",
       "      <th>vgg</th>\n",
       "      <th>vgg19</th>\n",
       "      <th>lenet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977051</td>\n",
       "      <td>0.525496</td>\n",
       "      <td>0.897786</td>\n",
       "      <td>0.504032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753548</td>\n",
       "      <td>0.285678</td>\n",
       "      <td>0.986055</td>\n",
       "      <td>0.647878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237472</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.062903</td>\n",
       "      <td>0.004565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.901699</td>\n",
       "      <td>0.690666</td>\n",
       "      <td>0.516560</td>\n",
       "      <td>0.125253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182136</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>0.963147</td>\n",
       "      <td>0.535211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   davemodel       vgg     vgg19     lenet\n",
       "0   0.977051  0.525496  0.897786  0.504032\n",
       "1   0.753548  0.285678  0.986055  0.647878\n",
       "2   0.237472  0.007978  0.062903  0.004565\n",
       "3   0.901699  0.690666  0.516560  0.125253\n",
       "4   0.182136  0.147875  0.963147  0.535211"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results2[\"very_positive\"] = results2.apply(lambda x: x[\"davemodel\"] > 0.5 and x[\"vgg\"] > 0.5 and x[\"vgg19\"] > 0.5 and x[\"lenet\"] > 0.5, axis = 1)\n",
    "results2[\"very_negative\"] = results2.apply(lambda x: x[\"davemodel\"] <= 0.5 and x[\"vgg\"] <= 0.5 and x[\"vgg19\"] <= 0.5 and x[\"lenet\"] <= 0.5, axis = 1)\n",
    "results2[\"definitive\"] = results2[\"very_positive\"] | results2[\"very_negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>davemodel</th>\n",
       "      <th>vgg</th>\n",
       "      <th>vgg19</th>\n",
       "      <th>lenet</th>\n",
       "      <th>very_positive</th>\n",
       "      <th>very_negative</th>\n",
       "      <th>definitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977051</td>\n",
       "      <td>0.525496</td>\n",
       "      <td>0.897786</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.237472</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.062903</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950964</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.997978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999868</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.929262</td>\n",
       "      <td>0.813650</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.959610</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.974176</td>\n",
       "      <td>0.870007</td>\n",
       "      <td>0.997253</td>\n",
       "      <td>0.935104</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.987627</td>\n",
       "      <td>0.653146</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>0.809050</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.998570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997085</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.998058</td>\n",
       "      <td>0.853549</td>\n",
       "      <td>0.998825</td>\n",
       "      <td>0.869176</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.987544</td>\n",
       "      <td>0.995662</td>\n",
       "      <td>0.831871</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.999025</td>\n",
       "      <td>0.993362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.679366</td>\n",
       "      <td>0.665289</td>\n",
       "      <td>0.719769</td>\n",
       "      <td>0.819528</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.868918</td>\n",
       "      <td>0.597198</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>0.705197</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.998129</td>\n",
       "      <td>0.545090</td>\n",
       "      <td>0.984597</td>\n",
       "      <td>0.683172</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.991998</td>\n",
       "      <td>0.783890</td>\n",
       "      <td>0.998986</td>\n",
       "      <td>0.833166</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.999767</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.993598</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.997275</td>\n",
       "      <td>0.844333</td>\n",
       "      <td>0.978010</td>\n",
       "      <td>0.888792</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.997421</td>\n",
       "      <td>0.951484</td>\n",
       "      <td>0.997959</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.801122</td>\n",
       "      <td>0.587474</td>\n",
       "      <td>0.703377</td>\n",
       "      <td>0.858597</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.967516</td>\n",
       "      <td>0.766685</td>\n",
       "      <td>0.987285</td>\n",
       "      <td>0.755146</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.994405</td>\n",
       "      <td>0.969124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998380</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.994123</td>\n",
       "      <td>0.940342</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.996603</td>\n",
       "      <td>0.997519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999966</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.040285</td>\n",
       "      <td>0.035302</td>\n",
       "      <td>0.158920</td>\n",
       "      <td>0.163348</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.800622</td>\n",
       "      <td>0.696546</td>\n",
       "      <td>0.999031</td>\n",
       "      <td>0.879031</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.125030</td>\n",
       "      <td>0.094538</td>\n",
       "      <td>0.345225</td>\n",
       "      <td>0.089538</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968118</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>0.967853</td>\n",
       "      <td>0.764385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987558</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>0.951018</td>\n",
       "      <td>0.507129</td>\n",
       "      <td>0.990691</td>\n",
       "      <td>0.547715</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999730</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>0.971313</td>\n",
       "      <td>0.649902</td>\n",
       "      <td>0.931583</td>\n",
       "      <td>0.715099</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>0.999705</td>\n",
       "      <td>0.886371</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.783397</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>0.986235</td>\n",
       "      <td>0.741645</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.888741</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.981810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.971476</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.983344</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.992463</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>0.948485</td>\n",
       "      <td>0.697658</td>\n",
       "      <td>0.988974</td>\n",
       "      <td>0.713865</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>0.895821</td>\n",
       "      <td>0.551985</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.883960</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>0.097332</td>\n",
       "      <td>0.013326</td>\n",
       "      <td>0.132125</td>\n",
       "      <td>0.083998</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>0.972110</td>\n",
       "      <td>0.929657</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.983513</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991206</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964275</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0.999891</td>\n",
       "      <td>0.894837</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>0.924533</td>\n",
       "      <td>0.546600</td>\n",
       "      <td>0.990983</td>\n",
       "      <td>0.795410</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>0.141239</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.018361</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.998536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968035</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>0.992930</td>\n",
       "      <td>0.791776</td>\n",
       "      <td>0.987976</td>\n",
       "      <td>0.662806</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.649304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992791</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0.942587</td>\n",
       "      <td>0.555725</td>\n",
       "      <td>0.889647</td>\n",
       "      <td>0.901102</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0.999235</td>\n",
       "      <td>0.602265</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.993273</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0.991523</td>\n",
       "      <td>0.881009</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.916032</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>835 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      davemodel       vgg     vgg19     lenet  very_positive  very_negative  \\\n",
       "0      0.977051  0.525496  0.897786  0.504032           True          False   \n",
       "2      0.237472  0.007978  0.062903  0.004565          False           True   \n",
       "7      0.999999  0.999595  1.000000  0.950964           True          False   \n",
       "8      0.999982  0.997978  1.000000  0.999996           True          False   \n",
       "9      1.000000  0.999806  1.000000  0.999868           True          False   \n",
       "10     0.929262  0.813650  0.999986  0.959610           True          False   \n",
       "11     0.974176  0.870007  0.997253  0.935104           True          False   \n",
       "12     0.987627  0.653146  0.647587  0.809050           True          False   \n",
       "14     0.999294  0.998570  1.000000  0.999980           True          False   \n",
       "15     1.000000  0.999618  1.000000  0.997085           True          False   \n",
       "19     0.998058  0.853549  0.998825  0.869176           True          False   \n",
       "20     0.999937  0.987544  0.995662  0.831871           True          False   \n",
       "21     0.999025  0.993362  1.000000  0.999997           True          False   \n",
       "24     0.679366  0.665289  0.719769  0.819528           True          False   \n",
       "27     0.868918  0.597198  0.999541  0.705197           True          False   \n",
       "29     0.998129  0.545090  0.984597  0.683172           True          False   \n",
       "30     0.991998  0.783890  0.998986  0.833166           True          False   \n",
       "31     0.999815  0.999767  0.999999  0.993598           True          False   \n",
       "32     0.997275  0.844333  0.978010  0.888792           True          False   \n",
       "33     0.997421  0.951484  0.997959  0.997848           True          False   \n",
       "34     0.801122  0.587474  0.703377  0.858597           True          False   \n",
       "35     0.967516  0.766685  0.987285  0.755146           True          False   \n",
       "38     0.994405  0.969124  1.000000  0.998380           True          False   \n",
       "39     0.994123  0.940342  0.999997  0.999166           True          False   \n",
       "40     0.996603  0.997519  1.000000  0.999966           True          False   \n",
       "41     0.999955  0.999997  1.000000  1.000000           True          False   \n",
       "42     0.040285  0.035302  0.158920  0.163348          False           True   \n",
       "43     0.999997  0.999887  1.000000  1.000000           True          False   \n",
       "46     0.800622  0.696546  0.999031  0.879031           True          False   \n",
       "47     0.125030  0.094538  0.345225  0.089538          False           True   \n",
       "...         ...       ...       ...       ...            ...            ...   \n",
       "1384   1.000000  0.968118  0.999915  0.815615           True          False   \n",
       "1388   0.967853  0.764385  1.000000  0.987558           True          False   \n",
       "1392   0.951018  0.507129  0.990691  0.547715           True          False   \n",
       "1395   1.000000  0.999026  1.000000  0.999730           True          False   \n",
       "1396   0.971313  0.649902  0.931583  0.715099           True          False   \n",
       "1398   1.000000  1.000000  1.000000  0.999980           True          False   \n",
       "1399   0.999705  0.886371  0.999909  0.783397           True          False   \n",
       "1402   0.986235  0.741645  0.999976  0.888741           True          False   \n",
       "1406   0.999999  0.981810  1.000000  0.999813           True          False   \n",
       "1407   0.999963  0.971476  0.999998  0.999381           True          False   \n",
       "1408   0.999784  0.983344  0.999981  0.992463           True          False   \n",
       "1409   1.000000  0.999994  1.000000  1.000000           True          False   \n",
       "1410   0.948485  0.697658  0.988974  0.713865           True          False   \n",
       "1412   0.895821  0.551985  0.999898  0.883960           True          False   \n",
       "1413   1.000000  0.999809  1.000000  0.999996           True          False   \n",
       "1414   0.097332  0.013326  0.132125  0.083998          False           True   \n",
       "1415   0.999993  0.999899  1.000000  0.999955           True          False   \n",
       "1419   0.972110  0.929657  0.999896  0.983513           True          False   \n",
       "1423   1.000000  0.966867  1.000000  0.991206           True          False   \n",
       "1424   1.000000  0.996597  1.000000  0.964275           True          False   \n",
       "1425   0.999891  0.894837  0.999977  0.999143           True          False   \n",
       "1426   0.924533  0.546600  0.990983  0.795410           True          False   \n",
       "1428   0.141239  0.000022  0.018361  0.003237          False           True   \n",
       "1429   0.999992  0.998536  1.000000  0.968035           True          False   \n",
       "1431   0.992930  0.791776  0.987976  0.662806           True          False   \n",
       "1434   0.999991  0.649304  1.000000  0.992791           True          False   \n",
       "1436   0.942587  0.555725  0.889647  0.901102           True          False   \n",
       "1437   0.999235  0.602265  0.999883  0.993273           True          False   \n",
       "1438   1.000000  0.999849  1.000000  0.999996           True          False   \n",
       "1439   0.991523  0.881009  0.999812  0.916032           True          False   \n",
       "\n",
       "      definitive  \n",
       "0           True  \n",
       "2           True  \n",
       "7           True  \n",
       "8           True  \n",
       "9           True  \n",
       "10          True  \n",
       "11          True  \n",
       "12          True  \n",
       "14          True  \n",
       "15          True  \n",
       "19          True  \n",
       "20          True  \n",
       "21          True  \n",
       "24          True  \n",
       "27          True  \n",
       "29          True  \n",
       "30          True  \n",
       "31          True  \n",
       "32          True  \n",
       "33          True  \n",
       "34          True  \n",
       "35          True  \n",
       "38          True  \n",
       "39          True  \n",
       "40          True  \n",
       "41          True  \n",
       "42          True  \n",
       "43          True  \n",
       "46          True  \n",
       "47          True  \n",
       "...          ...  \n",
       "1384        True  \n",
       "1388        True  \n",
       "1392        True  \n",
       "1395        True  \n",
       "1396        True  \n",
       "1398        True  \n",
       "1399        True  \n",
       "1402        True  \n",
       "1406        True  \n",
       "1407        True  \n",
       "1408        True  \n",
       "1409        True  \n",
       "1410        True  \n",
       "1412        True  \n",
       "1413        True  \n",
       "1414        True  \n",
       "1415        True  \n",
       "1419        True  \n",
       "1423        True  \n",
       "1424        True  \n",
       "1425        True  \n",
       "1426        True  \n",
       "1428        True  \n",
       "1429        True  \n",
       "1431        True  \n",
       "1434        True  \n",
       "1436        True  \n",
       "1437        True  \n",
       "1438        True  \n",
       "1439        True  \n",
       "\n",
       "[835 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(results2.shape)\n",
    "\n",
    "results2[results2[\"definitive\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
