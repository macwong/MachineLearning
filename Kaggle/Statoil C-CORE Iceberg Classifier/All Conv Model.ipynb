{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Reshape, Conv2D, Convolution2D, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"_RawData/test.json/data/processed/test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_1']])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_2']])\n",
    "\n",
    "X_train = np.concatenate([x_band1[:, :, :, np.newaxis],\n",
    "                          x_band2[:, :, :, np.newaxis],\n",
    "                          ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "target_train=train['is_iceberg']\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n",
    "\n",
    "X_test = np.concatenate([x_band1[:, :, :, np.newaxis],\n",
    "                         x_band2[:, :, :, np.newaxis],\n",
    "                         ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "id_test = test['id'].values\n",
    "\n",
    "del test; del x_band1; del x_band2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), padding=\"same\", input_shape=(75, 75, 3...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), padding=\"same\", strides=(2, 2))`\n",
      "  \n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), padding=\"same\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), padding=\"same\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), padding=\"same\", strides=(2, 2))`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), padding=\"same\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), padding=\"valid\")`\n",
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2, (1, 1), padding=\"valid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 75, 75, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 75, 75, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 75, 75, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 75, 75, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 38, 38, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 38, 38, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 38, 38, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 38, 38, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 38, 38, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 38, 38, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 19, 19, 192)       331968    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 19, 19, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 19, 19, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 19, 19, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 19, 19, 192)       37056     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 19, 19, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 19, 19, 2)         386       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,368,197\n",
      "Trainable params: 1,368,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define CNN Model Architecture (Kaggle can't access the weights file)\n",
    "img_height = 75\n",
    "img_width = 75\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "\n",
    "def inceptionv3(img_dim=img_dim):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(96, 3, 3, border_mode = 'same', input_shape=img_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(96, 3, 3,border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(96, 3, 3, border_mode='same', subsample = (2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(192, 3, 3, border_mode = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(192, 3, 3,border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(192, 3, 3,border_mode='same', subsample = (2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Convolution2D(192, 3, 3, border_mode = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(192, 1, 1,border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(2, 1, 1, border_mode='valid'))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "#     model = make_parallel(model, 4)\n",
    "\n",
    "#     x = Reshape((1, 1, 1024), name='reshape_1')(x)\n",
    "#     x = Dropout(0.2, name='dropout')(x)\n",
    "#     x = Conv2D(2, (1, 1),\n",
    "#                padding='same', name='conv_preds')(x)\n",
    "#     x = Dense('sigmoid', name='act_softmax')(x)\n",
    "#     x = Reshape((classes,), name='reshape_2')(x)\n",
    "    \n",
    "#     bn = BatchNormalization()(input_tensor)\n",
    "#     x = base_model(bn)\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "#     output = Dense(1, activation='sigmoid')(x)\n",
    "#     model = Model(input_tensor, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = inceptionv3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Model and predict\n",
    "def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n",
    "        \n",
    "    train_scores = []; valid_scores = []\n",
    "    preds_test = np.zeros(len(test), dtype = np.float)\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train = x[train_index]; x_valid = x[test_index]\n",
    "        y_train = y[train_index]; y_valid = y[test_index]\n",
    "\n",
    "        def augment(src, choice):\n",
    "            if choice == 0:\n",
    "                # Rotate 90\n",
    "                src = np.rot90(src, 1)\n",
    "            if choice == 1:\n",
    "                # flip vertically\n",
    "                src = np.flipud(src)\n",
    "            if choice == 2:\n",
    "                # Rotate 180\n",
    "                src = np.rot90(src, 2)\n",
    "            if choice == 3:\n",
    "                # flip horizontally\n",
    "                src = np.fliplr(src)\n",
    "            if choice == 4:\n",
    "                # Rotate 90 counter-clockwise\n",
    "                src = np.rot90(src, 3)\n",
    "            if choice == 5:\n",
    "                # Rotate 180 and flip horizontally\n",
    "                src = np.rot90(src, 2)\n",
    "                src = np.fliplr(src)\n",
    "            return src\n",
    "\n",
    "        def train_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_train), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(x_train))\n",
    "                    y_batch = y_train[start:end]\n",
    "                    for img in x_train[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        new_img = augment(new_img, np.random.randint(6))\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def valid_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_valid), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(x_valid))\n",
    "                    y_batch = y_valid[start:end]\n",
    "                    for img in x_valid[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def test_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(test), n_fold):\n",
    "                    x_batch = []\n",
    "                    end = min(start + n_fold, len(test))\n",
    "                    for img in test[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    yield x_batch\n",
    "                    \n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n",
    "                               verbose=1, min_lr=1e-7),\n",
    "             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True, mode='auto')]\n",
    "\n",
    "        train_steps = len(x_train) / batch_size\n",
    "        valid_steps = len(x_valid) / batch_size\n",
    "        test_steps = len(test) / n_fold\n",
    "        \n",
    "        model = model\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n",
    "                            callbacks=callbacks, validation_data=valid_generator(), \n",
    "                            validation_steps=valid_steps)\n",
    "\n",
    "        model.load_weights(filepath='inception.fold_' + str(i) + '.hdf5')\n",
    "\n",
    "        \n",
    "        print('----------------------------------------')\n",
    "        print('Running train evaluation on fold {}'.format(i))\n",
    "        train_score = model.evaluate_generator(train_generator(), steps=train_steps)        \n",
    "        print('Running validation evaluation on fold {}'.format(i))\n",
    "        valid_score = model.evaluate_generator(valid_generator(), steps=valid_steps)\n",
    "        print('----------------------------------------')   \n",
    "        \n",
    "        print('Train loss: {:0.5f}\\n Train acc: {:0.5f} for fold {}'.format(train_score[0],\n",
    "                                                                            train_score[1], i))\n",
    "        print('Valid loss: {:0.5f}\\n Valid acc: {:0.5f} for fold {}'.format(valid_score[0],\n",
    "                                                                            valid_score[1], i))\n",
    "        print('----------------------------------------')\n",
    "\n",
    "        train_scores.append(train_score[1])\n",
    "        valid_scores.append(valid_score[1])\n",
    "        print('Avg Train Acc: {:0.5f}\\nAvg Valid Acc: {:0.5f} after {} folds'.format\n",
    "              (np.mean(train_scores), np.mean(valid_scores), i))\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "        print('Running test predictions with fold {}'.format(i))        \n",
    "        preds_test_fold = model.predict_generator(generator=test_generator(),\n",
    "                                              steps=test_steps, verbose=1)[:, -1]\n",
    "\n",
    "        preds_test += preds_test_fold\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i <= n_fold:\n",
    "            print('Now beginning training for fold {}\\n\\n'.format(i))\n",
    "        else:\n",
    "            print('Finished training!')\n",
    "\n",
    "    preds_test /= n_fold\n",
    "\n",
    "    return preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.6874 - acc: 0.5301Epoch 00001: val_loss improved from inf to 2.45180, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 7s 41ms/step - loss: 0.6809 - acc: 0.5354 - val_loss: 2.4518 - val_acc: 0.5084\n",
      "Epoch 2/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.6369 - acc: 0.5669Epoch 00002: val_loss improved from 2.45180 to 0.57469, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.6369 - acc: 0.5624 - val_loss: 0.5747 - val_acc: 0.7009\n",
      "Epoch 3/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5833 - acc: 0.6582Epoch 00003: val_loss improved from 0.57469 to 0.56412, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5839 - acc: 0.6527 - val_loss: 0.5641 - val_acc: 0.6991\n",
      "Epoch 4/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5770 - acc: 0.6535Epoch 00004: val_loss did not improve\n",
      "179/178 [==============================] - 6s 31ms/step - loss: 0.5778 - acc: 0.6481 - val_loss: 0.5655 - val_acc: 0.7009\n",
      "Epoch 5/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5669 - acc: 0.6733Epoch 00005: val_loss improved from 0.56412 to 0.55402, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5680 - acc: 0.6676 - val_loss: 0.5540 - val_acc: 0.7009\n",
      "Epoch 6/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5748 - acc: 0.6761Epoch 00006: val_loss did not improve\n",
      "179/178 [==============================] - 6s 31ms/step - loss: 0.5742 - acc: 0.6788 - val_loss: 0.5949 - val_acc: 0.5084\n",
      "Epoch 7/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5712 - acc: 0.6601Epoch 00007: val_loss improved from 0.55402 to 0.55011, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5726 - acc: 0.6546 - val_loss: 0.5501 - val_acc: 0.7009\n",
      "Epoch 8/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5691 - acc: 0.6733Epoch 00008: val_loss did not improve\n",
      "179/178 [==============================] - 6s 31ms/step - loss: 0.5704 - acc: 0.6676 - val_loss: 0.5596 - val_acc: 0.6972\n",
      "Epoch 9/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5646 - acc: 0.6733\n",
      "Epoch 00009: reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 00009: val_loss did not improve\n",
      "179/178 [==============================] - 6s 31ms/step - loss: 0.5659 - acc: 0.6676 - val_loss: 0.5534 - val_acc: 0.6991\n",
      "Epoch 10/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5608 - acc: 0.6704Epoch 00010: val_loss improved from 0.55011 to 0.54857, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5622 - acc: 0.6648 - val_loss: 0.5486 - val_acc: 0.7047\n",
      "Epoch 11/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5559 - acc: 0.6676Epoch 00011: val_loss improved from 0.54857 to 0.54683, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5573 - acc: 0.6620 - val_loss: 0.5468 - val_acc: 0.7028\n",
      "Epoch 12/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5540 - acc: 0.6742Epoch 00012: val_loss improved from 0.54683 to 0.54627, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5555 - acc: 0.6685 - val_loss: 0.5463 - val_acc: 0.6991\n",
      "Epoch 13/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5531 - acc: 0.6742Epoch 00013: val_loss improved from 0.54627 to 0.54608, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5546 - acc: 0.6685 - val_loss: 0.5461 - val_acc: 0.7009\n",
      "Epoch 14/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5535 - acc: 0.6789Epoch 00014: val_loss improved from 0.54608 to 0.54582, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5550 - acc: 0.6732 - val_loss: 0.5458 - val_acc: 0.7028\n",
      "Epoch 15/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5519 - acc: 0.6733Epoch 00015: val_loss improved from 0.54582 to 0.54537, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5534 - acc: 0.6676 - val_loss: 0.5454 - val_acc: 0.7028\n",
      "Epoch 16/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5560 - acc: 0.6733Epoch 00016: val_loss improved from 0.54537 to 0.54445, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5576 - acc: 0.6676 - val_loss: 0.5445 - val_acc: 0.6991\n",
      "Epoch 17/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5538 - acc: 0.6751Epoch 00017: val_loss improved from 0.54445 to 0.54392, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5554 - acc: 0.6695 - val_loss: 0.5439 - val_acc: 0.7009\n",
      "Epoch 18/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5509 - acc: 0.6780Epoch 00018: val_loss improved from 0.54392 to 0.54365, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5525 - acc: 0.6723 - val_loss: 0.5437 - val_acc: 0.7028\n",
      "Epoch 19/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5532 - acc: 0.6770Epoch 00019: val_loss improved from 0.54365 to 0.54256, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5547 - acc: 0.6723 - val_loss: 0.5426 - val_acc: 0.7028\n",
      "Epoch 20/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5499 - acc: 0.6751Epoch 00020: val_loss improved from 0.54256 to 0.54210, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 33ms/step - loss: 0.5516 - acc: 0.6695 - val_loss: 0.5421 - val_acc: 0.7028\n",
      "Epoch 21/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5496 - acc: 0.6846Epoch 00021: val_loss improved from 0.54210 to 0.54159, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 33ms/step - loss: 0.5513 - acc: 0.6788 - val_loss: 0.5416 - val_acc: 0.7047\n",
      "Epoch 22/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5480 - acc: 0.6874Epoch 00022: val_loss improved from 0.54159 to 0.54113, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 33ms/step - loss: 0.5497 - acc: 0.6816 - val_loss: 0.5411 - val_acc: 0.7103\n",
      "Epoch 23/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5502 - acc: 0.6780Epoch 00023: val_loss improved from 0.54113 to 0.53959, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 33ms/step - loss: 0.5518 - acc: 0.6732 - val_loss: 0.5396 - val_acc: 0.7140\n",
      "Epoch 24/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5430 - acc: 0.6770Epoch 00024: val_loss did not improve\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5443 - acc: 0.6732 - val_loss: 0.5396 - val_acc: 0.7178\n",
      "Epoch 25/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5414 - acc: 0.6893\n",
      "Epoch 00025: reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 00025: val_loss did not improve\n",
      "179/178 [==============================] - 6s 32ms/step - loss: 0.5425 - acc: 0.6853 - val_loss: 0.5431 - val_acc: 0.7121\n",
      "Epoch 26/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5402 - acc: 0.6949Epoch 00026: val_loss improved from 0.53959 to 0.53831, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 33ms/step - loss: 0.5416 - acc: 0.6909 - val_loss: 0.5383 - val_acc: 0.7159\n",
      "Epoch 27/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5422 - acc: 0.6987Epoch 00027: val_loss improved from 0.53831 to 0.53721, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 33ms/step - loss: 0.5436 - acc: 0.6946 - val_loss: 0.5372 - val_acc: 0.7178\n",
      "Epoch 28/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.5370 - acc: 0.6966Epoch 00028: val_loss improved from 0.53721 to 0.53676, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 34ms/step - loss: 0.5388 - acc: 0.6928 - val_loss: 0.5368 - val_acc: 0.7196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5379 - acc: 0.7062Epoch 00029: val_loss improved from 0.53676 to 0.53633, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 34ms/step - loss: 0.5394 - acc: 0.7011 - val_loss: 0.5363 - val_acc: 0.7215\n",
      "Epoch 30/50\n",
      "177/178 [============================>.] - ETA: 0s - loss: 0.5395 - acc: 0.7072Epoch 00030: val_loss improved from 0.53633 to 0.53602, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 6s 33ms/step - loss: 0.5409 - acc: 0.7030 - val_loss: 0.5360 - val_acc: 0.7196\n",
      "Epoch 31/50\n",
      " 57/178 [========>.....................] - ETA: 3s - loss: 0.5454 - acc: 0.7135"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-29af5a207366>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m prediction = train_model(model, batch_size, epochs, img_size, X_train, \n\u001b[1;32m----> 8\u001b[1;33m                                 target_train, X_test, n_fold, kf)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msubmit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mid_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is_iceberg'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-3641f4cc3f35>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, batch_size, epochs, img_size, x, y, test, n_fold, kf)\u001b[0m\n\u001b[0;32m     87\u001b[0m         model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n\u001b[0;32m     88\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                             validation_steps=valid_steps)\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inception.fold_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2147\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 6\n",
    "epochs = 50\n",
    "n_fold = 3\n",
    "img_size = (img_height, img_width)\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "prediction = train_model(model, batch_size, epochs, img_size, X_train, \n",
    "                                target_train, X_test, n_fold, kf)\n",
    "\n",
    "submit = pd.DataFrame({'id': id_test, 'is_iceberg': prediction.reshape((prediction.shape[0]))})\n",
    "submit.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
