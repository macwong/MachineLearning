{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications import ResNet50et50\n",
    "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Reshape, Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"_RawData/test.json/data/processed/test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_1']])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_2']])\n",
    "\n",
    "X_train = np.concatenate([x_band1[:, :, :, np.newaxis],\n",
    "                          x_band2[:, :, :, np.newaxis],\n",
    "                          ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "target_train=train['is_iceberg']\n",
    "\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\n",
    "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n",
    "\n",
    "X_test = np.concatenate([x_band1[:, :, :, np.newaxis],\n",
    "                         x_band2[:, :, :, np.newaxis],\n",
    "                         ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "id_test = test['id'].values\n",
    "\n",
    "del test; del x_band1; del x_band2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 55, 55, 256)  0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 55, 55, 256)  0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 55, 55, 256)  0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 28, 28, 512)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 28, 28, 512)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 28, 28, 512)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 28, 28, 512)  0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 14, 14, 1024) 0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 14, 14, 1024) 0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 14, 14, 1024) 0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 14, 14, 1024) 0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 1024) 0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 14, 14, 1024) 0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 2048)   0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 2048)   0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 2048)   0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "globalaveragepooling2d (GlobalA (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 1)            2049        globalaveragepooling2d[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define CNN Model Architecture (Kaggle can't access the weights file)\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "\n",
    "def inceptionv3(img_dim=img_dim):\n",
    "    base_model = ResNet50(weights=None, include_top=False, input_shape= img_dim)\n",
    "    \n",
    "    x_model = base_model.output\n",
    "    \n",
    "    x_model = GlobalAveragePooling2D(name='globalaveragepooling2d')(x_model)\n",
    "    \n",
    "#     x_model = Dense(1024, activation='relu',name='fc1_Dense')(x_model)\n",
    "#     x_model = Dropout(0.5, name='dropout_1')(x_model)\n",
    "    \n",
    "#     x_model = Dense(256, activation='relu',name='fc2_Dense')(x_model)\n",
    "#     x_model = Dropout(0.5, name='dropout_2')(x_model)\n",
    "    predictions = Dense(1, activation='sigmoid',name='output_layer')(x_model)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    \n",
    "#     input_tensor = Input(shape=img_dim)\n",
    "#     base_model = ResNet50(include_top=False,\n",
    "#                    weights='imagenet',\n",
    "#                    input_shape=img_dim)\n",
    "    \n",
    "#     bn = BatchNormalization()(input_tensor)\n",
    "#     x = base_model(bn)\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "# #     x = Reshape((1, 1, 1024), name='reshape_1')(x)\n",
    "#     x = Dropout(0.2, name='dropout')(x)\n",
    "# #     x = Conv2D(2, (1, 1),\n",
    "# #                padding='same', name='conv_preds')(x)\n",
    "# #     x = Dense('sigmoid', name='act_softmax')(x)\n",
    "# #     x = Reshape((classes,), name='reshape_2')(x)\n",
    "    \n",
    "# #     bn = BatchNormalization()(input_tensor)\n",
    "# #     x = base_model(bn)\n",
    "# #     x = GlobalAveragePooling2D()(x)\n",
    "# #     x = Dropout(0.5)(x)\n",
    "#     output = Dense(1, activation='sigmoid')(x)\n",
    "#     model = Model(input_tensor, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = inceptionv3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train Model and predict\n",
    "def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n",
    "        \n",
    "    train_scores = []; valid_scores = []\n",
    "    preds_test = np.zeros(len(test), dtype = np.float)\n",
    "\n",
    "    i = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        x_train = x[train_index]; x_valid = x[test_index]\n",
    "        y_train = y[train_index]; y_valid = y[test_index]\n",
    "\n",
    "        def augment(src, choice):\n",
    "            if choice == 0:\n",
    "                # Rotate 90\n",
    "                src = np.rot90(src, 1)\n",
    "            if choice == 1:\n",
    "                # flip vertically\n",
    "                src = np.flipud(src)\n",
    "            if choice == 2:\n",
    "                # Rotate 180\n",
    "                src = np.rot90(src, 2)\n",
    "            if choice == 3:\n",
    "                # flip horizontally\n",
    "                src = np.fliplr(src)\n",
    "            if choice == 4:\n",
    "                # Rotate 90 counter-clockwise\n",
    "                src = np.rot90(src, 3)\n",
    "            if choice == 5:\n",
    "                # Rotate 180 and flip horizontally\n",
    "                src = np.rot90(src, 2)\n",
    "                src = np.fliplr(src)\n",
    "            return src\n",
    "\n",
    "        def train_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_train), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(x_train))\n",
    "                    y_batch = y_train[start:end]\n",
    "                    for img in x_train[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        new_img = augment(new_img, np.random.randint(6))\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def valid_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(x_valid), batch_size):\n",
    "                    x_batch = []\n",
    "                    end = min(start + batch_size, len(x_valid))\n",
    "                    y_batch = y_valid[start:end]\n",
    "                    for img in x_valid[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    y_batch = np.array(y_batch, np.uint8)\n",
    "                    yield x_batch, y_batch\n",
    "\n",
    "        def test_generator():\n",
    "            while True:\n",
    "                for start in range(0, len(test), n_fold):\n",
    "                    x_batch = []\n",
    "                    end = min(start + n_fold, len(test))\n",
    "                    for img in test[start:end]:\n",
    "                        new_img = cv2.resize(img, img_size)\n",
    "                        x_batch.append(new_img)\n",
    "                    x_batch = np.array(x_batch, np.float32) / 255.\n",
    "                    yield x_batch\n",
    "                    \n",
    "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n",
    "                               verbose=1, min_lr=1e-7),\n",
    "             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n",
    "                             save_best_only=True, save_weights_only=True, mode='auto')]\n",
    "\n",
    "        train_steps = len(x_train) / batch_size\n",
    "        valid_steps = len(x_valid) / batch_size\n",
    "        test_steps = len(test) / n_fold\n",
    "        \n",
    "        model = model\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n",
    "                            callbacks=callbacks, validation_data=valid_generator(), \n",
    "                            validation_steps=valid_steps)\n",
    "\n",
    "        model.load_weights(filepath='inception.fold_' + str(i) + '.hdf5')\n",
    "\n",
    "        \n",
    "        print('----------------------------------------')\n",
    "        print('Running train evaluation on fold {}'.format(i))\n",
    "        train_score = model.evaluate_generator(train_generator(), steps=train_steps)        \n",
    "        print('Running validation evaluation on fold {}'.format(i))\n",
    "        valid_score = model.evaluate_generator(valid_generator(), steps=valid_steps)\n",
    "        print('----------------------------------------')   \n",
    "        \n",
    "        print('Train loss: {:0.5f}\\n Train acc: {:0.5f} for fold {}'.format(train_score[0],\n",
    "                                                                            train_score[1], i))\n",
    "        print('Valid loss: {:0.5f}\\n Valid acc: {:0.5f} for fold {}'.format(valid_score[0],\n",
    "                                                                            valid_score[1], i))\n",
    "        print('----------------------------------------')\n",
    "\n",
    "        train_scores.append(train_score[1])\n",
    "        valid_scores.append(valid_score[1])\n",
    "        print('Avg Train Acc: {:0.5f}\\nAvg Valid Acc: {:0.5f} after {} folds'.format\n",
    "              (np.mean(train_scores), np.mean(valid_scores), i))\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "        print('Running test predictions with fold {}'.format(i))        \n",
    "        preds_test_fold = model.predict_generator(generator=test_generator(),\n",
    "                                              steps=test_steps, verbose=1)[:, -1]\n",
    "\n",
    "        preds_test += preds_test_fold\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i <= n_fold:\n",
    "            print('Now beginning training for fold {}\\n\\n'.format(i))\n",
    "        else:\n",
    "            print('Finished training!')\n",
    "\n",
    "    preds_test /= n_fold\n",
    "\n",
    "    return preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.7614 - acc: 0.6685Epoch 00001: val_loss improved from inf to 1.12851, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 56s 313ms/step - loss: 0.7572 - acc: 0.6704 - val_loss: 1.1285 - val_acc: 0.5402\n",
      "Epoch 2/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.6778 - acc: 0.7032Epoch 00002: val_loss did not improve\n",
      "179/178 [==============================] - 40s 221ms/step - loss: 0.6741 - acc: 0.7048 - val_loss: 2.2798 - val_acc: 0.5159\n",
      "Epoch 3/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.5925 - acc: 0.7210\n",
      "Epoch 00003: reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 00003: val_loss did not improve\n",
      "179/178 [==============================] - 42s 234ms/step - loss: 0.5894 - acc: 0.7225 - val_loss: 1.9244 - val_acc: 0.5159\n",
      "Epoch 4/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.5811 - acc: 0.7116Epoch 00004: val_loss improved from 1.12851 to 0.51247, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 41s 231ms/step - loss: 0.5796 - acc: 0.7132 - val_loss: 0.5125 - val_acc: 0.7421\n",
      "Epoch 5/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.4711 - acc: 0.7875Epoch 00005: val_loss improved from 0.51247 to 0.45850, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 233ms/step - loss: 0.4700 - acc: 0.7886 - val_loss: 0.4585 - val_acc: 0.8000\n",
      "Epoch 6/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.4572 - acc: 0.8034- ETA: 0s - loss: 0.4534 - acc: 0.8Epoch 00006: val_loss did not improve\n",
      "179/178 [==============================] - 40s 225ms/step - loss: 0.4560 - acc: 0.8045 - val_loss: 0.4604 - val_acc: 0.8000\n",
      "Epoch 7/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.8212- ETA: 6s - loss: - ETA: 2s - loss: 0.4321 - aEpoch 00007: val_loss improved from 0.45850 to 0.43904, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 233ms/step - loss: 0.4449 - acc: 0.8222 - val_loss: 0.4390 - val_acc: 0.8093\n",
      "Epoch 8/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.4231 - acc: 0.8249Epoch 00008: val_loss did not improve\n",
      "179/178 [==============================] - 40s 226ms/step - loss: 0.4213 - acc: 0.8259 - val_loss: 0.4529 - val_acc: 0.8056\n",
      "Epoch 9/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.4226 - acc: 0.8268- \n",
      "Epoch 00009: reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 00009: val_loss did not improve\n",
      "179/178 [==============================] - 41s 227ms/step - loss: 0.4212 - acc: 0.8277 - val_loss: 0.4673 - val_acc: 0.7888\n",
      "Epoch 10/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.4134 - acc: 0.8287Epoch 00010: val_loss improved from 0.43904 to 0.39260, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 235ms/step - loss: 0.4124 - acc: 0.8296 - val_loss: 0.3926 - val_acc: 0.8393\n",
      "Epoch 11/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8464Epoch 00011: val_loss improved from 0.39260 to 0.37811, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 233ms/step - loss: 0.3776 - acc: 0.8473 - val_loss: 0.3781 - val_acc: 0.8411\n",
      "Epoch 12/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3762 - acc: 0.8464- ETA: 1s - loss: 0.3598 - acEpoch 00012: val_loss improved from 0.37811 to 0.36919, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 236ms/step - loss: 0.3760 - acc: 0.8473 - val_loss: 0.3692 - val_acc: 0.8411\n",
      "Epoch 13/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3694 - acc: 0.8483Epoch 00013: val_loss improved from 0.36919 to 0.36229, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 233ms/step - loss: 0.3692 - acc: 0.8492 - val_loss: 0.3623 - val_acc: 0.8430\n",
      "Epoch 14/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3639 - acc: 0.8502Epoch 00014: val_loss improved from 0.36229 to 0.35485, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 234ms/step - loss: 0.3634 - acc: 0.8510 - val_loss: 0.3549 - val_acc: 0.8449\n",
      "Epoch 15/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3633 - acc: 0.8521Epoch 00015: val_loss improved from 0.35485 to 0.35129, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 235ms/step - loss: 0.3626 - acc: 0.8529 - val_loss: 0.3513 - val_acc: 0.8523\n",
      "Epoch 16/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8577Epoch 00016: val_loss improved from 0.35129 to 0.34724, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 235ms/step - loss: 0.3517 - acc: 0.8585 - val_loss: 0.3472 - val_acc: 0.8505\n",
      "Epoch 17/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3430 - acc: 0.8614Epoch 00017: val_loss improved from 0.34724 to 0.34324, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 233ms/step - loss: 0.3429 - acc: 0.8622 - val_loss: 0.3432 - val_acc: 0.8523\n",
      "Epoch 18/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3396 - acc: 0.8614- ETA: 5s - loss: 0.3 - ETA: 1s - loss: 0.3232 - acEpoch 00018: val_loss improved from 0.34324 to 0.34023, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 235ms/step - loss: 0.3389 - acc: 0.8622 - val_loss: 0.3402 - val_acc: 0.8523\n",
      "Epoch 19/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.8670- ETA: 2s - loss: 0.3217 -Epoch 00019: val_loss improved from 0.34023 to 0.33493, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 234ms/step - loss: 0.3376 - acc: 0.8678 - val_loss: 0.3349 - val_acc: 0.8598\n",
      "Epoch 20/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3268 - acc: 0.8567Epoch 00020: val_loss improved from 0.33493 to 0.33245, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 235ms/step - loss: 0.3266 - acc: 0.8575 - val_loss: 0.3324 - val_acc: 0.8654\n",
      "Epoch 21/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3188 - acc: 0.8689Epoch 00021: val_loss did not improve\n",
      "179/178 [==============================] - 41s 227ms/step - loss: 0.3179 - acc: 0.8696 - val_loss: 0.3326 - val_acc: 0.8542\n",
      "Epoch 22/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.8614Epoch 00022: val_loss improved from 0.33245 to 0.32946, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 235ms/step - loss: 0.3145 - acc: 0.8622 - val_loss: 0.3295 - val_acc: 0.8561\n",
      "Epoch 23/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.8764- ETEpoch 00023: val_loss did not improve\n",
      "179/178 [==============================] - 41s 228ms/step - loss: 0.3055 - acc: 0.8771 - val_loss: 0.3302 - val_acc: 0.8542\n",
      "Epoch 24/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.3039 - acc: 0.8661- ETA: 5s -Epoch 00024: val_loss improved from 0.32946 to 0.32333, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 234ms/step - loss: 0.3032 - acc: 0.8668 - val_loss: 0.3233 - val_acc: 0.8561\n",
      "Epoch 25/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.8652Epoch 00025: val_loss improved from 0.32333 to 0.31872, saving model to inception.fold_1.hdf5\n",
      "179/178 [==============================] - 42s 236ms/step - loss: 0.2983 - acc: 0.8659 - val_loss: 0.3187 - val_acc: 0.8579\n",
      "Epoch 26/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.2809 - acc: 0.8811Epoch 00026: val_loss did not improve\n",
      "179/178 [==============================] - 41s 228ms/step - loss: 0.2801 - acc: 0.8817 - val_loss: 0.3222 - val_acc: 0.8710\n",
      "Epoch 27/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.2695 - acc: 0.8811\n",
      "Epoch 00027: reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 00027: val_loss did not improve\n",
      "179/178 [==============================] - 41s 229ms/step - loss: 0.2687 - acc: 0.8817 - val_loss: 0.3215 - val_acc: 0.8636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "178/178 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.8858Epoch 00028: val_loss did not improve\n",
      "179/178 [==============================] - 41s 229ms/step - loss: 0.2677 - acc: 0.8864 - val_loss: 0.3194 - val_acc: 0.8729\n",
      "Epoch 00028: early stopping\n",
      "----------------------------------------\n",
      "Running train evaluation on fold 1\n",
      "Running validation evaluation on fold 1\n",
      "----------------------------------------\n",
      "Train loss: 0.31120\n",
      " Train acc: 0.87746 for fold 1\n",
      "Valid loss: 0.31872\n",
      " Valid acc: 0.85794 for fold 1\n",
      "----------------------------------------\n",
      "Avg Train Acc: 0.87746\n",
      "Avg Valid Acc: 0.85794 after 1 folds\n",
      "----------------------------------------\n",
      "Running test predictions with fold 1\n",
      "2808/2808 [==============================] - 104s 37ms/step\n",
      "\n",
      "\n",
      "\n",
      "Now beginning training for fold 2\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-29af5a207366>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m prediction = train_model(model, batch_size, epochs, img_size, X_train, \n\u001b[1;32m----> 8\u001b[1;33m                                 target_train, X_test, n_fold, kf)\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msubmit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mid_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is_iceberg'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-45f229467b2d>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, batch_size, epochs, img_size, x, y, test, n_fold, kf)\u001b[0m\n\u001b[0;32m     87\u001b[0m         model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n\u001b[0;32m     88\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                             validation_steps=valid_steps)\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inception.fold_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2015\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2016\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2017\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2018\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    988\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[0;32m    989\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m                         loss=self.total_loss)\n\u001b[0m\u001b[0;32m    991\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m                 \u001b[1;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, loss, params)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'clipnorm'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclipnorm\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   2392\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mgradients\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \"\"\"\n\u001b[1;32m-> 2394\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method)\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mout_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZerosLike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m               \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                 \u001b[0mout_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZerosLikeOutsideLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_grad\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mZerosLikeOutsideLoop\u001b[1;34m(op, index)\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       \u001b[0mbranch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop_ctxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m       \u001b[0mswitch_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mswitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbranch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m       \u001b[0mzeros_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mswitch_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzeros_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mswitch\u001b[1;34m(data, pred, dtype, name)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_control_flow_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_switch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIndexedSlices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_control_flow_ops.py\u001b[0m in \u001b[0;36m_switch\u001b[1;34m(data, pred, name)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[0moutput_true\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mforwarded\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthis\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m   \"\"\"\n\u001b[1;32m--> 356\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op_def_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Switch\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_SwitchOutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    669\u001b[0m       output = pywrap_tensorflow.RunCppShapeInference(\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No shape inference function exists for op\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 6\n",
    "epochs = 50\n",
    "n_fold = 3\n",
    "img_size = (img_height, img_width)\n",
    "kf = KFold(n_splits=n_fold, shuffle=True)\n",
    "\n",
    "prediction = train_model(model, batch_size, epochs, img_size, X_train, \n",
    "                                target_train, X_test, n_fold, kf)\n",
    "\n",
    "submit = pd.DataFrame({'id': id_test, 'is_iceberg': prediction.reshape((prediction.shape[0]))})\n",
    "submit.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
