{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "import helpers\n",
    "from models import DaveModel, DaveVGG, DaveVGG19, SimpleModel, LeNetModel\n",
    "from trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"_RawData/test.json/data/processed/test.json\")\n",
    "\n",
    "X = helpers.get_images(train)\n",
    "X_test = helpers.get_images(test)\n",
    "\n",
    "y = to_categorical(train.is_iceberg.values,num_classes=2)\n",
    "\n",
    "ids = test[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainRunner = Trainer(ids, X, y, [\n",
    "    DaveModel(ids),\n",
    "    DaveVGG(ids),\n",
    "    DaveVGG19(ids),\n",
    "    LeNetModel(ids)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================\n",
      "Model: davemodel\n",
      "Batch Size: 32\n",
      "Epochs: 1\n",
      "Epoch 1/1\n",
      "51/50 [==============================] - 3s - loss: 0.5531 - acc: 0.7126     \n",
      "\n",
      "\n",
      "================================================\n",
      "Model: vgg\n",
      "Batch Size: 32\n",
      "Epochs: 1\n",
      "Epoch 1/1\n",
      "51/50 [==============================] - 8s - loss: 0.6887 - acc: 0.5178     \n",
      "\n",
      "\n",
      "================================================\n",
      "Model: vgg19\n",
      "Batch Size: 32\n",
      "Epochs: 1\n",
      "Epoch 1/1\n",
      "51/50 [==============================] - 8s - loss: 0.6930 - acc: 0.5258     \n",
      "\n",
      "\n",
      "================================================\n",
      "Model: lenet\n",
      "Batch Size: 32\n",
      "Epochs: 1\n",
      "Epoch 1/1\n",
      "51/50 [==============================] - 2s - loss: 0.6744 - acc: 0.6047     \n"
     ]
    }
   ],
   "source": [
    "# trainRunner.train(32, 1, False)\n",
    "trainRunner.train_full(32, 1, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRunner.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.46230322,  0.53769678],\n",
       "        [ 0.46604916,  0.53395075],\n",
       "        [ 0.4575015 ,  0.54249853],\n",
       "        ..., \n",
       "        [ 0.45932385,  0.54067612],\n",
       "        [ 0.45786059,  0.54213941],\n",
       "        [ 0.45556942,  0.54443055]], dtype=float32),\n",
       " array([[ 0.5057869 ,  0.4942131 ],\n",
       "        [ 0.69722164,  0.30277836],\n",
       "        [ 0.85135168,  0.14864834],\n",
       "        ..., \n",
       "        [ 0.50723886,  0.49276114],\n",
       "        [ 0.50646132,  0.49353865],\n",
       "        [ 0.64603692,  0.35396308]], dtype=float32),\n",
       " array([[ 0.51047188,  0.48952809],\n",
       "        [ 0.51094073,  0.48905921],\n",
       "        [ 0.51345146,  0.48654848],\n",
       "        ..., \n",
       "        [ 0.51019639,  0.48980364],\n",
       "        [ 0.51085556,  0.48914438],\n",
       "        [ 0.51018059,  0.48981938]], dtype=float32),\n",
       " array([[ 0.27341908,  0.72658086],\n",
       "        [ 0.34210107,  0.65789896],\n",
       "        [ 0.6335004 ,  0.3664996 ],\n",
       "        ..., \n",
       "        [ 0.29279649,  0.70720351],\n",
       "        [ 0.31360942,  0.68639052],\n",
       "        [ 0.49054417,  0.50945592]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainRunner.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
