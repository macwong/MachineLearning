{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"_RawData/train.json/data/processed/train.json\")\n",
    "test = pd.read_json(\"_RawData/test.json/data/processed/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>id</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>e25388fd</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>271f93f4</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              band_1  \\\n",
       "0  [-27.878360999999998, -27.15416, -28.668615, -...   \n",
       "1  [-12.242375, -14.920304999999999, -14.920363, ...   \n",
       "2  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "\n",
       "                                              band_2        id inc_angle  \\\n",
       "0  [-27.154118, -29.537888, -31.0306, -32.190483,...  dfd5f913   43.9239   \n",
       "1  [-31.506321, -27.984554, -26.645678, -23.76760...  e25388fd   38.1562   \n",
       "2  [-24.870956, -24.092632, -20.653963, -19.41104...  58b2aaa0   45.2859   \n",
       "3  [-27.889421, -27.519794, -27.165262, -29.10350...  4cfc3a18   43.8306   \n",
       "4  [-27.206915, -30.259186, -30.259186, -23.16495...  271f93f4   35.6256   \n",
       "\n",
       "   is_iceberg  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_channel(band_data):\n",
    "    print(\"get_channel\")\n",
    "    band_data = np.array([np.array(band).astype(np.float32) for band in band_data])\n",
    "    \n",
    "    print(band_data.shape)\n",
    "    band_data_new = np.empty((1604, 150, 150))\n",
    "\n",
    "    for ind in range(band_data.shape[0]):\n",
    "        arr_image = band_data[ind]\n",
    "        band_data_new[ind] = (scipy.misc.fromimage(scipy.misc.toimage(arr_image.reshape(75, 75)).resize((150, 150))))\n",
    "\n",
    "    print(band_data_new.shape)\n",
    "\n",
    "    return band_data_new\n",
    "\n",
    "def concat_data(data):\n",
    "    channel1 = get_channel(data[\"band_1\"])\n",
    "    channel2 = get_channel(data[\"band_2\"])\n",
    "    channel3 = (channel1 + channel2) / 2.\n",
    "\n",
    "    return np.concatenate([channel1[:, :, :, np.newaxis], channel2[:, :, :, np.newaxis],channel3[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_channel\n",
      "(1604, 5625)\n",
      "(1604, 150, 150)\n",
      "get_channel\n",
      "(1604, 5625)\n",
      "(1604, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X_train = concat_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  69. ,  119. ,   94. ],\n",
       "        [  69. ,  119. ,   94. ],\n",
       "        [  74. ,   99. ,   86.5],\n",
       "        ..., \n",
       "        [  79. ,   99. ,   89. ],\n",
       "        [  52. ,  116. ,   84. ],\n",
       "        [  52. ,  116. ,   84. ]],\n",
       "\n",
       "       [[  69. ,  119. ,   94. ],\n",
       "        [  69. ,  119. ,   94. ],\n",
       "        [  74. ,   99. ,   86.5],\n",
       "        ..., \n",
       "        [  79. ,   99. ,   89. ],\n",
       "        [  52. ,  116. ,   84. ],\n",
       "        [  52. ,  116. ,   84. ]],\n",
       "\n",
       "       [[  64. ,   86. ,   75. ],\n",
       "        [  64. ,   86. ,   75. ],\n",
       "        [  69. ,   65. ,   67. ],\n",
       "        ..., \n",
       "        [  64. ,  110. ,   87. ],\n",
       "        [  44. ,  125. ,   84.5],\n",
       "        [  44. ,  125. ,   84.5]],\n",
       "\n",
       "       ..., \n",
       "       [[  44. ,   99. ,   71.5],\n",
       "        [  44. ,   99. ,   71.5],\n",
       "        [  69. ,   99. ,   84. ],\n",
       "        ..., \n",
       "        [  76. ,  110. ,   93. ],\n",
       "        [  72. ,   65. ,   68.5],\n",
       "        [  72. ,   65. ,   68.5]],\n",
       "\n",
       "       [[  61. ,   95. ,   78. ],\n",
       "        [  61. ,   95. ,   78. ],\n",
       "        [  76. ,  106. ,   91. ],\n",
       "        ..., \n",
       "        [  69. ,  106. ,   87.5],\n",
       "        [  67. ,  103. ,   85. ],\n",
       "        [  67. ,  103. ,   85. ]],\n",
       "\n",
       "       [[  61. ,   95. ,   78. ],\n",
       "        [  61. ,   95. ,   78. ],\n",
       "        [  76. ,  106. ,   91. ],\n",
       "        ..., \n",
       "        [  69. ,  106. ,   87.5],\n",
       "        [  67. ,  103. ,   85. ],\n",
       "        [  67. ,  103. ,   85. ]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train=train['is_iceberg']\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, y_train, random_state=1, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generators(train_data, valid_data):\n",
    "    data_gen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            rotation_range=180,\n",
    "            vertical_flip=True,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "    data_gen.fit(train_data)\n",
    "\n",
    "    val_gen = ImageDataGenerator(rescale=1./255)\n",
    "    val_gen.fit(valid_data)\n",
    "    \n",
    "    return data_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dgen, vgen = get_generators(X_train_cv, X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DaveBaseModel:\n",
    "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_valid = X_valid\n",
    "        self.y_valid = y_valid\n",
    "        self.dgen, self.vgen = get_generators(X_train, X_valid)\n",
    "        \n",
    "    def train(self, epochs, batch_size):\n",
    "        self.model.fit_generator(self.dgen.flow(self.X_train, self.y_train, batch_size=batch_size),\n",
    "                            steps_per_epoch=len(self.X_train) / batch_size, \n",
    "                            validation_data=self.vgen.flow(self.X_valid, self.y_valid, batch_size=batch_size, shuffle=False),\n",
    "                            validation_steps = len(self.X_valid) / batch_size,\n",
    "                            epochs=epochs)\n",
    "\n",
    "class DaveVGG(DaveBaseModel):\n",
    "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
    "        DaveBaseModel.__init__(self, X_train, X_valid, y_train, y_valid)\n",
    "        vgg_model = VGG16(include_top=False, weights=None, input_shape=(150, 150, 3))\n",
    "\n",
    "        top_model = Sequential()\n",
    "        top_model.add(Flatten(input_shape=vgg_model.output_shape[1:]))\n",
    "        top_model.add(Dense(512, activation='relu'))\n",
    "        # top_model.add(Dense(512, activation='relu'))\n",
    "        # top_model.add(Dropout(0.5))\n",
    "        top_model.add(Dense(1, activation='sigmoid'))\n",
    "        # top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "        self.model = Model(inputs= vgg_model.input, outputs= top_model(vgg_model.output))\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        print(self.model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_11 (Sequential)   (None, 1)                 4195329   \n",
      "=================================================================\n",
      "Total params: 18,910,017\n",
      "Trainable params: 18,910,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DaveVGG(X_train_cv, X_valid, y_train_cv, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "38/37 [==============================] - 16s - loss: 0.6921 - acc: 0.5237 - val_loss: 0.6785 - val_acc: 0.5312\n",
      "Epoch 2/80\n",
      "38/37 [==============================] - 15s - loss: 0.6785 - acc: 0.5374 - val_loss: 1.0349 - val_acc: 0.6135\n",
      "Epoch 3/80\n",
      "38/37 [==============================] - 15s - loss: 0.6932 - acc: 0.5251 - val_loss: 0.6915 - val_acc: 0.5611\n",
      "Epoch 4/80\n",
      "38/37 [==============================] - 15s - loss: 0.6650 - acc: 0.6145 - val_loss: 0.5965 - val_acc: 0.6933\n",
      "Epoch 5/80\n",
      "38/37 [==============================] - 15s - loss: 0.6182 - acc: 0.6370 - val_loss: 0.6873 - val_acc: 0.4988\n",
      "Epoch 6/80\n",
      "38/37 [==============================] - 15s - loss: 0.6163 - acc: 0.6243 - val_loss: 0.6129 - val_acc: 0.6384\n",
      "Epoch 7/80\n",
      "38/37 [==============================] - 15s - loss: 0.5935 - acc: 0.6633 - val_loss: 0.6294 - val_acc: 0.6409\n",
      "Epoch 8/80\n",
      "38/37 [==============================] - 15s - loss: 0.6124 - acc: 0.6191 - val_loss: 0.5942 - val_acc: 0.6484\n",
      "Epoch 9/80\n",
      "38/37 [==============================] - 15s - loss: 0.5700 - acc: 0.6707 - val_loss: 0.6098 - val_acc: 0.6808\n",
      "Epoch 10/80\n",
      "38/37 [==============================] - 15s - loss: 0.5749 - acc: 0.6715 - val_loss: 0.6136 - val_acc: 0.6683\n",
      "Epoch 11/80\n",
      "38/37 [==============================] - 15s - loss: 0.5537 - acc: 0.6902 - val_loss: 0.6613 - val_acc: 0.6708\n",
      "Epoch 12/80\n",
      "38/37 [==============================] - 15s - loss: 0.5709 - acc: 0.6811 - val_loss: 0.5827 - val_acc: 0.6584\n",
      "Epoch 13/80\n",
      "38/37 [==============================] - 15s - loss: 0.5740 - acc: 0.6764 - val_loss: 0.5974 - val_acc: 0.6384\n",
      "Epoch 14/80\n",
      "38/37 [==============================] - 15s - loss: 0.5806 - acc: 0.6828 - val_loss: 0.5997 - val_acc: 0.6708\n",
      "Epoch 15/80\n",
      "38/37 [==============================] - 15s - loss: 0.5695 - acc: 0.6795 - val_loss: 0.5717 - val_acc: 0.6733\n",
      "Epoch 16/80\n",
      "38/37 [==============================] - 15s - loss: 0.5715 - acc: 0.6688 - val_loss: 0.5867 - val_acc: 0.6833\n",
      "Epoch 17/80\n",
      "38/37 [==============================] - 15s - loss: 0.5516 - acc: 0.6819 - val_loss: 0.7729 - val_acc: 0.6434\n",
      "Epoch 18/80\n",
      "38/37 [==============================] - 15s - loss: 0.5842 - acc: 0.6622 - val_loss: 0.5564 - val_acc: 0.6808\n",
      "Epoch 19/80\n",
      "38/37 [==============================] - 15s - loss: 0.5507 - acc: 0.6869 - val_loss: 0.5950 - val_acc: 0.6683\n",
      "Epoch 20/80\n",
      "38/37 [==============================] - 15s - loss: 0.5439 - acc: 0.6745 - val_loss: 0.5323 - val_acc: 0.6933\n",
      "Epoch 21/80\n",
      "38/37 [==============================] - 16s - loss: 0.5418 - acc: 0.6866 - val_loss: 0.5646 - val_acc: 0.6958\n",
      "Epoch 22/80\n",
      "38/37 [==============================] - 15s - loss: 0.5366 - acc: 0.6756 - val_loss: 0.5575 - val_acc: 0.7357\n",
      "Epoch 23/80\n",
      "38/37 [==============================] - 15s - loss: 0.4683 - acc: 0.7650 - val_loss: 0.5447 - val_acc: 0.7132\n",
      "Epoch 24/80\n",
      "38/37 [==============================] - 15s - loss: 0.4622 - acc: 0.7804 - val_loss: 0.4379 - val_acc: 0.8030\n",
      "Epoch 25/80\n",
      "38/37 [==============================] - 15s - loss: 0.4397 - acc: 0.7880 - val_loss: 0.7065 - val_acc: 0.7531\n",
      "Epoch 26/80\n",
      "38/37 [==============================] - 15s - loss: 0.4587 - acc: 0.7982 - val_loss: 0.5679 - val_acc: 0.7681\n",
      "Epoch 27/80\n",
      "38/37 [==============================] - 16s - loss: 0.4469 - acc: 0.7817 - val_loss: 0.4060 - val_acc: 0.7930\n",
      "Epoch 28/80\n",
      "38/37 [==============================] - 16s - loss: 0.4097 - acc: 0.7963 - val_loss: 0.4034 - val_acc: 0.8130\n",
      "Epoch 29/80\n",
      "38/37 [==============================] - 16s - loss: 0.4069 - acc: 0.8048 - val_loss: 0.4441 - val_acc: 0.7805\n",
      "Epoch 30/80\n",
      "38/37 [==============================] - 16s - loss: 0.3821 - acc: 0.8127 - val_loss: 0.3926 - val_acc: 0.8229\n",
      "Epoch 31/80\n",
      "38/37 [==============================] - 16s - loss: 0.3887 - acc: 0.8086 - val_loss: 0.4203 - val_acc: 0.7930\n",
      "Epoch 32/80\n",
      "38/37 [==============================] - 16s - loss: 0.4085 - acc: 0.8012 - val_loss: 0.4518 - val_acc: 0.8005\n",
      "Epoch 33/80\n",
      "38/37 [==============================] - 16s - loss: 0.3715 - acc: 0.8168 - val_loss: 0.3931 - val_acc: 0.8105\n",
      "Epoch 34/80\n",
      "38/37 [==============================] - 16s - loss: 0.3794 - acc: 0.8138 - val_loss: 0.3730 - val_acc: 0.8354\n",
      "Epoch 35/80\n",
      "38/37 [==============================] - 16s - loss: 0.3652 - acc: 0.8229 - val_loss: 0.3481 - val_acc: 0.8204\n",
      "Epoch 36/80\n",
      "38/37 [==============================] - 16s - loss: 0.3812 - acc: 0.8053 - val_loss: 0.4656 - val_acc: 0.7880\n",
      "Epoch 37/80\n",
      "38/37 [==============================] - 16s - loss: 0.3601 - acc: 0.8292 - val_loss: 0.3819 - val_acc: 0.8180\n",
      "Epoch 38/80\n",
      "38/37 [==============================] - 16s - loss: 0.3354 - acc: 0.8418 - val_loss: 0.3607 - val_acc: 0.8379\n",
      "Epoch 39/80\n",
      "38/37 [==============================] - 16s - loss: 0.3563 - acc: 0.8237 - val_loss: 0.4228 - val_acc: 0.8180\n",
      "Epoch 40/80\n",
      "38/37 [==============================] - 16s - loss: 0.3702 - acc: 0.8330 - val_loss: 0.3361 - val_acc: 0.8379\n",
      "Epoch 41/80\n",
      "38/37 [==============================] - 16s - loss: 0.3404 - acc: 0.8401 - val_loss: 0.3603 - val_acc: 0.8329\n",
      "Epoch 42/80\n",
      "38/37 [==============================] - 18s - loss: 0.3467 - acc: 0.8344 - val_loss: 0.3296 - val_acc: 0.8529\n",
      "Epoch 43/80\n",
      "38/37 [==============================] - 17s - loss: 0.3418 - acc: 0.8404 - val_loss: 0.3322 - val_acc: 0.8454\n",
      "Epoch 44/80\n",
      "38/37 [==============================] - 17s - loss: 0.3329 - acc: 0.8432 - val_loss: 0.4957 - val_acc: 0.8030\n",
      "Epoch 45/80\n",
      "38/37 [==============================] - 17s - loss: 0.3479 - acc: 0.8311 - val_loss: 0.3343 - val_acc: 0.8279\n",
      "Epoch 46/80\n",
      "38/37 [==============================] - 17s - loss: 0.3510 - acc: 0.8305 - val_loss: 0.3143 - val_acc: 0.8429\n",
      "Epoch 47/80\n",
      "38/37 [==============================] - 17s - loss: 0.3305 - acc: 0.8338 - val_loss: 0.3126 - val_acc: 0.8454\n",
      "Epoch 48/80\n",
      "38/37 [==============================] - 17s - loss: 0.3290 - acc: 0.8448 - val_loss: 0.3451 - val_acc: 0.8329\n",
      "Epoch 49/80\n",
      "38/37 [==============================] - 17s - loss: 0.3454 - acc: 0.8352 - val_loss: 0.3574 - val_acc: 0.8204\n",
      "Epoch 50/80\n",
      "38/37 [==============================] - 17s - loss: 0.3214 - acc: 0.8379 - val_loss: 0.3750 - val_acc: 0.8254\n",
      "Epoch 51/80\n",
      "38/37 [==============================] - 17s - loss: 0.3318 - acc: 0.8366 - val_loss: 0.3164 - val_acc: 0.8304\n",
      "Epoch 52/80\n",
      "38/37 [==============================] - 17s - loss: 0.3145 - acc: 0.8467 - val_loss: 0.3889 - val_acc: 0.8304\n",
      "Epoch 53/80\n",
      "38/37 [==============================] - 17s - loss: 0.3495 - acc: 0.8415 - val_loss: 0.5315 - val_acc: 0.7830\n",
      "Epoch 54/80\n",
      "38/37 [==============================] - 17s - loss: 0.3283 - acc: 0.8418 - val_loss: 0.3944 - val_acc: 0.8279\n",
      "Epoch 55/80\n",
      "38/37 [==============================] - 17s - loss: 0.3316 - acc: 0.8478 - val_loss: 0.3128 - val_acc: 0.8728\n",
      "Epoch 56/80\n",
      "38/37 [==============================] - 17s - loss: 0.3225 - acc: 0.8462 - val_loss: 0.3390 - val_acc: 0.8454\n",
      "Epoch 57/80\n",
      "38/37 [==============================] - 17s - loss: 0.3465 - acc: 0.8421 - val_loss: 0.4333 - val_acc: 0.8080\n",
      "Epoch 58/80\n",
      "38/37 [==============================] - 17s - loss: 0.3435 - acc: 0.8396 - val_loss: 0.3218 - val_acc: 0.8329\n",
      "Epoch 59/80\n",
      "38/37 [==============================] - 17s - loss: 0.2939 - acc: 0.8637 - val_loss: 0.3501 - val_acc: 0.8155\n",
      "Epoch 60/80\n",
      "38/37 [==============================] - 17s - loss: 0.3418 - acc: 0.8522 - val_loss: 0.3573 - val_acc: 0.8379\n",
      "Epoch 61/80\n",
      "38/37 [==============================] - 18s - loss: 0.3193 - acc: 0.8558 - val_loss: 0.3366 - val_acc: 0.8304\n",
      "Epoch 62/80\n",
      "38/37 [==============================] - 16s - loss: 0.3196 - acc: 0.8522 - val_loss: 0.3502 - val_acc: 0.8279\n",
      "Epoch 63/80\n",
      "38/37 [==============================] - 17s - loss: 0.3066 - acc: 0.8610 - val_loss: 0.3229 - val_acc: 0.8529\n",
      "Epoch 64/80\n",
      "38/37 [==============================] - 17s - loss: 0.3127 - acc: 0.8451 - val_loss: 0.3262 - val_acc: 0.8429\n",
      "Epoch 65/80\n",
      "38/37 [==============================] - 17s - loss: 0.3398 - acc: 0.8563 - val_loss: 0.4135 - val_acc: 0.8554\n",
      "Epoch 66/80\n",
      "38/37 [==============================] - 17s - loss: 0.4168 - acc: 0.8251 - val_loss: 0.4121 - val_acc: 0.8304\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/37 [==============================] - 17s - loss: 0.3509 - acc: 0.8341 - val_loss: 0.3506 - val_acc: 0.8254\n",
      "Epoch 68/80\n",
      "38/37 [==============================] - 17s - loss: 0.3230 - acc: 0.8470 - val_loss: 0.3926 - val_acc: 0.8130\n",
      "Epoch 69/80\n",
      "38/37 [==============================] - 17s - loss: 0.3170 - acc: 0.8484 - val_loss: 0.4092 - val_acc: 0.8105\n",
      "Epoch 70/80\n",
      "38/37 [==============================] - 17s - loss: 0.3156 - acc: 0.8484 - val_loss: 0.3249 - val_acc: 0.8404\n",
      "Epoch 71/80\n",
      "38/37 [==============================] - 17s - loss: 0.2994 - acc: 0.8544 - val_loss: 0.3378 - val_acc: 0.8454\n",
      "Epoch 72/80\n",
      "38/37 [==============================] - 19s - loss: 0.3019 - acc: 0.8574 - val_loss: 0.4198 - val_acc: 0.8229\n",
      "Epoch 73/80\n",
      "38/37 [==============================] - 18s - loss: 0.3220 - acc: 0.8522 - val_loss: 0.3606 - val_acc: 0.8379\n",
      "Epoch 74/80\n",
      "38/37 [==============================] - 16s - loss: 0.3209 - acc: 0.8530 - val_loss: 0.3260 - val_acc: 0.8504\n",
      "Epoch 75/80\n",
      "38/37 [==============================] - 18s - loss: 0.3117 - acc: 0.8525 - val_loss: 0.3539 - val_acc: 0.8404\n",
      "Epoch 76/80\n",
      "38/37 [==============================] - 18s - loss: 0.3096 - acc: 0.8489 - val_loss: 0.3322 - val_acc: 0.8279\n",
      "Epoch 77/80\n",
      "38/37 [==============================] - 17s - loss: 0.2935 - acc: 0.8530 - val_loss: 0.3175 - val_acc: 0.8579\n",
      "Epoch 78/80\n",
      "38/37 [==============================] - 18s - loss: 0.2878 - acc: 0.8684 - val_loss: 0.3376 - val_acc: 0.8529\n",
      "Epoch 79/80\n",
      "38/37 [==============================] - 18s - loss: 0.2944 - acc: 0.8588 - val_loss: 0.3306 - val_acc: 0.8504\n",
      "Epoch 80/80\n",
      "38/37 [==============================] - 17s - loss: 0.3173 - acc: 0.8443 - val_loss: 0.3523 - val_acc: 0.8379\n"
     ]
    }
   ],
   "source": [
    "model.train(80, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "class DaveInceptionV3(DaveBaseModel):\n",
    "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
    "        DaveBaseModel.__init__(self, X_train, X_valid, y_train, y_valid)\n",
    "        v3_model = InceptionV3(include_top=False, weights=None, input_shape=(150, 150, 3))\n",
    "\n",
    "#         top_model = Sequential()\n",
    "#         top_model.add(Flatten(input_shape=vgg_model.output_shape[1:]))\n",
    "#         top_model.add(Dense(512, activation='relu'))\n",
    "        # top_model.add(Dense(512, activation='relu'))\n",
    "        # top_model.add(Dropout(0.5))\n",
    "#         top_model.add(Dense(1, activation='sigmoid'))\n",
    "        # top_model.load_weights(top_model_weights_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "# # let's add a fully-connected layer\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# # and a logistic layer -- let's say we have 200 classes\n",
    "# predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# # this is the model we will train\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "        x = v3_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(100, activation='relu')(x)\n",
    "        predictions = Dense(1, activation='sigmoid')(x)\n",
    "        \n",
    "        self.model = Model(inputs=v3_model.input, outputs=predictions)\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])\n",
    "        print(self.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_17 (InputLayer)            (None, 150, 150, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)              (None, 74, 74, 32)    864         input_17[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchNo (None, 74, 74, 32)    96          conv2d_471[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_471 (Activation)      (None, 74, 74, 32)    0           batch_normalization_471[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)              (None, 72, 72, 32)    9216        activation_471[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchNo (None, 72, 72, 32)    96          conv2d_472[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_472 (Activation)      (None, 72, 72, 32)    0           batch_normalization_472[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)              (None, 72, 72, 64)    18432       activation_472[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchNo (None, 72, 72, 64)    192         conv2d_473[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_473 (Activation)      (None, 72, 72, 64)    0           batch_normalization_473[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D)  (None, 35, 35, 64)    0           activation_473[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)              (None, 35, 35, 80)    5120        max_pooling2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_474 (BatchNo (None, 35, 35, 80)    240         conv2d_474[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_474 (Activation)      (None, 35, 35, 80)    0           batch_normalization_474[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)              (None, 33, 33, 192)   138240      activation_474[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_475 (BatchNo (None, 33, 33, 192)   576         conv2d_475[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_475 (Activation)      (None, 33, 33, 192)   0           batch_normalization_475[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D)  (None, 16, 16, 192)   0           activation_475[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_479 (Conv2D)              (None, 16, 16, 64)    12288       max_pooling2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_479 (BatchNo (None, 16, 16, 64)    192         conv2d_479[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_479 (Activation)      (None, 16, 16, 64)    0           batch_normalization_479[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_477 (Conv2D)              (None, 16, 16, 48)    9216        max_pooling2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_480 (Conv2D)              (None, 16, 16, 96)    55296       activation_479[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_477 (BatchNo (None, 16, 16, 48)    144         conv2d_477[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_480 (BatchNo (None, 16, 16, 96)    288         conv2d_480[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_477 (Activation)      (None, 16, 16, 48)    0           batch_normalization_477[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_480 (Activation)      (None, 16, 16, 96)    0           batch_normalization_480[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_46 (AveragePoo (None, 16, 16, 192)   0           max_pooling2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)              (None, 16, 16, 64)    12288       max_pooling2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_478 (Conv2D)              (None, 16, 16, 64)    76800       activation_477[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_481 (Conv2D)              (None, 16, 16, 96)    82944       activation_480[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_482 (Conv2D)              (None, 16, 16, 32)    6144        average_pooling2d_46[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_476 (BatchNo (None, 16, 16, 64)    192         conv2d_476[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_478 (BatchNo (None, 16, 16, 64)    192         conv2d_478[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchNo (None, 16, 16, 96)    288         conv2d_481[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_482 (BatchNo (None, 16, 16, 32)    96          conv2d_482[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_476 (Activation)      (None, 16, 16, 64)    0           batch_normalization_476[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_478 (Activation)      (None, 16, 16, 64)    0           batch_normalization_478[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_481 (Activation)      (None, 16, 16, 96)    0           batch_normalization_481[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_482 (Activation)      (None, 16, 16, 32)    0           batch_normalization_482[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, 16, 16, 256)   0           activation_476[0][0]             \n",
      "                                                                   activation_478[0][0]             \n",
      "                                                                   activation_481[0][0]             \n",
      "                                                                   activation_482[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_486 (Conv2D)              (None, 16, 16, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_486 (BatchNo (None, 16, 16, 64)    192         conv2d_486[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_486 (Activation)      (None, 16, 16, 64)    0           batch_normalization_486[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_484 (Conv2D)              (None, 16, 16, 48)    12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_487 (Conv2D)              (None, 16, 16, 96)    55296       activation_486[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_484 (BatchNo (None, 16, 16, 48)    144         conv2d_484[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_487 (BatchNo (None, 16, 16, 96)    288         conv2d_487[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_484 (Activation)      (None, 16, 16, 48)    0           batch_normalization_484[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_487 (Activation)      (None, 16, 16, 96)    0           batch_normalization_487[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_47 (AveragePoo (None, 16, 16, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_483 (Conv2D)              (None, 16, 16, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_485 (Conv2D)              (None, 16, 16, 64)    76800       activation_484[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_488 (Conv2D)              (None, 16, 16, 96)    82944       activation_487[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_489 (Conv2D)              (None, 16, 16, 64)    16384       average_pooling2d_47[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_483 (BatchNo (None, 16, 16, 64)    192         conv2d_483[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_485 (BatchNo (None, 16, 16, 64)    192         conv2d_485[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_488 (BatchNo (None, 16, 16, 96)    288         conv2d_488[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_489 (BatchNo (None, 16, 16, 64)    192         conv2d_489[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_483 (Activation)      (None, 16, 16, 64)    0           batch_normalization_483[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_485 (Activation)      (None, 16, 16, 64)    0           batch_normalization_485[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_488 (Activation)      (None, 16, 16, 96)    0           batch_normalization_488[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_489 (Activation)      (None, 16, 16, 64)    0           batch_normalization_489[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, 16, 16, 288)   0           activation_483[0][0]             \n",
      "                                                                   activation_485[0][0]             \n",
      "                                                                   activation_488[0][0]             \n",
      "                                                                   activation_489[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_493 (Conv2D)              (None, 16, 16, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_493 (BatchNo (None, 16, 16, 64)    192         conv2d_493[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_493 (Activation)      (None, 16, 16, 64)    0           batch_normalization_493[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_491 (Conv2D)              (None, 16, 16, 48)    13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_494 (Conv2D)              (None, 16, 16, 96)    55296       activation_493[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_491 (BatchNo (None, 16, 16, 48)    144         conv2d_491[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_494 (BatchNo (None, 16, 16, 96)    288         conv2d_494[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_491 (Activation)      (None, 16, 16, 48)    0           batch_normalization_491[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_494 (Activation)      (None, 16, 16, 96)    0           batch_normalization_494[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_48 (AveragePoo (None, 16, 16, 288)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_490 (Conv2D)              (None, 16, 16, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_492 (Conv2D)              (None, 16, 16, 64)    76800       activation_491[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_495 (Conv2D)              (None, 16, 16, 96)    82944       activation_494[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_496 (Conv2D)              (None, 16, 16, 64)    18432       average_pooling2d_48[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_490 (BatchNo (None, 16, 16, 64)    192         conv2d_490[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_492 (BatchNo (None, 16, 16, 64)    192         conv2d_492[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_495 (BatchNo (None, 16, 16, 96)    288         conv2d_495[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_496 (BatchNo (None, 16, 16, 64)    192         conv2d_496[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_490 (Activation)      (None, 16, 16, 64)    0           batch_normalization_490[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_492 (Activation)      (None, 16, 16, 64)    0           batch_normalization_492[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_495 (Activation)      (None, 16, 16, 96)    0           batch_normalization_495[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_496 (Activation)      (None, 16, 16, 64)    0           batch_normalization_496[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, 16, 16, 288)   0           activation_490[0][0]             \n",
      "                                                                   activation_492[0][0]             \n",
      "                                                                   activation_495[0][0]             \n",
      "                                                                   activation_496[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_498 (Conv2D)              (None, 16, 16, 64)    18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_498 (BatchNo (None, 16, 16, 64)    192         conv2d_498[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_498 (Activation)      (None, 16, 16, 64)    0           batch_normalization_498[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_499 (Conv2D)              (None, 16, 16, 96)    55296       activation_498[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_499 (BatchNo (None, 16, 16, 96)    288         conv2d_499[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_499 (Activation)      (None, 16, 16, 96)    0           batch_normalization_499[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_497 (Conv2D)              (None, 7, 7, 384)     995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_500 (Conv2D)              (None, 7, 7, 96)      82944       activation_499[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_497 (BatchNo (None, 7, 7, 384)     1152        conv2d_497[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_500 (BatchNo (None, 7, 7, 96)      288         conv2d_500[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_497 (Activation)      (None, 7, 7, 384)     0           batch_normalization_497[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_500 (Activation)      (None, 7, 7, 96)      0           batch_normalization_500[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D)  (None, 7, 7, 288)     0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, 7, 7, 768)     0           activation_497[0][0]             \n",
      "                                                                   activation_500[0][0]             \n",
      "                                                                   max_pooling2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_505 (Conv2D)              (None, 7, 7, 128)     98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_505 (BatchNo (None, 7, 7, 128)     384         conv2d_505[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_505 (Activation)      (None, 7, 7, 128)     0           batch_normalization_505[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_506 (Conv2D)              (None, 7, 7, 128)     114688      activation_505[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_506 (BatchNo (None, 7, 7, 128)     384         conv2d_506[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_506 (Activation)      (None, 7, 7, 128)     0           batch_normalization_506[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_502 (Conv2D)              (None, 7, 7, 128)     98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_507 (Conv2D)              (None, 7, 7, 128)     114688      activation_506[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_502 (BatchNo (None, 7, 7, 128)     384         conv2d_502[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_507 (BatchNo (None, 7, 7, 128)     384         conv2d_507[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_502 (Activation)      (None, 7, 7, 128)     0           batch_normalization_502[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_507 (Activation)      (None, 7, 7, 128)     0           batch_normalization_507[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_503 (Conv2D)              (None, 7, 7, 128)     114688      activation_502[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_508 (Conv2D)              (None, 7, 7, 128)     114688      activation_507[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_503 (BatchNo (None, 7, 7, 128)     384         conv2d_503[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_508 (BatchNo (None, 7, 7, 128)     384         conv2d_508[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_503 (Activation)      (None, 7, 7, 128)     0           batch_normalization_503[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_508 (Activation)      (None, 7, 7, 128)     0           batch_normalization_508[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_49 (AveragePoo (None, 7, 7, 768)     0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_501 (Conv2D)              (None, 7, 7, 192)     147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_504 (Conv2D)              (None, 7, 7, 192)     172032      activation_503[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_509 (Conv2D)              (None, 7, 7, 192)     172032      activation_508[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_510 (Conv2D)              (None, 7, 7, 192)     147456      average_pooling2d_49[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_501 (BatchNo (None, 7, 7, 192)     576         conv2d_501[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_504 (BatchNo (None, 7, 7, 192)     576         conv2d_504[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_509 (BatchNo (None, 7, 7, 192)     576         conv2d_509[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_510 (BatchNo (None, 7, 7, 192)     576         conv2d_510[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_501 (Activation)      (None, 7, 7, 192)     0           batch_normalization_501[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_504 (Activation)      (None, 7, 7, 192)     0           batch_normalization_504[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_509 (Activation)      (None, 7, 7, 192)     0           batch_normalization_509[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_510 (Activation)      (None, 7, 7, 192)     0           batch_normalization_510[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, 7, 7, 768)     0           activation_501[0][0]             \n",
      "                                                                   activation_504[0][0]             \n",
      "                                                                   activation_509[0][0]             \n",
      "                                                                   activation_510[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_515 (Conv2D)              (None, 7, 7, 160)     122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_515 (BatchNo (None, 7, 7, 160)     480         conv2d_515[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_515 (Activation)      (None, 7, 7, 160)     0           batch_normalization_515[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_516 (Conv2D)              (None, 7, 7, 160)     179200      activation_515[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_516 (BatchNo (None, 7, 7, 160)     480         conv2d_516[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_516 (Activation)      (None, 7, 7, 160)     0           batch_normalization_516[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_512 (Conv2D)              (None, 7, 7, 160)     122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_517 (Conv2D)              (None, 7, 7, 160)     179200      activation_516[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_512 (BatchNo (None, 7, 7, 160)     480         conv2d_512[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_517 (BatchNo (None, 7, 7, 160)     480         conv2d_517[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_512 (Activation)      (None, 7, 7, 160)     0           batch_normalization_512[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_517 (Activation)      (None, 7, 7, 160)     0           batch_normalization_517[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_513 (Conv2D)              (None, 7, 7, 160)     179200      activation_512[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_518 (Conv2D)              (None, 7, 7, 160)     179200      activation_517[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_513 (BatchNo (None, 7, 7, 160)     480         conv2d_513[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_518 (BatchNo (None, 7, 7, 160)     480         conv2d_518[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_513 (Activation)      (None, 7, 7, 160)     0           batch_normalization_513[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_518 (Activation)      (None, 7, 7, 160)     0           batch_normalization_518[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_50 (AveragePoo (None, 7, 7, 768)     0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_511 (Conv2D)              (None, 7, 7, 192)     147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_514 (Conv2D)              (None, 7, 7, 192)     215040      activation_513[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_519 (Conv2D)              (None, 7, 7, 192)     215040      activation_518[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_520 (Conv2D)              (None, 7, 7, 192)     147456      average_pooling2d_50[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_511 (BatchNo (None, 7, 7, 192)     576         conv2d_511[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_514 (BatchNo (None, 7, 7, 192)     576         conv2d_514[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_519 (BatchNo (None, 7, 7, 192)     576         conv2d_519[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_520 (BatchNo (None, 7, 7, 192)     576         conv2d_520[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_511 (Activation)      (None, 7, 7, 192)     0           batch_normalization_511[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_514 (Activation)      (None, 7, 7, 192)     0           batch_normalization_514[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_519 (Activation)      (None, 7, 7, 192)     0           batch_normalization_519[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_520 (Activation)      (None, 7, 7, 192)     0           batch_normalization_520[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, 7, 7, 768)     0           activation_511[0][0]             \n",
      "                                                                   activation_514[0][0]             \n",
      "                                                                   activation_519[0][0]             \n",
      "                                                                   activation_520[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_525 (Conv2D)              (None, 7, 7, 160)     122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_525 (BatchNo (None, 7, 7, 160)     480         conv2d_525[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_525 (Activation)      (None, 7, 7, 160)     0           batch_normalization_525[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_526 (Conv2D)              (None, 7, 7, 160)     179200      activation_525[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_526 (BatchNo (None, 7, 7, 160)     480         conv2d_526[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_526 (Activation)      (None, 7, 7, 160)     0           batch_normalization_526[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_522 (Conv2D)              (None, 7, 7, 160)     122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_527 (Conv2D)              (None, 7, 7, 160)     179200      activation_526[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_522 (BatchNo (None, 7, 7, 160)     480         conv2d_522[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_527 (BatchNo (None, 7, 7, 160)     480         conv2d_527[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_522 (Activation)      (None, 7, 7, 160)     0           batch_normalization_522[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_527 (Activation)      (None, 7, 7, 160)     0           batch_normalization_527[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_523 (Conv2D)              (None, 7, 7, 160)     179200      activation_522[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_528 (Conv2D)              (None, 7, 7, 160)     179200      activation_527[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_523 (BatchNo (None, 7, 7, 160)     480         conv2d_523[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_528 (BatchNo (None, 7, 7, 160)     480         conv2d_528[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_523 (Activation)      (None, 7, 7, 160)     0           batch_normalization_523[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_528 (Activation)      (None, 7, 7, 160)     0           batch_normalization_528[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_51 (AveragePoo (None, 7, 7, 768)     0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_521 (Conv2D)              (None, 7, 7, 192)     147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_524 (Conv2D)              (None, 7, 7, 192)     215040      activation_523[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_529 (Conv2D)              (None, 7, 7, 192)     215040      activation_528[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_530 (Conv2D)              (None, 7, 7, 192)     147456      average_pooling2d_51[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_521 (BatchNo (None, 7, 7, 192)     576         conv2d_521[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_524 (BatchNo (None, 7, 7, 192)     576         conv2d_524[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_529 (BatchNo (None, 7, 7, 192)     576         conv2d_529[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_530 (BatchNo (None, 7, 7, 192)     576         conv2d_530[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_521 (Activation)      (None, 7, 7, 192)     0           batch_normalization_521[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_524 (Activation)      (None, 7, 7, 192)     0           batch_normalization_524[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_529 (Activation)      (None, 7, 7, 192)     0           batch_normalization_529[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_530 (Activation)      (None, 7, 7, 192)     0           batch_normalization_530[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, 7, 7, 768)     0           activation_521[0][0]             \n",
      "                                                                   activation_524[0][0]             \n",
      "                                                                   activation_529[0][0]             \n",
      "                                                                   activation_530[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_535 (Conv2D)              (None, 7, 7, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_535 (BatchNo (None, 7, 7, 192)     576         conv2d_535[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_535 (Activation)      (None, 7, 7, 192)     0           batch_normalization_535[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_536 (Conv2D)              (None, 7, 7, 192)     258048      activation_535[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_536 (BatchNo (None, 7, 7, 192)     576         conv2d_536[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_536 (Activation)      (None, 7, 7, 192)     0           batch_normalization_536[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_532 (Conv2D)              (None, 7, 7, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_537 (Conv2D)              (None, 7, 7, 192)     258048      activation_536[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_532 (BatchNo (None, 7, 7, 192)     576         conv2d_532[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_537 (BatchNo (None, 7, 7, 192)     576         conv2d_537[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_532 (Activation)      (None, 7, 7, 192)     0           batch_normalization_532[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_537 (Activation)      (None, 7, 7, 192)     0           batch_normalization_537[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_533 (Conv2D)              (None, 7, 7, 192)     258048      activation_532[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_538 (Conv2D)              (None, 7, 7, 192)     258048      activation_537[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_533 (BatchNo (None, 7, 7, 192)     576         conv2d_533[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_538 (BatchNo (None, 7, 7, 192)     576         conv2d_538[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_533 (Activation)      (None, 7, 7, 192)     0           batch_normalization_533[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_538 (Activation)      (None, 7, 7, 192)     0           batch_normalization_538[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_52 (AveragePoo (None, 7, 7, 768)     0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_531 (Conv2D)              (None, 7, 7, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_534 (Conv2D)              (None, 7, 7, 192)     258048      activation_533[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)              (None, 7, 7, 192)     258048      activation_538[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)              (None, 7, 7, 192)     147456      average_pooling2d_52[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_531 (BatchNo (None, 7, 7, 192)     576         conv2d_531[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_534 (BatchNo (None, 7, 7, 192)     576         conv2d_534[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_539 (BatchNo (None, 7, 7, 192)     576         conv2d_539[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_540 (BatchNo (None, 7, 7, 192)     576         conv2d_540[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_531 (Activation)      (None, 7, 7, 192)     0           batch_normalization_531[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_534 (Activation)      (None, 7, 7, 192)     0           batch_normalization_534[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_539 (Activation)      (None, 7, 7, 192)     0           batch_normalization_539[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_540 (Activation)      (None, 7, 7, 192)     0           batch_normalization_540[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, 7, 7, 768)     0           activation_531[0][0]             \n",
      "                                                                   activation_534[0][0]             \n",
      "                                                                   activation_539[0][0]             \n",
      "                                                                   activation_540[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)              (None, 7, 7, 192)     147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_543 (BatchNo (None, 7, 7, 192)     576         conv2d_543[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_543 (Activation)      (None, 7, 7, 192)     0           batch_normalization_543[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)              (None, 7, 7, 192)     258048      activation_543[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_544 (BatchNo (None, 7, 7, 192)     576         conv2d_544[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_544 (Activation)      (None, 7, 7, 192)     0           batch_normalization_544[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)              (None, 7, 7, 192)     147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)              (None, 7, 7, 192)     258048      activation_544[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_541 (BatchNo (None, 7, 7, 192)     576         conv2d_541[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_545 (BatchNo (None, 7, 7, 192)     576         conv2d_545[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_541 (Activation)      (None, 7, 7, 192)     0           batch_normalization_541[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_545 (Activation)      (None, 7, 7, 192)     0           batch_normalization_545[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)              (None, 3, 3, 320)     552960      activation_541[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)              (None, 3, 3, 192)     331776      activation_545[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_542 (BatchNo (None, 3, 3, 320)     960         conv2d_542[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_546 (BatchNo (None, 3, 3, 192)     576         conv2d_546[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_542 (Activation)      (None, 3, 3, 320)     0           batch_normalization_542[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_546 (Activation)      (None, 3, 3, 192)     0           batch_normalization_546[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D)  (None, 3, 3, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, 3, 3, 1280)    0           activation_542[0][0]             \n",
      "                                                                   activation_546[0][0]             \n",
      "                                                                   max_pooling2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)              (None, 3, 3, 448)     573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_551 (BatchNo (None, 3, 3, 448)     1344        conv2d_551[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_551 (Activation)      (None, 3, 3, 448)     0           batch_normalization_551[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)              (None, 3, 3, 384)     491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)              (None, 3, 3, 384)     1548288     activation_551[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_548 (BatchNo (None, 3, 3, 384)     1152        conv2d_548[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_552 (BatchNo (None, 3, 3, 384)     1152        conv2d_552[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_548 (Activation)      (None, 3, 3, 384)     0           batch_normalization_548[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_552 (Activation)      (None, 3, 3, 384)     0           batch_normalization_552[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)              (None, 3, 3, 384)     442368      activation_548[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)              (None, 3, 3, 384)     442368      activation_548[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)              (None, 3, 3, 384)     442368      activation_552[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)              (None, 3, 3, 384)     442368      activation_552[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_53 (AveragePoo (None, 3, 3, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)              (None, 3, 3, 320)     409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_549 (BatchNo (None, 3, 3, 384)     1152        conv2d_549[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_550 (BatchNo (None, 3, 3, 384)     1152        conv2d_550[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_553 (BatchNo (None, 3, 3, 384)     1152        conv2d_553[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_554 (BatchNo (None, 3, 3, 384)     1152        conv2d_554[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)              (None, 3, 3, 192)     245760      average_pooling2d_53[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_547 (BatchNo (None, 3, 3, 320)     960         conv2d_547[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_549 (Activation)      (None, 3, 3, 384)     0           batch_normalization_549[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_550 (Activation)      (None, 3, 3, 384)     0           batch_normalization_550[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_553 (Activation)      (None, 3, 3, 384)     0           batch_normalization_553[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_554 (Activation)      (None, 3, 3, 384)     0           batch_normalization_554[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_555 (BatchNo (None, 3, 3, 192)     576         conv2d_555[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_547 (Activation)      (None, 3, 3, 320)     0           batch_normalization_547[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, 3, 3, 768)     0           activation_549[0][0]             \n",
      "                                                                   activation_550[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)     (None, 3, 3, 768)     0           activation_553[0][0]             \n",
      "                                                                   activation_554[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_555 (Activation)      (None, 3, 3, 192)     0           batch_normalization_555[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, 3, 3, 2048)    0           activation_547[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_11[0][0]             \n",
      "                                                                   activation_555[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_560 (Conv2D)              (None, 3, 3, 448)     917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_560 (BatchNo (None, 3, 3, 448)     1344        conv2d_560[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_560 (Activation)      (None, 3, 3, 448)     0           batch_normalization_560[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)              (None, 3, 3, 384)     786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)              (None, 3, 3, 384)     1548288     activation_560[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_557 (BatchNo (None, 3, 3, 384)     1152        conv2d_557[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_561 (BatchNo (None, 3, 3, 384)     1152        conv2d_561[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_557 (Activation)      (None, 3, 3, 384)     0           batch_normalization_557[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_561 (Activation)      (None, 3, 3, 384)     0           batch_normalization_561[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)              (None, 3, 3, 384)     442368      activation_557[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_559 (Conv2D)              (None, 3, 3, 384)     442368      activation_557[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)              (None, 3, 3, 384)     442368      activation_561[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)              (None, 3, 3, 384)     442368      activation_561[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_54 (AveragePoo (None, 3, 3, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)              (None, 3, 3, 320)     655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_558 (BatchNo (None, 3, 3, 384)     1152        conv2d_558[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_559 (BatchNo (None, 3, 3, 384)     1152        conv2d_559[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_562 (BatchNo (None, 3, 3, 384)     1152        conv2d_562[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_563 (BatchNo (None, 3, 3, 384)     1152        conv2d_563[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)              (None, 3, 3, 192)     393216      average_pooling2d_54[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_556 (BatchNo (None, 3, 3, 320)     960         conv2d_556[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_558 (Activation)      (None, 3, 3, 384)     0           batch_normalization_558[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_559 (Activation)      (None, 3, 3, 384)     0           batch_normalization_559[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_562 (Activation)      (None, 3, 3, 384)     0           batch_normalization_562[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_563 (Activation)      (None, 3, 3, 384)     0           batch_normalization_563[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_564 (BatchNo (None, 3, 3, 192)     576         conv2d_564[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_556 (Activation)      (None, 3, 3, 320)     0           batch_normalization_556[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 3, 3, 768)     0           activation_558[0][0]             \n",
      "                                                                   activation_559[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)     (None, 3, 3, 768)     0           activation_562[0][0]             \n",
      "                                                                   activation_563[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_564 (Activation)      (None, 3, 3, 192)     0           batch_normalization_564[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 3, 3, 2048)    0           activation_556[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_12[0][0]             \n",
      "                                                                   activation_564[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glob (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 100)           204900      global_average_pooling2d_5[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_31 (Dense)                 (None, 1)             101         dense_30[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 22,007,785\n",
      "Trainable params: 21,973,353\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DaveInceptionV3(X_train_cv, X_valid, y_train_cv, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/18 [==============================] - 10s - loss: 0.2734 - acc: 0.8834 - val_loss: 0.3896 - val_acc: 0.8105\n",
      "Epoch 2/30\n",
      "19/18 [==============================] - 9s - loss: 0.2434 - acc: 0.8984 - val_loss: 0.5005 - val_acc: 0.7905\n",
      "Epoch 3/30\n",
      "19/18 [==============================] - 8s - loss: 0.2378 - acc: 0.8956 - val_loss: 0.3723 - val_acc: 0.8204\n",
      "Epoch 4/30\n",
      "19/18 [==============================] - 8s - loss: 0.2461 - acc: 0.8906 - val_loss: 0.4674 - val_acc: 0.8204\n",
      "Epoch 5/30\n",
      "19/18 [==============================] - 8s - loss: 0.2750 - acc: 0.8655 - val_loss: 0.4977 - val_acc: 0.8105\n",
      "Epoch 6/30\n",
      "19/18 [==============================] - 8s - loss: 0.2382 - acc: 0.8959 - val_loss: 0.5217 - val_acc: 0.8105\n",
      "Epoch 7/30\n",
      "19/18 [==============================] - 8s - loss: 0.2476 - acc: 0.8906 - val_loss: 0.4123 - val_acc: 0.8304\n",
      "Epoch 8/30\n",
      "19/18 [==============================] - 8s - loss: 0.2442 - acc: 0.8918 - val_loss: 0.3969 - val_acc: 0.8404\n",
      "Epoch 9/30\n",
      "19/18 [==============================] - 8s - loss: 0.2496 - acc: 0.8877 - val_loss: 0.3699 - val_acc: 0.8429\n",
      "Epoch 10/30\n",
      "19/18 [==============================] - 8s - loss: 0.2423 - acc: 0.9054 - val_loss: 0.3888 - val_acc: 0.8429\n",
      "Epoch 11/30\n",
      "19/18 [==============================] - 8s - loss: 0.2486 - acc: 0.9089 - val_loss: 0.3728 - val_acc: 0.8354\n",
      "Epoch 12/30\n",
      "19/18 [==============================] - 8s - loss: 0.2496 - acc: 0.8964 - val_loss: 0.3669 - val_acc: 0.8429\n",
      "Epoch 13/30\n",
      "19/18 [==============================] - 8s - loss: 0.2252 - acc: 0.9021 - val_loss: 0.3524 - val_acc: 0.8504\n",
      "Epoch 14/30\n",
      "19/18 [==============================] - 8s - loss: 0.2323 - acc: 0.8996 - val_loss: 0.3692 - val_acc: 0.8579\n",
      "Epoch 15/30\n",
      "19/18 [==============================] - 8s - loss: 0.2309 - acc: 0.8956 - val_loss: 0.4446 - val_acc: 0.8329\n",
      "Epoch 16/30\n",
      "19/18 [==============================] - 8s - loss: 0.2512 - acc: 0.8877 - val_loss: 0.4139 - val_acc: 0.7980\n",
      "Epoch 17/30\n",
      "19/18 [==============================] - 8s - loss: 0.2429 - acc: 0.8918 - val_loss: 0.3721 - val_acc: 0.8354\n",
      "Epoch 18/30\n",
      "19/18 [==============================] - 8s - loss: 0.2128 - acc: 0.9112 - val_loss: 0.4515 - val_acc: 0.8130\n",
      "Epoch 19/30\n",
      "19/18 [==============================] - 8s - loss: 0.2195 - acc: 0.9089 - val_loss: 0.4061 - val_acc: 0.8005\n",
      "Epoch 20/30\n",
      "19/18 [==============================] - 8s - loss: 0.2111 - acc: 0.9087 - val_loss: 0.4344 - val_acc: 0.8229\n",
      "Epoch 21/30\n",
      "19/18 [==============================] - 8s - loss: 0.2375 - acc: 0.8982 - val_loss: 0.4612 - val_acc: 0.8105\n",
      "Epoch 22/30\n",
      "19/18 [==============================] - 8s - loss: 0.2221 - acc: 0.9042 - val_loss: 0.4782 - val_acc: 0.8204\n",
      "Epoch 23/30\n",
      "19/18 [==============================] - 8s - loss: 0.2465 - acc: 0.8849 - val_loss: 0.5515 - val_acc: 0.8105\n",
      "Epoch 24/30\n",
      "19/18 [==============================] - 8s - loss: 0.2212 - acc: 0.9021 - val_loss: 0.4634 - val_acc: 0.8404\n",
      "Epoch 25/30\n",
      "19/18 [==============================] - 8s - loss: 0.2238 - acc: 0.9001 - val_loss: 0.6044 - val_acc: 0.7855\n",
      "Epoch 26/30\n",
      "19/18 [==============================] - 8s - loss: 0.2121 - acc: 0.9042 - val_loss: 0.4281 - val_acc: 0.8454\n",
      "Epoch 27/30\n",
      "19/18 [==============================] - 8s - loss: 0.2291 - acc: 0.9060 - val_loss: 0.5509 - val_acc: 0.8005\n",
      "Epoch 28/30\n",
      "19/18 [==============================] - 8s - loss: 0.2242 - acc: 0.8982 - val_loss: 0.3849 - val_acc: 0.8429\n",
      "Epoch 29/30\n",
      "19/18 [==============================] - 8s - loss: 0.2070 - acc: 0.9124 - val_loss: 0.4362 - val_acc: 0.8080\n",
      "Epoch 30/30\n",
      "19/18 [==============================] - 8s - loss: 0.2360 - acc: 0.8960 - val_loss: 0.4291 - val_acc: 0.8479\n"
     ]
    }
   ],
   "source": [
    "model.train(30, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
