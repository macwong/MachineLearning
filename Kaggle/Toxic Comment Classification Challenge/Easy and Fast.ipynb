{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import sparse\n",
    "# set stopwords\n",
    "\n",
    "# from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('_RawData/train_with_convai.csv', encoding='latin')\n",
    "test = pd.read_csv('_RawData/test_with_convai.csv', encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats_to_concat = ['comment_text', 'toxic_level', 'attack', 'aggression']\n",
    "# combining test and train\n",
    "alldata = pd.concat([train[feats_to_concat], test[feats_to_concat]], axis=0)\n",
    "alldata.comment_text.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=50000, analyzer='word', ngram_range=(1, 1))\n",
    "vect_chars = TfidfVectorizer(max_features=20000, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = vect_words.fit_transform(alldata.comment_text)\n",
    "all_chars = vect_chars.fit_transform(alldata.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_new = train\n",
    "test_new = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_words = all_words[:len(train_new)]\n",
    "test_words = all_words[len(train_new):]\n",
    "\n",
    "train_chars = all_chars[:len(train_new)]\n",
    "test_chars = all_chars[len(train_new):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = ['toxic_level', 'attack']\n",
    "# make sparse matrix with needed data for train and test\n",
    "train_feats = sparse.hstack([train_words, train_chars, alldata[feats][:len(train_new)]])\n",
    "test_feats = sparse.hstack([test_words, test_chars, alldata[feats][len(train_new):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Fit toxic\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit severe_toxic\n",
      "Fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dave\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test\n",
      "===Fit obscene\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit threat\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit insult\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit identity_hate\n",
      "Fitting model\n",
      "Predicting on test\n"
     ]
    }
   ],
   "source": [
    "col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "only_col = ['toxic']\n",
    "\n",
    "preds = np.zeros((test_new.shape[0], len(col)))\n",
    "\n",
    "for i, j in enumerate(col):\n",
    "    print('===Fit '+j)\n",
    "    \n",
    "    model = LogisticRegression(C=4.0, solver='sag')\n",
    "    print('Fitting model')\n",
    "    model.fit(train_feats, train_new[j])\n",
    "      \n",
    "    print('Predicting on test')\n",
    "    preds[:,i] = model.predict_proba(test_feats)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = pd.read_csv('_RawData/sample_submission.csv')\n",
    "\n",
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds, columns = col)], axis=1)\n",
    "submission.to_csv('easy and fast - submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
